[{"title":"Charming Chatroom","content":"Learning Objectives Networking Components Building working server code Building working client code Network error handling Read/Write error handlingGoal goal of this lab is help you understand networking components. You will accomplish this by writing a real chatroom program. You are going write a client which can send/receive data to/from server, a server which can receive data from multiple clients broadcast these messages each of clients, read/write functions than handle failures of read write. files you must modify are client. c server. c utils. c files client. c server. c provide an outline of what you are expected do via references questions in questions. txt. For example, if you see /QUESTION 1/ then question 1 in questions. txt should help you understand what do when filling that part of code. So sure answer questions in questions. txt begin with as these will help you get started!Client file chat_window. c is control center for setting up ncurses windows (that’s a thing). You do not need worry about this, but feel free look at it if you are interested.  client executable will accept up four arguments: host - address client should connect to.  port - port number connect host on.  username - name you want displayed in chatroom.  filename - Optional argument - will disable ncurses write bytes received from server output file.  client performs two main functions: (1) writes user input server (2) writes bytes from server user. We have handled overall logic of reading from user, writing server, reading from server, writing user. Your job is set up client connect it server. Implement provided function use a TCP IPv4 connection connect host at given port. A signal interrupt will sent client as a flag tell your client exit. precise, when your client program receives a SIGINT it should free memory, close sockets, gracefully exit program. Notice writing reading server use write_all_to_socket() read_all_from_socket(). You will have implement these functions handle failures of read/write calls, but more on that later.  figure below gives you an idea about how client side architecture looks like: So sum up, your job in client program is: Implement running client closing client functions Set up network connection (TCP + IPv4).  Free memory you allocate. Note: You do not need modify any of code in client. c except for function connect_to_server() close_server_connection() in order get client successfully working. However, you may modify any of other code if you want, but careful. Server port - port number accept connections on. Similar client. c, a lot of functionality in server. c has been implemented for you. Your job is set up server use TCP IPv4 with reusable addresses ports, gracefully close server when SIGINT is received. Reusable Addresses PortsMake sure you use SO_REUSEADDR SO_REUSEPORT ensure bind() doesn’t fail in event that your server or client crashes. This will enable faster debugging for you (otherwise, you would have wait for kernel reopen source address port). We will making sure that your socket is set up with these options (look into setsockopt) so please make sure you use both options! If you don’t, you will not pass this assignment. See for more information on differences between two why they are necessary.  figure below illustrates how a message propagates through system:  sum up, you have to: Implement run_server() close_server() (the signal handler for SIGINT) Set up connections (TCP &amp; IPv4).  (There is a giant while-loop - you need do something in it)Here is overall client-server architecture:Read/Write FailuresRead Write calls (general read/write - this extends recv, send, etc. ) can fail send/receive all bytes. Here is pseudocode for read all socket. In utils. c/h we have declared functions read_all_from_socket write_all_to_socket. You need implement these functions read/write from/to a socket handle failures of read/write (defined above). You should look at utils. h for detailed info on what your functions should do. Messages in our server/client will exchanged in following format:where first 4 bytes of message indicate size of message in bytes. We use network-to-host byte-order (ntohl) host-to-network byte-order (htonl) for this. We’ve given you get_message_size(), you must implement write_message_size(). As we will testing your server client separately, because our server client expect this setup, sure this works; it is like our “protocol”. Please see how get_message_size() it is done in utils. cIn user_hooks. c we have given an example of how emulate a read failure (feel free modify this file by adding a write failure call). You can include user_hooks. h in your utils/server/client code test your error handling. BE SURE NOT TO LEAVE ANYTHING RELATING TO user_hooks IN YOUR FILES. THEY ARE THERE FOR TESTING, THE AG WILL NOT COMPILE THEMError CheckingNetworks Break!Many things can go wrong when working with networks. sure do plenty of error checking! If anything fails, print error message exit(1). For each networking function call (except one of them) that you will using, use perror(NULL). For one that you cannot use perror, use man pages learn how print error. You must figure out which function does not set errno upon failure thus you cannot use perror. TestingYou should implement tests for testing functionality of client server side code separately. That way you don’t worry about client-server interactions. You can then consider cases where a message is written one client, is sent server is then broadcasted all other clients running. test such a code path, you start a test that writes one of clients c then verifies whether all clients have received message that was provided as input c. Note, you are writing a server that could potentially run for a long time. This is exactly a scenario where memory leaks can very costly cause your server crash. So ensure there are no memory leaks in your implementation. Otherwise, we will leave it open ended let you come up with other interesting test cases. We provided you with a Makefile. You can run client server as follows:Test your server client with a friend! On your VMs you can connect each others’ machines. Just ask them what their machine number is!Notice XYZ, that is machine number you will use connect server (the person hosting’s machine)In above “terminals”, there are things like “Waiting for connection…” “Ending Server”: do not worry about having do this. It is simply flavor text printed window. Feel free do that; we will only test bytes that are sent received. Because it’s particularly important for this lab, we want reiterate that you should not have any memory leaks :)Grading Client must function as specified Server must function as specified Implementation of read_all_from_socket write_all_from_socket handle failures Errors must handled as specified No memory leaksOnce again, you do not need modify any of provided code in order complete lab, but you can if you want (however, very careful; we are not responsible for your changes )Interesting ThingsWe are using pthread_cancel, pthread_detach, pthread_cleanup, ncurses. It is not necessary know about these (actually cancel might have been on one of your quizzes), so don’t let them distract/confuse you. However, if you are interested, definitely read up on them. In Makefile, we have -I. /includes. This lets you do #include \"something. h\" instead of #include \". /includes/something. h\"Also #pragma once in . h files","url":"/assignments/charming_chatroom"},{"title":"Critical Concurrency","content":"OverviewThere are four main components this lab, three of which are graded. These are Rendezvous (not graded), Semamore, Barrier, Thread-safe Queue. Each of these represent very common synchronization problem (or slight twists on them) that will do you well become familiar with. Good luck!Rendezvous (UNGRADED)This is a problem for you think about. We have provided a worked solution this problem but PLEASE try solve this problem before looking at solution!Problem description:Given two threads, a b, fact that both have run two tasks (a1, a2, b1, b2), how do you get both a1 b1 run before either a2 b2? In rendezvous. c, you need modify two functions (modifyB_printA &amp; modifyA_printB) using semaphores so that both quotes A B are modified before being printed. semamore. cNOTE: A semamore is NOT a real thing! It is simply a made up clever name! This means you can’t use them in future assignments (unless you re-implement it). A normal semaphore blocks when value within semaphore reaches 0. A semamore blocks when it reaches 0, but also blocks when it reaches some maximum value. You can think of a semamore as a top-bounded semaphore. In semamore. c, you are given four functions work on, semm_init, semm_wait, semm_post, semm_destroy. semm_post is important difference. When semm_post reaches max_val (as defined in semamore struct in semamore. h), it blocks. There are four functions in total you will writing: void semm_init(Semamore *s, int value, int max_val); void semm_wait(Semamore *s); void semm_post(Semamore *s); void semm_destroy(Semamore *s);barrier. cIn rendezvous you saw an example of an one-time-use barrier. Now, you get build code support a reusable barrier. At cost of being redundant, a reusable barrier is one that can get used more than once. Say you have threads executing code in a for loop you want them stay in sync. That is, each thread should on i’th iteration of loop when every other thread is on i’th iteration. With a reusable barrier, you can stop threads from going i+1’th iteration until all of them have finished i’th. Note that most barrier implementations (including pthread library barrier) are “reusable”, but never say so. This is because it simply does not make sense have a “not-reusable” barrier. Thus, we are only iterating you that barrier your build should reusable so that you understand what it means. You can find more info in Your goal is implement functions int barrier_destroy(barrier_t *barrier); int barrier_init(barrier_t *barrier, unsigned num_threads); int barrier_wait(barrier_t *barrier);so that a barrier_t using these functions is a working reusable barrier. queue. cNOTE: Do not use semaphores or your semamore here. Your task is build a thread safe queue, that also may or may not bounded, by implementing functions in queue. c. maxSize of queue can set either a positive number or a non-positive number. If positive, your queue will block if user tries push when queue is full. If not positive, your queue should never block upon a push (the queue does not have a max size). If your queue is empty then you should block on a pull. You should make use of node struct store retrieve information. In end, your queue implementation should able handle concurrent calls from multiple threads. queue_create queue_destroy will not called by multiple threads. Your goal is implement functions queue* queue_create (ssize_t max_size); void queue_destroy (queue* this); void queue_push (queue* this, void* element); void* queue_pull (queue* this);TestingTesting is ungraded, but highly recommendedSince implementation of your semamore is quite close an actual semaphore, please test this on your own in a variety of ways. careful of race conditions! They can hard find! We’ve given you a semamore_tests. c file write tests in. For barrier_test. c we have provided you with a simple test case. Feel free expand on it, as it is not exhaustive/perfect. Learning how use barrier is just as important as writing it, since you will using barriers on Password Cracker MP :)For queue_test. c we would like you write tests yourself. Learning write tests for multi-threaded code is very important. You will also using this queue in Password Cracker MP :) (we will give you a working version; you will not penalized on MP for not successfully completing lab)Thread SanitizerWe have another target executed by typing make tsan. This compiles your code with Thread Sanitizer. ThreadSantizer is a race condition detection tool. See for more information. We will using ThreadSanitizer grade your code! If autograder detects a data race, you won’t automatically get 0 points, but a few points will deducted. Helpful Hints Notes Make sure you thoroughly test your code! Race conditions can hard spot! Attempting visualize your code or diagram it in certain cases can sometimes a huge aid is highly recommended!** In any of semamore. c, barrier. c, or queue. c you may not use semaphores or pthread_barriers **ANYTHING not specified in these docs is considered undefined behavior we will not test itFor example, calling queue_push(NULL, NULL) can do whatever you want it to. We will not test it. ","url":"/assignments/critical_concurrency"},{"title":"Decentralized Network","content":"OverviewThis section of doc will introduce you some fundamental concepts in networking distributed systems, such as network protocol decentralization. If you already feel very comfortable with these ideas, feel free skip it jump directly “Requirements” section. What is a network?A network is a set of processes (usually running on multiple machines, but not always) that communicate with each other over some communication channel (LAN, WiFi, Bluetooth, etc). Networks are incredibly useful because they can leverage power of resource-sharing. Here are some examples of networks: fax machines (what’s a fax machine?), a city’s traffic control system, an email system, a virtual private network, a website its visitors, iPhones of Uber drivers riders, and–very generally–the internet. What is a network protocol? definition of a network protocol, according Wikipedia, is this: “A system of rules that allow two or more entities of a communications system transmit information via any kind of variation of a physical quantity. ”In layman’s term, a network protocol is just an agreement made by all nodes in a network on how communicate with one another. It is like a blueprint: You sent me a bunch of bytes over network, how do I reconstruct your message understand it?Here are some examples of network protocols: TCP (Transmission Control Protocol)  TCP is a protocol at transport layer, which delivers streams of bytes between hosts communicating via an IP network.  main purpose of TCP as a protocol is make sure that packages are delivered reliably in correct order without error.    HTTP (Hypertext Transfer Protocol)  HTTP is a protocol at application layer. It is built on top of TCP, which guarantees that packages are sent received in right orders, is used by browsers. So HTTP does not concern itself with low-level implementations of network layer, but focuses more on higher-level functionalities like sessions, request methods (GET, POST, etc. ), status code.   Here is an example of what a HTTP request looks like:   Notice how HTTP includes headers that communicate informations such as what language is accepted. This is often level of abstraction that most distributed systems deal with.   In this assignment, you will learn develop your own protocol. Your protocol does not need as complicated as HTTP, but it needs contain enough information satisfy what your network tries achieve. For example, if I’m designing a protocol for a chat service, my protocol might look something like this:[sender ID (4 bytes)][timestamp (8 bytes)][message size (4 bytes)][text message]In this protocol, sender ID informs other nodes who is sending message, timestamp can used order messages, message size helps nodes verify that they’ve received whole uncorrupted message, message will contain actual string message. This is a minimalistic protocol that meets requirement of system. When designing your own protocol, think about: What are needs of your system? What information need communicated between nodes?What is a network topology?Network topology is structure, either graphically or logically, of a network. It essentially describes how nodes in a network are connected.  simplest example of a network topology is client-server model, where one computer (or node as often referred in distributed systems) is a dedicated server, passively listening for incoming connections serving requests. rest of network consists of clients, which actively make requests server make requests.  underlying topology of a client-server model is star topology, where every node is connected a central hub. Note how none of clients are directly communicating with each other, every message needs go through server.  In distributed systems, however, notion of client server is often blurred. Since a node often needs talk multiple other nodes at same time, both listening for new messages sending out its own messages, it is often both a client a server. In practice, this is very easy implement: just create a long-running thread for server, spawn as many client threads as needed on-demand. Another network topology you sometimes see in distributed systems is fully-connected network, where every node is connected each other:A fully-connected network is extremely resilient, since: cost of routing a message a node is O(1) (by just sending message directly).  It can tolerates as many node failure as possible. In other word, if one node fails, all other nodes can still talk each other. However, fully-connected networks do not scale very well. number of connections in system grows quadratically (O(n^2)) with number of nodes, which can easily over-flood a network. So in reality, this topology is only used for small networks with a relatively small number of nodes.  most common topology in distributed systems is partially-connected network, which broadly covers all networks in which nodes are partially connected. Here are some common examples of partially-connected topologies (ignore top right one):Each topology has its own pros cons. For example, a ring network performs really well under heavy network load; it can easily achieve mutual exclusion (by passing a token along ring); it is easy configure. But a ring network is not fault-tolerant, its communication delay is bottlenecked by slowest connection between two nodes. In this MP, you will implement a decentralized network topology that looks like a hybrid between a star network a fully-connected network. But first, let’s talk about what a decentralized network means. DecentralizationA decentralized system, described in one sentence, is a network in which no one node can control every other nodes. Formally, a decentralized system has two properties: It uses local computation achieve global goal.   For example, averaging all values across a network can done locally by each node averaging with its neighbor’s averages, which eventually converges a global average (sometimes called average consensus).    It stores data locally.   In other word, no single node has all information in a network.   Examples of decentralized systems include: P2P applications like original Skype, BitTorrent, Napster.  Blockchain applications like BitCoin friends.  Many techniques used in cloud applications are decentralized by nature.   For example, distributed database Apache Cassandra uses a ring topology under hood for fast querying.   Pros Of Decentralized Systems: Scalability:  Decentralized networks tend* scale really well, since instead of global computation they favor local communications, which means that system is not limited by resource (bandwidth, CPU, disk, etc) of a single node.   *Note that, this is a generalization. In many cases, decentralization scales well, but there are very valid reasons why majority of large scale systems (think Google or Facebook) are not truly decentralized. As you will read later, scalability is a very ambiguous metric.      Fault-Tolerance:  Since there is no central node, there is no single point of failure. A well designed decentralized system can tolerate a portion of its nodes failing. In contrast, if a “super-node” fails in a centralized system, whole system is at risk of failing.    Trustless:  One of main reasons why there has been so much hyper over decentralization is that a decentralized system doesn’t require trust in a central authority. Now, motivation for wanting a trust-less system often ties into politics business incentives. But regardless, from a purely technical standpoint, achieving consensus without a central authority is quite impressive by itself.   Cons of Decentralized Systems: Security:  In a decentralized network, everyone needs maintain network’s integrity security, which is very hard do. Usually, a decentralized system tries make sure that as long as majority of nodes are not compromised, system will still function properly.    Scalability:  Wait, didn’t you just say that scalability is a pro for decentralized systems? Yes, but turns out, scalability does not grow in a single direction. As network becomes larger larger, it becomes harder harder synchronize system. Sometimes, cost synchronize data coordinate nodes can out-weight benefit of decentralization.   So, in reality, scalability in decentralized system often becomes a trade-off between global computation cost synchronization cost.     RequirementsFor this MP, your goal is design a network protocol for a decentralized network, implement it using any language you want. Topology network topology you will implement is a hybrid between a star network a fully-connected network:In this network, nodes in middle (labeled 0, 1, 2) are fully-connected. They function as routers. Each router is at center of a sub-graph that is star-shaped; there are 3 such sub-graphs: (0, A, B), (1, C, D), (2, E, F). Notice that in order for peripheral nodes (A, B, C, D, E, F) talk each other, they must send their message a router node (0, 1, 2) first, then router node will forward message until it reaches destination. You will implement such a network consisting of 9 nodes. Node A, B, C, D, E, F are peripheral nodes that can send message each other through routers. Node 0, 1, 2 are router nodes that only forward messages but do not create any new message. ImplementationFeatures: Design a simple network protocol for this MP describe it in words.  Implement a program that can run on multiple nodes have following features:  On a router:  Listen for incoming messages, deliver message correct destination node.  Print out all messages it receives for easy visualization.    On a peripheral node:  Get inputs from user that include: a message a destination node ID. (You can use any format you want. ) Send message a router using your network protocol.  Listen for any incoming messages print them out.     Network Configuration Files:You can test your code on localhost by using different ports. You can have following setups: Node A run on 107. 0. 0. 1, port 4000.  Node B run on 107. 0. 0. 1, port 4001.  Node 0 run on 107. 0. 0. 1, port 4002.  … so on … make sure that correct nodes are connected each other according topology, you can hardcode IP addresses ports of all connections a node has in a set of configuration files. For example, node A will have following configuration file:where first line is address port node A itself will listen on, lines following are connections other nodes it will make. Using same example, node 0 will have following configuration file:where node 0 will listen on address port specified on first line, other 4 lines specify connections node A, B, 1, 2. This way, run your code, you can simply open up 9 terminals run same program with 9 different configuration files achieve desired network topology!Suggested Implementations: Router node:  Load network configuration file for node into a lookup table.  If it receives a message, try find destination node in lookup table.   If node is in lookup table, which means router is connected it, simply send message corresponding address port.  If node is not in lookup table, forward message another router.   You must find a way avoid having same message forwarded back yourself, creating an infinite forwarding loop. (hint: what information do you need put into your network protocol achieve this?)       Peripheral node:  Load network configuration file.  Spawn a thread listen for any incoming message.   If it receives any incoming message, print it out screen.    Have main thread read in user input in a while loop.   Parse user input into a message a destination node ID (which should A, B, C, D, E, or F).  Send message router that node is connected to.     Grading MP will hand-graded.   Different from CS 341 MPs, in this MP, you do not need worry about design details. If there is something unclear about requirement, feel free use your own interpretation. We will not knock off points for small inconsistencies.  That being said, you must demonstrate a good understanding of concepts. Your network protocol your code must reflect what you learned from this doc.    In your repository, you must update file README. md include following:  Text description of network protocol you designed.  Instructions on how run your program.    If you do not have a fully functioning program, don’t worry–you will still get partial credits.   We don’t expect you become network-programming masters in three weeks! points you get will largely reflect your understanding effort.   FAQs Can I use any language I want?  Yes.    I don’t know how write networking code, how do I learn?  There are many great resources online:  For Python: https://realpython. com/python-sockets/ For C: https://beej. us/guide/bgnet/ CS341 WikiBook:  C client: http://cs341. cs. illinois. edu/wikibook/networking-part-3-building-a-simple-tcp-client. html C server: http://cs341. cs. illinois. edu/wikibook/networking-part-4-building-a-simple-tcp-server. html   When in doubt, Google!     I don’t understand a concept, what do I do?  Post a question on Piazza! We will try answer them as fast as possible.  Email me at shang9@illinois. edu set up an office hour.    I’m worried that I can’t finish this MP even though I have put in effort.   We understand that this MP may hard for someone who doesn’t have any experience writing network code. Simply do your best, document your ideas. We will grade fairly!  ","url":"/assignments/dangerous_decentalization"},{"title":"Deadlock Demolition","content":"Backstory Do you suffer from writing multithreaded code that deadlocks? Wish that mutexes would provide feedback instead of deadlocking? Well have no fear, drms are here! drm, short for deadlock-resistant mutex, are mutexes that will notify you when an attempt lock them would cause a deadlock! Fancy, right? With this, you won’t ever need worry about deadlock ever again!Your friend, work partner Foo showed you presentation slides which will introduce your project in upcoming Cool C Libraries Fair. both of you have decided implement a mutex library that prevents deadlock, Foo was so excited that they made presentation slides before even implenting library itself. Facepalming at Foo’s lack of proper workflow priorities, you decide just work on it, have Foo create tests videos that will show off drm’s capabilities. OverviewA drm behaves exactly like a pthread_mutex_t, but will prevent deadlocks from ever occurring. This is done by not allowing a thread lock drm if attempt lock it would result in deadlock. For example, suppose you had two threads, two drms: drm_1 drm_2. Then, thread 1 locks drm_1.  thread 2 locks drm_2.  thread 1 tries lock drm_2, waits.  thread 2 tries lock drm_1. Notice that this call will cause a deadlock. Your drm library will detect this, reject thread 2’s request lock drm_1. FunctionalityWe will use binary semaphore notation for your drm’s functions: i. e. post is equivalent unlocking wait is equivalent locking. You will writing four functions: drm_t *drm_init(); int drm_post(drm_t *drm, pthread_t *thread_id); int drm_wait(drm_t *drm, pthread_t *thread_id); void drm_destroy(drm_t *drm); details of what these functions do can found in header file libdrm. h. Resource Allocation Graph detect deadlock, you will need maintain a able perform cycle detection on it. assist you with this, we have provided you an implementation of a graph data structure. See graph. h for details on how use graph. Since your Resource Allocation Graph will need represent both drm locks threads as vertices, use a shallow graph. You will need lazy initialize a global graph in drm_init(). Here is an example of lazy initialization with an integer variable::warning: provided graph data structure is not thread-safe. Algorithmdrm_init() drm_destroy() are straighforward, you only need allocate destroy resources. fun happens in drm_wait() drm_post(). drm_post()When a thread calls drm_post(): Check see if vertex is in graph. If it is not, return without unlocking drm_t.  Otherwise, if an edge from drm thread exists, remove edge unlock drm_t. drm_wait()When a thread calls drm_wait(): Add thread Resource Allocation Graph if not already present. Hint: what unique identifier can you use for each thread? Add appropriate edge Resource Allocation Graph.  Check if attempt lock drm by thread would cause deadlock.  If attempt lock drm would cause a deadlock, then reject locking attempt by returning without locking drm.   One case that would deadlock is a thread trying lock a mutex it already owns. Think about how factor this in.  Another case is if newly added edge creates a cycle in Resource Allocation Graph.    If not, then lock drm. Note that you may need modify edges of Resource Allocation Graph in this step. TestingTesting is ungraded, but highly recommendedYou should test your drm library thoroughly. We’ve given you a libdrm_tester. c file write tests in. tester file comes with an example on how use drm. You will need create more involved tests ensure that your drm behaves correctly. Testing Tips pthread_self may useful for this lab.  You will want write test cases where there is no deadlock, ensure your drm behaves like a normal pthread_mutex_t.  You will also want write test cases where there is deadlock. Perhaps a different synchronization primitive you’ve learned in class can assist you artificially create deterministic deadlocks… Consider logging important events inside of your functions.  Ensure that your return values are correct.  Note that you will have still reachable memory in your Resource Allocation Graph upon program termination. That is expected behavior, still reachable memory is not considered a memory leak. Edge Cases Undefined BehaviorAnything not specified in these docs or header files is considered undefined behavior. We will not test undefined behavior. Some examples: initializing a drm that is already initialized.  calling drm_destroy() on a locked drm. Thread SanitizerWe have another target executed by typing make tsan. This compiles your code with Thread Sanitizer. ThreadSantizer is a race condition detection tool. See for more information. We will using ThreadSanitizer grade your code, but we will ONLY test for data race warnings, NOT any other warning type. Good luck!","url":"/assignments/deadlock_demolition"},{"title":"Deepfried dd","content":"Lore year is 3072. Other than being sum of two consecutive powers of two, nothing was particularly special about this year. That is, until you came across an ancient laptop washed up on sides of Boneyard Creek. Opening laptop, you were delighted find block I CS 125 stickers still firmly attached keyboard. Of course, you’d heard stories. Before humanity had found a way implant knowledge in each other via electromagnetic gimmicks, so-called “students” used attend “classes” where “professors” disperesed their knowledge in oral visual form. CS 125 had been such a class - oh, wonder it must have been! stickers alone, ancient relics of a past society, went for millions of dollars these days. Looking around make sure no one else had laid eyes upon your lottery ticket, you hurried away your apartment have a closer look at laptop. After some research on how ancient laptops were powered (turns out quantum resonance charging wasn’t discovered until 2048!), you quickly splice together a compatible laptop “charger” that would make any fire marshall wince, finally hit one thousand year old power button. After a few moments, you see a password prompt. Thinking for a moment on anything that could unite two CS @ Illinois nerds across a millenium, you smile enter “imaginebeinganECEmajor”. Almost unsurprisingly, laptop unlocks. inside it, you find something even more enticing than CS 125 sticker - four years worth of ancient homework assignments, practice exams, even infamous MPs of old. Almost eight hours pass before you look at clock again, having quenched your insatiable curiosity for ways of ancient societies. How did such a primitive world build such advanced exercises for their school children? what was “PraireLearn”? Thousands of questions go through your head, but before you can answer you realize what you must do first: make a backup of this quaint laptop’s disks, so you can meticulously dissect its contents later on your own computer without threat of burning an entire building down. Luckily, you have a USB-C flash drive you purchased from a museum gift store, but how do you go about making a copy of laptop’s entire disk? There’s no tool you could possibly download, since surely networking stack won’t able connect with any modern network. Luckily, you notice that laptop has a C IDE already installed. Somehow, C survived all way from 1980s present day. Almost gleefully, you realize you’ll have code a C utility on this ancient relic of a laptop in order make an image of drive - just like CS students of old would have done. You put on your hacking gloves, get work. Introductiondd is a command-line utility used copy data from files. Since Linux treats many external devices (including USB drives) as files, this makes dd very powerful. For example, tool can used create a backup image of your hard drive store it as a file which can uploaded cloud storage. dd could also used directly clone one drive another, write a bootable iso image a USB drive, much more. For example, following command would write an . img file (if) a USB drive represented as /dev/disk4 (of), in chunks of 4 MB blocks (bs). See man pages for dd , example usage . We suggest you get a feel of dd by using it copy a file from one folder another. careful, however! dd can easily used (accidentally or on purpose) corrupt entirely wipe disk drives partitions, so make sure you know exactly what a dd command is going do before running it! We recommend you make a testing folder on your VM only use dd with paths pointing that folder, so there’s virtually no chance of overwriting something you don’t want to. Note that Linux will automatically prevent you (usually) from writing physical devices unless you run dd as root (i. e. via sudo). Implementing ddFor this assignment, you will implementing dd utility in C. Your dd implementation will copy data from an input file an output file in a manner specified by its arguments. Background: BlocksA block is simply a unit measuring number of bytes that are read or written at one time. For example, modern hard drives have a sector (block) size of 4 kB - reads or writes disk can only address 4 kB portions at a time. If you write a 64 kB file disk, it will broken down into 16 writes of 4 kB each. Because dd is a file manipulation tool, it supports reading/writing with a configurable block size. For example, if we run . /dd -i input_file -o output_file -b 128, we are telling dd copy input_file output_file, 128 bytes at a time. Your code should write first 128 bytes of input_file output_file, then next 128, so on so forth in a loop until input_file is exhausted (as opposed copying entire file in one go). arguments of dd along with more example usage can found below. ArgumentsYou must implement following arguments from real dd. Since it is $CURRENT_YEAR, we won’t using dd’s style of arguments (if=file, etc), instead use standard style (-i file, etc). You should use getopt parse these arguments, just as you did in Shell MP.  -i &lt;file&gt;: input file (defaults stdin) -o &lt;file&gt;: output file (defaults stdout)  You should create this file if does not already exist.    -b &lt;size&gt;: block size, number of bytes copied at a time (defaults 512) -c &lt;count&gt;: total number of blocks copied (defaults entire file) -p &lt;count&gt;: number of blocks skip at start of input file (defaults 0) -k &lt;count&gt;: number of blocks skip at start of output file (defaults 0)  on mode parameter of fopen may useful here.    For any other arguments, you should exit with code 1. getopt will automatically print an error message for you. Your code will compiled into an executable run via command line. :bangbang: WARNING: Note that some of these arguments refer blocks, not bytes. Reading from stdinIf implemented optimally, there is no need specially handle case where input file defaults stdin, instead of a “real” file. Keep in mind that you don’t need know size of entire input file in order copy full thing: is a useful function. When copying from stdin, dd should write bytes until user enters Control+D (i. e. end of file) into their terminal. You can see this functionality by running real dd: simply run dd of=my_file in your terminal, write some text, press Control+D. my_file will then contain text you typed into terminal. Note that fseek is not meant used on streams such as stdin stdout! As such, we will not testing -p or -k functionality when input or output files are set stdin or stdout respectively. Status ReportsYou must print a status report after dd finishes, similar real dd. An example is below:In addition, your dd should able give a “live” status report. You should catch SIGUSR1 print a status report when signal is triggered:Use functions provided in format. h print these reports. You should use clock_gettime time execution of dd. :bangbang: WARNING: printf (among other functions) is not safe call in a signal handler, since it is not reentrant. Ensure your signal handler does not call these functions, including any function in format. h, instead indicates your program print this status report elsewhere. Example Usage following command should copy 32 blocks of size 4 kB (a total of 128 kB) from input. dat output. dat, skipping 2 blocks from start of input. dat 10 blocks from start of output. datThis command should dump output of echo \"Hello, World!\" into a file called output. dat:This command should write about 2 GB of random data (from /dev/urandom) into a file called random. bin, in chunks of 1000 bytes:ErrorsIf input or output file given your dd is invalid, use functions in format. h print corresponding error exit with return code 1. Any other invalid inputs (e. g. negative block sizes) are considered undefined behavior. TestingThough it is helpful write tests that call any functions you write in dd. c, because your code will run as a command line utility, we recommend testing in command line as well. You can assemble a series of calls your dd executable in a bash script, use diff/md5sum along with spot checks ensure correct functionality. For example, following shell script would print nothing if your dd implementation is correct:We included a Makefile target automatically generate a few files of different sizes in test_files directory. You can build it by running make test-data inside assignment directory on your VM. GradingYour code will auto-graded on all of parameters listed above. We will also testing your status reports, both while dd is running (via SIGUSR1) after it completes. Note that a handful of tests depend on various aspects of your progress report working. :bangbang: WARNING: Make sure remove all print statements from your code (except calls functions in format. h) before running autograder!:bangbang: WARNING: You will fail assignment if you use use fork, system, exec, or similar. ","url":"/assignments/deepfried_dd"},{"title":"Extreme Edge Cases","content":"BackstoryWhat makes code good? Is it camelCased strings? Good comments? Descriptive variable names, perhaps?One thing we know is that good code is generally modular - it consists of discrete “units” of functionality that are only responsible for very specific certain behavior. In our case, working with C, these “units” are functions. For example, C string function strlen is solely responsible for determining length of a string; it doesn’t do any I/O or networking, or anything else. A function that knows all tries do all would bad design, testing whether that kind of function adheres expectations would nontrivial. A programmer might ask, “do my units of work behave way I expect?” or “if my function expects a string, how does it behave when given NULL?”. These are crucial questions, since ensuring that units of code work exactly way one would expect makes it easy build reliable robust software. An unreliable unit in a large system can affect entire system significantly. Imagine if strcpy, for example, did not behave properly on all inputs; all of higher-level units that use strcpy, all of units that interact with those units, would in-turn have unpredictable behavior, so unreliability would propagate through whole system. Enter unit testing. Unit TestingUnit testing is a ubiquitous crucial software development method used heavily in industry. , “a unit test is an automated piece of code that invokes a unit of work in system then checks a single assumption about behavior of that unit of work”. This sounds like testing - leave it QAs, right? Actually, developers, much their chagrin, are expected write their own unit tests. In order write effective unit tests, all possible cases of input a unit (mainly functions, in C), including edge cases, should tested. Good unit tests test (extreme) edge cases, making sure that discrete unit of functionality performs as specified with unexpected inputs. In this MP, your goal is create test behavior of an arbitrary string manipulation function determine if it is reliable, predictable, correct. While writing your functions, try write modular code, as this will make your life easier when you test it. You’ll learn how write effective test cases - an incredibly helpful skill for rest of course. Finally, you’ll able take these skills Facenovel for your next internship impress your coworkers. Man pages man (manual) pages are main system of documentation for C system calls, library functions, other information related Unix-based operating systems like Linux. Learning how use documentation unblock yourself when stuck is an integral part of software development, in CS 341 beyond. For purposes of this course, man pages are an excellent resource direct documentation-related questions to. For example, some good questions related this MP direct man pages: What does strtok take as input, what does it return? What is difference between strcpy strncpy? Which characters are considered whitespace characters by isspace?You can view man pages through your terminal’s command-line interface by typing in man &lt;command&gt; or man &lt;function&gt;, like man ls or man malloc. man pages are also accessible via several sites on web, such as https://man7. org/linux/man-pages/ https://linux. die. net/man/camelCaserWe have chosenas your arbitrary string manipulation function. Your manager at Facenovel, celebrate Hump Day, has asked all of interns implement a brand new camelCaser convert sentences into . give you a chance earn your return offer, he also assigned you write test cases for all other interns’ implementations of camelCaser, with implementations hidden from you. Let’s say I want get a sequence of sentences in camelCase. This is string passed into your method:Your method should return following: brackets denote that above is an array of those strings. Here is a formal description of how your camelCaser should behave: You can’t camelCase a NULL pointer, so if input is a NULL pointer, return a NULL pointer.  If input is NOT NULL, then it is a NUL-terminated array of characters (a standard C string).  A input sentence, input_s, is defined as any MAXIMAL substring of input string that ends with a punctuation mark. This means that all strings in camelCased output should not contain punctuation marks.   This means that “Hello. World. ” gets split into 2 sentences “Hello” “World” NOT “Hello. World”.    Let camelCasing of input_s called output_s.  output_s is the concatenation of all words w in input_s after w has been camelCased.   punctuation from input_s is not added output_s.    Words are nonempty substrings delimited by MAXIMAL amount of whitespace.   This means that \" hello world \" is split into \"hello\" \"world\" NOT \"hello \", \" \", \" world\" or any other combination of whitespaces.    A word w is camelCased if only if:  it is first word every letter is lowercased.  it is any word after first word, its first letter is uppercased every subsequent letter in word is lowercased.    Punctuation marks, whitespace, letters are identified by ispunct, isspace, isalpha respectively.   These are functions in C standard library, so you can man ispunct for more information.  If input_s has ANY non-{punctuation, letter, whitespace} characters, they go straight into output_s without any modifications. ALL ASCII characters are valid input. Your camelCaser does not need handle all of Unicode.    camel_caser returns an array of output_s for every input_s in input string, terminated by a NULL pointer. Hint: ctype. h has a lot of useful functions for this. Your implementation goes in camelCaser. c, you may not leak any memory. DestroyYou must also implement destroy(char **result), a function that takes in output of your camel_caser() frees up any memory used by it. We will calling this in our test cases checking for memory leaks in your implementation, so remember test this!camelCaser Result In Memorycamel_caser() takes in a C string, which represents an arbitrary number of sentences, returns a pointer a NULL-terminated array of C strings where each sentence has been camelCased. It is up you how resulting structure is allocated, but it must completely deallocated by your destroy() function. For those who like pictures, here is what return value of camelCaser looks like in memory:In above picture, you can see that we have a char double pointer called ‘array’. In this scenario, char double pointer points beginning of a NULL-terminated array of character pointers. Each of character pointers in array points beginning of a NUL-terminated char array that can anywhere in memory. These arrays are NULL-terminated because your user will need know when these arrays end so they do not start reading garbage values. This means that array[0] will return a character pointer. Dereferencing that character pointer gets you an actual character. For demonstration purposes, here is how grab character “s” in “as”:Writing Unit TestsYour goal is show that other interns’ implementations of camelCaser - which, of course, you can’t see directly - fail on some extreme test cases, and, in meantime, demonstrate head honcho at Facenovel exactly how robust your own function is. Facenovel promises pass in C-strings. Likewise, you promise return a dynamically allocated NULL-terminated array of C strings that can deallocated with your destroy() function. What kinds of edge cases might come up?Run make camelCaser test. You will have fill in tests in camelCaser_tests. c. Because Facenovel values their testing server time, you may not try more than 16 different inputs, each input must less than 256 characters (only characters). This does NOT mean your implementation can assume input of 256 characters or less. Your implementation of camel_caser() should able handle any valid C string of any length with any combination of ASCII characters. Also, it is not in spirit of unit testing diff output of your implementation with one you are testing. Therefore, you may NOT call your own camel_caser() function when implementing your test cases. Other helpful resources: Reference ImplementationYour senior coworkers at Facenovel have taken a liking you for your work ethic, they decided help you by providing you a reference implementation. You are given an interface camelCaser_ref_tests. c which allows you access black-box reference implementation. You are given two utility functions help you understand what camelCase looks like.  first function provided isprint_camelCaser(char *input). It takes a string input prints out transformed camelCased output onto stdout. This function is meant used help you answer questions like, “What should result of inputting &lt;blah&gt; into camel_caser()?” Note that this function might behave weirdly with non-printable ASCII characters.  second function that you can use is check_output(char *input, char **output). This function takes input string you provided expected output camelCased array of strings, compares expected output with reference output. This function is used as a sanity check, confirm your understanding of what camelCased output is like. This will also help you understand how deal with non-printable ASCII characters. A few important things aware of when you use reference implementation: DO NOT use any functions provided in camelCaser_ref_tests. c camelCaser_ref_utils. h in any part of your camel_caser() implementation as well as your unit tests (that is, don’t use it anywhere outside of camelCaser_ref_tests. c). Your code will definitely not compile during grading if you use any of those functions in any graded files.  reference only serves as a starting guideline a sanity check, ensure that you understand how camelCase works. reference implementation does not represent only possible good implementation. Your implementation is restricted by specifications provided above, only specifications above. An implementation is good if only if it meets requirements in specifications.  reference does not replace actual testing of your own implementation. You are responsible rigorously test your own code make sure it is robust guards against all possible edge cases. You may not use reference implementation test your implementation of camel_caser().  use reference, modify camelCaser_ref_tests. c file, run make camelCaser_ref you should have a camelCaser_ref executable. Note: reference implementation is only available in release form. There is no debug version of reference. GradingGrading is split up into two parts. Your Implementation first portion of test cases test your implementation of camel_caser(). We pass in some input, check that your output matches expectations laid out in this document. Essentially, your code is put up against our unit tests, which means you can write as-good (or even better) unit tests ensure that your camel_caser() passes ours. Your Unit Tests second portion of test cases test your unit tests. We have a handful of camel_caser() implementations, some that work, some that don’t. test your unit tests, we feed each of our camel_caser() implementations through your test_camelCaser() function (found in camelCaser_tests. c) see if it correctly identifies its validity. For each of camel_caser() implementations that you correctly identify - marking a good one as good, or a bad one as bad - you get a point. prevent guessing, randomization, or marking them all same, any incorrect identification loses you a point. However, after each autograde run, we will tell you how many good ones you correctly identified how many bad ones you identified, so you know which unit tests may need improvement. If your unit test segfaults or otherwise crashes, our test will interpret that as evaluating that implementation as a bad one. You cannot assume anything about input, other than input string being NUL-terminated, just like all C strings. ExampleLet’s say there are five good implementations five bad implementations. If you correctly say all five good are good, then you’d get +5 points. If you correctly identify three of bad ones as bad, then you would get +3 for those -2 for incorrectly labeling others. In this case, you’d get a 6/10. Tips tricks on approaching assignments Always read documentation entirely, before beginning approach assignment. Note down what you need do, what you should not doing. Keep a checklist of things implement prevent yourself from forgetting things.  Read header files of assignments first. These files will contain comments on behavior of functions. Please report staff if a function is not sufficiently documented.  Work incrementally. Add in a function or two, then test make sure it works before moving on.  Test extensively. most evil user you can be, try various nasty (but valid) inputs see if your code handles them or not.  Good function/variable naming well placed comments save lives.  For every malloc you call, make sure there is a corresponding free somewhere.  Pay attention small details (such as function return values, side effects, etc). C is a language where every detail matters.  Make sure your code works in release build, as we will run tests on that build (see Luscious Locks documentation for a detailed explanation of different builds).  Always debug your code using debug build, as debug build is compiled with -O0 flag, which means no compiler optimizations. In addition, debug build is compiled with -g flag. This allows you view source code in GDB, shows line numbers where things fail in Valgrind.  Ensure that code you submitted is version that you want grade (before deadline, or before running an autograder run).  Take note of graded files. Make sure any changes you want graded are placed in graded files.  Do not declare your functions as just inline, as it is a keyword that may cause issues with linkage. Functions declared with inline will not have an external definition (unless overrided with keywords like extern), so it may considered undefined unless an explicit external definition is provided. In addition, auto-grader compiles code in debug mode for valgrind checks, which inline can break. You can read more about this or .  Pay attention Ed for pitfalls issues that you may have overlooked. Print smartMany assignments in this course will read your output grade them. This means that having stray prints may cause you randomly fail tests. Furthermore, excessive logging prints can reduce performance of your code, which can also cause you fail tests. Therefore, you should always check your code make sure you don’t have random prints in your code. Instead of writing print statements removing them repeatedly, a recommended strategy is use following function below perform logging: DEBUG macro is enabled in debug build by passing flag -DDEBUG compiler when compiling debug build of an assignment (please report staff if an assignment’s debug build does not have -g or -DDEBUG flags). #ifdef statement is a preprocessor directive which includes a code snippet into executable if macro is enabled during compilation. Therefore, statements in #ifdef DEBUG blocks do not appear in release builds of assignments. This will prevent you from impacting performance of release builds (if you need these logging prints in release builds, remove #ifdef directive). Furthermore, this logging function prints stderr. We typically do not check what’s in stderr, so feel free use that output stream dump your logging messages. errno knows what’s upOften, you’ll see that system calls library functions will return -1 set errno upon execution failure. errno is a special global variable that stores error codes for failures in function calls. Many system calls do not guarantee success can fail at random, even malloc! Therefore, whenever you encounter bizarre failures, one thing keep in mind is check if a function/system call failed, if so, determine why it failed. Attached below is a sample code snippet of reading errno using perror:A note on strtokUsing strtok (instead of strchr) for this MP can confusing without an understanding of how it works, often leads pitfalls. An important fact about strtok keep in mind for this MP is that it ignores multiple consecutive separators when parsing a string. If you still choose use strtok, read first few paragraphs of man page thoroughly. Good luck!","url":"/assignments/extreme_edge_cases"},{"title":"Finding Filesystems","content":"Introduction / BackstorySo you’ve been doing well at Macrohard. Your turbo malloc really impressed your boss you also went on work on infamous password cracker parmake programs. However, your bosses have been looking for a way store data in a proprietary format so that they can easily share chunks of data without having first compress it. They have following requirements: data must stored in a single file so that it’s easy share - however, keep file within company format must proprietary Current tools like cp, ls, touch, etc must work with this data format for easy usageSounds tough. That second requirement really throws a spin on things. It’s such an arbitrary requirement. Almost as if it was just thrown in as a TA’s lazy writing motivate an MP or something. Lame!Of course, as a student of CS341, you know exactly what they’re asking for - a loopback filesystem! After doing some research, you decide that a good filesystem base your implementation off of is minixfs. Your friendly coworkers have already made some progress on this project created a filesystem wrapper, fakefs, that can load a mininxfs image. It’s now your job implement a few filesystem operations for minix. In this MP, you will implementing several callbacks file system operations, namely, chmod, chown, read, write. do this you will exploring how metadata is stored in inode how data is stored in data blocks. You will also exploring idea of virtual filesystems how they can used present metadata about a system. minixfsext2 is good filesystem, but keep things simple, we will using a modified version of its predecessor (the ) in this MP. file_system struct file_system struct keeps track of metadata, root inode (where fs-&gt;inode_root[0] is root \"/\" inode), root of data_blocks.  meta pointer points start of file system, which includes superblock.  inode_root points start of inodes as in picture.  data_root points start of data_blocks as in picture, right after inodes.  data_map keeps track of which blocks are used is placed at end of filesystem which makes it easy resize filesystem (although resizing is not supported by your implementation). Remember from class that inodes become free when their hard link count reaches zero, but data blocks need some kind of bitmap or sentinel indicate if they are being used. data_map is a variable-sized array that holds this information. You don’t need worry about these abstractions, they are taken care of for you.  inodes data blocks are laid sequentially out so you can treat them like an array. Think about how you could get a pointer nth data_block. Superblock superblock stores information like size of filesystem, number of inodes, number of data blocks. InodesThis is famous inode struct that you have been learning about! Here are a breakdown of variables: uid is user ID of inode owner.  gid is ID of inode group (does not have include owner).  mode is a bitmask. bottom 9 bits are read-write-execute for owner-group-others. Bits 11-10 are type of file. (mode &gt;&gt; 9) corresponds a particular type. We have given you two functions, is_file is_directory, that tell you whether or not inode represents a directory or file. There are no other types in our filesystem.  nlink is hard link count which is number of directories that file is linked from (directories can’t hard linked).  atim is access time, which is time of last access or last time a file was read(2).  mtim is last modification time, or in other words, last time file was changed with write(2).  ctim is last change time, or in other words, last time file’s metadata was changed.  size is size of file in bytes direct is an array where direct[i] is ith data block’s offset ( data_block_number) from data_root.  indirect is offset number (data_block_number) of a data block, which contains NUM_INDIRECT_BLOCKS number of data_block_number’s. We are using direct indirect members of inode index our data blocks, which works like so. Data blocksData blocks are currently defined 16 kilobytes. Nothing fancy here. fakefs interfaceYou do not need modify or read any of code in fakefs_src/.  make this MP possible, we’ve developed our own userspace filesystem interface which we’re calling fakefs. Normally, filesystems are a piece of code which you load into your kernel must provide a few things. It needs a constructor, destructor, callbacks for all system calls involving files file descriptors within your filesystem. However, writing kernel code is a bit more cumbersome than writing normal code since you need additional security checks among other things, can even lead instability in your operating system. avoid this, there are various ways implment a filesystem in userspace. most common (and preferred) method is use a library called FUSE (Filesystems in USErspace). FUSE allows you implement your file operations in userspace, but still interacts with kernel provide it’s functionality. While this allows you mount filesystem use it like any other filesystem, there are a few reasons why we chose not use it for this MP. A major reason is that if a FUSE callback crashes while it is mounted, it renders mounted partition unusable in some cases, you won’t able even unmount partition without rebooting machine. prevent making this MP annoying tedious, we’ve made our own way of implementing filesystems in userspace by hooking filesystem operations. If you take a look at fakefs_src/fakefs. c you’ll see that we’ve overridden most of glibc’s filesystem operations. Note that this only hooks functions from code or programs that were either written in C or in something that compiles C. Running a program written in assembly will not affected by these hooks. Note that not all programs will work with fakefs. At least, we guarantee that ls, cat, mkdir, unlink cp work. vim neovim seem work although you might run into some weird bugs using these programs within fakefs. TL;DR: running a program with fakefs will replace glibc’s filesystem operations with your own functions. Make sure you use this when testing your code. Helper Functions/MacrosThere are some functions that you are going need know in order finish this MP. get_inodeThis function takes a string name like /path/to/file returns inode corresponding file at end of that path. get_inode returns NULL when intended file does not exist or file is invalid. is_file / is_directoryCall is_file or is_directory on an inode tell whether it is a directory or a file. You don’t need consider other inode types. is_virtual_pathCall is_virtual_path on a path see if it’s a path in virtual component. If it is, this function will return a path relative virtual directory. Returns NULL otherwise. minixfs_min_blockcountCall minixfs_min_blockcount ensure that an inode has a certain minimum number of data blocks directly, or indirectly, associated with it. NUM_DIRECT_BLOCKSNUM_DIRECT_BLOCKS is number of direct data_block nodes in a single inode. indirect array also has this many entries (for sake of simplicity). UNASSIGNED_NODEYou may not need use this macro, but if you choose to, then any data_block or inode that is not currently being used will have this number. Other useful functions make_string_from_dirent add_single_indirect_block add_data_block_to_indirect_block add_data_block_to_inode parent_directory init_inodeYou can find information about these in minixfs. h minixfs_utils. h. It’s also a good idea read through provided functions briefly (at least headers) get an idea of what tools we provide you with. So what do I need do?You will need implement following 5 functions int minixfs_chmod(file_system *fs, char *path, int new_permissions) int minixfs_chown(file_system *fs, char *path, uid_t owner, gid_t group) inode *minixfs_create_inode_for_path(file_system *fs, const char *path) ssize_t minixfs_read(file_system *fs, const char *path, void *buf, size_t req, off_t *off) ssize_t minixfs_write(file_system *fs, const char *path, const void *buf, size_t count, off_t *off) you will need implement a virtual file /virtual/info. For more information about that, scroll down virtual filesystem section. You can find more information about required functions in minixfs. h. Remember set errno on errors in your code!! We will checking errno while grading. Note that for all functions where you need update times, you should use clock_gettime(CLOCK_REALTIME, variable_to_update);. Some notes on minixfs_create_inode_for_pathSince we’ve had many students ask about this function, this section willcontain some hints. Note that parent directory of a path passed in will always exist when wetest your code. A valid file path is absolute, unique, links a directory containing a file with a valid filename. When you find an unused inode, you will need use init_inode initializeit. make_string_from_dirent will write contents of a minixfs_dirent char * you provide.  number of bytes written by calling make_string_from_dirent will equal FILE_NAME_ENTRY as defined in minixfs. hVirtual FilesystemIn order quickly get meta-information about filesystem, we’re going implement a virtual filesystem. Virtual filesystems are filesystems that present file-like objects, but don’t provide access data in traditional sense that you would expect from a filesystem. Some examples are procfs (usually mounted at /proc) that gives a user information about running processes, also has some special files that can control various system parameters or provide debugging information about a running machine, or devfs (usually mounted at /dev) that provides information about devices presents some virtual devices such as dev/zero, /dev/random /dev/null which have special actions when being read or written to.  virtual filesystem we will baking into our mininxfs implementation will live at /virtual with respect root of your minix filesystem. There will at least one file inside, info. You do not need implement writing /virtual/info, but do need support read. When read from, /virtual/info will return a string with following format:Note that there is a new line at end of each line above. You will need compute number of free used blocks insert into data. Also note that you will need support reading virtual file from an offset, must not copy more bytes user’s buffer than requested (just like a normal read).  simplify your implementation we recommend first generating data above as a string then copying a certain number of bytes of string from a desired offset user buffer. TestingTesting is ungraded, but highly recommendedYou can grab test filesystem using make testfs. Do not commit this file. If you overwrite it want original version just rm test. fs do make testfs againYou will probably want reset your test. fs file frequently while testing your write functionality. Note: There’s a small chance that make testfs can fail - in this case rm test. fs make testfs again. make will generate minixfs_test executable that you can use for testing. We strongly recommend writing your own testcases in minixfs_test. c not just using output of commands like ls cat (which we describe how test with below). This is because subtle bugs in your code can make output look right, but have random unprintable characters as well.  goodies directory is also included can also used check against /goodies directory in test. fs. For example, output of:. /fakefs test. fs cat test. fs/goodies/hello. txt should same as cat . /goodies/hello. txtHere are some sample (and not comprehensive) testcases!You can even cat directories!So that’s what really is going on under hood?You can also use /goodies directory in minixfs_test. c. Here’s an example:Want something fun?You can store anything on filesystems. See what we hid around testfs filesystem for you…You can also test by generating your own filesystems. Simply run . /fakefs mkfs filename generate a filesystem with filename filename. If you’ve implemented write functionality, you can use commands like . /fakefs cp file1 filename/ copy files over. programs like mkdir should work as well. Other Edge Cases You do need update atim ctim! You don’t need worry about data corruption or checksums or anything fancy, filesystem will valid. (Unless your write has bugs in it) Make sure all files you cat out in /goodies look correct when you xdg-open them. Make sure you can get PNGs PDFs print out correctly.  Make sure your output is same size as files inside filesystem. You can check this by running stat on files inside filesystem(. /fakefs test. fs stat test. fs/FILE_PATH), wc -c on on output of running cat on file (. /fakefs test. fs cat test. fs/FILE_PATH | wc -c) check that number of bytes is same. Helpful Hints Notes Handle edge conditions. You can assume that size will valid. What is code supposed do when you get a singly indirect block? Draw pictures! Understand what each of things in structs mean.  Review your pointer arithmetic.  Only changeminixfs. c. ","url":"/assignments/finding_filesystems"},{"title":"Ideal Indirection","content":"OverviewIn this assignment, you will working on managing a mapping of a 32-bit virtual address space a 32-bit physical address space with 4 KB (kilobyte) pages. Each component of virtual memory has been split up into several files help you build a mental model of virtual memory. Reading through these files will help you understand roles of different hardware software involved in managing virtual memory. You will only have write two functions in mmu. c, but it requires a good understanding of virtual memory translation process decent understanding of rest of provided code. How Tackle This Assignment  First, you will need understand how virtual memory translation process works. You will writing functions translate virtual addresses into physical addresses, so a good first step is understand that process. coursebook has details on this process, feel free ask about this if you are unsure.    Then, you will want understand how we simulate different components of a computer in this assignment. header files describe various structs involved in this simulation, as well as their member variables. At a minimum, you also need following helper functions complete assignment:  tlb_flush() in tlb. h tlb_add_pte() in tlb. h tlb_get_pte() in tlb. h mmu_raise_segmentation_fault() in mmu. h mmu_tlb_miss() in mmu. h mmu_raise_page_fault() in mmu. h ask_kernel_for_frame() in kernel. h get_system_pointer_from_pde() in kernel. h read_page_from_disk() in kernel. h get_system_pointer_from_address() in kernel. h find_segment() in segments. h address_in_segmentations() in segments. h  However you are free use whichever other helper functions you’d like. source code for these functions have been given you; you should able get a grasp on whole model just by reading header files, but if you are interested see how we model different components, you can read source code.   Once you have a good mental model, you will want plan out steps your code needs perform. Start by following pseudocode below:  Use pid check for a context switch. If there was a switch, flush TLB Make sure that address is in one of segmentations. If not, raise a segfault return Check TLB for page table entry. If it’s not there:  Raise a TLB miss Get page directory entry. If it’s not present in memory:  Raise a page fault Ask kernel for a frame Update page directory entry’s present, read_write, user_supervisor flags   Get page table using PDE Get page table entry from page table. Add entry TLB   If page table entry is not present in memory:  Raise a page fault Ask kernel for a frame Update page table entry’s present, read_write, user_supervisor flags Read page from disk   Check that user has permission perform read or write operation. If not, raise a segfault return Use page table entry’s base address offset of virtual address compute physical address. Get a physical pointer from this address Perform read or write operation Mark PTE as accessed. If writing, also mark it as dirty.    Once you understand these steps, turn them into code. Then, test with given test cases.  rest of this documentation will serve help you understand purpose of each file give you a high level understanding of virtual memory. implementation details of each function are documented in header files. recommended sequence of reading provided files will follow sequence of files introduced in this documentation. Simulated vs Actual Memory Spaces (types. h)In this assignment, we are simulating 32-bit virtual memory spaces 32-bit physical memory spaces. All simulated memory addresses, both virtual physical, will stored in addr32 variables. Note that once you translate a simulated virtual address into a simulated physical address, you will want convert simulated physical address into an actual memory address in your process space, so that you can read from write memory. Page Directories Page Tables (page_table. h)Each process has two levels of paging: top level page table is known as a page_directory has entries (page_directory_entry) that hold base address of page tables (beginning of a page_table). Each of these page_tables hold entries (page_table_entry) that hold base address of an actual frame in physical memory, which you will reading from writing to. Each table entry in both page_directory page_table contain base physical address of lower-level paging structure metadata bits flagsThese metadata bits flags are explained in detail in page_table. h. actual layout is taken directly from a real 32 bit processor operating system, which you can read more about in . For illustrative purposes a Page Table Entry looks like following:In our simulation, each entry is represented as a struct with bit fields whose syntax you can learn about in a . bit fields basically allows us squeeze multiple flags into a single 32 bit integer. For purposes of this lab you are only responsible for knowing how following fields works: Page base address, bits 12 through 32 Present (P) flag, bit 0 Read/write (R/W) flag, bit 1 User/supervisor (U/S) flag, bit 2 Accessed (A) flag, bit 5 Dirty (D) flag, bit 6You will need read update these fields in table entries. Here are some helpful tips for correctly setting bits: Once a page_directory or a page_table is created, it will remain in physical memory will not swapped disk.  Each segmentation has a permissions field, there is a permissions struct in segments. h. If permissions &amp; WRITE is not 0, then it has write permission. Same is true for READ EXEC.  page_directory_entry’s should always have read write permission For purposes of this lab, all page_table_entrys page_directory_entrys will have user_supervisor flagset 1Note: naming scheme of “page directory” “page table” is unique this assignment. Typically, we just know them as “first level page table” so on. Note: careful when writing into bit fields! What happens when value you try write into a bit field is larger than maximum value that bit field can store?Translation Lookaside Buffer (tlb. h) Translation Lookaside Buffer will cache base virtual addresses their corresponding page_table_entry pointers. implementation header is provided you. Make note of use of double pointers (why do we need that?). You will need check TLB update it everytime you translate a simulated virtual address into a simulated physical address. You will also need flush TLB during context switches.  reason why our TLB caches page_table_entry pointers instead of physical addresses of frames is because you will need update metadata bits when translating addresses. Segments (segments. h)A process’ virtual address space is divided into several segments. You are familiar with many of these: Stack Heap BSS Data CodeFor this lab, a process’ address space is split into memory segments like so:Photo Cred: http://duartes. org/gustavo/blog/post/anatomy-of-a-program-in-memory/Notice how some of memory segments like stack mmap have an arrow pointing down. This indicates that these regions “grow down” by decreasing their end boundary’s virtual address as you add elements them. This is so that stack heap can share same address space, but grow in different directions. It is now easy see that if you put too many elements onto stack it will eventually run into heap memory leading classic Stack Overflow.  reasons why this external structure is needed for this lab is answer question: “How do you know when an address is invalid?”. You cannot rely on present bit of a page table entry, since that page may valid, but just happens paged disk. solution is check see if an address is in any memory segment with bool address_in_segmentations(vm_segmentations *segmentations, uint32_t address);. If address is not in any of process’s segments, then you get dreaded segmentation fault (segfault). Note: There is one other form of segfault. Can you determine what it is?Kernel (kernel. h)For this assignment all memory allocations will abstracted by kernel. c. This file will maintain a global array of pages that you will use model all of physical memory. That is say that all simulated virtual addresses get translated an address in:char physical_memory[PHYSICAL_MEMORY_SIZE] __attribute__((aligned(PAGE_SIZE))); caveat this lab is that it is all done in user space. That means you are technically mapping one virtual address another virtual address that represents a physical address. However, all concepts involved remain same in a real operating system’s memory management software. We use a global char array for our physical memory as it so happens that global variables such as these are storedin some of lowest addresses in memory. Because of this, array, despite existing in a 64-bit environment, onlyneeds 32 lower bits of a 64-bit address address it. This is great because it allows us use 32-bit addresses refer a simulated physical memory location, despite being on a 64-bit system. downside is that we will need convertany 32-bit simulated physical memory addresses, which are stored as addr32 variables, into 64-bit void * pointers before we actually try access that memory. We have provided a few helper functions help with this conversion:Examples usages of these helper functions can found in some of implemented features in mmu. c. Note: Shifting signed numbers can produce unexpected behavior, as it will always extend sign, meaning if most significant bit is 1, “leftmost” bits after shifting right will all 1s instead of 0s. Do yourself a favor, work with unsigned values. Memory Management Unit (mmu. c mmu. h)For this assignment you are only responsible for handling reads writes from virtual addresses. functions you are complete are:This means you have translate a simulated virtual address into a simulated physical address, then read from/write that memory location.  following illustration demonstrates how translate from a virtual address a physical address:This image is saying that you are take top 10 bits of provided virtual address index an entry in page directory of process. That entry should contain base address of a page table. You are then take next 10 bits index an entry page table you got in previous step, which should point a frame in physical memory. Finally you are use last 12 bits offset a particular byte in 4kb frame. TestingMake sure you throughly test your code as usual. We have provided some tests cases, but we encourage you write your own as well. Use provided test cases as a reference learn create tests with good coverage. ","url":"/assignments/ideal_indirection"},{"title":"Know Your Tools","content":"HW0You have already been assigned a HW0 for class. – beware link does not save so ready submit when going through. We’ll spend first part of class going over various questions from HW0. Your grade for this lab is partly HW0 partly assignment below. DevelopmentRead !Git(Read first section of development site!) You will using git submit all your assignments in this course. First go . DO NOT DO THE README TUTORIALOnce you are in your VM, you’ll need set up some global defaultsMake sure replace FIRST_NAME LAST_NAME NETID with your information. Then checkout your repository as followswhich will check out your entire git repo into a folder called ‘NETID’ into your current directory. Now change your directory into that folder:You’ve probably noticed repository is empty! In order grab latest version of our assignment, complete following steps. Graded FilesOne section we will have on top of every assignment is a section called graded_files these are files that we use grade assignment. git does not allow us set rest of files readonly prevent changing them (header files, Makefile). You have careful avoid changing these files. We are working on a system that prevents you from accidentally committing changes, but there is no easy way set permissions on your local copy. BackgroundYou are working for ShadyCorp Inc. Your boss commissioned your coworker write a program. program reads a file, overwrites it multiple times so that it is harder recover on hard disk, then encrypts file, then writes it once an output file.  head of ShadyCorp is lazy, so they want more features. They want first five lines of file last five lines of file copied beginning. They also want file wrapped more easily read on mobile devices. Lines should at most 80 characters (not including newline). If a line is longer than 80 characters, then it should split into two or more lines, where all but last line has 80 characters (not including newline). Your co-worker sighs comes up with following game plan.  Read entire file from disk Wrap lines 80 characters max Do rewrite make sure file is mangled Find first five last five lines copy them in front of string Write it an output file In case where all is successful, print out process address space. (You need implement this)Usage:Your boss at ShadyCorp is very paranoid. test that his program, he wrote a test suite himself. Your co-worker went home sick that day. Now, he hasn’t been heard from in two weeks; you don’t ask any questions. boss sent you an email fix code that your co-worker gave you. Since you are Boss’ cousin, he gives you test cases that you failed promises run test cases every day (your mom is very convincing). But, he imposed a penalty. You are currently passing some test cases, but you won’t get any points for those because your co-worker wrote that code. You are failing four test cases. If you get those test cases pass, you get full points for this lab keep your job at ShadyCorp. If you mess any test cases that you were passing before, you will lose one point. boss assures that code is well sectioned, so you won’t have even look at files that aren’t related test case.  output of file should be:Where &lt;newline&gt; = '\\n'. A line is defined as zero or more characters terminated by a newline character. Problem 1: No Such FileIf file does not exist, program currently doesn’t work. Instead of crashing, exit with a status NO_FILE_RETURN_CODE found in secure_move. cProblem 2: Address SpaceDue new vulnerabilities, your bosses are worried no end about shadier corporations trying get your data. There are some available detect against variations of meltdown, ones against variation of spectre are few far between. security gurus have found was of detecting spectre attacks can now track attacks against processes. They are able get address all other parameters of affected area, but they need know what region of memory was read. For instance, if a c library function was read, then no big deal. But if one of file* structs was read, ShadyCorp’s shady dealings could uncovered. As such, they want you print out following in descending order.  address of main address of strdup A string literal (e. g char *ptr = \"abs\") A malloc’d array Address of argcHint: Do you need check order every time? What do you know about process address spaces?Entrypoint driver program is in secure_move. c. There, we do some basic input validation, open a file, shred it, print output that your boss wants. I wonder where it could going wrong…Debugging GuideRead get started with debugging!Manual TestingIn end, your boss was nice enough give you some test cases. In files/, there are a few files that your boss will use test program with. One is files/blank. txt, which you can use test blank input. Another is files/final. txt, which is full of secret business-y type stuff. In order run a test case, try following commands:CS 241 MakefileAll assignments in this class will use a similar makefile. Note: This is not a class about makefile programming, so you will not need know advanced parts of makefiles (pattern matching, expansion phases, etc). Still, it is important that you know a little bit about how they work for a future assignment. Here is what a typical makefile will look like:This looks scary, but if you Google some makefile basics carefully read comments it should start make sense. These are things you will need know, at minimum: Compile assignment: Clean up assignment directory: Compile a debug-able version of your code that you can use gdb on: Compile a release version of your assignment that you test with: Outline Log into your VM Clone or Update your git repository on your VM Fix code using test cases you develop  Look through code in files! Use printf’s! Use valgrind! Use GDB! Run on given files see if output is what you expect.  Problem 1: See why file is not shredded Problem 2: See why program crashes on non-existent-file Problem 3: Are there any memory errors or leaks (check valgrind?) Problem 4: What does address space look like?   git commit -a -m \"My Submission\" (commit your work git). Lab AttendancePart of your grade in this class relies on you attending labs. Towards end of every lab, we will ask you swipe out (swipe your i-card). You may only leave early if you show that you have finished lab your lab attendant or if lab attendant calls time. If you are more than ten minutes late class, then your lab attendant reserves right not swipe you out for day. You may never swipe yourself out without your lab attendant’s consent. Any violation will result in a zero in lab attendance for semester. Due seating limitations, you are required go lab section you signed up for. If you wish go any other lab section, you may get permission from TA of another section go their section, provided that either: You will working on your laptop in room There is seating available where registered students get priority. You must email TA of that lab section beforehand. You can still get credit for attending a different section due special or occasional circumstances by making arrangements with graduate assistant (GA) at . However, you must change your registered lab if you start regularly going a different lab. Please contact Holly Bagwell in academic office (SC 1210) change your section without having drop your enrollment. We will never grant exemptions for lab attendance. If you have an interview, then you are just going have use your lab attendance drop. You also can not make up lab attendance. warned that forgetting swipe out is not a valid excuse—your lab attendant is not allowed vouch for your attendance. ","url":"/assignments/know_your_tools"},{"title":"Luscious Locks","content":"HW0You have already been assigned a HW0 for class, which is available on . We’ll spend first part of class going over various questions from HW0. Your grade for this lab is partly HW0 partly assignment below. DevelopmentRead learn about how set up your environment!Background GuideRead get started with course!Graded FilesOne section we will have on top of every assignment is a section called graded_files. These are files that we use grade assignment. git does not allow us set rest of files readonly prevent changing them (header files, Makefile). You have careful avoid changing these files. We are working on a system that prevents you from accidentally committing changes, but there is no easy way set permissions on your local copy. No exceptions: please make sure you’re only submitting modifications graded files listed. Background AssignmentYou are working for ShadyCorp Inc. , listening your favorite song, . Your boss discover’s that your competitor, ShadierCorp Inc. , has uploaded a safe your company’s production server. Your boss is curious wants know what’s in safe. Luckily you boss has a lockpick help you. Initial analysis of safe indicates that it has two modes: interactive mode file mode. Interactive mode use:File mode use:In interactive mode safe allows you directly provide input safe attempt unlock it. In file mode safe reads input line by line from specified file. In both of these modes safe will reset if given wrong input. Luckily you have a lockpick which will help you find correct input unlock safe.  lockpick can used as follows:This will launch GDB load safe debug symbols source code. Use your debugging skills figure out how unlock safe. Keep in mind that run a program in GDB with arguments you use r arg1 arg2 arg3 etc. , so run safe with your netid command would r &lt;netid&gt;. You should begin by running lockpick then starting safe with r &lt;netid&gt;. Read debugging guide section of docs for more information about how use GDB. Answer SubmissionThere is a file in your repository called submission. txt. You should provide answers each phase of safe in this file. Answers should separated by Unix newlines (\\n also known as line feed (LF)). For example if you think safe has three phases answers phases are answer1, answer2, answer3 then your submission. txt should look like:TestingYou can use your submission. txt file with safe’s file mode test your answers. If you have correct answers then Sucessfully unlocked safe! will printed. Make sure you use your own netid for everything in this assignment. We will grading your answers using your netid.  Outline Log into your VM Clone or Update your git repository on your VM Use lockpick figure out how unlock safe Add your answers submission. txt Submit your work via git:  git add submission. txt git commit -m \"My Submission\" (commit your work git).  git push origin main (push your committed work Github – Required for your changes visible Autograder).   CS 341 MakefileThere is no Makefile for this assignment, but all future assignment in this class will use a Makefile similar one which follows. It’s important have a basic understanding of how it works. Note: This is not a class about makefile programming, so you will not need know advanced parts of makefiles (pattern matching, expansion phases, etc). Still, it is important that you know a little bit about how they work for a future assignment. This looks scary, but if you Google some makefile basics carefully read comments it should start make sense. These are things you will need know, at minimum: Compile assignment: Clean up assignment directory: Compile a debug-able version of your code that you can use gdb on: Compile a release version of your assignment that you test with:Lab AttendancePart of your grade in this class relies on you attending labs. Towards end of every lab, we will ask you swipe out (swipe your i-card). You may only leave early if you show that you have finished lab your lab attendant or if lab attendant calls time. If you are more than ten minutes late class, then your lab attendant reserves right not swipe you out for day. You may never swipe yourself out without your lab attendant’s consent. Any violation will result in a zero in lab attendance for semester. Due seating limitations, you are required go lab section you signed up for. If you wish go any other lab section, you may get permission from TA of another section go their section, provided that either: You will working on your laptop in room There is seating available where registered students get priority. You must email TA of that lab section beforehand. You can still get credit for attending a different section due special or occasional circumstances by making arrangements with graduate assistant (GA) at . However, you must change your registered lab if you start regularly going a different lab. Please contact academic office (SC 1210) change your section without having drop your enrollment. We will never grant exemptions for lab attendance. If you have an interview, then you are just going have use your lab attendance drop. You also can not make up lab attendance. warned that forgetting swipe out is not a valid excuse—your lab attendant is not allowed vouch for your attendance. ","url":"/assignments/lockpicking_lab"},{"title":"Lovable Linux","content":"ECE 391 vs. CS 341A common point of contention among ECE CS majors: “Is CS 341 harder than ECE 391?”. This has probably been debated, since beginning of either course’s conception. Your TAs discussed this wanted settle this question once for all. ECE 391 is known for their killer semester long final project, which is building an operating system from scratch. Normally a 391 student is given 6 weeks 3 partners finish this assignment, but since 341 students are superior programmers we feel that 1. 5 weeks should plenty of time do this on your own. rest of documentation starter code is transcribed from actual assignment. IntroductionRead Whole document before you begin, or you may miss points on some requirements (for example, bug log). In this machine problem, you will work in teams develop core of an operating system. We will provide you withcode that boots you into protected mode, sets up GDT, LDT, initial TSS, maps a read-only file systemimage into physical memory for you. You must set up interrupt descriptor table (IDT), basic paging support fortasks, separate 4 MB pages for kernel applications, initialize a few devices, write system call interfacealong with ten system calls, provide support for six tasks from program images in file system which interface with kernel via system calls, multiple terminals basic scheduling.  goal for assignment is provide you with hands-on experience in developing software used interfacebetween devices applications, i. e. , operating systems. We have deliberately simplified many of interfaces reduce level of effort necessary complete project, but we hope that you will leave class with skillsnecessary extend implementation that you develop here along whatever direction you choose by incrementallyimproving various aspects of your system. Processor InitializationLoad GDTYou learned about global descriptor table (GDT) in class. Linux creates four segments in this table: Kernel CodeSegment, Kernel Data Segment, User Code Segment, User Data Segment. In x86_desc. S, starting at line 38, wehave created an empty GDT for you. Write code that makes an emulated Intel IA-32 processor use this GDT. We have marked a location in code (boot . 8line 27) at which you will need place this initialization code for GDT ensure that you follow correct bootsequence. You will need look through ISA Reference Manual for information about how write this code(https://courses. engr. illinois. edu/ece391/secure/references/IA32-ref-manual-vol-3. pdf)Initialize IDTYour IDT must contain entries for exceptions, a few interrupts, system calls. Consult x86 ISA manuals for descriptor formats please see Appendix D for more information. exception handler(s) should use printing support report errors when an exception occurs in kernel, should squash any user-level programthat produces an exception, returning control shell (the shell should not cause an exception in a working OS)-see System Calls (Appendix B) for further details. You will also need handle interrupts for keyboard RTC. Finally, you will need use entry ox8 0 for system calls, as described below. Initialize DevicesAdapt initialization code from Linux initialize PIC, keyboard, RT C. Set up a general-purposeinfrastructure similar what is done in Linux kernel. You need handle keyboard RT C interrupts, butyou also need make sure that these devices are initialized before taking interrupts. We suggest that you first maskout all interrupts on PIC, then initialize PIC, initialize devices, and, as part of each device’s initialization,enable its associated interrupt on PIC. handler addresses should installed dynamically/indirectly via a datastructure used by default handlers (as in Linux). You may also want review RT C data sheet linked from class web page. For checkpoint, your OS must execute test_interrupts handler (provided in lib. c) when an RTC interruptoccurs. When a keyboard interrupt occurs, you must echo correct characters screen. These simple tests willdetermine if you have IDT entries set up correctly, PIC enabled, devices initialized able generateinterrupts. Initialize PagingAs preparation for next steps in MP you must have paging enabled working. You will creating a page directory a page table with valid page directory entries (PDEs) page table entries (PTEs). More information about this process appears in Appendix C in Intel ISA manual linked from class web page.  image right shows how virtual physical memory are laid out for this checkpoint. keep things simple, kernel video memory will at same location in virtualmemory as they are in physical memory. Your kernel code is already loaded at 4 MB for you, so you need only map virtual memory 4-8 MB physical memory at 4-8 MB. This kernel page should a single 4 MB page, whereas first 4 MB of 4 MBmemory should broken down into 4 kB pages. In addition 8MB 4GB being marked not present, you should also set anyunused pages not present as well. In this layout everything in Kernel first 4MB, that isn’t page for video memory, should marked not present. Make sure that you align your pages (page directory page 8 MBtables) on 4 kB boundaries. align things in x86: align things in C:Troubleshooting/DebuggingSee Appendix G for more information about debugging common issues. HandinFor this handin, we expect you have written your own “blue screen” of death for each of exceptions. At aminimum, this screen must identify exception taken. You may also want read about how exceptions are handledin Intel ISA print more useful information, such as memory address reference that caused a page fault. This information will of use you later for debugging. We expect you able boot your operating systemwith paging turned on enter a halt loop or a while (1) loop. Then we expect you boot your operatingsystem explicitly dereference NULL demonstrate your “blue screen” identifying resulting page fault. Wealso expect you able press a key demonstrate that your operating system reaches test_interruptsfunction in on RTC interrupts, but you do not need write a full interrupt handler for RTC yet, merely show thatyou can receive interrupts. Finally, we expect your keyboard interrupt handler echo correct character screen, although where each character appears on screen doesn’t matter. As with RTC, you need not write afull interrupt handler for keyboard for this checkpoint. Device DriversCreate a Terminal DriverWhen any printable characters are typed at keyboard, they should displayed screen. This includes handlingall alphanumeric characters, symbols, shift capslock, but you do not need support number pad. You willnow need keep track of screen location for this purpose. You do need support vertical scrolling (but nothistory) will need interpret CTRL-L (non-printable key) as meaning “clear screen put cursor at top” which will make your testing experience more pleasant. You do also need support backspace line-bufferedinput. size of buffer should 128 characters for this checkpoint. For more details on how terminal read write functions should work, how handle buffer filling up, please see Appendix B. Keep in mind that you will also want have an external interface support delivery of external data terminaloutput. In particular, write system calls terminal should integrate cleanly with keyboard input. helloprogram in file system will eventually help test basics, but for now its source code will show you how userprograms will pass parameters your terminal. Parse Read-only File SystemYou will need support operations on file system image provided you, including opening reading fromfiles, opening reading directory (there’s only one-the structure is flat), copying program images intocontiguous physical memory from randomly ordered 4 kB “disk” blocks that constitute their images in filesystem. source code for our 15 program will show you how reading directories is expected work. Also seeAppendix A for an overview of file system as well as Appendix B for how each function should work.  Real-Time Clock DriverYou will need write open, read, write, close functions for real-time clock (RTC) demonstratethat you can change clock frequency. You will need do some research on how RTC works what device driver needs do communicate with it. Virtualizing RT C is not required, but does make testing easierwhen you run multiple programs with RT C open. Again, see Appendix B for how each function should work. HandinFor this handin, you will need demonstrate that your open, read, write functions for three device driverswork correctly. This functionality is independent of how your operating system may use devices, but it is a goodidea for you start thinking about how you want interface these functions with corresponding system calls (seeAppendix B). You will need show that when a key is pressed, keyboard driver stores corresponding letter in a buffer thatby explicitly calling keyboard read function you can receive correct letters print them out on screen. Similarly, you will need demonstrate that you can change rate of RT C clock using write function that read function returns after an interrupt has occurred. A good way of doing so is by having RT C interrupthandler increment a counter write a specific spot on screen. Finally, you will need demonstrate that you can read from read-only file system. A good check for this testis use xxd command, which prints a hexadecimal dump, compare output of your file system code with bytes stored in file system image. Please note that you should run xxd on filesys_img not individualexecutables; as your code reads from filesystem image, its output might not directly match that of xxd run on individual executables. For handin, you must have some test/wrapper code that given a filename, a buffer, abuffer length, will read data from given file into buffer. System Calls TasksSupport System CallsEventually, all ten system calls must supported via a common IDT entry, so you will have set up some genericassembly linkage along lines of that used in Linux, including syscall value checking, register save restore, a jump table C functions that implement system calls themselves. details of each call are provided inAppendix B. For this checkpoint, you only need support system calls necessary run testprint from shell: execute,halt, open/close/read/write for terminal filesystem. TasksPrograms execute completion, so you need not write a scheduler or deal with timer chip yet, but you do need able squash programs if they generate exceptions, returning control shell in such cases. As in Linux, tasks will share common mappings for kernel pages, in this case a single, global 4 MB page. UnlikeLinux, we will provide you with set physical addresses for images of two tasks, will stipulate that theyrequire no more than 4 MB each, so you need only allocate a single page for each task’s user-level memory. SeeAppendix C for more details. Support A LoaderExtend code for your file system driver copy a program image from randomly ordered 4 kB “disk” blocksconstituting image in file system into contiguous physical memory. This process is normally performed by a program loader in cooperation with OS, but in your case will performedcompletely within kernel, since file system code control of memory is internal. In addition, you will need set up stack properly then return into user-level, since privilege level 0 cannot calldown into privilege level 3, your user-level code must execute at lower privilege level. Executing User-level CodeKernel code executes at privilege level 0, while user-level code must execute at privilege level 3. x86 processordoes not allow a simple function call from privilege level 0 code privilege level 3, so you must use an x86-specificconvention accomplish this privilege switch.  convention use is IRET instruction. Read ISA reference manual for details of this instruction. Youmust set up correct values for user-level EIP, CS, EFLAGS, ESP, SS registers on kernel-mode stack, then execute an IRET instruction. processor will pop values off stack into those registers, by doingthis, will perform a privilege switch into privilege level specified by low 2 bites of CS register. valuesfor CS SS registers must point correct entries in Global Descriptor Table that correspond user-mode code stack segments, respectively. EIP you need jump is entry point from bytes 24-27 of executable that you have just loaded. Finally, you need set up a user-level stack for process. For simplicity,you may simply set stack pointer bottom of 4 MB page already holding executable image. Two finalbits: DS register must set point correct entry in GDT for user mode data segment (USER_DS)before you execute IRET instruction (conversely, when an entry into kernel happens, for example, through asystem call, exception, or interrupt, you should set D8 point KERNEL_DS segment). Finally, you will need modify TSS; this is explained in Appendix E. Process Control Block next piece support tasks in your operating system is per-task data structures, for example, process controlblock (PCB). One bit of per-task state that needs saved is file array, described earlier; another is signalinformation. You may need store some other things in process control block; you must figure rest out onyour own. final bit of per-task state that needs allocated is a kernel stack for each user-level program. Sinceyou only need support two tasks, you may simply place first task’s kernel stack at bottom of 4 MB kernelpage that you have already allocated. second task’s stack can then go 8 kB above it. This way, both tasks will have8 kB kernel stacks use when inside kernel. Each process’s PCB should stored at top of its 8 kB stack, stack should grow towards them. Since you’ve put both stacks inside 4 MB page, there is no need “allocate”memory for process control block. get at each process’s PCB, you need only AND process’s ESP registerwith an appropriate bit mask reach top of its 8 kB kernel stack, which is start of its PCB. Finally, when anew task is started with execute system call, you’ll need store parent task’s PCB pointer in child task’sPCB so that when child program calls halt, you are able return control parent task. Completing System Calls TasksFor this handin, we expect that you have all of system calls working that all of programs we have provided you will execute without problems. You are also expected handle multiple “shell” case where you executea shell from first shell. Just for this checkpoint, you can assume a maximum of two programs. Further programsshould not allowed run. You can exit shells by typing “exit”, return previous shell. You will also expected able answer questions about how you got various system calls work about task structuresthat you created. SchedulingFor final due date, following functionality must implemented:Multiple Terminals Active TasksAs you may already know, it is possible switch between different terminals in Linux using ALT+Function-Keycombination. You will need add a similar feature by running several instances of shell executable. You mustsupport three terminals, each associated with a different instance of shell. As an example, pressing ALT+F2 whilein first terminal must switch active task of second terminal. Further, you must support up six processesin total. For example, each terminal running shell running another program. For other extreme, have 2 terminalsrunning 1 shell have 1 terminal running 4 programs (a program on top of shell, on top of shell, etc). In order support notion of a terminal, you must have a separate input buffer associated with each terminal. Inaddition, each terminal should save current text screen cursor position in order able return correctstate. Switching between terminals is equivalent switching between associated active tasks of terminals. Finally, your keyboard driver must intercept ALT+Function-Key combinations perform terminal switches. Lastly, keep in mind that even though a process can interrupted in either user mode or in kernel mode (while waitingin a system call). After interrupt, processor will in kernel mode, but data saved onto stack dependson state before interrupt. Each process should have its own kernel stack, but careful not implicitly assumeeither type of transition. SchedulingUntil this point, task switching has been done by either executing a new task or by halting an existing one returning parent task. By adding a scheduler, your OS will actively preempt a task in order switch next one. YourOS scheduler should keep track of all tasks schedule a timer interrupt every 10 50 milliseconds in order switch next task in a round-robin fashion. When adding a scheduler, it is important keep in mind that tasks running in an inactive terminal should not write screen. In order enforce this rule, a remapping of virtual memory needs done for each task. Specifically, page tables of a task need updated have a task write non-display memory rather than display memorywhen task is not active one (see previous section). If task belongs active terminal, video memory virtual address should mapped physical videomemory address. Otherwise, these virtual addresses must map into different physical pages allocated as a backingstore for task’s screen data. These backing pages are then written whenever task calls write on standardoutput. Eventually, when user makes task’s terminal active again, your OS must copy screen data from backing store into video memory re-map virtual addresses point video memory’s physical address. HandinFor this final handin, we expect you demonstrate that multiple terminals work by switching between active terminals. We will execute a program on one screen, switch another screen, start another program, then expect able switch back forth see programs running. For scheduling, we expect that programs running in background(on an inactive terminal) will make progress. For example, we expect a fish program running on such a terminal continue despite not actually being displayed on screen. Bells Whistle following is OPTIONAL is only for fun:SignalsAdd support for delivery of five different signals a task. Appendix F details specifications implementationdetails make this work. Dynamic Memory AllocationCreate a dynamic memory allocator (such as malloc). This can done by simply keeping track of where free pagesare using some method, then creating a malloc system call that adds a new page program’s page table or pagedirectory. Remember that implementing dynamic memory will not get you any extra credit if you don’t have a way of demoing functionality. For example, writing a short user program or some kind of kernel-level functionality. Other IdeasGo wild, find something interesting add your operating system explain it. We will consider difficulty ofany addition when determining whether how much extra credit is merited. For example, don’t expect a huge gradeincrease for adding color support for text. Appendix A: File SystemFile System Utilities figure below shows structure contents of file system. file system memory is divided into 4 kBblocks. first block is called boot block, holds both file system statistics directory entries. Both statistics each directory entry occupy 64B, so file system can hold up 63 files. first directory entryalways refers directory itself, is named “. ”, so it can really hold only 62 files. Each directory entry gives a name (up 32 characters, zero-padded, but not necessarily including a terminal EOSor O-byte), a file type, an index node number for file. File types are 0 for a file giving user-level access real-time clock (RTC), 1 for directory, 2 for a regular file. index node number is only meaningful forregular files should ignored for RTC directory types. Each regular file is described by an index node that specifies file’s size in bytes data blocks that make up file. Each block contains 4 kB; only those blocks necessary contain specified size need valid, so carefulnot read make use of block numbers that lie beyond those necessary contain file data.  three routines provided by file system module return -1 on failure, indicating a non-existent file or invalidindex in case of first two calls, or an invalid inode number in case of last routine. Note that directoryentries are indexed starting with 0. Also note that read_data call can only check that given inode is within valid range. It does not check that inode actually corresponds a file (not all inodes are used). However, if a baddata block number is found within file bounds of given inode, function should also return -1. When successful, first two calls fill in dentry_t block passed as their second argument with file name, filetype, inode number for file, then return 0. last routine works much like read system call, reading up length bytes starting from position off set in file with inode number inode returning number of bytesread placed in buffer. A return value of 0 thus indicates that end of file has been reached. File System AbstractionsEach task can have up 8 open files. These open files are represented with a file array, stored in process controlblock (PCB). integer index into this array is called a file descriptor, this integer is how user-level programsidentify open file. This array should store a structure containing:  file operations jump table associated with correct file type. This jump table should contain entriesfor open, read, write, close perform type specific actions for each operation. open is used forperforming type specific initialization. For example, if we just open’d RTC, jump table pointer in thisstructure should store RTC’s file operations table.    inode number for this file. This is only valid for data files, should 0 for directories RTCdevice file.    A “file position” member that keeps track of where user is currently reading from in file. Every readsystem call should update this member.    A “flags” member for, among other things, marking this file descriptor as “in-use. ” When a process is started, kernel should automatically open stdin stdout, which correspond file descriptors O 1, respectively. stdin is a read-only file which corresponds keyboard input. stdout is a write-onlyfile corresponding terminal output. “Opening” these files consists of storing appropriate jump tables in these twolocations in file array, marking files as in-use. For remaining six file descriptors available, an entry in file array is dynamically associated with file being open‘d whenever open system call is made (return -1 if array is full). Appendix B: System CallsYou must support ten system calls, numbered 1 through 10. As with Linux, they are invoked using int 0x80, use a similar calling convention. In particular, call number is placed in EAX, first argument in EBX, thenECX, finally EDX. No call uses more than three arguments, although you should protect all of registers frommodification by system call avoid leaking information user programs. return value is placed in EAXif call returns (not all do); a value of -1 indicates an error, while others indicate some form of success. Prototypes appear below. Unless otherwise specified, successful calls should return 0, failed calls should return - 1.  int32_t halt (uint8_t status); int32_t execute (const uint8_t* command); int32_t read (int32_t fd, void* buf, int32_t nbytes); int32_t write (int32_t fd, const void* buf, int32_t nbytes); int32_t open (const uint8-t* filename); int32_t close (int32_t fd); int32_t getargs (uint8_t* buf, int32_t nbytes); int32_t vidmap (uint8_t** screen_start); int32_t set_handler (int32_t signum, void* handler_address); int32_t sigreturn (void); execute system call attempts load execute a new program, handing off processor new programuntil it terminates. command is a space separated sequence of words. first word is file name of program executed, rest of command stripped of leading spaces should provided newprogram on request via getargs system call. execute call returns -1 if command cannot executed,for example, if program does not exist or filename specified is not an executable, 256 if program dies by anexception, or a value in range 0 255 if program executes a halt system call, in which case value returnedis that given by program’s call halt.  halt system call terminates a process, returning specified value its parent process. system call handleritself is responsible for expanding 8-bit argument from BL into 32-bit return value parent program’sexecute system call. careful not return all 32 bits from EBX. This call should never return caller.  read system call reads data from keyboard, a file, device (RTC), or directory. This call returns numberof bytes read. If initial file position is at or beyond end of file, 0 shall returned (for normal files directory). In case of keyboard, read should return data from one line that has been terminated by pressingEnter, or as much as fits in buffer from one such line. line returned should include line feed character. In case of a file, data should read end of file or end of buffer provided, whichever occurssooner. In case of reads directory, only filename should provided (as much as fits, or all 32 bytes), subsequent reads should read from successive directory entries until last is reached, at which point read shouldrepeatedly return 0. For real time clock (RTC), this call should always return 0, but only after an interrupt hasoccurred (set a flag wait until interrupt handler clears it, then return 0). You should use a jump table referencedby task’s file array call from a generic handler for this call into a file type specific function. This jump tableshould inserted into file array on open system call (see below).  write system call writes data terminal or a device (RTC). In case of terminal, all data should displayed screen immediately. In case of RTC, system call should always accept only a 4-byteinteger specifying interrupt rate in Hz, should set rate of periodic interrupts accordingly. Writes regularfiles should always return -1 indicate failure since file system is read only. call returns number of byteswritten, or -1 on failure.  RTC device itself can only generate interrupts at a rate that is a power of 2 (do a parameter check), onlyup 8192 Hz. Your kernel should limit this further 1024 Hz - an operating system shouldn’t allow userspace programs generate more than 1024 interrupts per second by default. Look at drivers/char/rtc. c,include/linux/mc146818rtc. h possibly other associated header files for macros port numbers forinterfacing with RTC device. Note that you should using RTC’s Periodic Interrupt function generate interrupts at a programmable rate. RTC interrupt rate should set a default value of 2 Hz (2 interrupts per second) when RTC device is opened. For simplicity, RTC interrupts should remain on at all times.  open system call provides access file system. call should find directory entry corresponding named file, allocate an unused file descriptor, set up any data necessary handle given type of file (directory,RT C device, or regular file). If named file does not exist or no descriptors are free, call returns -1.  close system call closes specified file descriptor makes it available for return from later calls open. You should not allow user close default descriptors (O for input l for output). Trying close an invaliddescriptor should result in a return value of -l; successful closes should return 0.  getargs call reads program’s command line arguments into a user-level buffer. Obviously, these argumentsmust stored as part of task data when a new program is loaded. Here they are merely copied into user space. If arguments a terminal NULL (O-byte) do not fit in buffer, simply return -1. shell does not requestarguments, but you should probably still initialize shell task’s argument data empty string.  vidmap call maps text-mode video memory into user space at a preset virtual address. Although addressreturned is always same (see memory map section later in this handout), it should written into memorylocation provided by caller (which must checked for validity). If location is invalid, call should return -1. avoid adding kernel side exception handling for this sort of check, you can simply check whether address fallswithin address range covered by single userlevel page. Note that video memory will require you addanother page mapping for program, in this case a 4 kB page. It is not ok simply change permissions of video page located &lt; 4MB pass that address.  set_handler sigreturn calls are related signal handling are discussed in section Signals below. Even if your operating system does not support signals, you must support these system calls; in such a case, however,you may immediately return failure from these calls. Note that some system calls need synchronize with interrupt handlers. For example, read system call made on RTC device should wait until next RTC interrupt has occurred before it returns. Use simple volatile flag variables do this synchronization (e. g. , something like int rtc_interrupt_occurred;) when possible (try something more complicated only after everything works!), small critical sections with cli/sti. For example, writing RT C should block interrupts interact with device. Writing terminal also probably needs blockinterrupts, if only briefly, update screen data when printing (keyboard input is also printed screen from interrupt handler). Appendix C: Memory Map Task SpecificationWhen processing execute system call, your kernel must create a virtual address space for new process. This will involve setting up a new Page Directory with entries corresponding figure shown on right. virtual memory map for each task is show in figure. kernel is loaded at physical address 0x400000 (4 MB), 128MB also mapped at virtual address 4 MB. A global page directory entry with its Supervisor bit set should set up map kernel virtual address ox400000 (4 MB). This ensures that kernel, which is linked run with its starting address at 4 MB, will continue work even after paging is turned on.  make physical memory management easy, you may assume there is at least 16 MB of physical memory on system. Then, use following (static) strategy: first user-level program (the shell) should loaded at physical 8 MB, second user-level program, when it is executed by shell, should loaded at physical 12 MB. program image itself is linked execute at virtual address 0x08048000. way get this working is set up a single 4 MB page directory entry that maps virtual address 0x08000000 (128 MB) right physical memory address (either 8 MB or 12 MB). Then, program image must copied correct offset (0x00048000) within that page. Both kernel mapping user-level program mapping are critical; memory references in neither kernel nor program will not work correctly unless they are mapped at these exact addresses.  layout of executable files in file system is simple: entire file stored in file system is image of program executed. In this file, a header that occupies first 40 bytes gives information for loading starting program. first 4 bytes of file represent a “magic number” that identifies file as an executable. These bytes are, respectively, 0: 0x7f; 1: 0x45; 2: 0x4c; 3: 0x46. If magic number is not present, execute system call should fail. other important bit of information that you need execute programs is entry point into program, i. e. , virtual address of first instruction that should executed. This information is stored as a 4-byte unsigned integer in bytes 24-27 of executable, value of it falls somewhere near 0x08048000 for all programs we have provided you. When processing execute system call, your code should make a note of entry point, then copy entire file memory starting at virtual address 0x08048000. It then must jump entry point of program begin execution. details of how jump this entry point are explained in next section. Appendix D: System Calls, Exceptions, InterruptsRecall that when a hardware interrupt is asserted or a hardware exception is detected, a specific number is associatedwith exception or interrupt differentiate between different types of exceptions, or different hardware devices (forexample, differentiating between keyboard interrupt, network card interrupt, a divide-by-zero exception). This number is used index a table, called Interrupt Descriptor Table, or IDT. format of an IDT entry isshown in figure below, details of it are found in Intel architecture manuals (see “Getting Started”section for more info on references). Each IDT entry contains, among other things, a pointer correspondinginterrupt handler function run when that interrupt is received. When an exception or hardware interrupt isdetected, processor switches into privilege level 0 (kernel mode), saves some, but not all of processor registerson kernel stack (see Appendix E for more details), jumps function address specified in entry. Now,kernel code, specifically interrupt handler for correct interrupt number, is now executing. For system calls, you will use a similar mechanism. A user-level program will execute a int $0x80 instruction. int instruction functions similar an exception. It specifies that processor should use entry 0x80 in IDTas handler when this instruction is executed. same privilege-level switching, stack switching, etc, are allperformed, so after this instruction is run, kernel code will executing. You must set up a “system call handler” IDTentry at index ox80, as well as a function that will run for all system calls. This function can then differentiatedifferent system calls based on parameter passed in EAX. For this work properly, you must pay attention a few details of x86 architecture protection scheme when setting up IDT. IDT will contain entries for exception handlers, hardware interrupthandlers, system call handler. Each entry in IDT has a Descriptor Privilege Level (DPL) that specifies privilege level needed use that descriptor. Hardware interrupt handlers exception handlers should have their DPL set 0 prevent user-level applications from calling into these routines with int instruction. system call handler should have itsDPL set 3 so that it is accessible from user space via int instruction. Finally, each IDT entry also contains asegment selector field that specifies a code segment in GDT, you should set this field kernel’s codesegment descriptor. When x86 sees that a new CS is specified, it will perform a privilege switch, handlerfor IDT entry will run in new privilege level. This way, system call interface is accessible user space but code executes in kernel. Appendix E: Stack Switching TSS last detail of user space kernel transitions on system calls, interrupts, or exceptions is stack switching. stackswitch is taken care of by x86 hardware. x86 processor supports notion of a task; this hardware support isencapsulated in a Task State Segment, or TSS. You will not use full x86 hardware support for tasks in this project,but x86 requires that you set up one TSS for, among other things, privilege level stack switching. TSS in given code is a placeholder. Read Intel manuals for details on fields in it; important fields are 880 ESPO. These fields contain stack segment stack pointer that x86 will put into SS ESP when performinga privilege switch from privilege level 3 privilege level 0 (for example, when a user-level program makes a systemcall, or when a hardware interrupt occurs while a user-level program is executing). These fields must set point kernel’s stack segment process’s kernel-mode stack, respectively. Note that when you start a new process,just before you switch that process start executing its user-level code, you must alter TSS entry containits new kernel-mode stack pointer. This way, when a privilege switch is needed, correct stack will set up by x86 processor. Appendix F: SignalsFor extra credit, your OS can provide an infrastructure for user-level signals, similar Linux. table details signals that will supported.    Signal Name Signal Number Default Action     DIV_ZERO 0 Kill Task   SEGFAULT 1 Kill Task   INTERRUPT 2 Kill Task   ALARM 3 Ignore   USER1 4 Ignore   set_handler system call changes default action taken when a signal is received: signum parameterspecifies which signal’s handler change, handler-address points a user-level function run whenthat signal is received. It returns 0 if handler was successful set, -1 on failure. If handler-address is NULL(zero), kernel should reset action taken default action. DIV_ZERO should sent a task when x86 processor generates a divide-by-zero exception while executinguser-level code. SEGFAULT should sent when any other exception occurs, including any illegal instructions, illegalmemory references, page faults, general protection faults, illegal opcodes, etc. INTERRUPT signal should sentwhen a CT RL+C is pressed on keyboard. ALARM signal should sent currently-executing task (thereis only one currently-executing task in this OS) every 10 seconds. This should implemented by knowing at whatrate RTC’s Periodic Interrupts occur, counting how many Periodic Interrupts have occurred, sending an ALARMsignal after 10 seconds have elapsed. Finally, USER1 is user-defined can used implement any other signal ofyour choosing. Signals should only delivered a task when returning user space from kernel, so you’ll want add somecode in your return-to-user space linkage check for pending signals. support signal delivery, you should use amechanism similar what Linux uses:  Mask all other signals.    Set up signal handler’s stack frame. You’ll need current value of user-level ESP register find user’s current stack location. signal handler stack frame goes directly above this on stack. signal handler stack frame is shown in Figure 1. Setting up signal handler stack frame involves: copyinga return address a signal number parameter user-level stack, copying process’s hardware context(see Figure 2) from point when program was interrupted for signal, copying a small amount ofassembly linkage user-level stack that calls sigreturn when signal handler is finished.    Finally, execute (in user space) handler specified in signal descriptor. No other information needs passed signal handler (no siginfo_t structure like modern Linux signals).  When user-level signal handler returns, it will use return address you have copied on its stack, which will jump assembly linkage (also on stack). This assembly linkage should make sigreturn system call (using standard int $0x80 user-level system call calling convention).  sigreturn system call should copy hardware context that was on user-level stack back onto processor. find hardware context, you will need know user-level value of ESP (will saved by your system callhandler) as well as exact setup of user-level stack frame. copy hardware context back onto processor,you will actually overwrite kernel’s copy of process’s hardware context that was saved on kernel stack whenit handled sigreturn system call. In this way, when sigreturn system call handler returns user space, hardware context will automatically copied back onto processor by your return-from-kernel code that youhave already written. One thing careful of: you’ll probably have system calls set up return a value (in EAX) user space. sure you don’t clobber user’s EAX value from its hardware context with a bogus “return value”From sigreturn - have sigreturn return hardware context’s EAX value so that you won’t have special-case return from sigreturn. Shown in Figure 2 is a slightly-modified version of struct pt_regs structure that Linux uses for its hardwarecontext; this modified structure is what you should use in this MP. “Error Code / Dummy” field has been added hardware context simplify exception handling. For some exceptions, processor pushes an error code onto stack after XCS (for example, page faults do) whereas other exceptions do not (divide-by-zeros do not). For exceptionsthat do not push this error code, your exception handler should push a dummy value take up error code slot3. x86 interrupts never push error code, so you must also push a dummy value in all of your interrupt handlers system call handler. You can find documentation about which exceptions push error codes (and much more aboutexceptions) in Volume 11: System Programming of Intel ISA manual on Tools, References, Links sectionof website. Finally, signal handling information should go in process control block (PCB). You will need keep track ofpending signals, masked signals, handler actions / addresses for each signal. Much information on Linux’s implementation of signals (which your implementation will closely match) can found in Understanding Linux Kernelchapter 10. Alternative (with video)Please watch this before you begin. There is no lab assignment, just do review. It will not graded. ","url":"/assignments/lovable_linux"},{"title":"Mad Mad Access Pattern","content":"Mapping InventoryHere’s () introduction this assignment. You’ve landed an internship at Zing!, a search enginestart-up. Your first project is develop a keyword advertisementinventory tool. Advertisers can “buy” keywords such that their ad is shown whenevera user does a search that contains one of their keywords. For example,if a user searches for “stapler”, they will see ads for an office supplycompany who bought that keyword. Before buying a keyword, advertisers want know, “How much will thiscost me?” compute that, they’ll need know how often keywordis searched for, how valuable word is. For example “how” isa very common word but has little value. “Donate” is less common buthighly valuable, because a user searching for “donate” is probably willing do so.  intern before you scanned through a large volume of search logs determine frequency value of each word. Your job is perform efficient searches on data file she created. This file isexpected grow very large, larger than will fit in memory, soyou will need access it without reading it all into memory. Data File Structure file is structured like a binary search tree, where each tree nodeis an instance of this structure: first 4 bytes of input file are letters “BTRE”. Anyfile which does not start with these 4 bytes is an invalid data file. root node is stored at offset 4 in file. Each uint32_t float is stored in little-endian format (the same as processorsyour VMs use, so no conversion will necessary). “word” is an arrayof ASCII characters at end of each structure, it is anull-terminated string. There is no limit on length of a word in file or length of words your program will look up. Remember properties of a binary search tree: if a node has a leftchild, that child’s value is less than node. If it has a right child,that child’s value is greater than node. Comparison among nodes in this assignment is defined by their word’s int strcmp(const char *s1, const char *s2). In other words:Note that none of binary search trees we give you will have duplicate keys. FilesYou’ll given: tree. h - contains struct definition above a detailed description of data in sample. data Makefile - makefile you should use build lookup1 lookup2 sample. data - a small file containing words “sample”, “word”, “list”, “for”, “this”, “program” utils. h - Printing functions for you use input_file - Sample input create_file executable.  create_file - Creates binary tree structured data file corresponding input_file. This will used for your test cases.  print_file - Prints out human readable form of binary tree structured file from above. Make two versions of your program. Both should produce same results, but using different file access methods. Version 1: fseek / freadWhen reading a node from file, use fseek() jump correct position read node with fread() and/or fgetc(). You may not use mmap() for this part. Put code for this in lookup1. c. Version 2: mmapUse mmap() map entire file into memory withoutreading any part of file directly. When reading a node from memory mapped file, usepointer arithmetic jump correct position read nodeusing regular pointer dereferencing. Put code for this in lookup2. c. Notice that you can use only mmap() map WHOLE file for this version. Do not use other functions read files. Sample usageTesting notes You are given reference files! Compare your outputs with . /lookup1-reference . /lookup2-reference :) Write your test cases include comparison of performance between two versions (lookup1 lookup2). Think about which one is faster why.  In order generate different binary tree structured data files based on input required for each test case, use create_data executable. See input_file for sample input this executable.  print_file executable will provide a human readable form of a binary tree structured data file generated from create_data. Error cases: If run with less than 2 arguments, your program should print an errormessage describing arguments it expects exit with error code 1.  If data file cannot read or first 4 bytes are not“BTRE”, print a helpful error message exit with error code 2.  If a call mmap fails (for version 2), print a helpful error message exit with error code 3.  Helper functions for above error cases can found in utils. h. For each word that is found, print its count its price, where price is always printed with exactly two digits right of decimalpoint. ","url":"/assignments/mad_mad_access_pattern"},{"title":"Malloc","content":"BackstoryWell, color me impressed! Your shell was so fancy that you actually received that pay raise! However, you may have gone too far with your shell. Your boss is now so impressed at your skills that they sent you \\(n\\)th Inter-Company Turbo Malloc Contest - even though you’re just a new hire! But hey, a business trip doesn’t sound that bad, right?Upon arriving at competition venue, you realize that all your peers from CS 341 are in contest! Apparently, all of them went too far with their shells as well, ended up in same scenario as you. Just as you were reminiscing about your time in CS 341, you received an email from your senpai in company about contest, your face turns pale immediately. Turns out, Inter-Company Turbo Malloc Contest is official:tm: way tech companies compete with each other these days - winning competition guarantees fame glory for company, losing companies will suffer shame embarassment. What’s more, any company that cannot beat baseline will incur severe stock drops! Needless say, losing competition will ruin all your efforts in past weeks impress your boss, if you fail beat baseline, you will probably lose your job, again (and this time, everyone will know your failures, since this contest is heavily publicized).  competition lasts for two weeks, you get total freedom on your implementation. This time, you’ve decided not procrastinate, since your entire livelihood hinges on how well you perform in this competition. Can you out-think every other contestant’s implementations secure that epic victory royale?OverviewYou should write your implementations of calloc, malloc, realloc, free in alloc. c. alloc. c will only file we test. Don’t modify mcontest. c, contest. h, or contest-alloc. so. Those files create environment that replaces standard glibc malloc with your malloc. These files will used for testing. Your malloc must allocate heap memory using sbrk. You may not use files, pipes, system shared memory, mmap, a chunk of pre-defined stack memory, other external memory libraries found on Internet, or any of various other external sources of memory that exist on modern operating systems. You can find more information in coursebook entry. Malloc C ; Chicago Blues StyleImplementing a heap allocator is a challenging assignment that has been known rewire students’ brains. For inspiration, please listen this (). A Bad ExampleMemory allocation seems like a mystery, but in actuality, we are making a wrapper around system call . Here’s a really simple implementation of malloc:As you can see, when we request size bytes of memory, we call sbrk(size) increase heap by size bytes. Then, we return a pointer this memory, we’re done. Simple!Here is our implementation of free:This is a “correct” way implement free. However, obvious drawback with our implementation is that we can’t reuse memory after we are done with it. Also, we have not checked for errors when we call sbrk, we have not implemented realloc or calloc. Despite all of this, this is still a “working” implementation of malloc. So, job of malloc is not really allocate memory, but keep track of memory we’ve allocated so that we can reuse it. You will use methods that you’ve learned in class practiced in mini_memcheck lab do this. Debugging TipsMagic TagsAdding a magic tag is a great way quickly diagnose issues you find when stepping through your code in GDB. if you add a “magic” tag your metadata:Then in every function that modifies your block, you can update magic a unique value. For example, in malloc, you can set magic 0x1111 if you’re allocating new memory, or 0x2222 if you are assigning an existing free block. In your split coalesce, you can choose different magic values as well. Now, when debugging through GDB, if you notice a block is invalid, you can quickly determine what last changed it narrow down your search. You can also get more creative with magic tag if you want to, keeping track of any information you’d like. If you’re worried about performance, you can wrap magic tag in preprocessor definitions like this:Then, changing define line #define MAGIC_DEBUG 1 will enable magic tag, but otherwise it will disabledHeap Checker (REQUIRED FOR OH)New this semester, aid in your debugging, we are asking you write a heap checker. receive help at office hours, course staff will ask see if anything in your heap checker is failing before debugging specific bugs.  heap checker is a way ensure consistency between actual heap, any of internal data structures that you maintain. As such, heap checker should check maintain some set of invariants, suggestions are listed below. invariants design of your heap checker will depend on specifics of your malloc implementation. Suggested invariants: Heap Invariants:  Confirm that header footers store consistent data If coalescing is implemented, confirm that there are no two consecutive free blocks in heap   List Invariants:  Check that list pointers are consistent (if A-&gt;next == B, then B-&gt;prev == A) Check that all list elements are within heap bounds Confirm that number of free blocks match up with number of free blocks in heap If using a free list, confirm that every block in list is actually free If using a segregated list, confirm that all elements in list are of appropriate size  There are many other things you can check confirm that your malloc implementation is staying consistent, but these are a good starting point should help you catch majority of bugs. You do not need implement check every invariant, but doing so will save significant time in avoiding heap corruption whenever you make a change your malloc implementation. Course staff will ask see your heap checker, may suggest adding invariants if you are running into a bug have not covered everything. following section outlines an example heap checker aid you in writing your own:Example Heap CheckerThis heap checker will assume that you have store a list of every allocated block. First, near top of your alloc. c, we define some preprocessor macros so that we can enable disable heap checking:When HEAP_CHECKER is defined 1, calling heap_check() will call a function heap_checker with current line number, if function returns 0, it will terminate early. For testcases that do a lot of allocations, this will slow, so you can disable heap_check by changing line #define HEAP_CHECKER 0; this will make any calls heap_check() do nothing. Now, we can define heap_checker function:This example iterates from start of heap, which we must initialize elsewhere, until sbrk(0), at every step along way, it counts number of free blocks. This relies on implementation of a get_next_mem function, which moves from current metadata block next one in physical memory. implementation of get_next_mem will depend on how you structure your blocks in memory, consult course book for examples! Then, heap checker loops over our list of blocks, counts how many nodes are marked free. If these numbers do not align, heap_checker prints an error message with line number, returns 0, or false.  initialize start_of_heap, we can call sbrk(0) at first malloc call as such:Now, you can place calls heap_check at beginning end of every function you’d like analyze, this will ensure that invariants are held throughout your function calls.  reiterate, course staff will ask you demonstrate your heap checker if you are asking for help in office hours!!! Important Note: In above heap checker example, metadata struct was implemented with its next pointer pointing next physically adjacent block. This does NOT mean that you must implement your metdata struct or next pointer in this way - this was a simple example we created demonstrate how you may use a heap checker. You are allowed (and encouraged) design implement a different implementation of metadata struct improve performance. Testing Your CodeIn order run your solution on testers, run . /mcontest with tester you want. You must do this, or your code will run with glibc implementation!Example:We’ve also distributed a bash script run_all_mcontest. sh run all testers. We design script so that you caneasily test your malloc implementation. Here is how you use script:It will automatically make clean make again, then run each test case in testers folder. If you want skipsome test cases, you can do:where 1, 2, 3 are tests you want skip. You can skip as many as you like. Here is what some of our error codes mean:Good PracticesSince you can implement your malloc in whatever way you want, you may end up with a huge chunk of messy code that’s hard debug. Here are some suggestions for organizing maintaining your code better: Build simple functions before you add advanced features. In other words, make sure your program does what you want it do before moving on optimize it.  Separate functionality of your program into smaller chunks of independent code. For example, if you find that you’re frequently splitting a block of memory into two blocks, you probably want write a split function instead of copy-pasting splitting code every time you need split.  Keep your code readable. This can naming your variables appropriately or commenting your code well. This will really help you understand what your code is doing when you look back at them three days later!Debugging with GDB. /mcontest runs an optimized version of your code, so you won’t able debug with gdb. solve this, we have provided another version called . /mreplace which uses a version of your malloc compiled without optimization, so you can debug with gdb. Here’s an example, running tester 2 with gdb:Since . /mreplace calls fork, you need change follow-fork-mode in gdb able set a breakpoint in your alloc. c:Note: if you terminate your running program run it again, i. e. if you do this:it will no longer use your own implementation, therefore will not stop at breakpoints you set, will use glibc implementations of malloc/calloc/etc. This is because of way gdb handles dynamically loaded libraries. Real ProgramsBoth mcontest mreplace can used launch “real” programs (not just testers). For example:orThere are some programs that might not work correctly under your malloc, for a variety of reasons. You might able avoid this problem if you make all yourglobal variables static. If you encounter a program for which this fix doesn’t work, post on Ed!GradingHere is grading breakdown: Correctness (75%)  Part 1 (25%): tests 1-6 complete successfully.  Part 2 (50%): tests 1-12 complete successfully.    Performance (25%): Points only awarded if all part 2 testers completesuccessfully - due with part2There are 12 testcases in total. For part 1, you will graded using tests 1through 6. For part 2, you will graded using tests 1 12 (tests 1 through 6get graded twice). Tester 13 is not graded. There are also performance points, which you are only eligible for if you passall testcases. Your malloc will compared against glibc version ofmalloc, given a base performance score as a percentage (accounting forruntime, maximum memory usage, average memory usage). base score iscalculated using formula from contest section below; higher percentagesare better. Performance points are then awarded in buckets: Better than or equal 85% of glibc: Full 25% awarded.  75-85% (include 75%, exclude 85%): 20% awarded.  60-75%: 15% awarded.  40-60%: 10% awarded.  40% worse: 0% awarded. So, let’s work out some scenarios: Scenario 1: A student gets tests 1 through 6 working for part1 misses 2tests on part2. Then they get all of correctness points for part1, 10/12of correctness points for part2 none of performance points. Thusthis student will receive a (6 / 6) * 25 + (10 / 12) * 50 + 0 = 66. 67%.  Scenario 2: A student gets none of tests working for part1 getseverything working for part2 beats glibc. Then they get none of correctness points for part1, 12/12 of correctness points for part2, performance points. This student will receive a(0 / 6) * 25 + (12 / 12) * 50 + 25 = 75. 00%.  Scenario 3: A student gets tests 1 through 6 working for part1, then they getall tests except test 4 working for part2. Then they get all of correctness points for part1, 11/12 of correctness points for part2, butthey will not receive any of performance points. This student willreceive a (6 / 6) * 25 + (11 / 12) * 50 + 0 = 70. 83%.   Scenario 4: A student gets tests 1 through 6 working for part1, then they getall of tests working for part2, but they can only get 65% ofglibc. In this case, they get all of correctness points for part 1, allof correctness points for part 2, but only 15% performance points. So,they get (6 / 6) * 25 + (12 / 12) * 50 + 15 = 90. 00%  We modify allocation numbers slightly when we actually grade. ContestView malloc contest ! malloc contest pits your memory allocator implementation against your fellow students. There are a few things know: test cases used for grading will randomized with a different seed every day.  There may additional, more advanced tests added which won’t count for anything but contest.  memory limit is 2. 500GB.  submit your program contest, you simply commit, push your code run distributed autograder. contest page will updated reflect results. You will have a number of runs per day, so that you can update your score as desired.  We will assign a score each of three categories (max heap, average heap, total time) based on how well your program performs memory management relative a standard solution.  You can pick a nickname in nickname. txt. You will show up as this name on contest webpage.  On webpage, each test will either green, which signifies that you passed test, or red, which signifies that you failed test. Scores rankingYour score will computed by following formula:\\(100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\bigg(\\log_2\\Big(\\frac{time_{\\textit{reference}, i}}{time_{\\textit{student}, i}} + 1\\Big) + \\log_2\\Big(\\frac{avg_{\\textit{reference}, i}}{avg_{\\textit{student}, i}} + 1\\Big) + \\log_2\\Big(\\frac{max_{\\textit{reference}, i}}{max_{\\textit{student}, i}} + 1\\Big)\\bigg)\\)Where: \\(n\\) is number of tests \\(\\textit{reference}\\) in subscript means reference implementation, \\(\\textit{student}\\) means student’s implementation \\(time_{\\textit{reference}, i}\\) is time reference implementation spends on test \\(i\\) \\(time_{\\textit{student}, i}\\) is time student spends on test \\(i\\) \\(avg_{\\textit{reference}, i}\\) is average memory used by reference implementation on test \\(i\\) \\(avg_{\\textit{student}, i}\\) is average memory used by student implementation on test \\(i\\) \\(max_{\\textit{reference}, i}\\) is max memory used by reference implementation on test \\(i\\) \\(max_{\\textit{student}, i}\\) is max memory used by student implementation on test \\(i\\)Higher scores are better. Note: We reserve right slightly modify constants inside formula ensure fair grading prevent gaming system. However, basic idea will not changing, whatever we use will same for everyone. Example 1. If a student implementation \\(x\\) performs like reference implementation, which means it spends same time memory as reference, then \\(x\\)’s score will be: \\(\\begin{aligned}score_x&amp;=100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\bigg(\\log_2\\Big(\\frac{time_{\\textit{reference}, i}}{time_{x, i}} + 1\\Big) + \\log_2\\Big(\\frac{avg_{\\textit{reference}, i}}{avg_{x, i}} + 1\\Big) + \\log_2\\Big(\\frac{max_{\\textit{reference}, i}}{max_{x, i}} + 1\\Big)\\bigg) \\\\&amp;=100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\big(\\log_2(2) + \\log_2(2) + \\log_2(2)\\big) \\\\&amp;= 100\\%\\times \\frac{1}{3n} \\sum_{i=1}^n 3\\\\&amp;= 100\\%\\end{aligned}\\)Example 2. If a student implementation \\(y\\) performs same as reference implementation on memory usage, but is twice as slow (meaning \\(time_{y, i} = 2 \\times time_{\\textit{reference}, i}\\)), then \\(y\\)’s score will be: \\(\\begin{aligned} score_y &amp;= 100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\bigg(\\log_2\\Big(\\frac{time_{\\textit{reference}, i}}{time_{y, i}} + 1\\Big) + \\log_2\\Big(\\frac{avg_{\\textit{reference}, i}}{avg_{y, i}} + 1\\Big) + \\log_2\\Big(\\frac{max_{\\textit{reference}, i}}{max_{y, i}} + 1\\Big)\\bigg) \\\\ &amp;= 100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\big(\\log_2(\\tfrac{1}{2} + 1) + \\log_2(2) + \\log_2(2)\\big) \\\\ &amp;= 100\\%\\times \\frac{1}{3n} \\sum_{i=1}^n 2. 585\\\\ &amp;= 86. 2\\% \\end{aligned}\\)Example 3. If a student implementation \\(z\\) performs three times better than reference implementation, which means \\(time_{z, i} = \\frac{time_{\\textit{reference}, i}}{3}\\), \\(avg_{z, i} = \\frac{avg_{\\textit{reference}, i}}{3}\\), \\(max_{z, i} = \\frac{max_{\\textit{reference}, i}}{3}\\), then \\(z\\)’s score will be: \\(\\begin{aligned}score_z&amp;=100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\bigg(\\log_2\\Big(\\frac{time_{\\textit{reference}, i}}{time_{z, i}} + 1\\Big) + \\log_2\\Big(\\frac{avg_{\\textit{reference}, i}}{avg_{z, i}} + 1\\Big) + \\log_2\\Big(\\frac{max_{\\textit{reference}, i}}{max_{z, i}} + 1\\Big)\\bigg) \\\\&amp;=100\\% \\times \\frac{1}{3n} \\sum_{i=1}^n \\big(\\log_2(4) + \\log_2(4) + \\log_2(4)\\big) \\\\&amp;= 100\\%\\times \\frac{1}{3n} \\sum_{i=1}^n 6 \\\\&amp;= 200\\%\\end{aligned}\\)WARNING: As deadline approaches, contest page will refresh more slowly. There are 400 students, 12 test cases, up a minute or so. It will only retest a student’s code if it has been updated, but many more students will updating their code causing longer waits. Start early, don’t become reliant on contest page by testing locally!","url":"/assignments/malloc"},{"title":"MapReduce","content":"MapReduceIn 2004, Google released a general framework for processing large data sets on clusters of computers. We recommend you read on Wikipedia for a general understanding of MapReduce. Also, written by Jeffrey Dean Sanjay Ghemawat gives more detailed information about MapReduce. However, we will explain everything you need know below.  demonstrate what MapReduce can do, we’ll start with a small dataset–three lines of text: goal of this MapReduce program will count number of occurrences of each letter in input. MapReduce is designed make it easy process large data sets, spreading work across many machines. We’ll start by splitting our (not so large) data set into one chunk per line.      Chunk #1 Chunk #2 Chunk #3     Input “Hello” “there” “class!”  Map. Once data is split into chunks, map() is used convert input into (key, value) pairs. In this example, our map() function will create a (key, value) pair for each letter in input, where key is letter value is 1.      Chunk #1 Chunk #2 Chunk #3     Input “Hello” “there” “class!”   Output (h, 1) (t, 1) (c, 1)     (e, 1) (h, 1) (l, 1)     (l, 1) (e, 1) (a, 1)     (l, 1) (r, 1) (s, 1)     (o, 1) (e, 1) (s, 1)  Reduce. Now that data is organized into (key, value) pairs, reduce() function is used combine all values for each key. In this example, it will “reduce” multiple values by adding up counts for each letter. Note that only values for same key are reduced. Each key is reduced independently, which makes it easy process keys in parallel.      Chunk #1 Chunk #2 Chunk #3     Input (h, 1) (t, 1) (c, 1)     (e, 1) (h, 1) (l, 1)     (l, 1) (e, 1) (a, 1)     (l, 1) (r, 1) (s, 1)     (o, 1) (e, 1) (s, 1)   Output (a, 1)         (c, 1)         (e, 3)         (h, 2)         (l, 3)         (o, 1)         (r, 1)         (s, 2)         (t, 1)      MapReduce is useful because many different algorithms can implemented by plugging in different functions for map() reduce(). If you want implement a new algorithm you just need implement those two functions. MapReduce framework will take care of all other aspects of running a large job: splitting data CPU time across any number of machines, recovering from machine failures, tracking job progress, etc.  LabFor this lab, you have been tasked with building a simplified version of MapReduce framework. It will run multiple processes on one machine as independent processing units use IPC mechanisms communicate between them. map() reduce() will programs that read from standard input write standard output. input data for each mapper program will lines of text. Key/value pairs will represented as a line of text with “: “ between key value:Many mappers, one reducerYou’ll spread work across multiple instances of mapper executable.  input file will need split into chunks, with one chunk for each mapper process. split input file, we’ve supplied tool splitter. Please run it without arguments for a brief explanation of how it works. You’ll start up one instance of splitter for each mapper, using a pipe send stdout of splitter stdin of mapper program. Command line:$ . /mapreduce &lt;input_file&gt; &lt;output_file&gt; &lt;mapper_executable&gt; &lt;reducer_executable&gt; &lt;mapper_count&gt;Sample Usage:$ . /mapreduce test. in test. out . /my_mapper . /my_reducer 3Your program will: Split input file into &lt;mapper_count&gt; parts pipe contents into &lt;mapper_count&gt; different mapper processes (use splitter).  Pipe output of mapper processes into reducer process Write output of reducer process output file.  Parallelize these tasks achieve speedupRemember close all unused file descriptors!MapReduce can also achieved in Unix shell:Things we will testing for: Inputs of varying size Different types of mapper reducer tasks Both mapper and reducer generating accurate output stdout file descriptor independently Splitter being used correctly generate equally sized input data for each mapper Correctly logging output, including printing non-zero return codes (see core/utils. h for helper functions!) All mappers being run in parallel, resulting in at least 2x performance speedup for pi executable when parallelizing with 4 mappers No memory leaks memory errors when running applicationIn addition, see comments we’ve placed in main method for more specific instructions!Things that will not tested for: Illegal inputs for either mapper or reducer (Input data in a format other than as described above) Invalid mapper or reducer code (mappers or reducers that do not work) Key Value pairs that are larger than a pipe buffer of 4096 bytes. Restricted FunctionsSince a learning objective of this assignment is use fork-exec-wait pattern learn interprocess communication, if you use popen, system, or related functions you will automatically fail this lab. Building RunningBuildingThis lab has a very complicated Makefile, but it defines all normal targets. Input Data download example input files (books from ), use Makefile:You should now see data/dracula. txt data/alice. txt in your lab folderRunning Your CodeWe have provided following mappers: mapper_wordcount mapper_lettercount mapper_asciicount mapper_wordlengths mapper_piThese each used anywhere we specify my_mapper in these docs.  following reducers: reducer_sum reducer_piThese each used anywhere we specify my_reducer in these docs. For example, if you wanted count occurrences of each word in Alice in Wonderland, you can run of following$ . /mapreduce data/alice. txt test. out . /mapper_wordcount . /reducer_sum 4Record Setting Pi CodeAs well as simple mapper/reducer pairs, we also have also included some really cool pi computation code (see for more info). For instructions on how use pi code, see file pi/README. txt. Note that we do not currently compile this with an NVIDIA compiler, so you willnot able use CUDA version of this code (which we have not tested) unless you fiddle with Makefile. ","url":"/assignments/mapreduce"},{"title":"Melt Kings Secret","content":"Melt King’s Secret king of Systems Programming is about retire impressed by your talent as Duke of P=NP wanted you take over iron throne. However, hand of king convinced him that you lack security white-hat / black-hat skills has thus created a fail proof system for you crack. If you fail uncover kings secret, hand of king becomes de-facto ruler will sentence you nights watch. Royal System architecture of system is based on CISC (Complex Instruction Set Computing) takes a command its type as input on each line. commands are static while types can change following are list of commands available: Possible values for key: a-z Size of cache: 26 You have access key for value: duke. Lets try retrieve key for value duke:Make sure you get familiar with all commands how use them. RequirementYou need find key associated with value kingsSecret. This requires privileged access as being equivalent stored inside kernel memory. Create a file secret. txt add kingsSecret it. Also, add final list of commands that you used hack system. Meltdown hand being happy with king’s decision decided impress him further. He did so by adding out-of-order execution or branch prediction processor underneath system. Essentially what that means is given an instruction, why wait for it fully pass through processor pipeline while other instruction can start simultaneously. same ideadoes not just apply next instruction but applies jumping any instruction inside code. If there is an error, state of code memory will go back where issue happened thus preserving integrity. following will enable this functionality inside royal system:Note: All modern processors by default use out of order execution for optimization is not dependant on user code for it. HackAs state of memory is reverted, you cannot read values from privileged locations but in combination with cache-timing, you can exploit this. This vulnerability in most modern processors allows user programs read kernal memory (Meltdown) also read memory of other user programs (Spectre). Can you frame a similar exploit for royal system read kingsSecret?Hints Understand what each command does observe what happens when you access kingsSecret Try EXECUTE block of commands with duke see how it functions Is output always going deterministic when you devise your hack?More https://medium. com/@mattklein123/meltdown-spectre-explained-6bc8634cc0c2 https://googleprojectzero. blogspot. com/2018/01/reading-privileged-memory-with-side. html https://meltdownattack. com/","url":"/assignments/meltdown"},{"title":"Mini Memcheck","content":"OverviewFor this lab, you will implementing a small version of called mini_memcheck. Valgrind is a great tool for monitoring memory usage, you have likely used it earlier in this class. Your version will print out a summary of memory leaks in a particular C program. This lab is meant in part as preparation for your Malloc MP, introducing some topics techniques which you will find helpful there. Main Concepts main concept of this lab is that we can track each block of memory using some extra space before each allocation (called metadata). We have provided you with a struct meta_data in mini_memcheck. h. metadata is set up as a linked list of nodes which store information for each allocated block. Each node stores amount of memory requested, filename location of instruction that made request, a pointer next allocated block. Here’s an illustration:When program is about exit, we can look at this metadata list see what user hasn’t freed. These are your memory leaks. If you feel that you need a refresher on linked lists or other prerequisite concepts, feel free ask a CA or TA one-on-one. mini_memcheck. cWe have set up mini_memcheck dynamically replace every call malloc, calloc, realloc, free in user’s program with a call mini_malloc, mini_calloc, mini_realloc, mini_free, respectively. You will implementing these four functions in order track memory user allocates. Inside mini_memcheck. c, it is safe call real versions of malloc related functions. You should not writing your own implementation of malloc using sbrk or related system calls. See mini_memcheck. h header file for details. Global VariablesIn addition four functions above, you’ll need maintain following global variables:  head: a pointer head of a linked list storing all metadata corresponding allocated memory blocks   total_memory_requested: stores total number of bytes of memory requested by user throughout lifetime of program (excluding metadata)   total_memory_freed: stores total number of bytes of memory freed by user throughout lifetime of program   invalid_addresses: stores number of times user has tried realloc or free an invalid pointer Since we keep track of this data, we can show user how much memory they’ve allocated, just like real Valgrind. We can also find out how much memory a user might leaking, by subtracting total_memory_freed from total_memory_requested. If you look in mini_memcheck. h, you’ll notice that these are declared as extern variables. This allows variables live somewhere else beside line where you are ‘declaring’ them, pushing responsibility of providing a real location in memory for these variables elsewhere letting resolve variable name where memory is actually reserved. This has a nice explanation of how use this. In order prevent your code from crashing, you will have declare these variables as globals in mini_memcheck. c. TestingYou’ll want test your mini_memcheck thoroughly. We’ve provided you with a test. c file that you can put test cases in. Running make will generate a . /test executable alongside mini_memcheck. You can use it like regular Valgrind: output should look familiar!Note that we always build . /test with debugging symbols (clang -g), so mini_memcheck can find line numbers corresponding memory leaks.  debug mini_memcheck itself, you can use gdb like usual. Use make debug generate a version of mini_memcheck with debugging symbols:Warning: printf() careful with printf in Mini Memcheck! By default, stdout is buffered, so printf calls malloc internally create a buffer. If you call printf inside of mini_malloc, it will allocate its buffer using real malloc (since calls malloc inside mini_memcheck. c use real version), but then free it using your mini_free since cleanup happens outside of mini_memcheck. c. As you can imagine, this results in unexpected behavior. Instead, you can use fprintf(stderr, . . . ), which is unbuffered, or use write, but easiest solution may turn off buffering for stdout:Warning: extra free() callNote that there will some extra calls your mini_free function at end of program. This is an unfortunate side effect of how we implement mini_memcheck internally. In mini_hacks. c, we call a cleanup function defined in C library (__libc_freeres) at end of program, which calls free several times deallocate any internal buffer created by C library. Here is an example of what backtrace looks like in gdb:This should not affect your implementation of mini_free. However, do aware of extra free calls when you’re debugging your program, just so that you’re not confused about where they’re coming from. ExampleHere’s a basic test case check your progress. Say you had following in your test. c file:mini_memcheck’s output should look like this (of course, your process ID addresses might different):Notice that leaks are reported most-recent-first. This is because we insert new metadata at head of linked list. Other ProgramsYou can also run mini_memcheck on other programs, like echo:It should work on most standard utilities, but just aware that it won’t work on everything. You’ll notice it may generate different output than Valgrind or may even crash when run on complex software like python. This is okay; writing a memory checker is hard! You only need implement what we’ve described above in mini_memcheck. h. Optional Fun: Sentinel Value!This part of assignment in this section is not graded. However, sentinel value is a pretty cool concept we encourage you try implement it. So, suppose that our users of mini_memcheck are terrible at coding. They wrote past end of their allocation (buffer overflow) corrupted memory beyond what’s allocated them. Can we detect this kind of memory corruption warn them? answer is yes, by using sentinel value!Sentinel value is a chunck of pre-defined bits at end of an allocated memory. In other word, each allocation would look like this:On every operation, we would check that sentinel value is still same as it was pre-defined. If sentinel value has changed, then we know for certain that user has corrupted memory. In your mini_memcheck, you will use 0xDEADBEEF for sentinel value. Implementation: Add bits 0xDEADBEEF end of every allocation. (Do you need do it for realloc?) Check if sentinel value of a previously allocated buffer has changed in mini_realloc mini_free.  If so, print out a warning user with fprintf(stderr, . . . ). (Do not print stdout!)If you want test out your implementation, you can add following code your test. c see if you get any warning when running . /mini_memcheck . /test:Behind ScenesThis section describes some details of how we’ve implemented mini_memcheck. You are encouraged, but not required, understand this. We compile your mini_ functions, along with some extra code from mini_hacks. c, into a called mini_memcheck. so. mini_hacks. c has two main jobs: Create wrappers around malloc other functions make sure they use your replacement functions when user’s program calls them, while still letting you use real versions within your code Print out leak info at program exit actual . /mini_memcheck program is implemented in mini_main. c. When you run . /mini_memcheck . /test, we use an environment variable called run . /test program using code in mini_memcheck. so. Essentially, it replaces normal references built-in malloc with references our version. “But,” you may ask, “how do we call real version of malloc if we’ve replaced it with our own version of it?” trick is a function called , which allows us bypass LD_PRELOAD ask for a function pointer real malloc. This is all handled within mini_hacks. c. ","url":"/assignments/mini_memcheck"},{"title":"Nonstop Networking","content":"Warning!We strongly recommend reading this entire document at least twice make sure you understand what exact requirements of assignment are. This is a three week MP (over one fifth of your MP grade!), it may long painstaking. We strongly recommend starting early. Make sure you also read grading portion, as it is different than standard multi-week MP grading scheme. Note: do not use threads for this assignment. Any code that uses pthread library automatically gets a zero. Threads start wearing outOne of common ways of handling multiple clients at a time is use threads. Sounds simple enough. A client connects, we spawn a new thread handle it, then that thread can clean up after itself once it’s done. What’s catch?Well, that usually works okay up until a point. After that, your server won’t scale as fast. in modern world, you have do things web scale (TM). Non blocking I/OWell, what can we do about this? Maybe we could keep a thread pool, that is, have a fixed number of threads, have them service connections. However, it’s an M:N mapping this time (M connections, N threads). But wait, how do I multiplex all these different connections, handle all those threads?Non-blocking I/O is your friend here. Remember how regular calls read(), accept() etc. block until there’s data or a new connection available? (If you don’t, try it out! Trace how your server code blocks in read() until your client sends some data!). Well, non-blocking I/O does exactly what it says, you structure your application in such a way that works with data that’s already present (in TCP buffers), not block for data that may or may not arrive! Functions that help you with this are select(), poll(), epoll(). Think of it as an event driven system. At a high level, you maintain a set of file descriptors (could map files, pipes, network sockets, etc. ) that you’re interested in, call appropriate wait() function on that set of descriptors. Your program waits until one (or more) of those descriptors have some data available (in a server scenario, when a client has actually sent data). When data is available, it’s like an ‘event’ occurred, so your program exits wait() call, can iterate over descriptors that have data, process each of them, then go back wait()-ing for additional data arrive. Epoll basicsepoll() arose out of inefficiencies of select() poll() (O(N) waiting is so 20th century) (Check out for more information). It provides two modes of operation, edge triggered (ET) level triggered (LT). Think of it as follows, you have a tank (the descriptor) that you want a notification for whenever there’s water (data) in it. Edge triggered mode would wake up your program once expect you empty out entire tank (process all data). If you only process half of it call epoll_wait() again, your process will block (that’s not good - there is data waiting processed other connections handle). On other hand, level triggered will wake up your epoll_wait() call any time there is any data in descriptor. In this case, if you process half, then call epoll_wait() again, it’ll immediately return with a notification about that descriptor. So why would we ever want use edge triggered behavior? Well, consider what happens when there are multiple threads blocking on same epoll descriptor (yes, we can do that; yes, people do that). Some data arrives on a socket, a thread wakes up starts processing it. But there’s still data, so another thread might accidentally get woken up start processing data for same descriptor. That’s bad, very bad. Edge triggered mode (together with EPOLLONESHOT flag) guarantees that a single thread will handle all data that arrived on that given socket, so (although with some additional code complexity) it’s not possible that two threads accidentally ‘steal’ file descriptor data from each other.  above overview is also available as a () introduction. Note: You must use epoll() for this assignment. If you do not, you will get a 0 on all tests that use your server.  ProblemYou’ll writing client server for a simplified file sharing application. TCP is used for everything here, so reliability is taken care of. server uses non-blocking I/O (with epoll) handle concurrent requests. application supports four basic operations - GET, PUT, LIST DELETE. Their functions are as follows:GET - Client downloads (GETs) a file from serverPUT - Client uploads (PUTs) a file serverLIST - Client receives a list of files from serverDELETE - Client deletes a file from serverFor simplicity, you can assume that there are no conflicting requests (that is, nobody will upload a file while someone else is downloading or deleting it, etc. ) ProtocolThis is a text-based protocol (similar HTTP FTP). client sends plaintext requests along with some binary data (depending on operation), then server responds with plaintext containing either error messages or optional binary data. binary data in this case is file being transferred, if it is a GET or PUT request. maximum header length (header is part before data) for both request response is 1024 bytes. format for protocol is as follows:Client request VERB can any one of ‘GET’, ‘PUT’, ‘DELETE’ or ‘LIST’ (Case sensitive - VERB must capitalized).  ‘\\n’ is newline character (a single byte).  There is a space character in between VERB [filename].  [filename] is limited 255 bytes.  File size binary data are only present for a PUT operation (since client is trying upload a file). File size is a size_t which indicates how many bytes are present in binary data in request. For example, if file size is 32, then server should expect 32 bytes of binary data in request from client. For this binary data, we will using Little Endian form of byte ordering (the system used by Intel hardware) while sending size_t over network. Because of this, you do not need convert byte ordering in either client or server.  On PUT, if local file does not exist, simply exiting is okay. If VERB is “LIST”, then only newline after will present (no space, file size, or data). Server responseRESPONSE can either OK or ERROR, depending on how request went (details on error handling are in a later section). Error message newline after it are only present if only if RESPONSE is ERROR. File size binary data are only present in GET or LIST responses, refer number of bytes (size_t, same way client sent size_t in a PUT request) of binary data that follows. If it’s a GET request, binary data is data in file being requested. If it’s a LIST request, binary data is a series of filenames, separated by newlines, referring files currently stored on server. For example, if a server is hosting files ‘you. txt’, ‘gonna. log’, ‘give. avi’, ‘never. mp3’, ‘up. mov’, response a LIST might look like this- large size_t referred comes from length of filenames, plus newlines between filenames (there is no newline after last file, or before first one) - value is broken down into a sum on a per line basis for ease of understanding. In that example, actual value that would sent would 43. Specifics: ExamplesIn all four examples, first line represents how we call client in command line, followed by client’s request server, finally followed by server’s response. Notice how we always send all sizeof(size_t) as raw bytes. That is, in each below, [size] is 8 bytes that represent number of bytes binary data that follows should be. You did something similar this in chatroom. While you’re looking at these examples, think about what parts of request response you want print (if any), depending on request response types.  GETHere, client is GET’ing file “The. Social. Network. 2010. 1080p. BluRay. x265. 10bit-z97. mp4” saving it locally as “social_network. mp4”.  PUTIn this example, client is PUT’ing file “Prison. Break. S05E01. WEB-DL. x264-FUM[ettv]. mp4” (local client) on server as “prison_break_s05_e01. mp4”.  DELETEIn this case, client DELETE’s file “prison_break_s05_e01. mp4” from server.  LISTIn LIST requests, client LIST’s all available files on server. Notice there is no new line at end of list. Specifics: Client client’s job is simple: execute a single request. usage is as follows:. /client &lt;server IP&gt;:&lt;server port&gt; VERB [remote] [local]Where remote is filename used in request local is filename that client uses while uploading/downloading. For example:. /client 127. 0. 0. 1:9001 GET remotefile localfileThat would download file ‘remotefile’ from server store it as ‘localfile’.  client runs a single command (GET, PUT, LIST or DELETE) with chosen arguments, makes sure file it’s trying upload (if it is uploading one) actually exists, connects server, sends request (and file data, if needed), finally prints out any error messages STDOUT. Once client has sent all data server, it should perform a ‘half close’ by closing write half of socket (hint: shutdown()). This ensures that server will eventually realize that client has stopped sending data, can move forward with processing request. For LIST, binary data from server should printed STDOUT, each file on a separate line. For GET, binary data should written [local] file specified when user ran command. If not created, create file. If it exists, truncate file. You should create file with all permissions set (r-w-x for all users groups). Your client is allowed use blocking I/O, since clients don’t really care about scaling. However, there are a few important things keep in mind:1) Use provided argument checkers. In starter files, we provide you with two functions called check_args parse_args, used validate parse arguments, respectively. If you choose write your own argument checkers, make sure they behave exactly same as ones provided — no more or less strict. 2) Parse response carefully. When you’re reading, you may accidentally read into application binary data without realizing it (since you don’t have fixed size fields in responses). 3) write(fd, buffer, n) may not always write n bytes for various reasons. Buffers may become full, signals may arrive, Skynet revolution might begin. None of which are excuses for not sending correct amount of data server. Good practice is wrap your read/write calls in a loop that runs until specified number of bytes are read, connection is closed, or an error (with exception of EINTR) occurs. 4) Your client needs able handle large files (more than physical RAM) should do so efficiently. Error HandlingYour client should handle following errors use appropriate function in format. h: Received too much or too little data from server.  Invalid response from server (malformed or nonexistent STATUS).  Print any ERROR message from server. Specifics: Server real fun lies here. As discussed, you’ll using epoll allow non-blocking I/O. As you know, epoll allows you add various descriptors epoll set ‘monitored’ for events. After that, when you call epoll_wait(), it will block until there are events on one or more epoll descriptors (either indicating data is available or that data can written socket).  server usage is as follows:. /server &lt;port&gt;Request statesOne way reason about connections in a nonblocking server is visualize each one as a traversal of a finite state machine. That is, there is some initial state (probably when connection was created), you transition between different states depending on what action occurred (the type of request, whether there was an error or not, etc. ). A suggested flowchart for server automata:Maintaining persistent connection stateNew connections arrive old connections close all time. Your server needs know what current status of command it’s serving is. One suggested way is maintain a mapping from socket handle connection state (you are provided a dictionary data structure for this purpose). When a connection arrives, this state is allocated on heap added dictionary. When server is handling epoll events, it can check descriptor of event that occurred, quickly find out underlying state of request. Information that might go into a connection state could be: What state in DFA you’re in request VERB Various buffers offsets Filenames Anything else you’d like put in there, really, this is your design decisionGlobal data structuresYou should maintain file list (server-side) with a global vector that gets appended every time a file is added (using push_back()). Entries are removed one file at a time, by using vector_erase() with appropriate index. You might also want maintain a map from file descriptor connection state, as discussed above. Remember clean up any state when you’re done serving a single connection!Memory limitsSince your server is expected able serve a large number of clients multiple (possibly large) files concurrently, you cannot assume that files will entirely fit in memory (that is, you cannot read entire file data into one giant buffer). Instead, you should maintain some (reasonably) fixed size buffers (say, 1024 bytes), reuse these buffers as you send or receive data over time. You may use different buffers for different kinds of data (for instance, request header, file list, file being sent/received) if you wish. It is also okay keep different buffers for different connections. File StorageYou should create a temporary directory using mkdtemp() function (make sure you follow this convention exactly!). Your server will store all uploaded files in this directory. Immediately after creating your directory, you must print it out using print_temp_directory (found in format. h) from current directory (do not cd into another directory then call print_temp_directory - if you don’t follow this rule, do not expect pass any of autograder tests. When your server exits, it should clean up any files stored in this directory, then delete directory itself. unlink() rmdir() might helpful here. Note: sure use directory name that mkdtemp(char \\*template) gives you. Additionally, make sure that your template is exactly 6 X’s, as in XXXXXX. Exiting serverYour server should exit on receiving SIGINT. You might find sigaction useful. Note: Do not store newlines in your filenames. There will no whitespace or slashes in filenames at all. Error handlingYour server is expected able handle misbehaving/stark raving mad clients. That means you can never assume request is formatted way protocol says it should be. While handling a request, as you read data from connected socket into your local buffers, you should parse command make sure it is well-formed (the legal verb, number of arguments is as expected, etc. )Another thing keep in mind is that if you try writing data a client that has disconnected for any reason (they close()d socket, for instance), your server might receive a SIGPIPE - you should setup your program ignore that signal. This may also result in write() calls returning -1 with errno set EPIPE. If this happens, your server should also close connection clean up any associated state. Your server should handle these errors: Bad request (malformed or nonexistent verb) Bad file size (too much or too little data from client) No such file (GET/DELETE on nonexistent file)Notes: If a PUT request fails, delete file.  If a PUT request is called with an existing file. overwrite file.  You should use error messaged defined in format. hWriting your server codeKeep things modular! Write functions for everything. This has multiple advantages. First, it lets you debug your code in small, incremental units, rather than writing a huge monolith of code trying figure out which part of it is broken through trial error. Secondly, you’d surprised how much code you can end up reusing if you design your application appropriately. Third, it’ll helpful while debugging or discussing your approach with course staff - it’s really hard tell what your code is supposed doing, otherwise. Reusable Addresses PortsMake sure you use SO_REUSEADDR SO_REUSEPORT ensure bind() doesn’t fail in event that your server or client crashes. This will enable faster debugging for you (otherwise, you would have wait for kernel reopen source address port). We will making sure that your socket is set up with these options (look into setsockopt) so please make sure you use both options! If you don’t, you will not pass this assignment. See for more information on differences between two why they are necessary. LoggingThis assignment is challenging enough, debugging it is even more so. We recommend that you constantly log state as your client/server program executes. You might want log at beginning/end of function calls, entry exit of loops etc. maybe log values of key variables, pointers, file descriptors etc. sanity check what’s going on with your code. We provide a simple LOG() macro, if you’re interested in that. Or, you could play around with writing one of your own (ours is just a wrapper around fprintf()). If you decide not use this macro, ensure you log only stderr. stdout of your client server implementation are used for testing purposes so writing stdout should deliberate. Any unwarranted new line characters or extraneous logging within stdout could result in a test failure. TestingTesting networking programs can always challenging. There are a few ways we suggest going about this:Client - You could write a toy server in any language of your choice that logs adheres protocol above (even if it doesn’t do multithreading, nonblocking I/O etc. )Server - By time you start your server, you will (hopefully) have a working client implementation. Use that test your server! In addition, feel free setup a server have each others’ clients try connecting them (As long as you’re not sharing any code/design decisions) - this is a good way stress test your own implementation. Another way simulate multiple clients could write a program that fork()s a bunch of times, each child calling exec() on your client executable sending a request (no fork bombing, please!). Alternatively, if higher level languages are more your thing, you could try writing a script in some other language (say, Python or Ruby). As long as you strictly adhere specified protocol, it should work fine (be careful about width byte ordering of types in other languages, though!). catch is, you have sure your mock client/server actually works as expected, since you’ll end up debugging programs in different languages at this point, which is never fun. On bright side, this lets you practice multilingualism. :bangbang: We will also providing a reference client server. These print out helpful logging messages stderr that you do not need mirror in your code. These might also not perfect, so please report things us (they do pass our tests though). An instructive example of how run server-reference client-reference with some example files:It is important note that client-reference server-reference output some text stdout, some text stderr. view only stdout content of reference client or server, we recommend using . For example, command below will run server redirect any error (stderr) messages /dev/null, essentially discarding them. As a result, this command will only print stdout content. GradingThere are three parts for this assignment: Part 1: ClientPart 1 requires full client functionality, is due at first deadline (i. e. one week after assignment is released). We will refer this score as part1_orig.  Part 2: Server Part 1Part 2 requires you begin implementing your server. We will run full server-client autograder for this week (except for stress test). Obtaining 50% of points is a 100% on week 2, 45% yields a 90%, 40% an 80%, so on. You may choose which parts of server you wish implement first. This is due at second deadline (i. e. two weeks after assignment is released). We will refer this score as part2_orig.  Part 3: Server Part 2Part 3 is full server-client functionality. All tests will run, including stress test. This is due at third deadline (i. e. three weeks after assignment is released). We will refer this score as part3.  compute your final grade:During week 1, autograder will test exclusively your client, whereas we will add server-related tests in week 2. In week 3, we will add stress test. purpose of stress test is gauge performance of your server in handling many clients concurrently. ","url":"/assignments/networking_mp"},{"title":"Netfilter Kernel Module","content":"Requirements: Understand how netfilter could used block packets Understand how concepts you leared in CS 341 apply kernel Log incoming packets from google Have a proc endpoint display how many times each of google’s IP ranges sent a packet Optional: Implement something extra (more statistics or some actual filtering)Part 1 - Making a kernel module (optional)There’s two main components making a kernel module, an initializer anexit handler. initializer will run when module is loaded exithandler will run when module is unloaded.  accomplish this, either create two functions named init_module cleanup_module or create two functions with any names (foo bar) call module_init module_exit on initializer exit handlerrespectively (module_init(foo), module_init(bar)). Additionally, we will need specify a module license (you don’t have to, but compiler will warn you if you don’t). We’ll stick GPL, so include line:in your code. Since it is cumbersome use debuggers with kernel modules (there are kerneldebuggers, but we won’t use them today), we will rely on logging for outputingdebug info. Unlike with a normal program, you do not have a stdout/stdin channelso there is no way have a “default” output stream for non-logging purposes. log information you will use printk (It works almost exactly likeprintf). view log either view contents of files in /var/log oruse program dmesg. I prefer use dmesg -wH since that shows a streamof output with human readable timestamps.  complete part 1, write a kernel module in filter. c using printk write“hello world” log. Part 2 - Making a netfilter moduleIn this part we will experiment with netfilter - a way of filtering packets at kernel level. accomplish this, we’ll need setup a few things. We’ll need a global variable keep track of our netfilter options, we’ll need initialize those options in our init callback, finally, we’ll need register/unregister our netfilter hook at init/exit. These options will create a netfilter that will filter incoming packets. You canfind details online about how filter outbound packets. In this example main_hook is function that actually implements functionality of module. More generally, it needs a function with following signature: static isn’t strictly necessary, but it’s good practice declareeverything in your module as static besides your init cleanup.  only parameter we’ll using is skb. We want extract source ip ofpackets we are recieving. You can do that with following lines of code:Using google ranges provided in filter. h find index of range incoming packet belongs log it. If you’d like also view humanreadable ip in your log, use format specifier %pI4 in printk pass ina pointer ip address. Finally you’ll want return NF_ACCEPT allow packet continue onit’s journey through network stack. If you wanted block packetinstead, use NF_DROP. Try playing around with those options block specificgoogle ranges. Warning: dropping all packets will result in kernel modulealso dropping your ssh connection your vm! If this happens, let one of usknow so that we can reset your vm.  test this, run dmesg -wH in one terminal in other terminals, trycommands like: check your dmesg log for updates. Part 3 - Using proc for outputNow, we’re going create an endpoint in /proc that will allow you viewstatistics about packets you’ve intercepted. accomplish this, create aglobal array that will store in ith index, number of times ithrange sent a packet. In order prevent race conditions, we’ll need lock access this array. While there are spinlocks in kernel, we’ll using a mutex today forlearning purposes. You’ll need create a mutex with mutex_init destroy it withmutex_destroy. Locking unlocking are provided by mutex_(un)lock. Revise lecture slides for more info about how use a mutex in kernel how that is different from a spinlock.  create your proc endpoint, you can use following code:Implementing proc_fs endpointHere is some sample code for implementing read. In this code, range_count isan array of size_ts such that ith element of array contains number of packets recieved from range i. Try experimenting with write. Maybe enable or disable filter with a write a proc endpoint or try allowing a user add in new ranges. ","url":"/assignments/notorious_netfilter"},{"title":"Parallel Make","content":"IntroductionMore more programs today are being programmed as multithreaded applications. goal of this MP is give you more practice writing multithreaded applications expose common pitfalls that occur while designing a program work in a parallel manner. Additionally, you will need make use of synchronization primitives protect memory shared amongst threads. You are given a task of writing an application which will imitate common make utility. make is a utility that automatically builds executable programs from source code by reading files called Makefiles which specify how derive program. You have encountered Makefiles in CS 341 MPs as well as in your previous undergraduate CS classes should familiar with them. We have provided code parse a Makefile list dependencies commands specified in file. Once file is parsed, you will need perform actions specified by Makefile following rules specified later in docs. Using a fixed pool of threads, you will parallelize this execution process such that all commands are executed as soon as their dependencies are satisfied. Before starting you should read Wikipedia article on . You might also want look for some notes that explain makefiles really well. (They start with some C++ specific details but you can skip ‘Now, makefiles’ section. Also, do note that makefile for this MP does NOT use makefile macros. )Resource Allocation GraphsA good way think about this MP at a high level is by using a model , Resource Allocation Graphs. You can think of make rules as nodes in graph dependency relations as directed edges that point from rules dependencies. This visualization comes in handy when we are dealing with programs that may encounter deadlock. Given that a Makefile may contain a circular dependency (what are required conditions for a program deadlock?), keep this model at back of your mind when building your solution. Here is an example Makefile: following graph represents above Makefile. Note that ‘a’ ‘b’ form a cycle (-&gt; ‘b’ -&gt; ‘a’ -&gt;). Note that not all Makefiles form RAG-like graphs, so your cycle detection from deadlock_demolition may not work here! Does graph below have a cycle?Some more resources on RAGs &amp; Deadlock: . Program Inputs input for this MP will in following form: input parsing step is already handled for you in parmake_main. c. Makefile, thread count, target list will provided as arguments parmake() function, which you will have implement. Process Makefile first thing you will need do is parse Makefile into a dependency graph.  Makefile will always consist of one or more rules of form:For example:You may want take a look at if you do not know how read or write a basic Makefile. However, you will not need parse Makefile yourself. Instead,you must use parser_parse_makefile() function represent Makefile as a dependency graph. parser_parse_makefile() takes filename a NULL-terminated array of strings as inputs.  array of strings specify targets you are planning run. Remember, if array is null or empty, parser will use first target found in Makefile. parser returns a graph data structure containing all rules dependencies in Makefile, including those that do not need executed. For example, suppose we have following Makefile: parser will return a graph containing 5 vertices, once each for rule ‘a’, ‘b’, ‘c’, ‘d’, as well as one sentinel (labeled as an empty string) whose neighbor is rule ‘a’ (i. e. only rule). Those curious of implementation can view source in parser. c although this is not necessary. We have provided an implementation of a vector, a set, a dictionary, a graph, a thread-safe queue. This is same queue from luscious locks same vector you’ve used in prior assignments. set, graph, dictionary are new data structures from CS 341 provided library. You can view header information in includes/. Graph Data StructureSince a Makefile is a representation of a dependency graph, our parser returns a directed graph data structure. You may find graph API in includes/graph. h. access Makefile rules from this graph, you would usewhere target is a string labelling a rule. get a list of all targets, use get a list of all dependencies of a rule with a given target, use graph returned from parmake parser will contain all vertices edges depicting rules dependencies in a Makefile. In addition, it will contain an empty sentinel rule (with key “”) whose neighbors are goal rules. Do not execute this rule. Instead, you should only work on rules that descend from this rule (i. e. goal rules all their descendants). Here, “B descends from A” means that ‘A’ implicitly depends on ‘B’ run. See rule. h for a description of rule_t API. read parser. h for more usage details on dependency graph. USAGE WARNINGS:  Any vectors returned from graph functions must destroyed manually prevent memory leaks. Destroying these vectors will not destroy anything in actual graph.   Destroying graph or removing vertices from graph will completely destroy all associated targets (i. e. rule labels), rules, edges. So copy anything you need for later use before removal or destruction.   You should not add new vertices graph. If you choose do this using graph_set_vertex(), keep in mind that both key value must strings, since graph’s value copy constructor transforms strings new rule_t structs. Read parser. c in order understand dependency graph’s memory management scheme.   graph vector classes are not thread-safe! You must enforce mutual exclusion if multiple threads are concurrently modify access these structures. Graph Searching Cycle DetectionGNU make handles cyclical dependencies by attempting delete edges that cause cycles. If you tried call make d on example Makefile shown earlier, GNU make would essentially attempt convert that Makefile this one: highlight importance of cycle detection in resource allocation schemes, we also require that you explicitly handle cycles. However, your implementation of parmake will ignore all goal rules whose descendants belong cycles. That is, calling . /parmake d on this makefile would execute nothing, since ‘d’ cannot satisfied due cyclical dependency (-&gt; ‘a’ -&gt; ‘b’ -&gt;). However, calling . /parmake c will still execute echo C, since (nonexistent) descendants of ‘c’ don’t belong cycles. Moreover, you must announce any goal rules that are dropped due existence of cyclical dependencies using function print_cycle_failure() found in format. h. Read header file for usage information. Since this MP requires you implement some graph algorithms, you may want consult jog your CS 225 memory. Note: You do NOT have parallelize cycle detection essential rule extraction. You only need parallelize execution of commands. Satisfy rulesEach rule depends on a (possibly empty) set of other rules. It is important note that every dependency will a rule, even if dependency isn’t explicitly defined in Makefile. For example, these two Makefiles are equivalent:Some rules might also files on disk. A rule can satisfied if only if all of rules that it depends on have been satisfied none of them have failed (See what determines a failed rule in Running Commands). Note that you shouldn’t try satisfy rules that aren’t “good” goal rules don’t have any “good” goal rules as ancestors. Specifically, you should not try satisfy a rule if any of following is true: rule is a goal rule, but is involved in a cycle, i. e. there exists a path from rule itself in dependency graph rule is a goal rule, but at least one of its descendants, i. e. any rule in dependency graph reachable from goal rule, is involved in a cycle rule is not a goal rule, it has no ancestors that are goal rules rule is not a goal rule, all of its goal rule ancestors fall under (1) or (2)Basically, there is no need satisfy a rule if it isn’t necessary satisfy goal rules or if we already know that all goal rules it might satisfy are doomed fail due cycles. Trying satisfying any of them would impossible at worst or a waste of time at best. When a rule is ready satisfied, we must determine if we actually need run rule’s commands. We run its commands if only if at least one of following is true: name of rule is not name of a file on disk. Example:or rule depends on another rule that is not name of a file on disk. Example: rule is name of a file on disk, it depends on another file with a NEWER change time than change time of file which corresponds name of rule. determine whether a file is NEWER, you should use stat difftime determine if it is newer. differences in time will have a granularity of 1 second. If neither of these is true, then rule is already satisfied does not need its commands executed. Otherwise, rule is unsatisfied available run. Once a rule is satisfied, it shouldn’t run again. Running commandsYou can use system() run commands associated with each rule. There are a few conditions think about when running these commands: rule’s commands need run sequentially in order they appear in command vector If any of a rule’s commands fail while evaluating that rule, then rule should “fail” no more of its commands should run If a rule fails, its parent rules (rules which have this rule as a dependency) should fail as well. Note that this is not necessarily true for converse (i. e. if a parent fails, its children may still satisfied)For your convenience these rules are captured in following flow chart:Parallelize! (Part 2 Only)parmake must satisfy all of rules needed build specified targets correctly as quickly as possible. Because we want maximum runtime performance, you need running a rule on each worker thread whenever possible. Threads should not stay idle when there are rules that are available for execution. A rule is defined as available when all of its dependencies have been satisfied it is not already satisfied (see “Satisfy rules”). There are two important parallelism requirements: You should NOT run any rule unless its dependencies have been satisfied (all dependent rules have been run none have failed; see previous section) If a thread is available (not doing useful work), there is at least one rule that is available executed, available thread should work on executing that rule.  exact type of work that your worker threads perform will generally depend on your implementation. But for purposes of this MP, you must parallelize actual execution of commands. If any rule is ready have its commands executed, a worker thread should do so as soon as possible (i. e. within several milliseconds) unless all worker threads are already executing commands. If a rule is available because all its dependencies have been satisfied, some of your threads are still not executing any rules, then you probably haven’t achieved maximum parallelization. ExampleSuppose we have makefile:Running . /parmake should output:There are many more examples provided in your MP folder. Notes Only make changes in parmake. c.  Note that Makefiles require tabs for indentation, so do not use spaces or modify tabs in editor settings if you plan on directly editing a Makefile. cat -T may useful for detecting errors.  You will receive 0 points if your implementation uses sleep(), usleep(), or any other form of timed waiting (e. g. sem_timedwait()).  For full points, avoid busy-waiting. i. e. threads should not burning CPU when they aren’t doing useful work.  You must only ever launch T+1 threads, where T is number of worker threads (+1 comes from main thread). Do not keep re-spawning new threads for every rule.  We will try artificially create spurious wakeups, so think about how you would resolve those.  achieve a perfect score, you should maximize parallelization by ensuring that every given rule that can run at a given time is being run.  Because rules should run as soon as they are available, there will sometimes a well-defined, optimal order of rule execution when multiple threads are used. Think about why that might case. Compiling RunningAs usual, we have provided you with a Makefile which will compile your code in a variety of ways. Unfortunately, you can’t use parmake compile parmake, because our parser does not support variables variable expansions.  compile in release mode, run make, for debug mode, use make debug. If you want write more test cases yourself (which we highly recommend!) in VSCode, make sure you turn off Editor: Insert Spaces in settings first, or you will get missing separator error when you try run parmake on them. This is because makefile parser expects tab characters instead of space characters at beginning of indented lines for . ThreadSanitizer provided Makefile also builds a ThreadSanitizer instrumented version of your code. tsan executable is parmake-tsan. You can run this (instead of parmake) use ThreadSanitizer race condition detection tool with parmake. For a tsan example, see We will using ThreadSanitizer grade your code! If autograder detects a data race, you won’t automatically get 0 points, but a few points will deducted. (Almost) a reference implementationYou can use real GNU make check your implementation. However, it differs from parmake in certain substantive aspects that may or may not resolved. Here is a partial list of differences: make usually prints every command it runs. Run make with flag -s (for silent) suppress these.  make deals with cycles differently than parmake, so do not use make as a reference for cycle handling.  make kills program immediately after a rule fails. Run make with flag -k (for keep going) continue satisfying rules that aren’t doomed fail.  make requires every dependency either explicitly declared in Makefile or present as a file on disk. get parmake make work same way, define every rule explicitly.  make spits out error messages when commands fail, even when flag -k is used. parmake will not do this. Example “good” Makefile:Example commands:This should generate same output as:except maybe for some printouts that make emits when ‘b’ fails. Remember that you don’t need implement any GNU Make features that aren’t prescribed in these docs. GradingHere is grading breakdown: Part 1 (50%): Create a single-threaded version of parmake (so just make). This version should:  identify cycles in dependency graph returned by parser remove goal rules that depend on them attempt run all other goal rules by running all their descendants (i. e. implicit dependencies) only their descendants identify whether or not run a rule as per flowchart recipe run it once possible (or reject it if not possible)   Part 2 (50%): Create full multi-threaded version of parmake (so par). This version should:  perform same functions as in Part 1 run with 2-4 threads (excluding main thread) for any given Makefile concurrently run all rules whose dependencies have been satisfied, subject thread limit avoid deadlock, data races, livelock, busy-waiting create performant code that doesn’t incur excessive overhead (e. g &gt; 10 ms per rule)  ","url":"/assignments/parallel_make"},{"title":"Password Cracker","content":"IntroductionIn this MP, you will creating a program that can recover lost passwords. For security reasons, passwords are usually never stored in plain text. Instead, hashed versions of passwords are stored. For an example of this, take a look at /etc/shadow file on any modern Linux machine. When a user tries log in, password they enter is hashed compared with stored hash. This way, there’s no need store your actual password. Given output of a good hash function, it is hard or impossible reconstruct input using hashed value. However, if you are willing burn some CPU time, it is possible try every possible password (brute force attack) until you find one that hashes target hash. crypt_r()We will using crypt_r() (a reentrant/thread-safe version of crypt() function) as our hashing function. crypt_r() takes three arguments: string hash, a salt string, a struct crypt_data. Make sure set initialized member of your struct crypt_data zero before using it for first time. For example:This code outputs following: struct crypt_data is necessary for crypt_r(). This is because crypt() stores information between invocations, so calling crypt() in multiple threads at same time will cause this information inaccurate. crypt_r() gets around this by storing information in a struct crypt_data instead. You should check man page for crypt_r. Do you need free string it returns?Why is there salt in my hash? salt argument “flavors” string so that when you hash same password with different salts, you’ll get different results. In practice, we might use a random value generated for every user. This prevents an attacker from noticing that two people have same password just by comparing their hash values. For this assignment, always use \"xx\" for salt argument. Problem StatementYou will given a list of hashes that you must recover passwords for. For each hash, we have two other pieces of information: first few letters in their password total length of passwordAll passwords only contain lowercase letters!For example, we may say that a password begins with \"hello\" has a total of 8 letters. We know hashed value associated with this password is \"xxsczBXm6z4zA\", so we simply have try hashing each possible password (starting with prefix provided) until we find one that hashes desired value. InputYour input will a file with one line for each password recover. Each line will contain: Username (1-8 characters) Password hash (13 characters) Known part of password (plus periods representing unknown characters) (1-8 characters, contains 0-8 lowercase letters followed by 0-8 periods)  A period in password represents an unknown letter.   These three fields are separated by a single space. Don’t worry about duplicate usernames, duplicate password hashes, or duplicate prefixes. Each line is an independent task. All input we provide is guaranteed in this format. Example input:Note: For both version 1 version 2, main thread is NOT used crack passwords. ONLY worker threads should try crack a password.  For both, you will editing a function called start that should return 0 when exiting under normal circumstances. You can return any non-zero exit status when an error occurs. Version 1: Thread PoolWe will not grade any output which is not result of a call a function in format. hIt is always a good idea write a single threaded version of your code before trying parallelize!Use multiple threads speed up password processing. main thread will start up a pool of worker threads, then read lines of input from standard input. Each line will converted a task which is added a task queue. task queue is provided in libprovided. a queue. h. This is same thread-safe queue that you’ve implemented in lab! worker threads will pull one task from task queue, then process task. When a worker thread starts processing a task, it will print username of task (use format. h). When a worker thread finishes a task, it will print cracked password (use format. h), along with index of thread (starting with index 1) amount of CPU time spent working on password (use getThreadCPUTime()). When main thread finishes reading in lines from input, it can’t shut down immediately, since worker threads may still cracking some passwords. You need decide how cleanly shut all threads down when there are no more passwords crack. Every thread must join with main thread!After all worker threads have exited, main thread will print (this is provided in cracker1_main. c): Number of successful unsuccessful password cracks Wall clock time since program was started (via getTime() in utils. h) CPU time used (a sum of CPU time used in all threads).  Proportion of CPU time wall clock time. By default, provided code creates 4 worker threads. If a command line argument is supplied program, it will use that as number of worker threads rather than default. Example:Example output: times order may vary slightly. “CPU usage” value will depend on number of cores in your VM. above example is run on a machine with 4 cores. If your machine has 2 cores, CPU usage should between 1x 2x. Your password cracker should processing passwords in a streaming manner. This means that once program is started, if both a password a worker thread are available, thread should immediately work on password. sure consider how your task queue is conducive this when you launch your threads achieve this. Note that queue does not have a queue_empty() function (as explained in queue. h). So a question you might ask yourself is “How do I know when queue is empty?”. This is an exercise we have intentionally left for reader, but one hint we will give is “How does strlen() know when it has reached end of a C style string?”. How can you reuse same idea in terms of a queue (what is analogue of null byte)?Remember use appropriate synchronization, make sure use crypt_r. If you create a new thread for each task (instead of keeping threads in thread pool running), you will lose points! (and your implementation will very slow)Version 2: Parallelize each taskWe will not grade any output which is not result of a call a function in format. hVersion 1 works great when there is a long list of passwords that need cracking in parallel, but it’s no faster than a single threaded version when there’s one really hard password that needs cracking. For version 2, you’ll still have a pool of threads, but rather than assigning one thread each password task, all threads will work in parallel on each password task. Example input:Example output:Distribute work by splitting search space into equal-sized chunks, one for each worker thread. For example, if there are 3 unknown characters, then there are 26^3 = 17576 possible passwords that need tested. With 4 worker threads, you would split work up like this: Thread 1: 0. . 4393 (aaa. . gmz) Thread 2: 4394. . 8787 (gna. . mzz) Thread 3: 8788. . 13181 (naa. . tmz) Thread 4: 13182. . 17575 (tna. . zzz)When number of threads doesn’t divide search space evenly, it’s easy get off-by-one errors due integer rounding. functions getSubrange() setStringPosition() are provided in utils. h file assist you with this. We require that you use these functions match our expected output. We cannot guarantee correctness of code that does not utilize these functions. With all threads working on same task, you may want restructure your thread synchronization a little. Rather than a queue, you may wish use a barrier. Like with version 1, you may not create new threads for each task. threads you create at beginning of program must same threads that compute last task. When main thread reads a task, it should print \"Start &lt;username&gt;\". When a thread starts processing a task, it should print its index starting position. As usual, make sure use format. h. For example:When a worker thread finds correct password, it should tell all other threads stop working on task. You can implement this with a simple flag variable that each thread checks on each iteration. Since all threads are reading this variable any thread may write it, you’ll need properly synchronize access it. When worker threads finish a task, each thread will print number of passwords it tried a word describing how its run finished: (found) - this thread found password (cancelled) - stopped early because another thread found password (end) - finished with no password found. Note: this can happen if password was found, but this thread finished its chunk before another thread found password. After all worker threads finish each task, main thread will print password (if found), total number of hashes, wall clock CPU time spent on that task, ratio of CPU time wall clock time. Note that we have not provided any of timing print statements in cracker2. Bounds2 &lt;= thread_pool_size &lt;= 131 &lt;= number of passwords &lt;= 10,0000 &lt;= number of periods &lt;= 8Performance: If you have n threads then CPU usage should be: in interval [n - 0. 5, n + 0. 5] if 2 &lt;= n &lt;= 3 more than 2 if n &gt;= 4ConceptLatency &amp; ThroughputBy definition, latency is delay from input into a system desired outcome or execution time of a single task. Throughput is maximum rate at which something can processed or amount of task that could completed in a period of time. Let’s take pizza delivery for an example, Do you want your pizza hot? Low latency = pizza arrives quicker! Or do you want your pizza inexpensive? High throughput = lots of pizzas per hourFor “Version 1: Thread Pool” solution, because amount of time needed for every task is different, tasks that need less time won’t blocked by tasks that needed longer time. On other hand, execution time for each task is longer than having all threads working on single task. Consider following tasks (in order), where a thread can run 100 iterations per second: task 1: 100 iterations task 2: 10000 iterations task 3: 100 iterations task 4: 100 iterations task 5: 100 iterationsThroughputSuppose there are 4 threads available program runs for 1 second. For version 1: throughput is 3 since tasks 1, 3, 4 will have completed, while 2 is still being worked on (and 5 is just being started). For version 2: throughput is 1 since only first task will have completed all of threads are busy working on task 2. Latency latency is determined by how quickly each password can cracked.                      Task1 Task2 Task3 Task4 Task5     Latency (version 1)   1    100     1   1   1   Latency (version 2)   0. 2   20   0. 2   0. 2   0. 2  Version 2 has much lower latency since each password is cracked faster by multiple threads working on same task. Building RunningAs usual, we have provided a Makefile which can build a release a debug version of your code. Running make will compile cracker1 cracker2 in release mode, as well as a tool called create_examples (more on this in next section). Running make debug will compile cracker1 cracker2 in debug mode, will also compile create_examples. ThreadSanitizerWe have also included target make tsan, which compiles your code with Thread Sanitizer (run cracker1-tsan cracker2-tsan)ThreadSantizer is a race condition detection tool. See for more information. We will using ThreadSanitizer grade your code! If autograder detects a data race, you won’t automatically get 0 points, but a few points will deducted. Helpful ExtrasThread status hookWe’ve provided a simple tool help you when debugging your program. See thread_status. h thread_status. c. We’ve install threadStatusPrint() as a handler for SIGINT. It will print a brief summary of what each thread is currently doing any time you hit ctrl-c. For example: use it: #include \"thread_status. h\" Call threadStatusSet() describe what thread is currently doing. argument threadStatusSet() should a string constant. For example:When threadStatusPrint() is called, it doesn’t print exact line number that each thread is at. It just prints line number of most recent call threadStatusSet(). So, for more precise reporting, add more calls threadStatusSet() your code. thread_status. h contains macros that will redefine calls common thread synchronization functions so that when a thread is blocking on one of them, its status will represent that (like “semaphore wait” on line 219 in example above). Note: Since Thread Status is hooked Ctrl-C, you might need use Ctrl-D (EOF) or Ctrl-\\ (SIGQUIT) shutdown a running password crackerYou’re not required use thread status tool as part of assignment, we just thought it might make your debugging easier. create_examplesWe’ve also provided a small program create example input files, help you with your testing. build create_examples program, run make create_examples. use program, write its output a file, then use file as input a cracker program. For example: see what cracked passwords should be, use -soln flag when running create_examples (see usage documentation given when running program with no arguments). timing exampleCPU time so called “wall clock” time are not always same thing. CPU time is defined as “the amount of time your program spends running on a CPU,” wall clock time is quite literally, amount of time that would pass on a wall clock (the kind of clock on a wall) between time a program starts a program finishes running. These numbers are often not same!If your program makes a large number of blocking system calls, it may take 10 seconds run, but only actually consume 5 seconds of CPU time. In this case, kernel spent time reading from a file, or writing packets network, while your program sat idle. CPU time can also much larger than wall clock time. If a program runs in multiple threads, it may use 40 seconds of CPU time, but only take 10 seconds of wall clock time (4 threads, each ran for 10 seconds).  demonstrate these differences, we’ve provided a program in tools/timing. c which shows an example of both kinds cases.  compile this program, run make timing, then run . /timing. You should see output like this:","url":"/assignments/password_cracker"},{"title":"Perilous Pointers","content":"IntroductionIn CS 128, CS 225, other classes, you have used various languages that are considered “C-based”, but up now you may have very limited experience in C programming. This lab will provide a short programming introduction pointers, strings, functions in C. This lab will divided up into two parts. In first part, you will debugging broken functions that use pointers incorrectly. In second part, you will need write code call some “creatively defined” functions so that each prints out “Illinois”. For this lab, you should modify only: part1-functions. c part2-main. cAll other files will replaced with new/different files for grading. If you modify any other files for debugging purposes, please ensure you test your program with original files. Part 1There are erroneous/unimplemented functions in part1-functions. c. Your task is modify functions according comment above each function so that output of . /part1 looks exactly as follows:Note that you can just diff with part1-expected-output. Part 2We have given you a file called part2-functions. c, that you may not change. Inside part2-functions. c, you will see twelve different functions, such as first_step(): complete Part 2, you must write part2-main. c so that it makes calls all eleven functions in part2-functions. c, such that each one prints out its “Illinois” line. When running . /part2, your output should look exactly like this:Note that you can just diff with part2-expected-output. You should not edit part2-functions. c file. In fact, when we grade your program, we will replace part2-functions. c file with a new version of file (and we’ll change “Illinois” string so printing out “Illinois” in a for-loop will get you no credit). Compile Run compile release version of code, run:This will compile your code with some optimizations enabled, will not include debugging information. If you use a debugger on ‘release’ build, it will not able show you original source code, or line numbers. Optimizations sometimes expose bugs in your code that would not show up otherwise, but since optimizations tend reorder your code while compiling, an optimized version of your code is not optimal for debugging. You probably don’t need worry about different build types very much for this assignment, but distinction will become more important on future assignments.  compile your code in debug mode, run make debug instead of make.  run Part 1:or run Part 2:or","url":"/assignments/perilous_pointers"},{"title":"Pugnacious Profiles","content":"Over course of this assignment, we will exploring how profilers can used optimize your C program through combination of dynamic analysis, data-structures algorithms along with systems programming. Note: We recommend using EWS systems instead of VM as there would further discrepancies of metrics compatibility between both. High Frequency TradingIn high-frequency trading (HFT), programs analyze market data find take advantage of trading opportunities that often only exist for a few seconds. Messages describing trade offers can reach rates of up 250,000 messages/second. Thus, programs involved in automated trading have process a lot of data extremely quickly.  program provided you will read in process a stream of order messages for multiple stocks. These messages will used update our program’s view of market state. This state is known as “order book”. messages we process will either trigger entry of a new order, change an existing order, or delete an order. At end of stream, this program will print out all current orders in order book. Input / Output program will check command line arguments for a -i input filename flag. If it is present, program will read input stream from file named there. If it is not, program will read input from standard input. Likewise, it will check command line arguments for a -o output filename flag. If it is present, program will write output stream file named there. If it is not, program will write output standard output. Stream Format program will read in input as ASCII text, of which format is as follows:  A &lt;id&gt; &lt;side&gt; &lt;symbol&gt; &lt;quantity&gt; &lt;price&gt; - A new order is added with supplied details. Side is either B for buy or S for sell   X &lt;id&gt; &lt;symbol&gt; - An order is cancelled   T &lt;id&gt; &lt;symbol&gt; &lt;quantity&gt; - An order is (partially) executed for given quantity (remove thisquantity from existing order in your records)   C &lt;id&gt; &lt;symbol&gt; &lt;quantity&gt; - An order is (partially) cancelled for given quantity (remove thisquantity from existing order in your records)   R &lt;id&gt; &lt;symbol&gt; &lt;quantity&gt; &lt;price&gt; - An order is changed have given price quantity Example input:This would a new order sell 300 shares of stock SPY at $117. 88. It is followed by a message change previous order sell at a price of $117. 84. next two messages indicate that order is partially executed cancelled by 100 respectively. next message is a new order buy 200 shares of stock SPY at $117. 11. lasttwo messages add a buy order then cancel it. If this was entire message stream, your program would print out following output. Example output:Part - 1High frequency trading requires optimal performance demanding high speed for this part of project we are going meet those goals. While program provided you does everything correctly, it is too slow scale up process real-time orders. On other hand your competitors solution (TA reference implementation) is way faster than this. Your job is analyze performance of this program bring it within a certain threshold thus defeating your competitor. Time measure time, use /usr/bin/time command:On EWS systems in Siebel, implementation provided you will roughly run around following time output:Note: While this may higher or lower based on computational resources available, it will never get close expected performance threshold. What do each of these values mean which one is relevant for us?  TaskYour job is defeat our reference implementation (your competitors) which has a user time of 2. 000 seconds a system time of 0. 020 seconds for data-set of ascii_data. txt provided you. Your program when executed with -h flag needs below this threshold maintaining correctness in order complete part 1. Profile TimeWhile time command does provide us with an overall performance of our program, it doesn’t help pin point where issue is. Gprof will come our rescue. utilize gprof, use following commands:Examine analysis. txt file which will break down performance of program as per respective functions whichshould help you get started. Note: performance with gprof can a little more due overhead. We will testing your program with time command which should provide more accurate measures. Hints Think whether issue is inside one particular function or underlying data-structure.  Theoretical time complexity ~ Computational time. Is there any particular type of data-structure well suited for this problem which can provide a near constant time complexity.  What contributes system time. Part - 2 (Optional)While time is an important factor while profiling, memory goes hand in hand with it. Once you have optimized for time, you need now bring your heap memory equal or less than our reference implementation. measure memory use following command:This should provide you with following output regarding amount of heap memory consumed:Note: orderbook_mem is compiled using -m32 flag which generates a 32 bit executable. This will thus generate consistent memory usage on both 32 bit 64 bit systems. TaskOur reference implementation uses 11320000 bytes of heap memory for ascii_data. txt dataset. For -h flag which will execute your time optimized implementation, bring your memory consumption equal or less than this value. We will looking out for stack segment as well thus ensure that your stack peak is less than 2500 bytes. Hints Go over data inside ascii_data. txt determining highest values. We will not crossing that threshold for our testing data-sets. Typically, in real world scenario’s there is a predefined min / max however you will also come across instances when you have come up with a comprehensive min-max values store it appropriately.  Think about respective data-types that can effectively store values without wasting memory.  Take into consideration padding. Memory is stored retrieved in form of words size of which is 4 bytes for 32-bit 8 bytes for 64-bit. Thus, size of 29 byte struct will padded 32 bytes. Challenge (Not Graded)Once you have optimized your program for both time memory, your implementation is ready face real world challenge. We have a data file with 10 million order entries. Do you think your program can handle so many transactions?Please click on following link download data file (~225 MB): Our reference implementation which uses no tricks no clever optimizations except for allocating more memory for our datastructure executes this with following performance:It is very well possible get below ~1. 000s for processing this dataset. Up for a challenge!","url":"/assignments/pugnacious_profilers"},{"title":"Resplendent RPCs","content":"WarningBefore you begin this lab, remember run rpcinfo, then rpcgen dns_query. x!This call generates a C version of dns_query. x, server stub, client stub. If you do not run this command, your implementations will not compile with make!BackgroundThis lab will serve as an introduction remote procedure calls UDP. Remote procedure calls, as name suggests, are a way execute a procedure (in C, a function) that exists in a different address space in any language. In this lab, our client in C executes a procedure in C, but it could execute a procedure written in python as well. In order accomplish this, server will agree take in a ‘request’ or ‘query’ from a client send a ‘response’ back, client will agree send a ‘request’ or ‘query’ receive a ‘response’. Actually implementing an RPC framework is really hard. Marshalling, unmarshalling, keeping data formats consistent could easily an MP! Most of time software engineers use an existing RPC format like protobuf thrift. For purposes of this lab we chose use rpcgen. In rpcgen, request response are defined in a . x file in XDR, which is a language that is useful for encoding data that is transferred between different machines. It is easy translate this file into any language, so in this lab it is translated into a C-language . h file with rpcgen. You don’t need worry about implementing this, we’ve done it for you. Server client stubs can generated as well from this . x file in any language (both in C in this lab), these stubs deal with networking between server client. implementation logic, AKA what server client decide do with these requests responses they send back forth, is left up you. Effectively, using RPCs abstracts away complex networking calls that are usually necessary complete this task (i. e. it’s one layer above TCP/UDP). only thing you have do is fill out structs defined in . x file create a responseOverviewIn this lab, we will create a client that queries a server for an IPv4 address for a given domain over RPC. server that receives this query over RPC sends a UDP packet an nameserver which will send back an IP Address – aka a DNS Proxy server. Note: This isn’t actually how true DNS protocol works. true protocol has different resolvers for different parts of domain. For example a domain like www. google. com will first contact . com server, then get routed google. com server then get routed www. google. com server. FailureIn this lab, if a server ever fails retrieve a result, it will return “-1. -1. -1. -1”. Make sure check for this set success field in server response accordingly!Like in chatroom’s read_all_from_socket/write_all_to_socket, remember check errno when sendto() recvfrom() return -1; errno = EAGAIN, meaning you have restart your call. Why UDP?In chatroom, a TCP connection made sense because you wanted stay in contact with chatting server for a long time, never lose messages, receive messages in a particular order. When it comes querying nameservers for DNS resolution in this lab, you only send one packet receive one packet per server then you’re done. overhead in using TCP for this purpose is not necessary, so we opt use faster less complex UDP. What writeMore information in header files – this is high level overview. dns_query_clnt_impl. c resolve_hostname() Given a host a dns server, figures out what IP this hostname points or reports if it couldn’t find hostname. dns_query_svc_impl. c create_response() Given a few parameters, allocates all needed fields for response object on heap contact_nameserver() Given all appropriate parameters, sends a UDP Packet nameserver containing hostname server sends back an IP address or sentinel value (check error section above). Testing make a nameservers for testing, run . /authoritative_nameservers which by default runs on port 9000. This will let you fully complete a DNS lookup of IPv4 addresses of various websites (check hosts. txt) given that you have a complete implementation. This shouldn’t necessary create a complete implementation, but if you want test your implementation out with other domains, you can supply your own files as arguments. Check usage of . /authoritative_nameservers with -h flag. Make sure follow format exactly make sure that you reference correct &amp; existing servers ports in files you create!ExampleThis command will set up a nameserver:Run your server with environment variables:Then send a query for a domain through client. client requires two arguments. first is IP address of server that will accept its RPC second is domain resolve. See if your client interprets correct input when A hostname is in none of caches or nameserver A hostname is in none of caches but on nameserver A hostname is in server not client cache A hostname is in client cache Makes sure that your client works with your serverThings you don’t need worry about: Don’t worry about retransmitting UDP packets.  For this lab we won’t testing memory as intensivelyExtra: Tech Descriptions motivation for this type of protocol is influenced by . In a nutshell, DNS is really insecure. Your computer first (usually) sends your host name request a server unencrypted, has no way of verifying that sent-to server is an actual server. Secondly, when your computer gets a response back, it has no way of verifying that response was sent from that server. This is all because UDP packets are plain text can spoofed – so first leg of this connection matters a lot. other parts of connection don’t need matter as much because often they are on your Internet Service Provider’s internal, trusted network.  benefit of our proxy server is that we can establish a secure TLS/TCP (Encrypted TCP connection) with a server verify that server is a DNS server with a Certificate. Then all hostnames sent from server will hidden from prying eyes it will nearly impossible forge requests.  DNS communications usually happen on port 53, so records don’t need specify a port send packets (unlike in this lab) IPv4 addresses in a cache need have a valid time live (they can’t too old or you have requery!) DNS has more details; you can do queries that specifically ask for a nameserver or a mailserver, for example.  There can multiple IP addresses for one domain, but not in this lab.  This lab only covers case where domain is defined as [something]. [something]. [top-level]. , but as you know there can more subdomains as well e. g. www. cs. illinois. edu DNS has some weak points as it is. A particular nameserver can DDOSed so that all caches of a domain expire no one can access it. You can mess with any computer’s DNS resolution so that it returns invalid IPs for a domain. A good way mess with your friends is making it so that www. google. com always directs an IP address for www. bing. com.  Mentioned before, but keep in mind how simple it is send data between 2 programs written in 2 different languages with RPCs If you’re curious about more modern frameworks for RPCs, check out gRPC (https://grpc. io/). Extra: DNS Resolution OverviewAs you know, domains are not useful as-is; they need translated into an IP address. IP addresses are not stored all at one place; they are distributed hierarchically through multiple servers responsible for them, called authoritative nameservers. A recursive DNS server (which is usually provided by your ISPs) does work of contacting all necessary nameservers in this hierarchy. Here’s an overview of how it does this: First it goes root nameserver, server responsible for ‘. ’ AKA root of all domains (fun fact; all domains have an implicit . at end, so www. microsoft. com is also www. microsoft. com. ). This server will hold nameservers responsible for top-level domains like . com, . org, . net, so appropriate nameserver is returned recursive server. recursive server then goes top-level nameserver it just got, which is responsible for holding nameservers responsible for domains registered under top-level domain, so . com is responsible for nameservers for reddit. com, tumblr. com, twitter. com, etc, so appropriate nameserver is returned. nameserver just received is authoritative for your initial domain, so when you contact it it will return your final answer! recursive server returns this final answer query is finished. This recursive DNS server is server you will implement in lab. ","url":"/assignments/resplendent_rpcs"},{"title":"Savvy Scheduler","content":"IntroductionIn this lab you’ll writing a scheduler. Rather than interacting directly with operating system, we’ve whipped up a userspace threading library!Before you startThink about how implement a scheduler!Try answer these questions… What do you do for incoming jobs? How do you sort your job so that you can find next job according different scheme? What kind of data structures do you need?What a scheduler does is put all jobs it gets in a queue then sort them in some order (related scheme). Scheduler gives them CPU one by one. key in scheduler is scheme it use, choice of scheduling algorithm depends on many factors. For example, First Come First Serve (FCFS) is really easy implement but might keep a short job waiting really long for a long process at front. So now we know that a scheduler puts jobs in a queue, sort them, give them CPU in some order. Then what will best data structure store these jobs? Priority queue can do this job really well! A priority queue is a queue with a really nice feature. It puts every incoming node in correct position so that queue is always ordered. Therefore, you don’t need call sort() every time you get a new node (job). you can simply give them out by pulling out first element of queue. An important question now is: “What do you mean by ordered?” Let’s take FCFS scheduling for example. Ideally, scheduler should able to: Receive a job.  Put it in a queue with some priority.  Pull job with highest priority give CPU.  since we are doing FCFS, we want element that comes first at front of queue. So you should give jobs arriving earlier higher priority jobs arriving afterwards lower priority. Take Shortest Job First (SJF) for another example. You can give those jobs that can finished faster higher priority. As you can see here, key implement a scheduler is decide PRIORITY. way decide priority in a priority queue is by giving a comparator function. By defining a job A is better than a job B in a priority queue, we mean that A has higher priority than B. So basically, half of your job in this lab is simply writing a comparator function that helps you decide which job has higher priority. MissionBackground: Priority Queue build a scheduler, a fundamental data structure is a priority queue. You do not need implement one, but should read understand libpriqueue, our priority queue library. You will using this library in your scheduler. SchedulerYou will need implement scheduling callbacks for a userspace threading library.  scheduling algorithms you are going implement are: First Come First Served (FCFS) Preemptive Priority (PPRI) Priority (PRI) Preemptive Shortest Remaining Time First (PSRTF) Round Robin (RR) Shortest Job First (SJF)You can read up on scheduling in You should use priority queue that we provided help you complete this part of lab.  complete this lab, you must implement six comparator functions eight scheduler functions (and one optional one) defined in libscheduler. c. These functions are self-descriptive, but a full function outline for each function is provided for you in file. These functions will utilized by green threading library (Check out section on Gthreads below). You might want understand how scheduler works. So we put a detailed explanation in bottom of this webpage. Directions help you finish this lab efficiently, we recommend you follow these steps: Understand when your function will called.  Try write pseudocode for each comparator first see what kind of information you will need. For example, you probably need arrival time of each job so you can implement FCFS by setting priority according time.  Create data members in job_info you need for step 2.  Go back complete your comparator functions.  second part of lab is set up scheduler itself manage incoming jobs completed jobs. Now you should implement those functions related CPU (like scheduler_new_job(), scheduler_job_finished(), scheduler_quantum_expired()).  Take a look at all these functions, write some pseudocode realize your thoughts.  You might need implement some helper functions help you write these functions.  Finish these functions.  last part of your job is computing stats clean-up, which is fairly trivial. You may need some extra variables help you keep track of these stats. Job StructWe have provided a job struct defined in libscheduler. h. You do not need modify state, ctx, or stack_start fields. only field you will using or modifying is metadata, where you must insert your job_info struct that you will define in libscheduler. c. Functions you need implement only graded file is libscheduler. c. You will need augment job_info struct implement following functions:void scheduler_start_up(scheme_t s)This function is implemented for you, but you can add some code it if you need initialize any global variables. int comparer_fcfs(const void *a, const void *b)Comparer function for fcfs schemeint comparer_ppri(const void *a, const void *b)Comparer function for ppri schemeint comparer_pri(const void *a, const void *b)Comparer function for pri sschemeint comparer_psrtf(const void *a, const void *b)Comparer function for psrtf schemeint comparer_rr(const void *a, const void *b)Comparer function for rr schemeint comparer_sjf(const void *a, const void *b)Comparer function for sjf schemevoid scheduler_new_job(job *newjob, int job_number, double time, scheduler_info *sched_data)This function is responsible for setting up a new job. You must populate newjob-&gt;metadata with information found in scheduler_info. contents of newjob-&gt;metadata cannot a pointer sched_data since this variable may on stack of calling function. Once you’ve set up newjob offer it queue. job *scheduler_quantum_expired(job *job_evicted, double time)This function is called at end of every time quantum. If there is no job currently running, job_evicted will NULL. If current scheme is not preemptive job_evicted is not NULL, return job_evicted. In all other cases, if job_evicted is not NULL, place it back on queue return a pointer next job that should run. (Note, it is possible for next job same as job_evicted)void scheduler_job_finished(job *job_done, double time)This function will called when a job is finished. You should update any statistics you are collecting free any buffers you may have allocated for this job’s metadata. double scheduler_average_waiting_time()This function returns average waiting time across all jobs so far. double scheduler_average_turnaround_time()This function returns average turnaround time across all jobs so far. double scheduler_average_response_time()This function returns average response time across all jobs so far. void scheduler_show_queue()This is an optional function that you can implement for debugging purposes. TestingWe have provided three interfaces testing this lab. first testing interface is scheduler_test. c. This file allows you directly test functions you’ve implemented in libscheduler. c. We recommend using this one, have already populated it with a few test cases of our own! This is how autograder will testing your code. There are 10 tests that we have provided you. You can run each test with following:On success test will return zero (you can check return code with echo $?). On failure one of asserts will cause an error.  second testing interface is write your own tests similar ones in main. c in gtest. c. You can then run . /gtest inspect gthreads. log or any printouts check if your implementation works.  final testing interface should thought of as more of a way gain intuition behind concepts rather than a way test your code for correctness. This method is run your scheduler with green threading library. You can see example code in main. c which you will not able edit. expected outputs for various scheduling algorithms are stored in examples/ you will able diff your output see if your scheduler produces correct output. There is an example below. For your convenience, we’ve wrapped this with bash script testall. sh. Running . /testall. sh will run all schemes diff them with expected output check if your implementation is correct. If you’d like test specific schemes, you can pass those in as arguments, for example . /testall. sh rr fcfs pri will only test round robin, first-come-first-serve priority. However, since this method of testing relies on outputs generated every second, it may not accurately reflect schedulers behavior, may falsely report your solution as correctly working. get around this, you can also take a look at generated log in gthread. log. This contains information about each thread’s context switches you can manually inspect it see if it does what you expect. Using log file, we have built a visualizer for this data that will display which thread ran in approximately 500ms intervals. Note that visualizer doesn’t perfectly display all context switches, performs especially badly with round robin output. However, it works well for schemes such as sjf will display following if gthread. log contains log of running . /main sjf:There are couple things note about this output. first is that each ‘+’ represents something slightly more than half a second so we interpret every two ‘+’s as something close 1s. second thing is note that thread names are replaced by a uid in log file. You can which ones corresponding which by looking through log for registration messages code check which order threads were created. Spooky bugsThis lab has some strange gotchas when testing with gthread library. For this reason, we recommend using (and augmenting) tests in scheduler_test. c. If you notice any random segfaults or freezes in program that occur non-deterministically (maybe only once or twice every 10 runs) please report this us so we can get that patched! (This will not affect grading since grader will directly test functions in libscheduler. c as opposed actual context switches generated by green threading library.  threading model - gthreads (optional reading)Initial idea code from . Gthreads is an implementation of green threads in c! It uses libscheduler schedule threads. NOTE: green thread scheduler uses alarms a SIGALRM handler, it is an error use some other handler for SIGALRM with gthreads. ConstantsThere are two constants defined as enums in gthread. h, MaxGThreads (not used, remove) StackSize. Stack size determines size of stack for each green thread spawned. Gthread FunctionsgtinitThis function should called before anything elseThis function sets up scheduler a signal handler for SIGALRM. It is undefined behavior call any other function in gthread before this one. Takes in a scheme_t detailing what scheduling algorithm used. gtgoThis is like pthread_create. It spawns a new green thread (won’t start until it’s actually scheduled). It takes in function execute a scheduler_info* get it’s scheduler attributes. gtstartThis function starts off scheduling process with a call ualarm. gtretThis function should called from a thread clean up exit. If called from main it will wait for all other threads finish before exiting with status as argument gtret. If any other thread calls this function, it is equivalent calling return. gtsleepThis function will sleep for at least number of seconds specified by argument. Unlike sleep(2), this function will also call yield allow another thread run (if there is one on queue). gtdoyieldThis function is a wrapper around internal function gtyield might perform a context switch another thread. return value will true if a context switch occurred false otherwise. argument is not important, so long as it is not -1 or SIGALRM. gtcurrjobReturns a job* indicating current running jobOkay, so how does this work? idea of green threads is essentially have a user-space thread that is lighter than a pthread, but at cost of not executing in parallel. Instead a green thread will switch between many “threads of execution” giving illusion of parallel processing. As you might have guessed, this switch involves what we call a “context switch” that allows us save current state of thread before moving a different one.  learn more about concept, read this article that we used as a starting point. Now, let’s talk about what we’ve added on top of that very simple implmentation. We need a way preempt threads. For our purposes, a signal is an acceptable solution this problem. We have used function ualarm(3) schedule alarms on regular intervals. handler then calls gtyield which will call scheduler_quantum_expired select next job run. Note that almost all scheduling magic is implemented in libscheduler! only exception is that main thread will never sent any of functions in libscheduler. Instead, every other quanta, gtyield will store current job do a context switch main, next time gtyield is called from main, process will switch back stored job. ","url":"/assignments/savvy_scheduler"},{"title":"Example1","content":"Example 1Consider following simple schedule:   job number arrival time running time priority     0 0 8 1   1 1 8 1   2 3 4 2   flow of execution of functions calls is as follows:When simulator is executed flow of execution is implemented correctly, you will see following output:","url":"/scheduler_example1"},{"title":"Example2","content":"Example 2Consider following simple schedule:   job number arrival time running time priority     0 0 8 1   1 1 8 1   2 3 4 2   flow of execution of functions calls is as follows:When simulator is executed flow of execution is implemented correctly, you will see following output:","url":"/scheduler_example2"},{"title":"Example3","content":"Example 3Consider following simple schedule:   job number arrival time running time priority     0 0 8 1   1 1 8 1   2 3 4 2   flow of execution of functions calls is as follows:…it’s important note that even though jobs arrive in order 0 1 2, order of jobs in your priority queue will following rotation: 0 2 1 -&gt; 2 1 0 -&gt; 1 0 2 -&gt; 0 2 1. When simulator is executed flow of execution is implemented correctly, you will see following output:","url":"/scheduler_example3"},{"title":"Shell","content":"BackstoryWell, we’ll keep it short – you got fired from Macrohard. Your boss brought you in for a code review was more than disappointed. Apparently, they wanted a C++ style vector: we didn’t get memo. Now, you’ve decided work for insert hot tech company here, you got job! However, there’s a catch - all newhires in insert hot tech company here apparently have go through a newcomers test if they want keep their jobs. task? Write a shell. So, you’re going drop a :fire: :fire: shell that is so fancy that your boss will not just keep you in company, they’ll immediately give you a pay raise as well.  basic function of a shell is accept commands as inputs execute corresponding programs in response. You will provided vector, sstring format. h libraries for your use. Hopefully, this will make things right you can secure your foothold at insert hot tech company here. Feel free refer Unix shell as a rough reference. Important Things NoteFork Bombs:fork_and_knife: :bomb: :bangbang: prevent you from fork bombing your own VM, we recommend looking into ulimit. This will allow you set a limit for how many times you can fork. Note that ulimit is terminal session specific, so you will need  do it everytime you launch a terminal add this your ~/. bashrc file (feel free look up online how do so), so that it is run every time you log in your VM. Note that you should give it a more generous amount (say, 100-200), since terminal will likely have background processes already running. If you give it too small a limit, you won’t able launch anything, you’ll need launch a new terminal. If you happen fork bomb your CS Cloud VM, please notify course staff in a private post with your VM number. Note that it may take up a few hours for us respond, so try not fork bomb your VM. Plan Before You StartThis assignment marks beginning of a series of projects where you will given mostly blank files without predefined functions fill in. Most of remaining MPs will challenge your design skills create interesting utilities. Therefore, it is important that you read entirety of documentation (including part 2), as well as header files get a clear idea on what needs done. A few reminders about good coding developing practices that will really help you in rest of semester: List down features that you need implement, as well as gotchas. Make a to-do list ensure you don’t miss out anything.  Plan out entirety of your assignment. Create a skeleton of how your entire code will look like. This will prevent you from needing restructure your entire code add in a single new feature.  Ensure that you fully understand system calls/library functions you’re using - parameters, return values, possible errors, gotchas notes.  Structure your code into modular functions. You do not want debug a 1500 line while loop within main.  Work incrementally. Implement a feature, test, debug, move on.  Good naming spacing will make your code much more readable.  Try putting TODO comments in unfinished portions of your code. They are automatically highlighted in many text editors, which alerts you incomplete code. Do Not Use systemSince a learning objective of this assignment is use fork-exec-wait pattern, if you use system, you will automatically fail this MP. Input FormattingDo not worry about irregular spacing in command inputs (i. e. extra whitespace before after each token). This is considered undefined behavior will not tested. You are free make your code as robust as you want, but we will only test basic cases without irregular spacing (unless specified). Output FormattingSince this MP requires your shell programs you launch print a variety of things like output messages error messages, we have provided you with our own highly customized formatting library. You should not printing out stdout stderr at all; instead, all output errors should printed using functions provided in format. h. In format. h you can find documentation about what each function does, you should use them whenever appropriate. If you place print statements in your debugging code, please remember remove them before autograding, or use #define DEBUG block place your print statements. Note: don’t worry if you don’t use all of functions in format. h, but you should use them whenever their documented purpose matches situation. Flush Before ForkingEnsure that you fflush output file handles before forking. See for more information on why this is necessary. Overview To-Dos shell is responsible for providing a command line for users execute programs or scripts. You should very familiar with bash by now, which will basis for your own shell. This is a 2 week MP, features you will need implement are as follows:Part 1 Starting up a shell Optional arguments when launching shell Interaction Built-in commands Foreground external commands Logical operators SIGINT handling ExitingPart 2Everything from part 1, and: Background external commands ps Redirection commands Signal commandsStarting Your Shell shell should run in a loop like this executing multiple commands: Print a command prompt Read command from standard input Print PID of process executing command (with exception of built-in commands), run command shell must support following two optional arguments, however, order of arguments does not matter, should not affect functionality of your shell. Your shell should able handle having none, one or both of these arguments. HistoryYour shell should support storing history of commands executed across shell sessions. command is as follows:When provided -h, shell should load in history file as its history. Upon exiting, shell should append commands of current session into supplied history file, even if shell is in a different working directory than where it started. If file does not exist, you should treat it as an empty file. format of history file stored should exactly same as a script file, where you list a series of commands executed. Example:history. txt:Updated history. txt:Notes: If the -h flag is not specified, shell will still keep a history of commands run, but will not read/write from/to a history file. Just think of it like private browsing mode for your terminal.  Every command should stored into history file, unless specified. FileYour shell should also support running a series of commands from a script file. command is as follows:When provided -f, your shell will both print run commands in file in sequential order until end of file. See following example file execution:commands. txt:You have been given a sample script file test_file. txt. Your history files script files should formatted in same manner (this means you can use your history file as a script file in -f). If user supplies an incorrect number of arguments, or script file cannot found, your shell should print appropriate error from format. h exit. Tip: getopt function may come in handy. :smile:Interaction Within Your ShellPromptingWhen prompting for a command, shell will print a prompt in following format (from format. h):&lt;pid&gt; is process ID of shell, &lt;path&gt; is a path current working directory. Note lack of a newline at end of this prompt. Reading in Commands shell will read in a command from stdin (or a file if -f was specified). Command Types FormatsShell supports two types of commands: built-in external (i. e. non-built-in). Built-in commands are part of shell’s code, are executed without creating a new process. External commands must executed by a new process, forked from your shell. If a command is not one of built-in commands listed, it is an external command. Command arguments will space-separated without trailing whitespace. Your shell does not need support quotes (for example, echo \"hello there\"). Running Commands shell should run command that was read in previously. If command is run by a new process, PID of process should printed like this:This should printed by process that will run command, before any of output of command is printed (prints used are in format. h). Keeping HistoryYour shell should store command that user entered, so user can repeat it later if they wish. Every command should stored unless otherwise noted. A vector may useful here. exit shell will exit once it receives exit command or once it receives an EOF at beginning of line. An EOF is sent by typing Ctrl-D from your terminal. It is also sent automatically from a script file (as used with -f flag) once end of file is reached. This should cause your shell exit with exit status 0. If there are currently stopped or running background processes when your shell receives exit or Control-D (EOF), you should kill cleanup each of those children before your shell exits. You do not need worry about SIGTERM. :warning: If you don’t handle EOF or exit exit, you will fail many of our test cases!:warning: Do not store exit in history!Catching Ctrl+CUsually when we do Ctrl+C, current running program will exit. However, we want shell itself ignore Ctrl+C signal (SIGINT) - instead, it should kill currently running foreground process (if one exists) using SIGINT. One way do this is use kill function on foreground process PID when SIGINT is caught in your shell. However, when a signal is sent a process, it is sent all processes in its process group. In this assignment, shell process is leader of a process group consisting of all processes that are fork‘d from it. So another way properly handle Ctrl+C is simply do nothing inside handler for SIGINT if it is caught in shell - your shell will continue running, but SIGINT will automatically propagate foreground process kill it. However, since we want this signal sent only foreground process, but not any backgrounded processes, you will want use setpgid assign each background process its own process group after forking. (Note: think about who should making setpgid call why). Built-in CommandsThere are several built-in commands your shell is expected support. cd &lt;path&gt;Changes current working directory of shell &lt;path&gt;. Paths not starting with / should followed relative current directory. If directory does not exist, then print appropriate error. Unlike your regular shell, &lt;path&gt; argument is mandatory here. A missing path should treated as a nonexistent directory. There is a system call that may helpful here. !historyPrints out each command in history, in order. :warning: This command is not stored in history. #&lt;n&gt;Prints executes \\(n\\)-th command in history (in chronological order, from earliest most recent), where \\(n\\) is a non-negative integer. Other values of \\(n\\) will not tested. command executed should stored in history. If \\(n\\) is not a valid index, then print appropriate error do not store anything in history.  following example assumes a fresh history::warning: Print out command before executing if there is a match. :warning: #&lt;n&gt; command itself is not stored in history, but command being executed (if any) is. !&lt;prefix&gt;Prints executes last command that has specified prefix. If no match is found, print appropriate error do not store anything in history. prefix may empty. following example assumes a fresh history::warning: Print out command before executing if there is a match. :warning: !&lt;prefix&gt; command itself is not stored in history, but command being executed (if any) is. Invalid Built-in CommandsYou should printing appropriate errors in cases where built-in commands fail; for example, if user tries cd into a nonexistent directory. External CommandsFor commands that are not built-in, shell should consider command name name of a file that contains executable binary code. Such a code must executed in a process different from one executing shell. You must use fork, exec, wait/waitpid.  fork/exec/wait paradigm is as follows: fork a child process. child process must execute command with exec*, while parent must wait for child terminate before printing next prompt. You are responsible of cleaning up all child processes upon termination of your program. It is important note that, upon a successful execution of command, exec never returns child process. exec only returns child process when command fails execute successfully. If any of fork, exec, or wait fail, appropriate error messages should printed. child should exit with exit status 1 if it fails execute a command. Some external commands you may test see whether your shell works are:Tip: It is good practice flush standard output stream before fork able correctly display output. This will also prevent duplicate printing from child process. :bangbang: Please read disclaimer at top of page! We don’t want have give any failing grades. :bangbang:Logical OperatorsLike bash, your shell should support &amp;&amp;, ||, ; in between two commands. This will require only a minimal amount of string parsing that you have do yourself. Important: each input can have at most one of &amp;&amp;, ||, or ;. You do not have support chaining (e. g. x &amp;&amp; y || z; w). Important: you should not try handle combination of !history, #&lt;n&gt;, !&lt;prefix&gt;, or exit commands with any logical operators. Rather, you can assume these commands will always run on a line by themselves. Important: logical operators are stored in history as one entry. This means your history should look like soAND&amp;&amp; is AND operator. Usage: shell first runs x, then checks exit status.  If x exited successfully (status = 0), run y.  If x did not exit successfully (status ≠ 0), do not run y. This is also known as . This mimics short-circuiting AND in boolean algebra: if x is false, we know result will false without having run y. :question: This is often used run multiple commands in a sequence stop early if one fails. For example, make &amp;&amp; . /shell will run your shell only if make succeeds. Tip: You may want look into provided macros read status of an exited child. OR|| is OR operator. Usage: shell first runs x, then checks exit status.  If x exited successfully, shell does not run y. This is short-circuiting.  If x did not exit successfully, run y. Boolean algebra: if x is true, we can return true right away without having run y. :question: This is often used recover after errors. For example, make || echo 'Make failed!' will run echo only if make does not succeed. Separator; is command separator. Usage: shell first runs x.  shell then runs y. :question: two commands are run regardless of whether first one succeeds. MemoryAs usual, you may not have any memory leaks or errors. Note that still reachable memory blocks do not count as memory leaks. Background ProcessesAn external command suffixed with &amp; should run in background. In other words, shell should ready take next command before given command has finished running. There is no limit on number of background processes you can have running at one time (aside from any limits set by system). There will a single space between rest of command &amp;. For example, pwd &amp; is valid while you need not worry about pwd&amp;. Since spawning a background process introduces a race condition, it is okay if prompt gets misaligned as in following example:Note this is not only way your shell may misalign. While shell should usable after calling command, after process finishes, parent is still responsible for waiting on child. Avoid creating zombies! Do not catch SIGCHLD, as catching SIGCHLD comes with all sorts of caveats subtleties that are hard work around. Instead regularly check see if your children need reaping (think about placement of this piece of code: where should you put this, why). Think about what happens when multiple children finish around same time, what happens if a foreground/background process finish around same time. Backgrounding will not chained with logical operators nor with redirection operators. psLike our good old ps, your shell should print out information about all currently executing processes. You should include shell its immediate children, but don’t worry about grandchildren or other processes. Make sure you use print_process_info_header(), print_process_info(), time_struct_to_string() (and maybe some other helper functions)!Note: while ps is normally a separate binary, it is a built-in command for your shell. (This is not “execing ps”, this is you implementing it in code. Thus you may have keep track of some information for each process. )Your version of ps should print following information for each process: PID: pid of process NLWP: number of threads currently being used in process VSZ: program size (virtual memory size) of process, in kilobytes (1 kilobyte = 1024 bytes) STAT: state of process START: start time of process. You will want add boot time of computer (), start time of process () calculate this. Make sure you are careful while converting from various formats - man pages for have helpful tips.  TIME: amount of cpu time that process has been executed for. This includes time process has been scheduled in user mode (utime) kernel mode (stime).  COMMAND: command that executed processSome things keep in mind: order in which you print processes does not matter.  ‘command’ for print_process_info should full command you executed. &amp; for background processes is optional. For main shell process only, you do not need include command-line flags. Ensure that ‘command’ does not have trailing whitespace at end of it.  You may not exec ps binary complete this part of assignment. Example output of this command:Hint: You may find /proc filesystem useful, as well as man pages for it. Redirection OperatorsYour boss wants some way for your shell commands able link together. You decide implement &gt;&gt;, &gt;, &lt;. This will require only a minimal amount of string parsing that you have do yourself. Important: each input can have at most one of &gt;&gt;, &gt; or &lt;. You do not have support chaining (e. g. x &gt;&gt; y &lt; z &gt; w). Important: you should not try handle combination of cd, !history, #&lt;n&gt;, !&lt;prefix&gt;, ps, or exit commands with any redirection operators. Rather, you can assume these commands will always run on a line by themselves. Note: Assume that redirection operator commands will formatted correctly. Any incorrectly formatted redirection commands is considered undefined behavior. OUTPUT&gt; places output of a command into a file. Usage:If file exists, overwrite contents of file with output of current command. Example usage:APPEND&gt;&gt; appends output of a command into a file. Usage:If file does not exist, assume that it is an empty file. Example usage (hi. txt does not exist in directory before these commands are executed):INPUT&lt; pipes contents of a file into a command as its input. Usage:If file does not exist, it is undefined behavior. Example usage:hello. txt contains:Hint: dup will useful for all redirection commandsSignal CommandsLike bash, your shell will support sending signals its child processes. We require you implement 3 signals listed below. kill &lt;pid&gt; ever-useful panic button. Sends SIGKILL specified process. Use appropriate prints from format. h for: Successfully sending SIGKILL process No process with pid exists kill was ran without a pidstop &lt;pid&gt;This command will allow your shell stop a currently executing process by sending it SIGSTOP signal. It may resumed by using command cont. Use appropriate prints from format. h for: Process was successfully sent SIGSTOP No process with pid exists stop was ran without a pidcont &lt;pid&gt;This command resumes specified process by sending it SIGCONT. Use appropriate prints from format. h for: Process was successfully sent SIGCONT No such process exists cont was ran without a pidNote: Any &lt;pid&gt; used in kill, stop, or, cont will either a process that is a direct child of your shell or a non-existent process. You do not have worry about killing other processes. Summary of History StoringIn case you are still confused about what exactly store in history, here are relevant examples. last row corresponds an “invalid command”, a histori-cally troublesome case.    Examples: What should I store?     cd &lt;path&gt; cd &lt;path&gt;   !history Don’t store anything.    #&lt;n&gt; Command #&lt;n&gt; points (IF any).    !&lt;prefix&gt; Command !&lt;prefix&gt; points (IF any).    echo HISTORY_IS_HARD echo HISTORY_IS_HARD   echo pi:G-&gt; &amp;&amp; echo G/ker(phi) echo pi:G-&gt; &amp;&amp; echo G/ker(phi)   echo x; echo y echo x; echo y   jarvis, store this in history jarvis, store this in history  GradingNote that Week 1 Week 2 count as one week of MP grades respectively. See overview for a list of features required for each week. ","url":"/assignments/shell"},{"title":"Teaching Threads","content":"reduce()In functional programming, there is an operation called . reduce takes three parameters: an input list, a function apply elements of that list, an initial value (or base case). function takes two inputs returns a value. It is first applied base case first element, from then on, function is repeatedly applied cumulative result next element. reduce then returns “reduced” value of entire list. Depending on which direction this is applied, this is sometimes called a left-fold or right-fold. In this problem, functions are associative, so it does not matter. Here’s a concrete example. Say we have input list [1, 2, 3], a callback function int add(int elem1, int elem2) which takes two numbers returns their sum, a base case of 0. If we call reduce, resulting value would add(add(add(0, 1), 2), 3) = 6. In C code, it looks something like this (you can find this in reduce. c):Notice that this is basically a for-loop on list. There are no fancy algorithms we can use improve runtime, since callback function is essentially a black box. So, how can we make it faster? Parallelism rescue!par_reduce()Since we guarantee that all given functions are commutative associative, reduce becomes , which means that: it is easy divide problem into subproblems, none of subproblems depend on each other. Given an input list [1, 2, 3, 4, 5, 6] add(), we can meet requirements for “embarrassingly parallel” by doing following with 2 threads: Thread 1: evaluate reduce([1, 2, 3]) Thread 2: evaluate reduce([4, 5, 6]) Thread 1: write reduce([1, 2, 3]) into index 0 of new list Thread 2: write reduce([4, 5, 6]) into index 1 of new list Join threads Main thread: evaluate reduce(new_list) = reduce([6, 15])Finally, we should have our answer of 21. Notice that size of list in last call in main thread is exactly number of threads used, because we have one result from each thread. In this case, final list is of size 2. Also, note that none of these subproblems depend on each other evaluate due our guarantees on associative property, so they can safely done concurrently. Now, it would unfortunate if someone had manually figure out assignment of jobs each thread every time some aspect of problem changed, such as size of input list, callback function, number of threads, or base case. alleviate that, we are providing our users with a nice par_reduce() function that takes in an input list, callback function, base case, number of threads (not including main thread). end goal is that par_reduce() does exactly what reduce() does (in case that given functions are associative) except in parallel, with multiple threads. user, it’s same old reduce() function—just faster!For this lab, you are responsible for implementing par_reduce() in par_reduce. c. Some food for thought: What does int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); do?  What are start_routine arg?   What information does each thread need know in order do its job? How would you divide problem among your threads?  What happens when num_threads does not divide list_len?   What does int pthread_join(pthread_t thread, void **retval); do?  What is retval?  We expect your par_reduce() not spawn unnecessary worker threads. Each worker thread you spawn should process at least one element of input list. Therefore, you should only spawn min(num_threads, list_len) worker threads. Testing your codeWe have provided a makefile that will compile your code along with our framework. We recommend that you read through main. c so that you understand how we are calling your par_reduce in par_reduce. c. After running make, you can run executable as follows: &lt;reducer_name&gt; is one of following: “add”, “mult”, or “slow”.   “add” adds every element with a base case of 0.  “mult” multiplies every element with a base case of 1.  “slow” doesn’t perform any computation, but sleeps a small amount each time it is called. You may notice that add multiply might get slower more threads you use–this is because starting new threads takes time, sometimes extra time needed spawn new threads exceeds time saved in computation, especially for extremely quick ones like addition. So, we’ve given you a “slow” reducer that will let you test make sure that running with n threads will take around 1/n time.    &lt;list_len&gt; is number of elements in list of random integers we’ll pass your par_reduce.  &lt;num_threads&gt; is number of threads use. You can also run make debug run debugging executable with same arguments:Examplesaddmultslow [example 1]slow [example 2]slow [example 3]","url":"/assignments/teaching_threads"},{"title":"Terrifying TODO lists","content":"Welcome CS 296’s first lab! Unlike CS 341, this course only has labs (and notevery week!). Each lab will usually involve getting some hands on experiencerelated our lectures. You will given time in class complete thisassignment. If you are unable finish it by end of period, you haveuntil end of this week complete submit your lab implementation. Thisweek, lab is due at end of this lab period. Your grade will determined based off of whether or not you made an attempt in good faith. Today’s lab is inteded help you explore concepts you have been learningin CS 341 also introduce, processing binary data how analyze aprogram like a systems programmer!Obtaining honors labsWe have a seperate repo set up for honors labs which you can add a remote your own repository. You can then pull future labs by running git pull honors master.  task at handFor starters, please read todo. txt format that can found here: Start by implementing a program that can parse todo. txt format displaytasks, sorting them by a user’s choice of completion, due date, priority,project, or tag. You must implement this parser/browser in bash, go or perl. Course staff will officially support bash. You may use any standard utilitiesinstalled on VM.  sure consider how your program will handle invalid inputs, how yourprogram provides a clean usable interface a user, how data will formated displayed a user.  submit, push your code with git push origin master we will grade thisassignment manually.  goal of this assignment is get you familiar with environment systemsprogrammers work with. A large part of systems programming is being able workwith various formats of data analyse a scenario, such as sifting through logs find out why a kernel crashed or sorting through some timed output findwhich inputs a program give you best performance. able work withthis kind of data efficiently, having mastery over a scripting languages such asbash, awk, perl, sed (to a certain extent), is incredibly useful. Furthermore, we hope that if you do this week’s assignment in bash you willexplore utilities availible on your machine which may help you throughout semester in 341 or in your project. Optional taskIf you finish, continue onwards design implement a more ‘effecient’version of todo. txt. Efficiency can determined based off of followingcriteria: Size of file vs number of entries Time taken retrieve an entry based on some criteria Time taken insert entries into fileHere are some hints get you started: Calling read frequently can impact performance due system call overhead.  When storing any data in a file, do you need store a string representation? What data structures have least overhead when serialized a file? Can you compress data you are storing?","url":"/assignments/terrifying_todo_lists"},{"title":"Utilities Unleashed","content":"OverviewIn this lab, you will implementing following C utilities:  Notes: Do not worry about flags or features that we do not mention.  Do not print any of your debug information out for your final submission.  All printing (except env vars) should handled with format. h.  A common issue is double printouts. If this happens you, try flushing stdout before you fork/exec. If this solves your issue, ask yourself why. WARNING!If you fork bomb on any autograder run, you will receive a zero on this assignment.  prevent you from fork bombing your own VM, we recommend looking into . This will allow you set a limit for various operations on your system, including how many files you can open concurrently or how many times you can fork. side effect is that a poorly chosen limit may throttle your system’s operations (e. g. setting fork limit too low may make your terminal unable execute commands!). format. c . hSince this lab requires your programs print messages stdout stderr, we have provided you with format. c format. h. You should not printing out stdout stderr at all. Instead, you should using provided functions. You can find documentation for each function in format. h. Please read documentation in format. h multiple times determine when each function should used. This is our way of ensuring that you do not lose points for formatting issues, but it also means that you are responsible for handling any errors mentioned in format. c format. h. It is common for students fail certain test cases on this assignment with seemingly functional code, it is almost always because of improper usage of format. h. timeIn this lab, you will implementing time. So if a user enters:then time will run sleep with argument 2 print how long it took in seconds:For more examples, you can play with Linux’s builtin time command by typing time YOURCOMMAND (time ls -l, for example) in your terminal. sure add . / beginning (or use full path your time executable file if you are in another directory), otherwise builtin time will called. We’ve also provided a test executable run basic tests on your time implementation. Note that although these tests are similar those that will run on autograder they are not identical, so passing locally does not guarantee you will receive full credit. It is still your responsibility ensure you have functional code. Note that we only care about , we recommend using with CLOCK_MONOTONIC. Pro tip: 1 second == 1,000,000,000 nanoseconds. Nota bene: You may not use existing time program.  You must use fork, exec, wait (no other solutions will accepted).  If child process does not terminate successfully (where its exit status is non-zero), you should exit with status 1 without printing time.  We will only run time with one program.  commands we will run can take any number of arguments.  Do your time computations with double-precision floating pointer numbers (double) rather that single-precision (float).  We have provided functions in format. h that we expect you use wherever appropriate. Useful Resources   envIn this lab, you will implementing a special version of env. Usage:Please re-read this section multiple times before starting: Each variable is in form of NAME=v1, separated by spaces.  Values may contain references environment variables in form %NAME, including variables that were set earlier. As a result, variables should processed from left right.  Each reference should replaced with its value.  names of variables (both in key in value) only contain letters, numbers, or underscore characters.  For each environment variable key/value pair, env will assign value key in child environment.  Each execution must done with fork, exec, wait.  last variable/value(s) pairing is followed by a --.  Everything following -- is command any arguments that will executed by env.  Invalid input should result in usage being printed. Invalid usage includes:  Cannot find -- in arguments Cannot find = in an variable argument Cannot find cmd after --  This is canonical example a practical use case:Alternatively:Example of using references other variables:Accordingly:This has exact same behavior as before, because TEMP is first set EST5EDT, then when TZ is set %TEMP, value of EST5EDT is retrieved then TZ is set that. Notice that variables are set sequentially, or else it wouldn’t work. We have provided you with a reference executable env-reference for you test your understanding of env’s expected behavior. You can also use it see if your env’s output matches expected output. Again like time, you can play with Linux’s builtin env command by typing env &lt;var-list&gt; &lt;command-name&gt; (env MYVAR=CS341 printenv, for example) in your terminal. Again, remember add . / beginning (or full path your env executable file if you are in another directory), otherwise builtin env will called. Do not use built-in env, or you will immediately fail assignmentIn addition, keep in mind that builtin env uses $ instead of % denote environment variables. In practice, it can very useful change some environment variables when running certain commands. Extra: Why Env?For example, you may notice people write #!/usr/bin/env python on first line of their Python script. This line ensures Python interpreter used is first one on user’s environment $PATH. However, users may want use another version of Python, it may not first one on $PATH. Say, your desired location is /usr/local/bin for instance. One way solve this is by exporting $PATH correct position in your terminal, however, this may mess up other commands or executable under same session. An alternative better way is use our env, enter:then it runs script with desired Python interpreter. Nota bene You may not use existing env program. (Our specification is different than existing env program. ) You may not replace % with $ or use wordexp(3).  You may not use execvpe, execve, or execle.  All changes in environment variables execution must happen only in child process.  You must use fork/exec/wait.  If a variable doesn’t exist, interpret its value as a zero-length string.  Do not fork bomb autograder! You will fail if you forkbomb AG. (See . )Useful Resources    ","url":"/assignments/utilities_unleashed"},{"title":"Vector","content":"Groundwork For ShellYou are an intern at Macrohard, where you’ll writing a shell for everyone on your team. These projects will take you several weeks, your mentor has decided on following timetable: Week A: Vector Sstream Week B+C: Shell Shell is a terminal. Like all good terminals, your shell will need remember what processes are running. However, after hearing tales of your talent, with vectors being all rage, other team leads have asked for vectors that they can use in their own projects. One option would write a vector for each team. However, being a good programmer, you know that code duplication is bad. Also, you’re a lazy programmer, so you want write as little code as possible accomplish everything. You decide implement a generic vector, something that every team can use with minimal changes. VectorA vector is an array that grows as a user adds removes items from it. (Since CS 225 was a prerequisite, you probably knew all of that already. ) However, your vector will need feature-rich enough for someone easily create a document from it, or anything else other sneaky teams want for their projects. Your implementation should go in vector. c, which is only file that will sent your team lead for review. As an intern looking become a full-time employee, you should create test cases in vector_test. c show you are a responsible programmer. Your mentor has left notes in vector. h guiding your implementation. In case a fellow employee asks what you learned in CS 225, here’s some review:   Since this vector is generic, it will have call custom constructor, destructor, default constructor functions when objects are added or removed. (How is this better than a single function which handles all possible types?) Thus, your vector structure will contain pointers your constructor or destructor routines, you can initialize vector by passing pointers these functions as parameters. What you’ll end up with is a useful general-purpose vector, capable of dynamically expanding. (No more fixed-sized buffers!). If you get confused about callback typedefs (i. e. what a copy constructor is) take a look at callbacks. h. Note: Remember that vector size (the number of actual objects held in vector) capacity (size of storage space currently allocated for vector) are two different things. Refer documentation in vector. h vector. c for more information. sstringsstring is a wrapper around C-strings which makes dealing with strings easierwith higher-level functions. We have not specified definition of sstringstruct, left that up you! You can find specification for sstring functions in sstring. h header file. Managing memoryRemember, man is man’s best friend. Since you’re working with dynamic memory, there are quite a few functions you should familiar with before you proceed. malloc(), free(), realloc(), calloc(), memmove() are your friends; don’t shy away! man 3 malloc man 3 free …there’s a pattern hereUndefined behaviorUndefined behavior is a scenario or edge case for which there is no documentation describing how code should react. For example, man pages do not describe what happens when you feed NULL into strcmp(). Your mentor will not answer questions like “What if my user wants an element past end of vector?”, because that is undefined behavior. So, for entirety of this MP, you should use assert() statements check that your user is passing valid input your function before operating on input. For example, if you were implementing strcmp(const char *s1, const char *s2), then your code might look like this::bangbang: A note about asserts: SIGABRT is a signal that will kill any process. It can called by writing abort(), is often used by libc implementations when unrecoverable errors occur. For example if you damage malloc’s internal structure via heap overflow, malloc will call abort() your program will exit immediately. Processes will also terminated via SIGABRT if an assert fails. SIGABRT is also known as “signal 6” - if you see this pop up on autograder, your implementation is either incorrect (or failing your own asserts) causing autograder crash. INITIAL_CAPACITYINITIAL_CAPACITY is starting capacity of vector, initialized 8. Do not modify this field, as doing so may cause you fail tests. CallbacksA set of callback functions representing copy constructors, default constructors, destructors for different types have been provided in callbacks. h. Please read callbacks. h callbacks. c carefully, especially function documentation, understand when use each one accordingly. function pointers defined in vector struct can store function pointers defined callback functions, which allows for flexibility emulation of Object-Oriented Programming in C. You can also learn more about callbacks how use them or . Writing test casesJust emphasize how important test cases are, this lab spec will repeat itself remind you that as good programmers, you are expected write your own test cases for sstring vector. ","url":"/assignments/vector"},{"title":"404","content":"\r           CS 341 · 404               \r\r\r \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r\r \r \r \r \r 404!\r \r \r \r \r \r \r \r\r\r","url":"/404.html"},{"title":"Course Staff Application","content":"IntroductionDo you want know how broadway works behind curtain? Is there one MP that you think just isn’t fair could made better? Do you want flip roles mentor an honors project? Or perhaps you just can’t get enough of system programming? Then consider becoming a course assistant for CS 341! apply, we will ask you submit an application via google form (link at bottom of this page). We will go over applications after deadline, send out interview offers soon after. After all interviews are complete, offers will sent out before end of break!We have following teams that you can join, we will ask you choose one or two primary team that interest you most in your application. However, you will not locked into team you initially signed up for, many of our best staff end up working in areas they did not start out in!TeamsPrimary Front Facing Assignment Development PrairieLearn Infrastructure HonorsSecondary Data Analytics Research Academic IntegrityWe want completely transparent about what we look in our applicants. We are not simply looking for A+ students. A good grade is neither necessary nor sufficient a good course assistant. Different teams look for different set of skills in applicants, which will described in greater details below. However, we expect everyone passionate about system programming, willing learn about new systems tools, most importantly a good communicator - whether it collaborating with your teammates, creating amending code documentations, or talking students. Your responsibilities time commitment will depend on team too. In general, every CA will expected hold at least one lab section (1. 5 hours / week), perform 2-4 hours of team specific work, participate in meetings (up 1 hour). Primary RolesFront Facing (Including Lab)Illinois Computer Science has a wide variety of talent, ranging from those who know as much as our instructors, those who are still learning use terminal. At some point, almost all of these students come office hours lab sections get extra help. Whether it drawing figures on white board or stepping through GDB, fruits of an instructor’s labor are priceless. In fact, few things are more rewarding than helping a student understand develop a passion for subject you teach. This is main responsibility of front facing team. In lab section, you will helping run lab activities, helping students out with labs, explaining concepts at a high level. During office hours, we have a team of staff ready eager answer student questions. You will hosting your own round-robin office hours, answering questions clarifying concepts. In addition, you will asked monitor Edstem ensure that student questions get answered. Last but not least, front facing team is eyes ears of entire staff team. We learn about ambiguities in asssignments bugs in autograder from student feedback, you will one relaying them rest of team. Skills Required Patience empathy - Most of time, you can fill gap in a student’s understanding of material just by remembering why you struggled with material what helped you understand it. However, some students might not get material even after third time you explain it them. You’ll need patient try different methods of explanation.  A friendly personality demeanor - Students will most likely stressed upset after debugging for several hours waiting on a long queue. A lot of this tension is easily alleviated if you approach them nicely. It is important never appear condescending or annoyed.  Communication teaching ability - Understanding is only half battle being an effective teacher. It helps understand material well comfortable with it, but you must able communicate material well. You also have adaptable in ways you explain things, since how you understand problem might not how your students best understand a problem.  Debugging - It should go without saying that debugging is a critical skill have when helping students. Most bugs can found by effectively using GDB, Valgrind, print statements. You should able look at a failed test case, know what tools you could use trace back bug at fault, you should able walk a student through steps.  Assignment knowledge - Students will mainly come into office hours needing help interpreting documentation or debugging code. You must familiar with assignments before you an help students master them. Expected Time Obligations Team Meetings (1 hr / week) - It is important for everyone on staff on same page, for everyone present make key decisions. For front facing specifically, this is time for summarizing student feedback brainstorming improvements that can made.  Office Hours (2 hrs / week) - It should go without saying that as an front facing course assistant you will hosting office hours. This is time where you will put yourself on queue help students.  Lab Sections (1 or 2 sections = 1. 5-3 hrs / week) - Most lab sections will run about an hour twenty minutes. You are expected have read documentation already at a high level know how solve assignment. In bulk of lab time, you will going around helping students with assignment. For more challening MPs, you will also walk through high level design pitfalls with students using our slides.  Edstem (1 hr / week) - It is also important answer questions on Edstem, since labs office hours are not available 24/7. Answering one question well on Edstem can potentially resolve a problem for entire class. Assignment DevelopmentMachine Problems Labs are meat cheese of any programming course. These assignments are supposed rigorous enough so that students can fully apply their knowledge of systems, interesting enough so that they have a memorable experience in course. You will responsible for improving existing assignments fixing any issue that pops up, as well as managing assignment documentation, occasioanlly creating brand new assignments (assignment creation has been migrated section). Instead, we are looking for people who can help clean up autograder backend, make life easy for other developers. Finally, with any good assignment comes excellent documentation that is clear, concise, contextual, correct. Also, documentation should mirror what we are looking for in autograder. One huge shift you’ll have get used is writing code for an assignment must perfect or near-perfect. Instead of passing our ~30 test cases, you’ll have resilient against 300 students’ edge cases. Skills Required Firm Knowledge of C System Programming - As an assignment developer, you must really understand things you write, since writing a bug in your MP is equivalent writing 400+ bugs that get deployed students. Any race conditions or memory leaks left in provided code you write will deployed 400+ students. In class, you only need get test cases working, here you need make sure that your code is resilient against all test cases, or you will end up with a bug in assignment.  Experience with developing unit tests quality assurance work. Skill with adversarial testing, being able spot plug testing holes, ability make informative test cases help other developers narrow down where an issue is.  Written Communication - Clear specifications informative examples are distinction between a challenging but satisfying MP an infuriating MP. same can said about test descriptions error messages. You should able describe what we expect from students’ code accurately succintly, sensitive ambiguities in writing.  Team-Oriented - If you don’t mind buzzword, we have a team of assignment developers that work on each assignment. You will need collaborate with them in order get your ideas code across pull requests. Expected Time Obligations Team Meetings (1 hr / week) - You will need meet with rest of assignment development team frequently. This is an excellent time for team separate out work for a divide-and-conquer strategy, since you will constantly up against a deadline. These meetings will also an excellent time learn from course staff more experienced than you.  Development Testing (2-4 hr / week) - You will need investigate solve assignment-related issues, improving quality of backend through testing.  Office Hours (0-2 hrs / week) - Although assisting students directly is not your main responsibility, office hours are an excellent venue spot bugs issues with assignments. Leads co-leads of assignment development team will expected hold office hours get first hand feedback.  Lab Sections (1 or 2 sections = 1. 5-3 hrs / week) - DittoInfrastructureWe need a lot of code support our code. Welcome infrastructure, where autograder is developed along with tools scripts that rest of staff uses. You will working on challenging problems in domain of distributed systems by working on our course’s very own Broadway-on-Demand auto-grader. We are always looking add more features, make this tool easier use for students staff. We are also looking automate routine tasks that staff team has perform, such as managing permissions codebase material, deploying assignments, granting extensions regrades, etc. There is plenty of projects that you can participate in. Skills Required Programming ability - You will most likely need a variety of skills. A little bit of Web development, some knowledge of scripting knowledge (Python, shell scripting etc. ). You also must have an aptitude for picking up skills independently as projects mature. In addition, we plan software structures we build, keep up with maintenance. Imagine this as a good combination of software engineer project manager.  Self-Directedness - Most of work will self directed. We will have a few meetings, but you will need deliver a polished project by coming up with specifications, executing based on best possible technologies maintaining project. You can receive help, but most of work success is on your own.  Working in a team - Although most of work is self directed, a few projects involve extensive collaboration either synchronously or asynchronously with other course staffs. You’ll need make sure that most of your work is readable people who have not looked at your code as well as explainable at a high level people who are just trying understand project. Expected Time Obligations Team Meetings (1 hr / week) - You will need meet with rest of staff team talk about your progress, see what new projects might pop up as new tasks get created.  Working on projects (2-4 hr / week) Lab Sections (1 or 2 sections = 1. 5-3 hrs / week) - DittoPrairieLearn (PL) is a web-assignment platform developed at UIUC. CS341 PL team is concerned with creating deploying extra-credit assignments called Pre-Labs (for now!). goal is make labs more educational, intuitive, interactive – because sometimes programming is not a good replacement for conceptual knowledge (e. g. MMAP lab). We envision that Lab slides contain intuitive information, PL supplements this with neat problems for students learn from. If you think this course has future potential with PL, or you believe some assignments are lacking want do something about it, then this team is for you. Writing assignments involves coming up with a meaningful tasks where students can master learning objectives. Writing these assignments involves a lot of time spent drafting on white boards bouncing ideas around. As you are writing these assignments, you will have ask yourself, “What am I trying have students learn?”. Skills Understanding of course content beyond content in assignments. Being able create thoughtful problems requires more knowledge than being able simply get-by with course content.  Strong opinions about course, what material we should teach.  Creativity interest in pedagogy. We foresee that PL work this semester will a lot of brainstorming outlining plans for pre-labs, with ultimate goal of reworking existing labs eventually. What makes a good lab? What are labs supposed teach? What do students retain? What makes a frustrating question? Did we give too many or not enough hints? If you are interested in creative, higher level questions such as these, then look no further.  vocal, a team player. Ultimately, TA’s professor decide which content gets through PL, so it is up you discuss with them plan out exciting future of this course. Additionally, you are expected work as a team pump out assignments during semester. This is going require you on top of things as a group.  Autonomy. Even though there is a team, it will not very big. You are expected have personal initiative, which goes back being able dig into content that may on border of what is covered in course.  Prior experience with PrairieLearn. Take a look at . If you have experience or are familiar with PL development, please mention it in your applications!Expected Time Obligations Team Meetings (1 hr / week) - It is important for everyone on staff on same page. Meetings also serve as a means for more experienced course staff members give less experienced course staff members advice.  Working on PrairieLearn (2-4 hr / week) Lab Sections (1 or 2 sections = 1. 5-3 hrs / week) - DittoHonorsIf you have a deep passion for systems want instill that passion in course’s one-percent, then this is position for you. You get mentor highly talented passionate students in a semester-long project of their choosing. Note: It is not required for you have taken CS 341 Honors (CS 199-341) work on Honors staff. Expected Time Obligations Team Meetings (1 hr / week) - It is important for everyone on staff on same page. Meetings also serve as a means for more experienced course staff members give less experienced course staff members advice.  Mentoring meetings (2 - 2. 5 hrs / week) - honors section has weekly one-hour meetings, you will expected have two or three 30 minutee meetings with your assigned groups. meeting will primarily cover what happened this past week prepare for next week.  Lecture Development (4 - 6 hrs / week per lecture week) - You will helping out prepare deliver part of a lecture honors students. This lecture needs well-documented, well-researched, expertly given. Not every Honors CA will helping out with lecture every week, but weeks you choose teach spike time spent on development.  Lab Sections (1 or 2 sections = 1. 5 - 3 hrs / week) - DittoSkills Mentoring Ability - Students need guidance in honors section, it is your job provide that! You will help students with their projects. Since topics vary widely, it’s useful a jack-of-all-trades with respect system programming topics, you should have an excellent ability advise oversee groups of students.  Deep Systems Programming Knowledge - These aren’t surface level lectures. You need either have or willing put in time understand these topics at an in-depth level. Think of it like taking an oral examination for a PhD. You need know topics you help out with in utmost detail. Secondary RolesData Analytics ResearchYou will doing exploratory data analysis, creating visualizations, mining patterns from all of data we collect as course staff. This roles is very open-ended, but you will get direction from senior staff members. Past projects have involved creating network visualizations for lab assignment partners, generating lab partners, graphing performance on assignments over time, studying factors that lead student success in course (such as commit timestamps, VM logins etc. ). You will have opportunity work with Prof. Lawrence Angrave on research projects, which will look great on a graduate school application. Skills Required Programming skills - Python, R, MATLAB/Octave, Scala, JavaScript are dominant programming languages in data analysis machine learning today. Experience with data analysis packages, such as pandas, matplotlib, numpy, d3. js etc. is a bonus! Statistics - Knowledge of basic statistics is invaluable especially if you are attempting create a model, or estimate a distribution.  Research experience - Past research experience, especially if it involved quantitative analysis will extremely relevant for tasks you will performing. Expected Time Obligations Varies by projectAcademic IntegrityWe take academic integrity seriously in this course, screen every MP submission for signs of plagiarism. Your will looking at suspicious submissions, using your knowledge of assignment deduce whether plagiarism is actually happening. Skills Required Assignment Knowledge - way MPs are structured means that successful student solutions will inevitably share similar design patterns, especially when starter codes are involved. You need able sense when similarity can attributed convergent ideas, when it is indicative of work being copied.  Familiarity of ChatGPT - We are seeing a trend of ChatGPT being used generate code snippets that get submited as students’ original work, although they might not even understand why snippets work (or do not work). Therefore, we are exploring what we could do detect this, how should we handle this situationExpected Time Obligations Varies by projects  Apply ","url":"/application"},{"title":"Assignments","content":"           CS 341 · Assignments                 @media only screen (max-width: 768px) { . col-xs-12 . table { margin-left: 0px; } } h1 { margin-bottom: 0px; padding-bottom: 10px; }  \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r  Assignments                    MPs       MP Release Date Due Date Slides       Week 2 Week 3        Week 3 Week 4        Week 4 Week 6        Week 6 Week 8        Week 8 Week 9        Week 9 Week 11          Week 11 Week 12        Week 12 Week 15            Labs       Lab Release Date Due Date\t\t\t\t\t\t\t\tSlides (Legacy)\t\t\t\t\t\t\t\tSlides (New) Handout       Week 1 Week 2     \t\t\t\t\t\t\t\t  \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 2 Week 3     \t\t\t\t\t\t\t\t  \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 3 Week 4     \t\t\t\t\t\t\t\t  \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 4 Week 5     \t\t\t\t\t\t\t\t  \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 5 Week 6     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 6 Week 7     \t\t\t\t\t\t\t\t  \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 7 Week 8     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 8 Week 9     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 9 Week 10     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 10 Week 11     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 11 Week 12     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 12 Week 13     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 13 Week 14     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t     Week 14 Week 15     \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t          ","url":"/assignments"},{"title":"Grades","content":" location. replace(\"https://grd-cs341. cs. illinois. edu/on-demand/student/course/cs341-sp25/grades\")","url":"/grades"},{"title":"Honors","content":"SyllabusCouldn’t get enough systems programming from CS 341? Welcome honors section! This course is recommended for those who want expand their systems knowledge with additional lectures a semester long project in systems programming. There will lectures throughout semester, usually every week or every other week, given by various members of honors course staff. These lectures are intended expose you advanced topics in systems that are outside scope of CS 341. On some weeks, we will have lecture activities complement lectures. You are also required propose complete a project of your own. Your project should related systems programming it should clearly demonstrate build upon concepts learned in regular [and/or honors] CS 341 lectures. Once your project has been approved by course staff, you will assigned a mentor who you will check in with weekly for progress reports code review. At end of semester, you will present your work your peers. presentation will consist of a demonstration of your project along with a brief explanation of your project results. Your presentation should include what you learned working on your project, challenges faced, results (if any), etc. GradingWe publish same grading thresholds as regular section of CS 341. Your project will graded in a holistic manner against other projects in class. Note that this does not imply only a handful of projects can receive an A; education is not a zero-sum game. Historically, grades have been assigned with a generous curve. AbsencesWe understand that student life is busy schedule conflicts can arise. In exchange for requiring attendance at lectures, we will drop one lecture attendance grade, no questions asked. These drops are meant for conflicts that you have control over, such as a vacation or job interviews. If you have a required conflict (e. g. an exam in another class), please notify course staff ahead of time we will excuse your absence. If you have a sudden illness or other personal emergencies, please refer . ProjectRequirements: Projects may done in teams of 2 or 3 people; if you want work alone or on a larger team, ask us first Your project should novel you your partners. We want you explore new things! Work on your project should take about 3 hours a week for each member of team Your project must relate systems programming in a meaningful way. If you aren’t sure whether your idea meets this requirement, ask us in advanceAfter first few weeks of course, you will required submit a project proposal. Your proposal should include following: Overview (Alternatively, “Explain it me like I am five”) Purpose (Why are you doing this? Why is it interesting?) Expected workload distribution among group members Projected project milestones (What will you do in first month? Second month? etc. ) Challenges you expect will arise in working on this projectProject proposals should submitted as a private post on Ed by due date (we will specify due date in lecture on Ed).  exact grading requirements of each project vary. You your mentor will decide on a reasonable scope for your project at beginning of semester, though this target may move as appropriate throughout semester. PresentationsPresentations will take place during last week or two of class during normal lecture time. Each group will have around 10 minutes present their project class. You should sure touch on what your project is, what interesting systems programming concepts were involved in your project, any challenges you encountered along way how you tackled them. If you have more questions about what include in your presentation, ask your mentor. You should have some sort of visual presentation (Powerpoint, Google Slides, LaTeX beamer, etc. ) accompany your talk. Feel free include screenshots of your project or pre-recorded demo videos. avoid losing time technical difficulties, live project demonstrations are not allowed; you must pre-record any demonstration you plan give. Please email your presentation course staff by 5pm on day you are presenting so that we have adequate time load presentations onto one machine reduce overhead of switching presenting groups. Remember that you do not have have completed your project by time you present. However, you should make sure you briefly cover any remaining work you plan do. Weekly Check-insYou are required meet with your mentor on a weekly basis. meeting can last up an hour you will typically go over what you did that week, what your goals are for next week, any roadblocks you encountered. get full credit, you must meet with your mentor display satisfactory progress on your project. If your project requires research before beginning your design implementation (i. e. , figuring out what a filesystem is before implementing it), you should write up a short summary of your work for that week share it with your mentor during your check-in. This should include what you learned that week, how it relates your project, what you plan learn about going forward. When you your group start writing code, we expect you use git for each group member commit their changes using their own account. Your commit history will used in part determine your individual contribution project. Keep in mind that a group project is a group effort; group must coordinate who is doing what what a fair work balance is between group members. Your mentor is here guide you through roadblocks, check in on progress, answer any questions you have about project. Your mentor is not a personalized debugger, nor are they an additional group member.  Team| Name | NetID | Interests ||:—–|:——|:———-|| TBA | TBA | TBA |LecturesLectures can watched at any time. table below contains a suggested cadence.  \t\t Date\t Lecture Content\t Slides\t Videos\t   \tFebruary 3\tIntroduction &amp; Advanced Tools\t\t\t\t\t\t\t  \tFebruary 10\tSecurity (Assignment Due on May 2nd)\t\t\t\t\t\t  \tFebruary 17\tDistributed Systems / Cloud / IoT\t\t\t\t\t\t  \tFebruary 24\tAdvanced Memory\t\t\t\t\t\t  \tMarch 3\tKernel Programming (Assignment Due on May 2nd)\t\t\t\t\t\t  \tMarch 10\tNetworking / TCP\t\t\t\t\t\t  \tMarch 17\tConcurrency / Lock Free Data Structures\t\t\t\t\t\t  \tMarch 24\tMidterm Presentations\t\t\t\t\t\t\t\t  \tMarch 31\tContainerization / Virtualization (Assignment Due on Reading Day)\t\t\t\t\t\t  \tApril 7\tEmbedded Programming\t\t\t\t\t\t  \tApril 14\tLoad Balancing\t\t\t\t\t\t  \tApril 21\tTBA \t\t\t\t\t\t\t\t  \tApril 28\tTBA \t\t\t\t\t\t\t\t  \tMay 5 (Tentative)\tFinal Presentations\t\t\t\t\t\t\t\t  EdWe will use Ed for this course post announcements, lecture schedules, etc. Project Ideas?Come check out what past students have created in . If not here are some project ideas GPU/Device Programming Networking  Decentralized Chat Proxies/Firewalls/Encryption Network Congestion [Other Project] With Networking Implementing Remote Procedure Calls Messaging Queues   Kernel Programming  Debugging with a Twist Hacking Kernel High Performance System Calls   Scheduling  Custom Scheduling   MultiThreading  High Performance Threading Library with Purpose   Memory Management  Garbage Collection  ","url":"/honors"},{"title":"Home","content":"            CS 341 · Home                 \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r    CS 341: System Programming   Spring 2025     Latest Assignments     MP          Due: Week 15 · 2025-04-21 23:59      Lab          Due: Week 15 · 1987-12-11 23:59       Homework 0 - \"My first grind\" or \"Love live learn love C programming?\" Can you show me your passion for learning basics of C? Homework 0 is available on . See you in class, Wednesday (2/22/2025) 11am ECEB1002 - Prof. Angrave.   Hunger For inspiration please see this () by Prof. Angrave Bring Your Own Laptop! Some students like annotate a pdf handouts during lecture but paper handouts are also provided. Bring your own Windows, Linux, or MacOSX laptop your CS341 discussion sections because lab will not have desktop machines. A Chromebook with Linux enabled may work but is not recommended. recommended minimum laptop specification for CS341 is: i) A basic 10 year-old laptop if you just want write code using VS Code locally but compile test remotely using CS Cloud : VS Code minimum requirements. Alternatively, run a multi-CPU core Linux locally (e. g. by running a Linux Virtual Machine on your laptop) then you will need something newer powerful e. g. i5 x64 4-core 8th generation (or similar) CPU, 8GB RAM (16GB recommended), 100 GB Disk Space, SSD recommended. High-end gaming laptops are not recommended because they are bulky, heavy have poor battery life.   There is new loaner laptop program run by Main Library at 3rd floor of U of I Main Library (Room 306, ). You may borrow a laptop for up 10 days e. g. while waiting for your laptop - just bring your physical ICARD. A typical loaner laptop is a .   There is also a limited laptop by EngrIT for students faculty in Grainger College of Engineering  Course Description   This course is designed challenge you as a programmer new computer scientist at University of Illinois Urbana-Champaign.  Rather than sand-boxed, contained, simple problems of your previous courses that used significant scaffolding pre-built libraries, you will interacting with a much more complex environment: entire system even computing networks.     You will need fully understand how memory is allocated, used, re-used within a process.     You will also need know how input output can optionally buffered between processes files.     In short, it is time remove training wheels off instead fling open doors, welcoming you big, wide world of computing.     Oh, did we mention challenge of concurrency solving asynchronous problems, so that your program can take advantage of multi-core CPU inside each machine?        Time Location   Instructor: Lawrence Angrave (angrave@illinois. edu)  Peer tutoring Office hours will announced in week 2: . Prof. Angrave's in-person office hours are Monday 10:15am in ECE coffee area, also immediately after every lecture. Other times by appointment at SC2217.   Recorded Lecture: : See    Class: ECEB 1002 MWF 11:00AM - 11:50AM    Lab Sections: See      Getting Help  Academic  You can find a full list of times locations on our .       Please read our       Grading Policy (subject minor changes)   Machine Problems: 45% (weekly)   Labs: 17% (weekly, lowest lab dropped)    Quizzes: 15% (7 quizzes, multiple re-takes, no drops). At ; Available until Reading Day.    Final Exam: 23% ; however upto 3% can pre-credited based on physical lab attendance i. e. fractional contribution of final exam can reduced.      Course Prerequisites           Mental Health, anti-racism inclusivity, CS Cares  Please see our important course on anti-racism inclusivity, information about CS Cares.       ","url":"/index"},{"title":"Getting Caught Up","content":"Quick Links  Syllabus:    EdStem:    Mini-Course:    Coursebook:    Class Transcribe (Lecture Recordings):    Development Guide:    PrairieLearn:  Join Forum!We use Ed as official staff-supported Q&amp;A forum is way that we communicate announcements rest of class (e. g. , assignment releases, changes office hour schedule). If you can’t access our forum, ask a member of course staff for Ed join link.  get a sense of what’s going on where we are in course, please read all posts by staff. Read Syllabus syllabus is an important read; we find that answers many student questions are in syllabus. Please read thoroughly!Assignments  You can see a list of assignments under “Assignments” tab. Assignment deadlines are stated on linked assignment pages.    Email cs341admin@cs. illinois. edu say that you have added late (please include date you added classes).  If you joining class after 10 days, then start on current lab MP. There will an opportunity () address missing grades towards end of semester. You will need set up/get familiar with tools necessary successful in this course, such as VM, ssh, git. Read do so.  only non-programming assignment in first few weeks is Homework 0, which is Professor Angrave’s introductory mini-course. You will submit your answers for this assignment in HW0. md file in Luscious Locks lab. See below for mini-course “Linux-In-TheBrowser” virtual machine:  You can find questions for Homework 0 in lecture handout repository corresponding current semester on . Catching up on MaterialSee recorded lectures you missed on . You can also review content you have missed by reading . You can find lecture handouts in lecture handout repository corresponding current semester on . Ask about material you don’t understand on forum, in your lab section, or in office hours!LabsGo lab section that you registered for tell TA that you added late. We will manually give you attendance until we can update roster. QuizzesNote that while PrairieLearn quizzes are due towards end of semester, we encourage spacing them out. See “Quizzes” page PrairieLearn for more information. ","url":"/late_add"},{"title":"Lectures","content":" location. replace(\"https://classtranscribe. illinois. edu/\");","url":"/lectures"},{"title":"Useful Links","content":"LecturesLecture videos: (For any issues related ClassTranscribe, you’d probably get a faster response by emailing )Lecture demo code handouts: https://github. com/angrave/CS341-Lectures-SP25HW 0 Mini Lectures &amp; in-browser VM: ","url":"/links"},{"title":"Malloc Hall of Fame","content":"           CS 341 · Malloc Hall of Fame               \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r    Malloc Hall of Fame Welcome malloc hall of fame! 'My name is Ozymandias, king of kings; Look on my works, ye Mighty, despair!' -- Percy Bysshe Shelley    Spring 2019       Place Nickname Score        🥇  Being nothingness 111. 13      🥈   gbezhanishvili2 107. 58      🥉   42 106. 97         Spring 2018       Place Nickname Score        🥇  Assassin Eclipse 302. 64      🥈   Max Memory: 0. 00 GB 302. 13      🥉   抖m 241代写了解一下 shout out CA!! &lt;3 298. 87         Fall 2017       Place Nickname Score        🥇  glibc (optimized) 113. 85      🥈   return sbrk(size); 108. 11      🥉   void ABJU() 107. 52         Spring 2017       Place Nickname Score        🥇  yeke 108. 11      🥈   LARGEONE 101. 94      🥉   承让了我的弟 100. 67       ","url":"/malloc_hall_of_fame"},{"title":"Schedule","content":"Course ScheduleIf you added late, check get caught up.  general structure of course has MP assignments due on Mondays at 11:59 PM Lab assignments due on Wednesdays at 11:59 PM. These repeat weekly - some MPs are multi-week but have checkpoints weekly. Week 1Highlights: Read course book background. Work on Homework 0. Sign up Quiz 1 slot. Watch online lectures 2 3 when they are published. First lab on Thursday.   Mon 01/14. Lecture 1. We met in person at ECEB1002 8am for first only Monday lecture.   Wed 01/16. Lecture 2 (available online). “See C Crash” 14 minivideos at . Supplemental code handouts are at https://github-dev. cs. illinois. edu/angrave/cs241-lectures  Wed 01/16. Angrave’s Optional review section/Office Hours in ECEB1002 8am - 9am; Additional Angrave office hours 9-9:30 ECEB atrium.    Thu 01/17. Lab sections in Siebel Basement SC0218/SC0222.    Fri 01/18. Lecture 3 “A Day At C side”” (available 1/18 on classtranscribe). No physical lecture or meeting in ECEB1002.    this week your 50 minute slot for next week’s CBTF   Weekend target: Finish HW0. Finish Chapters 2 (Background) 3 (C Programming Language). This will ensure you are ready for first quiz (see quiz page for topics)Week 2  Mon 01/21. Martin Luther King Day. No meetings. No CBTF.    Tues 01/22 - Thu 01/24. Quiz 1 at CBTF (see quiz page for details)   Wed 01/23. Online Lecture 4 “Reading data text”   Wed 01/23. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   HW0 due 2025-01-29 23:59. Lab Assignment due   Thur 01/24. Labs   Fri 01/25. Online Lecture 5 “Exec, Fork, environment variables” Week 3  Mon 01/28. Online Lecture   Mon 01/28. MP Assignment Due 2025-02-03 23:59   Mon 01/28 - Fri 02/1 (Not Wednesday). Quiz 2 at CBTF. Extended Friday due weather   Wed 01/30. Online Lecture   Wed 01/30. Angrave’s ECEB office hours cancelled due Martian climate   Wed 01/30. Lab Assignment due 2025-02-05 23:59   Thur 01/31. Labs   Fri 02/01. Online Lecture Week 4  Week’s Reading: Processes   Mon 02/04. Online Lecture   Mon 02/04. MP Assignment Due 2025-02-10 23:59   Wed 02/06. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 02/06. Lab Assignment due 2025-02-12 23:59   Thur 02/07. Labs   Fri 02/08. Online Lecture Week 5  Week’s Reading: Malloc Signals   Mon 02/11. Online Lecture   Mon 02/11. MP Assignment Due 2025-02-17 23:59   Mon 02/11 - Wed 02/06. CBTF Quiz 3   Wed 02/13. Online Lecture   Wed 02/13. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 02/13. Lab Assignment due   Thur 02/14. Labs   Fri 02/15. Online Lecture Week 6  Week’s Reading: Threads   Mon 02/18. Online Lecture   Mon 02/18. MP Assignment Due 2025-02-24 23:59   Wed 02/20. Online Lecture   Wed 02/20. Angrave Office Hours (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 02/20. Lab Assignment due 2025-02-26 23:59   Thur 02/21. Labs   Fri 02/22. Online Lecture Week 7  Week’s Readings: Synchronization   Mon 02/25. Online Lecture   Mon 02/25. MP Assignment Due 2025-03-03 23:59   Mon 02/25 - Wed 02/07. CBTF Quiz 4   Wed 02/27. Online Lecture   Wed 02/27. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 02/27. Lab Assignment due 2025-03-05 23:59   Thur 02/28. Labs   Fri 03/01. Online Lecture Week 8  Week’s Readings: Deadlock   Mon 03/04. Online Lecture   Mon 03/04. MP Assignment Due 2025-03-10 23:59   Wed 03/06. Online Lecture   Wed 03/06. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 03/06. Lab Assignment due   Thur 03/07. Labs   Fri 03/08. Online Lecture Week 9  Week’s Readings: Interprocess Communication   Mon 03/11. Online Lecture   Mon 03/11. MP Assignment Due 2025-03-24 23:59   Mon 03/11 - Mon 03/13. CBTF Quiz 5   Wed 03/13. Online Lecture   Wed 03/13. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 03/13. Lab Assignment due 2025-03-26 23:59   Thur 03/14. Labs   Fri 03/15. Online Lecture Heads-up Week 10  Week’s Readings: Scheduling   Mon 03/25. Online Lecture   Mon 03/25. MP Assignment Due 2025-03-31 23:59   Wed 03/27. Online Lecture   Wed 03/27. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 03/27. Lab Assignment due 2025-04-02 23:59   Thur 03/28. Labs   Fri 03/29. Online Lecture Heads-up Week 11  Week’s Readings: Networking   Mon 04/01. Online Lecture   Mon 04/01. MP Assignment Due 2025-04-07 23:59   Mon 04/01 - Wed 04/03. CBTF Quiz 6   Wed 04/03. Online Lecture   Wed 04/03. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 04/03. Lab Assignment due 2025-04-09 23:59   Thur 04/04. Labs   Fri 04/05. Online Lecture Heads-up Week 12  Week’s Readings: Filesystems   Mon 04/08. Online Lecture   Mon 04/08. MP Assignment Due 2025-04-14 23:59   Wed 04/10. Online Lecture   Wed 04/10. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 04/10. Lab Assignment due 2025-04-23 23:59   Thur 04/11. Labs   Fri 04/12. Online Lecture Heads-up Week 13  Week’s Readings: Signals   Mon 04/15. Online Lecture   Mon 04/15. MP Assignment Due 2025-04-21 23:59   Mon 04/15 - Wed 04/17. CBTF Quiz 7   Wed 04/17. Online Lecture   Wed 04/17. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 04/17. Lab Assignment due 2025-04-30 23:59   Thur 04/18. Labs   Fri 04/19. No lecture (in lieu of CBTF time) Heads-up Week 14  Week’s Readings: Review!   Mon 04/22. No lecture (in lieu of CBTF time)g   Mon 04/22. MP Assignment Due 2025-04-28 23:59   Wed 04/24. Online Lecture   Wed 04/24. Angrave World’s-Largest-Office Hours? (Optional) ECEB1002 8am-9am, then ECEB Atrium until 9:30   Wed 04/24. Lab Assignment due   Thur 04/25. Labs   Fri 04/26. Online Lecture Heads-up Week 15  Week’s Readings: Review!   Mon 04/29. Online Lecture   Mon 04/29. MP Assignment Due 2025-05-05 23:59   Mon 04/29 - 05/01. CBTF Quiz 8   Wed 05/01. Last Lecture in ECEB 1002 8am.    Wed 05/01. Office HOurs ECEB Atrium 9:00 until 9:30   Wed 05/01. Lab Assignment due 1987-12-11 23:59   Wed 05/01. Regrades are due CBTF Quiz summary. These are usually available Monday - Wednesday.  Mon 01/28. CBTF Quiz 2 Mon 02/11. CBTF Quiz 3 Mon 02/25. CBTF Quiz 4 Mon 03/11. CBTF Quiz 5 Mon 04/1. CBTF Quiz 6 Mon 04/15. CBTF Quiz 7 Mon 04/29 CBTF Quiz 8","url":"/past/scheduleSP19"},{"title":"Past_projects","content":"\r           CS 341 · Past_projects               \r\r\r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r\r\r\r \r \r Past Projects\r \r Fall 2017\r \r \r \r Name\r Description\r Link\r \r \r \r \r \r SSHFS\r Distributed filesystem task executor using FUSE\r \r \r \r \r \r \r \r \r TeaTime\r Real time file synchronization tool\r \r \r \r \r \r \r GummyWorm\r Android phone remote desktop tool\r \r \r \r \r \r \r BitMesh\r Distributed system library\r \r \r \r \r \r \r File Compressor\r Custom file compression server\r \r \r \r \r \r \r \r \r Fall 2016\r \r \r \r Name\r Description\r Link\r \r \r \r \r \r Distributed FUZE\r Distributed filesystem using FUSE\r \r \r \r \r \r \r Hermes\r Online real-time text editor\r \r \r \r \r \r \r \r \r Kernel Filesystem\r Kernel module virtual filesystem\r \r \r \r \r \r \r Root Kit\r Spying on your kernel\r \r \r \r \r \r \r Fluid Simulator\r 2D fluid simulation that takes advantage of GPU architecture\r \r \r \r \r \r \r Steganography Toolset\r Toolset capable of encoding information in images/audio/code subsequently decoding it\r \r \r \r \r \r \r Remote Desktop Client\r Remote client for your desktop\r \r \r \r \r \r \r ShadowPager\r Hacking around firewalls\r \r \r \r \r \r \r Multiplayer Tron Game\r An implementation of video game Tron entirely in terminal\r \r \r \r \r \r \r \r \r Spring 2016\r \r \r \r Name\r Description\r Link\r \r \r \r \r \r Super Debugger\r GDB-Like Debugger From Scratch\r \r \r \r \r \r \r C Garbage Collector\r A garbage collector for C code that supports multithreading\r \r \r \r \r \r \r \r \r LocChat\r Location-based app where nearby users can talk each other based on common interests\r \r \r \r \r \r \r \r \r Chess Engine\r Engine compute optimal moves in a game of chess\r \r \r \r \r \r \r High Frequency Sports Gambling\r Analyzes places bets on sports games in real-time\r \r \r \r \r \r \r TCP Network Encryption\r A network encryption tool that implements Serpent cipher\r \r \r \r \r \r \r Webcam Theremin\r Theremin simulation using a webcam video processing\r \r \r \r \r \r \r Spacecluster. io\r Remake of Agai. io in space\r \r \r \r \r \r \r \r \r EDF Schedluing Policy\r Implementation of earliest-deadline first scheduling policy as a Linux kernel module\r \r \r \r \r \r \r Win Debugger\r A gdb-like Windows C debugger written in C++\r \r \r \r \r \r \r \r \r Personalized Trash Control\r A feature-rich trash can for Linux that supports compression remote storage of trash\r \r \r \r \r \r \r \r \r \r\r\r\r","url":"/past_projects"},{"title":"Peer Tutoring","content":"Getting HelpFrom second week of classes, we hold peer tutoring sessions either in-person or via Zoom. You can join by adding yourself onto (the schedule can found below). More detailed instructions are on our page. Please note that this is not CS 225, so we will not do your assignments. This is one of last classes you will take before being thrown into 400-level courses, where assignments are much harder, help is much more limited, hand holding is negative.  Give a student answer you feed them for a day; teach a student find their own answers you feed them for a lifetime. These peer tutoring sessions will focus on diagnosing misconceptions holes in your understanding of problem. This is a fairly conceptual class where your understanding of problem will directly impact how you can implement a solution. If you have made it this far into CS curriculum simply compiling lecture notes documentation code, then you are going have make some serious changes in your work ethics. prepared asked explain what you think your program is doing. Odds are that what you think your code is doing is not equivalent what it is doing. This department is scaling rapidly, which is great, since computer science is an incredible field of knowledge that will take our civilization new frontiers. Unfortunately, number of people on course staff does not scale as fast. This means that we can not sit next you for 45 minutes read 800 lines of your code; this is peer tutoring not a dinner date. We will wear stopwatches between students on queue. Prof. Angrave’s office hours are listed on home page- TL;DR catch him outside lecture area Mon-Wed-Fri (Monday is his official hour). Calendar","url":"/peer_tutoring"},{"title":"Quiz Topics","content":"OverviewThese are not PrairleLearn quizzes that are part of your weekly lab. There are 7 graded Quizzes available at , attempt all 7 (there are no drops). Quizzes may retaken without penality are due last day of instruction at UIUC ie. day before Reading Day.  avoid leaving all quizzes last moment we suggest following due dates -Suggested due datesDon’t stress … These due dates are not enforced; they are just suggestions space out quizes over semester. You can take retake quizes before or after these dates (upto reading day). Spring / Fall Semesters 02-15 / 09-15 Quiz 1 (C foundation) 03-01 / 10-01 Quiz 2 (fork,exec,wait heap) 03-25 / 10-25 Quiz 3 (pthreads, producer-consumer, synchronization primitives) 04-01 / 11-01 Quiz 4 (threading issues &amp; race conditions, virtual memory) 04-13 / 11-13 Quiz 5 (networking pipes) 04-20 / 11-27 Quiz 6 (review -hand picked questions from above) 05-03 / 12-03 Quiz 7 (security)Quiz 1Topics C Strings representation C Strings as pointers char p[] vs. char* p Simple C string functions (strcmp, strcat, strcpy) sizeof char sizeof x vs x* Heap memory lifetime Calls heap allocation Dereferencing pointers Address-of operator Pointer arithmetic String duplication String truncation double-free error String literals Print formatting.  memory out of bounds errors static memory fileio POSIX vs. C library C io fprintf printf POSIX file IO (read, write, open) Buffering of stdoutQuiz 2Topics C Foundations (see above) Correct use of fork, exec waitpid Using exec with a path Understanding what fork exec waitpid do. E. g. how use their return values.  SIGKILL vs SIGSTOP vs SIGINT.  What signal is sent when you press CTRL-C Using kill from shell or kill POSIX call.  Process memory isolation.  Process memory layout (where is heap, stack etc; invalid memory addresses).  What is a fork bomb, zombie orphan? How create/remove them.  getpid vs getppid How use WAIT exit status macros WIFEXITED etc. Quiz 3Topics pthread lifecycle create join pthread_join pthread_exit vs exit threads vs process Critical sections Counting Semaphores Barriers Condition Variables Producer Consumer Ring bufferQuiz 4Topics Dining Philosopher Problem Reader Writer Problem four Coffman conditions (and definition of each one) Create thread safe code using semaphores Creating a barrier using condition variables Deadlock Resource Allocation Graph pthread race conditions Creating pipes Using fseek ftell page tables (page offsets, dirty bit,TLB)Quiz 5 Basic properties of TCP UDP Purpose properties of each TCP server call Correct order of “big 4” TCP server calls.  What is DNS, what is its purpose? POSIX calls required create a TCP client Properties of UDP, TCP, IPv4, IPv6, privileged ports Purpose basic properties of sockets able correctly choose when use ntohs, ntohl, htons, htonl Correct setting up addrinfo hints struct for a TCP server or client Purpose properties of getaddrinfo Reading writing pipes (including blocking, SIGPIPE detecting when no more bytes can read)Quiz 6 Review. This quiz includes questions from previous topics. Quiz 7 See chapter in course book. Topics Security fundamentals principles Confidentiality, Integrity, Availability (CIA) principles CIA examples Compiler developer-related targetted attacks Security-related development practices CPU Microarchitecture side channel attacks (Meltdown Spectre) Network protocol attacks (Heartbleed Syn-flooding, DDOS) POSIX Process-related security features (exectable memory, process-as-a-secure container model)","url":"/quiz_topics"},{"title":"Resources","content":"ResourcesLate Add InstructionsIf you added late, check get caught up. Textbook ReferencesAn gentle short introduction system programming is Angrave’s . We also have second iteration That provides html, pdf, wiki versions. Angrave’s mini searchable video-introduction playful system programming-in-the-browser environment is at: (Firefox Chrome recommended). No formal textbook is required, but if you really want buy a physical book, we recommend following custom book Angrave put together in 2007:Tutorials      How SucceedIs this course hard? Yes, but you are bright. You’re taking computer science at UIUC. Schedule time do it. two big changes from CS 225: Your code is now much smaller than complexity of system around it.  No, we will not debug your code for you. With lecture content, one lab, one MP, one Quiz/Midterm every week or two, it can get easy fall behind. How fail: some students do not take time learn how debug reason about system code then end up complaining that office hours is too busy before deadlines. If you can’t write correct solutions, you need learn exactly how C works, details of system calls you are using, learn better debugging skills reason behind synchronization. Only then can you spot fix mistakes. Hard? Yes. Impossible? No. There are no shortcuts mastery, but we can help you get there. We recommend learning. Remember, simply recognizing some text in a past exam or in coursebook is not mastery of those concepts! Find ways deeply engage your brain with ideas by working actively with those ideas. Yes, this requires effort. Start assignments early; expect get stuck. Write code slowly; reason about every line of code you write. Experiment with your own mind hacks so that you have fun spending “time on task” with these materials. Forum Q-and-A: Search First. Don’t Post. We’re using for our Question Answer forum - check your email for invite link. Before posting please search forum see if someone has already asked your question. Some questions where you need include your netid (e. g. regrade requests) should private posts. Low-Effort QuestionsWe will not accept “low effort questions”: “My code doesn’t work, can someone look at my github?” Questions that are already answered in a pinned post Questions that are already answered in docs Questions that have already been answered many times before can easily found by searching Questions that provide basically no information go off of (Debugging? Tests? Valgrind? Anything?)If we find you asking too many of these low-effort questions, then we reserve right remove your forum posting privileges. Hopefully these steps will lead you answer you’re looking for, or at very least help you find answer yourself. Asking on our forum should not first thing you do when you have a problem. You’re here learn; we’re not going give you answer every time you ask. DebuggingHave you run it in Valgrind? Are you testing simpler cases that might show where problem is? How about adding print statements or using breakpoints in gdb figure out if you’re actually getting code you think is running? Are you using VM we provide test code? If you’re getting erratic behavior, make sure you’ve fixed everything Valgrind complains about, as what you do wrong in one place can affect a completely unrelated piece of code. If you ask a question, make sure that you’ve made some effort find problem. prepared provide some Valgrind log. DocumentationA lot of questions can answered simply by looking at MP spec, pinned errata posts, or looking through a man page. Don’t know where your specific question is answered? Use Ctrl+F with some keywords search page. Don’t know how use a function? Read man page. It provides detailed info on how use a function, can even list some examples. Also note man page section 7. It’s all explanations of different parts of C library. There you can find how signal, epoll, more work in practice. Google Is Your FriendMost questions can simply answered by searching Edstem, or Googling your question. chances are that someone has had your exact problem, someone has answered it (especially near a due date when most people have already finished). Even if you don’t find your exact answer, questions you find can close enough what you’re looking for. Here are some tips on Googling: . I Found Nothing. What Now?If you are truly lost, can’t find an answer in docs, or in other questions, or wide expanse of internet, ask your question! What’s problem you’re having? (And give an example) What have you tried? Have you tested your code? What does Valgrind say? How about a gdb backtrace? If you need show code, don’t take a screenshot. Copy it into a pre tag (“code” on rich editor bar) If referencing your repo please include your netid or URL so we can easily look it up, make post private You can post anonymously if you wishCS 341 AdminPlease contact your section TA for most things. For unusual administrative items (e. g. exam sickness, DRES, 1% issues, problems with your TA) then please email explain your scenario. Note: We do not provide attendance misses for labs (this is not negotiable), especially for something that is 100% in your control like “I have an interview. ”Lawrence AngraveLawrence Angrave can often found on second floor of Siebel in or near SC2217. His office hours will posted once semester starts. He’s also able answer quick questions before or after most lectures. Graham Carl EvansGraham Carl Evans has also taught this course. His office is on third floor of Siebel 3209. ","url":"/resources"},{"title":"Schedule","content":"           CS 341 · Schedule                \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r Asynchronous Learning  For students who like learn independently you can succeed in this course using  pre-recorded on ClassTranscribe. original lecture handouts example code are . (Note minivideos are from when course was called CS241).   Synchronous Learning   schedule below is approximate subject change - it's an interactive class - so we may get a bit behind etc. handouts code examples for this semester are     Days   Monday   Wednesday   Friday                    Week 1: [01/20] - [01/24]              No class - MLK day      Topics: History of    Coursebook Reading:                1.   Welcome System Programming     Topics: 1. HW0 using my    Coursebook Reading:    See             2.   How crash in C     Topics: 2. Dive into C programming   Coursebook Reading:    Code handouts are . Alternatively see Lecture 2 on               Week 2: [01/27] - [01/31]              3.   C Crash Course 2     Topics: 3. man,asprintf,free,assert   Coursebook Reading:    See Lecture 3 on or             4.   A day at C side: C Crash Course 3     Topics: 4. getenv, scanf, getline, fork    Coursebook Reading:    See lecture 4 on             5.   Fork wait     Topics: 5. fork waitpid   Coursebook Reading:    See lecture 5               Week 3: [02/03] - [02/07]              6.   Forking Processes     Topics: 6. fork-exec-wait pattern   Coursebook Reading:    See lecture on             7.   Signals for Process Control     Topics: 7. Introducing POSIX signals suspend kill child processes. SIGSTOP, SIGKILL, SIGINT   Coursebook Reading:    See lecture on             8.   Thanks for heap memory     Topics: How build a memory allocator. Placement algorithms. Fragmentation.    Coursebook Reading:    See lecture on               Week 4: [02/10] - [02/14]              9.   Memory allocators I     Topics: Hone your pointer skills when writing malloc free.    Coursebook Reading:    See lecture on             10.   Memory allocators II      Topics: Memory allocators part 2.    Coursebook Reading:    See lecture on             11.   Threads     Topics: Introducing pthreads. stacks. Concurrency programming gotchas.    Coursebook Reading:    See lecture on               Week 5: [02/17] - [02/21]              12.   Threads, memory mutex locks     Topics: Introducing pthreads. stacks, shared memory. creating joining. Concurrency programming gotchas.    Coursebook Reading:    See lecture on             13.   Mutexes semaphores     Topics: Why we need Mutex locks semaphores. Basic usage of pthread implementations. Common gotchas.    Coursebook Reading:    See lecture on .             14.   Condition Variables     Topics: Mutex Condition Variable examples. How implement a lock (The critical section problem).    Coursebook Reading:    See lecture on               Week 6: [02/24] - [02/28]              15.   Critical Section Problem     Topics: Incorrect attempts solve Critical Section Problem. Introduction Condition Variables.    Coursebook Reading:    See lecture on .             16.   Condition Variables II     Topics: Condition Variables. Implementing a semaphore using a Condition Variable.    Coursebook Reading:    See lecture on .             17.   Producer Consumers. Barriers     Topics: Implementing a barrier. Implementing Producer Consumer.    Coursebook Reading:    See lecture on               Week 7: [03/03] - [03/07]              18.   Reader Writer Deadlock - Part 1     Topics:    Coursebook Reading:    See lecture on             19.   Reader Writer Deadlock - Part 2     Topics:    Coursebook Reading:    See lecture on             20.   Dining Philosophers     Topics: Dining Philosophers problem   Coursebook Reading:    See lecture on .               Week 8: [03/10] - [03/14]              21.   Page tables IPC     Topics: Virtual memory   Coursebook Reading:    See lecture on .             22.   Pipes seeking     Topics: Moving data using pipes, seekable streams, named pipes, behavior with fork   Coursebook Reading:    See lecture on             23.   Files. Pipes seeks part 2.      Topics: Working with files   Coursebook Reading:    See lecture on               Week 9: [03/17] - [03/21]              No class - Spring Break     Topics:    Coursebook Reading:                No class - Spring Break     Topics:    Coursebook Reading:                No class - Spring Break     Topics:    Coursebook Reading:                  Week 10: [03/24] - [03/28]              24.   UDP/TCP     Topics: Robust error handling. EINTR. Intro TCP,UDP,IP   Coursebook Reading:    See lecture on             25.   TCP Client     Topics: TCP/IP Header. IPv4 exhaustion. A web client   Coursebook Reading:    See lecture on             26.   TCP Server     Topics: Passive sockets. 4 server calls what they do. Gotchas.    Coursebook Reading:    See lecture on               Week 11: [03/31] - [04/04]              27.   Files     Topics: ext2/3/4 filesystem, index nodes (inodes), superbocks, ZFS / BtrFS   Coursebook Reading:    See lecture on .             28.   Files 2     Topics: ext2/3/4 filesystem, index nodes (inodes), superbocks, ZFS / BtrFS   Coursebook Reading:    See lecture on .             29.   Files 3     Topics: Symbolic links, hard links, directory searching, intro permissions   Coursebook Reading:    See lecture on .               Week 12: [04/07] - [04/11]              30.   Files 4     Topics: File permissions, directories, file globbing, intro RAID   Coursebook Reading:    See lecture on .             31.   Files-5     Topics: Redundant Array of Inexpensive Disks (RAID), various RAID levels   Coursebook Reading:    See lecture on .             32.   Scheduling Scheduling Algorithms     Topics: Scheduling examples   Coursebook Reading:    See lecture on .               Week 13: [04/14] - [04/18]              33.   Epoll     Topics: Intro select, poll, epoll   Coursebook Reading:    See lecture on             34.   Disks Signals     Topics: Disks Signals   Coursebook Reading:    See lecture on             35.   Working with Signals     Topics: Working with Signals   Coursebook Reading:    See lecture on               Week 14: [04/21] - [04/25]              36.   Networking Protocols     Topics: TCP handshakes, QUIC, HTTP/1. 1   Coursebook Reading:    See lecture on             37.   RPC     Topics: Remote Procedure Calls   Coursebook Reading:    See lecture on .             38.   Systems Concepts Review     Topics: Systems Concepts Review   Coursebook Reading:    See lecture on               Week 15: [04/28] - [05/02]              39.   Security     Topics:    Coursebook Reading:    See lecture on             40.   Course Review     Topics:    Coursebook Reading:    See lecture on             announced     Topics:    Coursebook Reading:                  Week 16: [05/05] - [05/09]              announced     Topics:    Coursebook Reading:           ","url":"/schedule"},{"title":"Search","content":"\r           CS 341 · Search               \r\r\r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r\r\r\r \r \r \r Search\r\r \r \r \r \r \r \r \r \r \r\r \r \r \r \r \r \r Loading. . . \r \r \r \r \r\r\r\r","url":"/search"},{"title":"Staff","content":"\r           CS 341 · Staff               \r\r\r \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r\r \r Course Staff\r \r \r \r Most questions should asked on our Q &amp; A Forum, so that answers can benefit entire class. \r Please acquaint yourself with our \r \r \r However, if you have a sensitive issue feel free make a private note on forum, or email course staff\r directly. \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r","url":"/staff"},{"title":"Statements","content":"            CS 341 · Statements                 \r\r \r \r \r \r \r Toggle navigation\r \r \r \r \r\r \r \r\r \r \r \r\r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r\r     Land Acknowledgement Statement We would like begin today by recognizing acknowledging that we are on lands of Peoria, Kaskaskia, Piankashaw, Wea, Miami, Mascoutin, Odawa, Sauk, Mesquaki, Kickapoo, Potawatomi, Ojibwe, Chickasaw Nations. These lands were traditional territory of these Native Nations prior their forced removal; these lands continue carry stories of these Nations their struggles for survival identity. As a land-grant institution, University of Illinois has a particular responsibility acknowledge peoples of these lands, as well as histories of dispossession that have allowed for growth of this institution for past 150 years. We are also obligated reflect on actively address these histories role that this university has played in shaping them. This acknowledgement centering of Native peoples is a start as we move forward for next 150 years.     Statement on anti-racism inclusivity intent of this section is raise student instructor awareness of ongoing threat of bias racism of need take personal responsibility in creating an inclusive learning environment.  Grainger College of Engineering is committed creation of an anti-racist, inclusive community that welcomes diversity along a number of dimensions, including, but not limited to, race, ethnicity national origins, gender gender identity, sexuality, disability status, class, age, or religious beliefs.  College recognizes that we are learning together in midst of Black Lives Matter movement, that Black, Hispanic, Indigenous voices contributions have largely either been excluded from, or not recognized in, science engineering, that both overt racism micro-aggressions threaten well-being of our students our university community.  effectiveness of this course is dependent upon each of us create a safe encouraging learning environment that allows for open exchange of ideas while also ensuring equitable opportunities respect for all of us. Everyone is expected help establish maintain an environment where students, staff, faculty can contribute without fear of personal ridicule, or intolerant or offensive language.  If you witness or experience racism, discrimination, micro-aggressions, or other offensive behavior, you are encouraged bring this attention of course director if you feel comfortable. You can also report these behaviors Bias Assessment Response Team . Based on your report, BART members will follow up reach out students make sure they have support they need healthy safe. If reported behavior also violates university policy, staff in Office for Student Conflict Resolution may respond as well will take appropriate action.     Statement on Sexual Misconduct Policy Reporting University of Illinois is committed combating sexual misconduct. Faculty staff members are required report any instances of sexual misconduct University’s Title IX Office. In turn, an individual with Title IX Office will provide information about rights options, including accommodations, support services, campus disciplinary process, law enforcement options. A list of designated University employees who, as counselors, confidential advisors, medical professionals, do not have this reporting responsibility can maintain confidentiality, can found here: Other information about resources reporting is available here:    Statement on CS CARES CS Values Code of Conduct (Approved by CS CARES Committee, January 13, 2022)All members of Illinois Computer Science department - faculty, staff, students - are expected adhere .  is available serve as a resource help people who are concerned about or experience a potential violation of Code.  If you experience such issues, please CS CARES Committee.  Instructors of this course are also available for issues related this class.    Statement on Mental HealthDiminished mental health, including significant stress, mood changes, excessive worry, substance/alcohol abuse, or problems with eating and/or sleeping can interfere with optimal academic performance, social development, emotional well-being.  University of Illinois offers a variety of confidential services including individual group counseling, crisis intervention, psychiatric services, specialized screenings at no additional cost.  If you or someone you know experiences any of above mental health concerns, it is strongly encouraged contact or visit any of University's resources provided below.  Getting help is a smart courageous thing do -- for yourself for those who care about you.  Counseling Center: , 610 East John Street Champaign, IL 61820 McKinley Health Center: , 1109 South Lincoln Avenue, Urbana, Illinois 61801University wellness center:       ","url":"/statements"},{"title":"Syllabus","content":"SyllabusFormal Course DescriptionThis course is an introduction System Programming. System Programming refers writing code that prioritizes operating system support for programmers. A computer needs an operating system manage its resources provide support for common functions, such as accessing peripherals. There are two categories of “customers” that an operating system must support.  first category is community of users. We have all used computers, you may recognize operating systems’ functions such as creating folders (directories) moving files around. These are examples of operating system support for users. User support is not objective of this course.  second category of users is programmers. This course addresses this category. When you write a program, it may have interact with physical hardware (memory, flash storage, screen, network, etc. ). For example, you may want get input from a keyboard or mouse; you may want read some configuration file stored on disk; you may want output data a screen or printer; or you may want access a remote server across a network.  operating system presents common interfaces for programmers perform these functions. It also provides useful abstractions such as “tasks” (also called processes), “threads”, “semaphores”. You can make computer multi-task by creating new tasks or new threads. You can make these tasks coordinate synchronize by using semaphores. You can tell computer order in which you want tasks executed by using a scheduling policy. Finally, you can manage computer memory by calling on function for memory management. Learning Goals/Skills Identify basic components of an operating system, describe their purpose, explain how they function.  Write, compile, debug, execute C programs that correctly use system interfaces provided by UNIX or a UNIX-like operating system.  familiar with important UNIX system calls invoke them correctly from within C programs.  Describe difference between programs, processes, threads.  Write a memory allocator or .  Explain meaning purpose of process control blocks other mechanisms that operating system uses implement process thread abstractions.  Write, compile, debug, execute C programs that create, manage terminate processes threads on UNIX.  Define concurrency explain problems that may arise because of concurrent execution of multiple processes or threads. Explain how these problems can avoided. Write code that avoids these problems.  Define semaphores, mutexes, other synchronization primitives. Also, explain their purpose, describe their internal implementation.  Describe possible problems that arise from improper use of synchronization primitives (such as deadlocks) present their solutions.  Write, compile, debug, execute C programs that use UNIX synchronization primitives.  Describe operating system scheduling use UNIX interfaces set modify scheduling policy parameters.  Define UNIX signals signal handlers, describe their use.  Write, compile, debug, execute C programs with processes threads that interact by invoking catching signals.  Describe concepts of I/O devices, files, directories.  Explain internal implementation of files systems operating system I/O.  Write, compile, debug, execute C programs that use files I/O on UNIX.  Describe machine memory hierarchy, describe its components such as caches virtual memory, explain memory management mechanisms pertaining these components such as paging segmentation.  Write, compile, debug, execute C programs that make use of memory management functions.  Describe protocols (such as TCP IP) interfaces (such as sockets) used for communication among different computers.  Write distributed applications that communicate across a network.  Understands uses system security mechanisms build secure programs.  By end of this course, you should proficient at writing programs that take full advantage of operating system support.  Can analyze how a specific security error (e. g. buffer overflow, file access control, page access control) impacts Confidentiality, Integrity and/or Availability of data or service.  Can identify multiple development practices (e. g. design reviews, code reviews, testing) as important practices build secure programs.  Can briefly describe well-known security case studies (e. g. network protocol implementation errors, CPU side channel attacks) how they comprise Confidentiality, Integrity and/or Availability of data or service. Grading following is subject minor changes:We publish following thresholds:   Points Minimum Grade     [90 - 100] A-   [80 - 90) B-   [70 - 80) C-  All lab programming assignments are equally weighted. MP programming assignments are weighted by time given complete them. This means that three week MPs are worth triple one week. For grading, we will drop your lowest lab score, two lab attendance grades. Some examples: you slept in late; your dog ate your homework; you destroyed internet.  final is take-home, 3 hours will available online. exam can completed at any time over a 3 day period during exam week. More details will published at end of semester. Early exams will not offered. exam will available on first Sunday after reading day closes 3 days later, Wednesday 11 pm. Opportunities for a small amount of extra credit may offered will annouced during semester. Grading issues should raised with your TA during section or by email. Missing scores need reported within 3 days of being published. RegradesAt end of semester there will a last chance regrade option for three weeks of machine problem or lab grades. able take advantage of this opportunity you will need have a “perfect” (we define) attendance grade after drops. When will this start? For Fall semesters, it will start around Thanksgiving week. for Spring semesters, it will around middle of April. Can we use autograder at this time? Yes! During regrade period, autograder will open for every assignment. You will able use one pre-deadline autograder run per day on each assignment (i. e. you can run autograder on different assignments on same day). Running autograder on an assignment does not use a regrade. How do I specify what assignments I want regraded? Regrades are determined by a file released during this period where you indicate what assignments you want use your regrades on. We trigger deadline autograder runs for only these assignments, which determines final grade. More info? We will announce regrade policy on course forum later in semester. Please note that score for each regrade will capped at 90%. For assignment’s final grade, we will automatically use your higher score between regrade score original score. Lab AttendanceChicago students will have their own online lab (arranged with TA). Urbana-Champaign students have in-person labs in Siebel. Labs are required there is also a small reward for in-person attendance: Your final exam contribution (23%) can reduced 20% by attending all labs. Partial attendance of in-person labs will prorated. For example, if after allowing for 2 drops, you attended 6 of 9 in-person labs (11 labs in total after drops in real) then your final exam will worth 21%, you will have 2% of full course credit. What this means: If you choose complete this course virtually, or are sick unable attend labs, or do not wish in close contact with other students you can still succeed earn a high grade. For those that need it: There is still a small carrot encourage you leave your dorm make it Siebel! But don’t get anxious about loosing points if you can’t attend. QuizzesEach quiz covers approximately 2 weeks of content. They can completed multiple times (highest score is used) at any time. They are due by last day of instruction (i. e. before reading day). No quizes are dropped; you should complete all 7 of them. Quizzes will online using . Please see Quiz topics page for more information. Coding AssignmentsThere are two different types of coding assignments in this course labs machine problems. Labs are primarily teaching exercises designed either prepare you for machine problems or allow you explore a topic of systems in a hands on manner. Labs may done in a collaborative manner. You are allowed work with each other so as learn in best manner for you. This can include sharing code, debugging each other’s code, discussing assignment at any level. You still may not publicly publish either your solutions or our code. Finally you should have a comment block with any students or other resources you used in completion of your lab assignments. This block will not used for grading but is needed same way that citing your sources is required when writing a paper. Machine Problems are different. While they are a key learning experience MPs are also a key assessment of your skills. These are solo exercises you must work alone. For MPs, you may not share code in any way. This includes show, share, email, or debug each others code. You may have high level discussions with each other on ideas in assignments but that is it. You are responsible for keeping code for you machine problems private this includes not letting people view your code. You may not publish your code on any open website. No late submissions will accepted. Autograding PolicyYou walk into investor meeting ready show your demo. You ship your code ready for a million Internet of things. You deploy your code Internet backbone. It had better compile functional. Forgot commit or your committed code that does not compile? Zero. basic headline is that you’re not in Kansas anymore (to quote Dorothy). Don’t leave it until last minute. There are two kinds of autograder runs: Pre-deadline runs: You are responsible for starting these. Our team has worked really hard improve our grading system make it more reliable flexible. Now, you can schedule your pre-deadline autograder runs using on-demand grading system, that you can find on Assignments page! You have log in with your GitHub Enterprise account. Assignments will become visible on web app as we release them. You will get one AG run a day which you can trigger at your disposal. Please careful in using these. These pre-deadline runs do not roll over. We recommend that you develop work on your assignments every day make best of this system. Once you click “Grade Now”, your code will start getting tested on our grading machines. You can expect see feedback in your CS 341 repository’s _feedback branch in a few minutes. In rare circumstances, grading process might fail (if your code made our Docker containers crash). In this scenario, there will no visible feedback. You should make a private post in course forums we will deal with this on a per-student basis. Use these runs for feedback as you work on assignment. Students are 100% responsible for pre-deadline runs they have no effect on your grade for assignment.  Deadline runs: These will triggered by us grades you get on these will counted towards your final grades. results will show up in _feedback branch as usual. Labs: Released every Wednesday Pre-deadline runs: Available every day from Wednesday Wednesday (you will get start these!) Deadline AG run on Wednesday at 11:59 pmMPs: Released on Mondays (for multi-week MPs, entire assignment is released at once) Pre-deadline runs: Available every day from Tuesday Monday (you will get start these!) Deadline run on Monday at 11:59 pmWe will test your code on a multi-core machine; testing on your own laptop is insufficient. Don’t surprised if race conditions that go undetected on a different machine cause your code fail. We encourage you develop test your code on your CS 341 VM, which is near-identical grading machine. We will attempt give you some partial credit if your code passes tests. If you have a question about your personal autograder results after final autograde run, then feel free make a private post in course forums titled “&lt;assignment name&gt; Autograde Question” with folders/tags/labels &lt;MP or Lab&gt; &lt;assignment name&gt; selected.  It will take time go through autograder questions, so please do not expect an immediate (or even same day or same week) response. We will try answer you as quickly as possible.  You must show us your test cases first. If they are not close exhaustive, we reserve right not answer your question.  We will not tell you details of specific tests, beyond what test description already says.  These questions should for “I have exhaustive test cases for X, so how am I failing Y?” Please mention your NetID in post, so we can look up your code if needed. Getting Help &amp; ExtensionsIt’s important say physically mentally healthy. Please see links below for mental health resources.  Office hours peer mentoring for course staff will posted in forums. Office hours will start second full week of semester For unusual administrative items (e. g. sickness preventing you from working, DRES, 1% issues, problems with your TA) then please email () explain your scenario. AbsencesIf you are in an exceptional situation – i. e. family emergency, sickness, please email () we will deal with your situation on a case-by-case basis via course admin (). For illness-related excuses, you will need a doctor’s note of some kind verifying your illness. No illness-related excuses will accepted without a dated note stating that you contacted Emergency Dean. Lab attendance credit will not given unless you are physically present in lab (there is no point asking admin for this if you are sick or away). Lab attendance reduces fraction contribution from your final exam by a small amount. This is a small reward for attending. Use of Large Language Models, Code Assistants, generative AI ModelsYou may use Large Language AI Models (e. g. Github Copilot, ChatGPT, other models) in this class with following conditions- You must document their use in your code. Clearly describe which parts of your submitted code were developed with help of generative AI.  Document when you used an AI model as part of your development process how well it worked. Specifically, in your code comments describe if you used an AI model assist in your initial design, initial implementation, developing test code, debugging code or other software development process.  Unless explicitly allowed by assignment or exam, you may NOT use generative AI complete (large portions of) assignments for you. Please see Academic Integrity section below. Academic IntegrityCS 341 is considered a critical step in your ability create useful programs for your later classes beyond. Unfortunately for grading purposes, a minority of students submit code that was created by others. Cheating is taken very seriously, all cases of cheating will brought University, your department, your college. You should understand how applies Computer Science courses. Rule of Thumb: If at any point you submit an assignment that does not reflect your understanding of material, then you have probably cheated. In cases of labs, you are allowed collaborate with others in class, which includes detailed debugging code sharing. All you need do is put your partners’ netid at top. This does not mean that will you share same grade for assignment, each group member must submit a solution receive credit. EVERY MACHINE PROBLEM IS A SOLO ASSIGNMENT IN THIS CLASS!This means you are not allowed split work with a partner. You are, however, allowed discuss assignments at a very high level. You can even share testing scripts!If you are found have shared code work on any machine problem, you will receive a zero on that assignment a 10% sanction in course for each infraction where you are found have used material that is not yours. Intentional obfuscation of code (e. g. , adding dead code, no-op functions, non-standard formatting, deceptive naming conventions) also constitutes a violation of course policy. You may not publish your solutions or leave them in “plain view”, thereby leaving your programs open copying, which constitutes cheating. If your code (or a variation of it) is found publicly accessible, then you will receive a letter grade reduction in class for each infraction. Do not put your code anywhere besides your private course repository take measures ensure that nobody can copy your code, so that you are not charged with a violation. In case of quizzes in CBTF, it is a violation of our course policy access or provide access quiz material outside your registered window. Cheating at CBTF may also result in immediate failure of course further action by college of engineering. If you are found have done so you will receive a zero on quiz a 10% sanction in course. This includes seeking descriptions of questions from students who have taken quiz, as well as any other method that would give you access quiz outside your scheduled time. If there is prep material provided in lecture or on course forums, you are welcome share that material freely. We want you get most out your education, cheating not only affects your peers, but also your level of knowledge ability. You may use AI other code-assist tools - see AI statement above. Land Acknowledgment StatementPlease see our important Diversity Statement . Sexual Misconduct Policy Reporting StatementPlease see our important Diversity Statement . Diversity StatementPlease see our important Diversity Statement . Mental Health StatementPlease see our important Mental Health Statement . CS Cares StatementPlease see our important CS Cares Statement . ","url":"/syllabus"},{"title":"Appendix","content":"                                                                                  AppendixShellA shell is actually how you are going interacting with system. Before user-friendly operating systems, when a computer started up allyou had access was a shell. This meant that all of your commands editing had done this way. Nowadays, our computers boot up indesktop mode, but one can still access a shell using a terminal. It is ready for your next command! You can type in a lot of Unixutilities like ls, echo Hello shell will execute them give you result. Some of these are what are known asshell-builtins meaning that code is in shell program itself. Some of these are compiled programs that you run. shell only looksthrough a special variable called path which contains a list of colonseparated paths search for an executable with your name, here is anexample path. So when shell executes ls, it looks through all of thosedirectories, finds /bin/ls executes that. You can always call through full path. That is always why in pastclasses if you want run something on terminal you’ve had do. /exe because typically directory that you are working in is notin PATH variable. . expands your current directory your shell executes &lt;current_dir&gt;/exe which is a valid command. Shell tricks tips  up arrow will get you your most recent command   ctrl-r will search commands that you previously ran   ctrl-c will interrupt your shell’s process   !! will execute last command   !&lt;num&gt; goes back that many commands runs that   !&lt;prefix&gt; runs last command that has that prefix   !$ is last arg of previous command   !* is all args of previous command   p̂atŝub takes last command substitutes pattern pat for substitution sub   cd - goes previous directory   pushd &lt;dir&gt; pushes current directory on a stack cds   popd cds directory at top of stack What’s a terminal?A terminal is an application that displays output from shell. You can have your default terminal, a quake based terminal, terminator, options are endless!Common Utilities  cat concatenate multiple files. It is regularly used print out contents of a file terminal but original use wasconcatenation.     diff tells you difference between two files. If nothing isprinted, then zero is returned meaning files are same bytefor byte. Otherwise, longest common subsequence difference isprinted    grep tells you which lines in a file or standard input match aPOSIX pattern.     ls tells you which files are in current directory.    cd this is a shell builtin but it changes a relative orabsolute directory    man every system programmers favorite command tells you more aboutall your favorite functions!   make executes programs according a makefile.  SyntacticShells have many useful utilities like saving some output a fileusing redirection &gt;. This overwrites file from beginning. Ifyou only meant append file, you can use &gt;&gt;. Unix also allowsfile descriptor swapping. This means that you can take output going one file descriptor make it seem like it’s coming out of another. most common one is 2&gt;&amp;1 which means take stderr make itseem like it is coming out of standard out. This is important becausewhen you use &gt; &gt;&gt; they only write standard output of file. There are some examples below.  pipe operator has a fascinating history. UNIX philosophy iswriting small programs chaining them together do new interesting things. Back in early days, hard disk space was limited write times were slow. Brian Kernighan wanted maintain philosophy while omitting intermediate files that take up hard drivespace. So, UNIX pipe was born. A pipe takes stdout of program on its left feeds it stdin of program on itswrite. Consider command tee. It can used as a replacement for redirection operators because tee will both write a file output standard out. It also has added benefit that it doesn’tneed last command in list. Meaning, that you can write anintermediate result continue your piping.  &amp;&amp; || operator are operators that execute a commandsequentially. &amp;&amp; only executes a command if previous commandsucceeds, || always executes next command. What are environment variables?Each process gets its own dictionary of environment variables that arecopied over child. Meaning, if parent changes theirenvironment variables it won’t transferred child viceversa. This is important in fork-exec-wait trilogy if you want exec a program with different environment variables than your parent (orany other process). For example, you can write a C program that loops through all of time zones executes date command print out date time in all locals. Environment variables are used for all sorts ofprograms so modifying them is important. Struct packingStructs may require something called(tutorial). We do not expect you pack structs in this course, knowthat compilers perform it. This is because in early days (and evennow) loading an address in memory happens in 32-bit or 64-bit blocks. This also meant requested addresses had multiples of block sizes. You think picture looks like this. One box is four bytes. [fig:clean_struct]However, with struct packing, it would conceptually look like this:Visually, we’d add two extra boxes our diagram[fig:sloppy_struct]This padding is common on a 64-bit system. Other time, a processorsupports unaligned access, leaving compiler able pack structs. What does this mean? We can have a variable start at a non-64-bitboundary. processor will figure out rest. enable this, set anattribute. Now our figure will look like clean struct as in figure But now, every time processor needs access data or encoding, two memory accessesare required. A possible alternative is reorder struct. Stack SmashingEach thread uses a stack memory. stack ‘grows downwards’ - if afunction calls another function, then stack is extended smallermemory addresses. Stack memory includes non-static automatic (temporary)variables, parameter values, return address. If a buffer is toosmall some data (e. g.  input values from user), then there is a realpossibility that other stack variables even return address will overwritten. precise layout of stack’s contents order of automatic variables is architecture compiler dependent. With alittle investigative work, we can learn how deliberately smash stack for a particular architecture.  example below demonstrates how return address is stored on stack. For a particular 32 bit architecture,we determine that return address is stored at an address twopointers (8 bytes) above address of automatic variable. codedeliberately changes stack value so that when input functionreturns, rather than continuing on inside main method, it jumps exploit function instead. There areof ways that computers tend get around this. Compiling LinkingThis is a high-level overview from time you compile your program time you run your program. We often know that compiling your programis easy. You run program through an IDE or a terminal, it justworks. Here are rough stages of compiling for gcc.   Preprocessing: preprocessor expands all preprocesor directives.    Parsing: compiler parses text file for functiondeclarations, variable declarations, etc.    Assembly Generation: compiler then generates assembly code forall functions after some optimizations if enabled.    Assembling: assembler turns assembly into 0s 1s creates an object file. This object file maps names pieces ofcode.    Static Linking: linker then takes a series of objects staticlibraries resolves references of variables functions fromone object file another. linker then finds main method makes that entry point for function. linker alsonotices when a function is meant dynamically linked. compiler also creates a section in executable that tells operating system that these functions need addresses right beforerunning.    Dynamic Linking: As program is getting ready executed, operating system looks at what libraries that program needs links those functions dynamic library.    program is run.  Further classes will teach you about parsing assembly –preprocessing is an extension of parsing. Most classes won’t teach youabout two different types of linking though. Static linking alibrary is similar combining object files. create a staticlibrary, a compiler combines different object files create oneexecutable. A static library is literally is an archive of object files. These libraries are useful when you want your executable secure,you know all code that is being included into your executable, portable, all code is bundled with your executable meaning noadditional installs.  other type is a dynamic library. Typically, dynamic libraries areinstalled user-wide or system-wide are accessible by most programs. Dynamic libraries’ functions are filled in right before they are run. There are a number of benefits this.   Lower code footprint for common libraries like C standardlibrary   Late binding means more generalized code less reliance onspecific behavior.    Differentiation means that shared library can updated whilekeeping executable same.  There are a number of drawbacks as well.   All code is no longer bundled into your program. This means thatusers have install something else.    There could security flaws in other code leading securityexploits in your program.    Standard Linux allows you “replace” dynamic libraries, leading possible social engineering attacks.    This adds additional complexity your application. Two identicalbinaries with different shared libraries could lead differentresults.  Explanation of Fork-FILE Problem parse ,we’ll have go deep into terminology. sentence that sets expectation is following result of function calls involving any one handle (the “activehandle”) is defined elsewhere in this volume of POSIX. 1-2008, but iftwo or more handles are used, any one of them is a stream, application shall ensure that their actions are coordinated asdescribed below. If this is not done, result is undefined. What this means is that if we don’t follow POSIX letter whenusing two file descriptors that refer same description acrossprocesses, we get undefined behavior. technical, filedescriptor must have a “position” meaning that it needs have abeginning an end like a file, not like an arbitrary stream of bytes. POSIX then goes on introduce idea of an active handle, where ahandle may a file descriptor or a FILE* pointer. File handles don’thave a flag called “active”. An active file descriptor is one that iscurrently being used for reading writing other operations (suchas exit). standard says that before a fork that application or your code must execute a series of steps prepare state of file. In simplified terms, descriptor needs closed, flushed, or read its entirety – gory details areexplained later.  For a handle become active handle, application shall ensurethat actions below are performed between last use of handle (the current active handle) first use of secondhandle (the future active handle). second handle then becomes active handle. All activity by application affecting fileoffset on first handle shall suspended until it again becomes active file handle. (If a stream function has as an underlyingfunction one that affects file offset, stream function shall considered affect file offset. )Summarizing as if two file descriptors are actively being used, behavior is undefined. other note is that after a fork, librarycode must prepare file descriptor as if other process were make file active at any time. last bullet point concerns itselfwith how a process prepares a file descriptor in our case.  If stream is open with a mode that allows reading underlying open file description refers a device that is capable ofseeking, application shall either perform an fflush(), or stream shall closed.  documentation says that child needs perform an fflush orclose stream because file descriptor needs prepared incase parent process needs make it active. glibc is in a no-winsituation if it closes a file descriptor that parent may expect open, so it’ll opt for fflush on exit because exit in POSIXterminology counts as accessing a file. That means that for our parentprocess, this clause gets triggered.  If any previous active handle has been used by a function thatexplicitly changed file offset, except as required above for first handle, application shall perform an lseek() or fseek() (asappropriate type of handle) an appropriate location. Since child calls fflush parent didn’t prepare, operating system chooses where file gets reset. Different filesystems will do different things which are supported by standard. OS may look at modification times conclude that file hasn’tchanged so no resets are needed or may conclude that exit denotes achange needs rewind file back beginning. Banker’s AlgorithmWe can start with a single resource Banker’s Algorithm. Consider abanker, who has a finite amount of money. With a finite amount of money,she wants make loans eventually get her money back. Let’s saythat we have a set of \\(n\\) people where each of them has a set amountor a limit \\(a_i\\) (\\(i\\) being \\(i\\)th process) that theyneed obtain before they can do any work. banker keeps track ofhow much she has given each person \\(l_i\\). She maintains an amountof money \\(p\\) with her, at all times. For people request money,they do following: Consider state of system\\((A=\\{a_1, a_2, . . . \\}, L_t=\\{l_{t,1}, l_{t,2}, . . . \\}, p)\\) at time\\(t\\). A precondition is that we have \\(p ≥min(A)\\), or we haveenough money suit at least one person. Also, each person will workfor a finite period give back our money.   A person \\(j\\) requests \\(m\\) from me   if \\(m ≥p\\), they are denied.    if \\(m + l_j &gt; a_i\\) they are denied   Pretend we are in a new state\\((A, L_{t+1}=\\{. . , l_{t+1, j} = l_{t, j} + m, . . . \\}, p - m)\\)where process is granted resource.      if now person \\(j\\) is either satisfied (\\(l_{t+1,j} == a_j\\))or \\(min(a_i - l_{t+1, i}) ≤p\\). In other words, we have enoughmoney suit one other person. If either, consider transactionsafe give them money.  Why does this work? Well at start we are in a safe state – definedby we have enough money suit at least one person. Each of these“loans” results in a safe state. If we have exhausted our reserve, oneperson is working will give us money greater than or equal ourprevious “loan”, thus putting us in a safe state again. Since we canalways make one additional move, system can never deadlock. Now,there is no guarantee that system won’t livelock. If process wehope request something never does, no work will done – but not due deadlock. This analogy expands higher orders of magnitude butrequires that either a process can do its work entirely or there existsa process whose combination of resources can satisfied, which makes algorithm a little more tricky (an additional for loop) but nothingtoo bad. There are some notable downsides.   program first needs know how much of each resource a processneeds. A lot of times that is impossible or process requests wrong amount because programmer didn’t foresee it.    system could livelock.    We know in most systems that resources vary, pipes sockets forexample. This could mean that runtime of algorithm could slow for systems with millions of resources.    Also, this can’t keep track of resources that come go. Aprocess may delete a resource as a side effect or create a resource. algorithm assumes a static allocation that each processperforms a non-destructive operation.  Clean/Dirty Forks (Chandy/Misra Solution)There are many more advanced solutions. One such solution is by Chandy Misra(???). This is not a true solution dining philosophers problem becauseit has requirement that philosophers can speak each other. It isa solution that ensures fairness for some notion of fairness. Inessence, it defines a series of rounds that a philosopher must eat in agiven round before going next one. We won’t detail proof here because it is a little more involved, butfeel free read more. Actor Model actor model is another form of synchronization that doesn’t have do anything with negotiating locks or waiting. idea is simple. Eachactor can either perform work, create more actors, send messages, orrespond messages. Any time an actor needs something from anotheractor, it sends a message. Most importantly, an actor is onlyresponsible for one thing. If we were implementing a real-worldapplication, we may have an actor that handles database, one thathandles incoming connections, one that services connections,etc. These actors would pass messages each other like “there is a newconnection” from incoming connection actor servicing actor. servicing actor may send a data request message databaseactor a data response message comes back. While this seems like perfect solution there are drawbacks. first is actual library of communication needs synchronized. If you don’t have a framework that does this already – like MessagePassing Interface or MPI for High-Performance Computing – then framework will have built would most likely as much work build efficiently compared direct synchronization. Also, messagesnow encounter additional overhead for serializing deserializing orat least. a final drawback is that an actor could take anarbitrarily long time respond a message, spurring need forshadow actors who service same job. As mentioned, there are frameworks likethat is somewhat based on actor model allows distributed systemsin high-performance computing work effectively, but your mileage mayvary If you want read further on model, feel free glance over Wikipedia page listed below. Includes conditionals other preprocessor include is #include directive conditionals. include directive is explained by example. This is our file bar. c unpreprocessed. After preprocessing, compiler sees this other tool is preprocessor conditionals. If a macro is defined ortruthy, that branch is taken. Using gcc your compiler would preprocess source following. Using clang your compiler would preprocess this. Thread SchedulingThere are a few ways split up work. These are common OpenMP framework(???).   static scheduling breaks up problems into fixed-size chunks(predetermined) have each thread work on each of chunks. This works well when each of subproblems takes roughly sametime because there is no additional overhead. All you need do iswrite a loop give map function each sub-array.    dynamic scheduling as a new problem becomes available have athread serve it. This is useful when you don’t know how long scheduling will take   guided scheduling This is a mix of above with a mix of benefits tradeoffs. You start with static scheduling moveslowly dynamic if needed   runtime scheduling You have absolutely no idea how long problems are going take. Instead of deciding it yourself, let program decide what do! No need memorize any of scheduling routines though. Openmp is astandard that is an alternative pthreads. For example, here is how parallelize a for loopStatic scheduling will divide problem into fixed-size chunks Dynamicscheduling will give a job once loop is over Guided scheduling isDynamic with chunks Runtime is a whole bag of worms. threads. hWe have a lot of threading libraries discussed in extra section. Wehave standard POSIX threads, OpenMP threads, we also have a new C11threading library that is built into standard. This library providesrestricted functionality. Why use restricted functionality? key is in name. Since this is C standard library, it has implemented in all operatingsystems that are compliant which are pretty much all of them. This meansthere is first-class portability when using threads. We won’t drone on about functions. Most of them are renaming ofpthread functions anyway. If you ask why we don’t teach these, there area few reasons  They are pretty new. Even though standard came out in roughly2011, POSIX threads have been around forever. A lot of their quirkshave been ironed out.    You lose expressivity. This is a concept that we’ll talk about inlater chapters, but when you make something portable, you lose someexpressivity with host hardware. That means that threads. hlibrary is pretty bare bones. It is hard set CPU affinities. Schedule threads together. Efficiently look at internals forperformance reasons.    A lot of legacy code is already written with POSIX threads in mind. Other libraries like OpenMP, CUDA, MPI will either use POSIXprocesses or POSIX threads with a begrudging port Windows.  Modern FilesystemsWhile API for most filesystems have stayed same on POSIX over years, actual filesystems themselves provide lots of importantaspects.   Data Integrity. File systems use journaling sometimes checksums ensure that data written is valid. Journalling is a simpleinvention where file system writes an operation in a journal. If filesystem crashes before operation is complete, it canresume operation when booted up again using partial journal.    Caching. Linux does a good job of caching file system operationslike finding inodes. This makes disk operations seem nearly instant. If you want see a slow system, look at Windows with FAT/NTFS. Disk operations need cached by application, or it willburn through CPU.    Speed. On spinning disk machines, data that is toward end of ametallic platter will spin faster (angular velocity is farther from center). Programs used this reduce time loading large fileslike movies in a video editing piece of software. SSDs don’t havethis problem because there is no spinning disk, but they willportion off a section of their space used as “swap space” forfiels.    Parallelism. Filesystems with multiple heads (for physical harddisks) or multiple controllers (for SSDs) can utilize parallelism bymultiplexing PCIe slot with data, always serving some data application whenever possible.    Encryption. Data can encrypted with one or more keys. A goodexample of this is Apple’s APFS file systems.    Redundancy. Sometimes data can replicated blocks ensurethat data is always available.    Efficient Backups. Many of us have data that we can’t store on cloud for one reason or another. It is useful that when afilesystems is either being used as a backup medium or is source backup that it is able calculate what has changedefficiently, compress files, sync between external drive.    Integriy Bootability. File systems need resillient bitflipping. Most readers have their operating system installed on same paritition as file system that they used do differentoperations. file system needs make sure a stray read or writedoesn’t destroy boot sector – meaning your computer can’t startup again.    Fragmentation. Just like a memory allocator, allocating space for afile leads both internal external fragmentation. samecaching benefit occurs when disk blocks for a single file arelocated next each other. File systems need perform well underlow, high, possible fragmentation usage.    Distributed. Sometimes, filesystem should single machinefault tolerant. Hadoop other distributed file system allow you do that.  Cutting Edge File systemsThere are a few filesystem hardware nowadays that are truly cuttingedge. one we’d briefly like touch on is AMD’s StoreMI. We aren’ttrying sell AMD chipsets, but featureset of StoreMI warrants amention. StoreMI is a hardware microcontroller that analyzes how operatingsystem accesses files moves files/blocks around speed up loadtime. A common usage can imagined as having a fast, but smallcapacity SSD a slower, large capcity HDD. make it seem like all files are on an SSD, StoreMI matches pattern of file access. If you are starting up Windows, Windows will often access many files in same order. StoreMI takes note of that when microcontrollernotices it is starting boot, it will move files from HDD drive SSD before they are requested by operating system. By time operating system needs then, they are already on SSD. StoreMI also does this with other applications as well. technologystill has a lot desired for, but it is an interesting intersectionof data pattern matching with filesystems. Linux SchedulingAs of February 2016, Linux by default uses Completely FairScheduler for CPU scheduling Budget Fair Scheduling “BFQ” forI/O scheduling. Appropriate scheduling can have a significant impact onthroughput latency. Latency is important for interactive soft-real time applications such as audio video streaming. See discussion comparative benchmarksfor more information. Here is how CFS schedules  CPU creates a Red-Black tree with processes virtual runtime(runtime / nice_value) sleeper fairness flag – if processis waiting on something, give it CPU when it is done waiting.    Nice values are kernel’s way of giving priority certainprocesses, lower nice value higher priority.    kernel chooses lowest one based on this metric schedulesthat process run next, taking it off queue. Since red-black tree is self-balancing this operation is guaranteed\\(O(log(n))\\) (selecting min process is same runtime) Although it is called Fair Scheduler there are a fair bit ofproblems.   Groups of processes that are scheduled may have imbalanced loads so scheduler roughly distributes load. When another CPU getsfree it can only look at average load of a group schedule, not individual cores. So free CPU may not take work from aCPU that is burning so long as average is fine.    If a group of processes is running on non-adjacent cores then thereis a bug. If two cores are more than a hop away, loadbalancing algorithm won’t even consider that core. Meaning if a CPUis free a CPU that is doing more work is more than a hop away,it won’t take work (may have been patched).    After a thread goes sleep on a subset of cores, when it wakes upit can only scheduled on cores that it was sleeping on. Ifthose cores are now busy, thread will have wait on them,wasting opportunities use other idle cores.    read more on problems of Fair Scheduler, read.  Implementing Software MutexYes With a bit of searching, it is possible find it in production forspecific simple mobile processors today. Peterson’s algorithm is used implement low-level Linux Kernel locks for Tegra mobile processor (asystem-on-chip ARM process GPU core by Nvidia)In general now, CPUs C compilers can re-order CPU instructions oruse CPU-core-specific local cache values that are stale if another coreupdates shared variables. Thus a simple pseudo-code Cimplementation is too naive for most platforms. Warning, here dragons! Consider this advanced gnarly topic but (spoiler alert) ahappy ending. Consider following code,An efficient compiler would infer that flag2 variable is never changedinside loop, so that test can optimized while(true) Usingvolatile goes some way prevent compiler optimizations of this kind. Let’s say that we solved this by telling compiler not optimize. Independent instructions can re-ordered by an optimizing compiler orat runtime by an out-of-order execution optimization by CPU. A related challenge is that CPU cores include a data cache storerecently read or modified main memory values. Modified values may not written back main memory or re-read from memory immediately. Thusdata changes, such as state of a flag turn variable in aboveexample, may not shared between two CPU codes. But there is a happy ending. Modern hardware addresses these issuesusing ‘memory fences’ also known as a memory barrier. This preventsinstructions from getting ordered before or after barrier. There isa performance loss, but it is needed for correct programs!Also, there are CPU instructions ensure that main memory CPU’s cache is in a reasonable coherent state. Higher-levelsynchronization primitives, such as pthread_mutex_lock are will callthese CPU instructions as part of their implementation. Thus, inpractice, surrounding critical sections with a mutex lock unlockcalls is sufficient ignore these lower-level problems. For further reading, we suggest following web post that discussesimplementing Peterson’s algorithm on an x86 process Linuxdocumentation on memory barriers.        Curious Case of Spurious WakeupsCondition variables need a mutex for a few reasons. One is simply that amutex is needed synchronize changes of condition variableacross threads. Imagine a condition variable needing provide its owninternal synchronization ensure its data structures work correctly. Often, we use a mutex synchronize other parts of our code, so whydouble cost of using a condition variable. Another example relates high priority systems. Let’s examine a code snippet.    Thread 1 Thread 2     while(answer &lt; 42)       answer++     pthread_cond_signal(cv)   pthread_cond_wait(cv)    Signaling without Mutex problem here is that a programmer expects signal wake up waiting thread. Since instructions are allowed interleaved withouta mutex, this causes an interleaving that is confusing applicationdesigners. Note that technically API of condition variable issatisfied. wait call happens-after call signal, signalis only required release at most a single thread whose call waithappened-before. Another problem is need satisfy real-time scheduling concernswhich we only outline here. In a time-critical application, waitingthread with highest priority should allowed continue first. satisfy this requirement mutex must also locked before callingpthread_cond_signal or pthread_cond_broadcast. For curious,. Condition Wait Example call pthread_cond_wait performs three actions:  Unlock mutex. mutex must locked.    Sleeps until pthread_cond_signal is called on same conditionvariable.    Before returning, locks mutex.  Condition variables are always used with a mutex lock. Before callingwait, mutex lock must locked wait must wrapped with aloop. This is a pretty naive example, but it shows that we can tell threads wake up in a standardized manner. In next section, we will use these implement efficient blocking data structures. Implementing CVs with Mutexes AloneImplementing a condition variable using only a mutex isn’t trivial. Hereis a sketch of how we could do it. This is all boring definitional stuff. interesting stuff isbelow. So how does this work? Instead of allocating space which could lead deadlock. We keep data structures or linked list nodes on eachthread’s stack. linked list in wait function is created while thread has mutex lock. This is important because we may have arace condition on insert removal. A more robust implementationwould have a mutex per condition variable. What is note about (dynamic)? In pthread man pages, wait createsa runtime binding a mutex. This means that after first call iscalled, a mutex is associated with a condition variable while there isstill a thread waiting on that condition variable. Each new threadcoming in must have same mutex, it must locked. Hence, beginning end of wait (everything besides while loop) aremutually exclusive. After last thread leaves, meaning when head isNULL, then binding is lost.  signal broadcast functions merely tell either one thread or allthreads respectively that they should woken up. It doesn’t modify linked lists because there is no mutex prevent corruption if twothreads call signal or broadcast. Now an advanced point. Do you see how a broadcast could cause a spuriouswakeup in this case? Consider this series of events.   Some number more than 2 threads start waiting   Another thread calls broadcast.    That thread calling broadcast is stopped before it wake any threads.    Another thread calls wait on condition variable adds itself queue.    Broadcast iterates through frees all of threads.  There is no assurance as when broadcast was called whenthreads were added in a high-performance mutex. ways prevent thisbehavior are include Lamport timestamps or require that broadcast called with mutex in question. That way something thathappens-before broadcast call doesn’t get signaled after. sameargument is put forward for signal too. Did you also notice something else? This is why we ask you signalor broadcast before you unlock. If you broadcast after you unlock, time that broadcast takes could infinite!  Broadcast is called on a waiting queue of threads   First thread is freed, broadcast thread is frozen. Since mutexis unlocked, it locks continues.    It continues for such a long time that it calls broadcast again.    With our implementation of a condition variable, this would terminated. If you had an implementation that appended tailof list iterated form head tail, this could go oninfinitely many times.  In high-performance systems, we want make sure that each thread thatcalls wait isn’t passed by another thread that calls wait. With current API that we have, we can’t assure that. We’d have ask users pass in a mutex or use a global mutex. Instead, we tell programmers always signal or broadcast before unlocking. Higher Order Models of SynchronizationWhen using atomics, you need specify right model ofsynchronization ensure a program behaves correctly. You can read moreabout themThese examples are adapted from those. Sequentially ConsistentSequentially consistent is simplest, least error-prone mostexpensive model. This model says that any change that happens, allchanges before it will synchronized between all threads. Will never quit. This is because either store happens before ifstatement in thread 2 y == 1 or store happens after x doesnot equal 2. RelaxedRelaxed is a simple memory order providing for more optimizations. Thismeans that only a particular operation needs atomic. One can havestale reads writes, but after reading new value, it won’t becomeold. But that means that previous loads stores don’t need affect otherthreads. In previous example, code can now fail. Acquire/Release order of atomic variables don’t need consistent – meaning ifatomic var y is assigned 10 then atomic var x 0 those don’tneed propagate, a threa could get stale reads. Non-atomicvariables have get updated in all threads though. ConsumeImagine same as above except non-atomic variables don’t need getupdated in all threads. This model was introduced so that there can an Acquire/Release/Consume model without mixing in Relaxed becauseConsume is similar relax. Actor Model GoroutinesThere are a lot of other methods of concurrency than described in thisbook. Posix threads are finest grained thread construct, allowingfor tight control of threads CPU. Other languages have theirabstractions. We’ll talk about a language go that is similar C interms of simplicity design, go or golang get 5 minuteintroduction, feel free readfor go. Here is how we create a “thread” in go. This actually creates what is known as a goroutine. A goroutine can thought of as a lightweight thread. Internally, it is a worker pool ofthreads that executes instructions of all running goroutines. When agoroutine needs stopped, it is frozen “context switched” another thread. Context switch is in quotes because this is done at run time level versus real context switching which is done at operating system level.  advantage gofuncs is pretty self explanatory. There is noboilerplate code, or joining, or odd casting void *. We can still use mutexes in go perform our end result. Consider counting example as before. But that’s boring error prone. Instead, let’s use actor model. Let’s designate two actors. One is main actor that will performing main instruction set. other actor will counter. counter is responsible for adding numbers an internalvariable. We’ll send messages between threads when we want add see value. Although there is a bit more boilerplate code, we don’t have mutexesanymore! If we wanted scale this operation do other things likeincrement by a number, or write a file, we can have that particularactor take care of it. This differentiation of responsibilities isimportant make sure your design scales well. There are even librariesthat handle all of boilerplate code as well. Scheduling ConceptuallyThis section could useful for those that like analyze thesealgorithms mathematicallyIf your co-worker asked you what scheduling algorithm use, you maynot have tools analyze each algorithm. So, let’s think aboutscheduling algorithms at a high level break them down by theirtimes. We will evaluating this in context of a random processtiming, meaning that each process takes a random but finite amount oftime finish. Just a refresher, here are terms.    Concept Meaning     Start time time scheduler first started work   End time When scheduler finished process   Arrival time When job first arrived at scheduler   Run time How long does process take run if there is no preemption  Scheduling Variables here are measures we are trying optimize.    Measure Formula     Response Time Start time minus Arrival time   Turnaround time End time minus Arrival time   Wait time End time minus Arrival time minus Run time  Scheduling Measures of EfficiencyDifferent use cases will discussed after. Let maximum amount oftime that a process run equal \\(S\\). We will also assume thatthere are a finite number of processes running at any given time\\(c\\). Here are some concepts from queueing theory that you’ll need know that will help simplify theories.   Queueing theory involves a random variable controlling interarrival time – or time between two different processesarriving. We won’t name this random variable, but we will assumethat (1) it has a mean of \\(λ\\) (2) it is distributed as aPoisson random variable. This means probability of getting aprocess \\(t\\) units after getting another process is\\(λ^t * \\frac{\\exp(-λ)}{t!}\\) where \\(t!\\) can approximatedby gamma function when dealing with real values.    We will denoting service time \\(S\\), deriving waiting time \\(W\\), response time \\(R\\); morespecifically expected values of all of those variables\\(E[S]\\) deriving turnaround time is simply \\(S + W\\). Forclarity, we will introduce another variable \\(N\\) that is number of people currently in queue. A famous result in queueingtheory is Little’s Law which states \\(E[N] = λE[W]\\) meaning that number of people waiting is arrival rate times expectedwaiting time (assuming queue is in a steady state).    We won’t make many assumptions about how much time it takes runeach process except that it will take a finite amount of time –otherwise this gets almost impossible evaluate. We will denotetwo variables that \\(\\frac{1}{μ}\\) is mean of waiting time that coefficient of variation \\(C\\) is defined as\\(C^2 = \\frac{var(S)}{E[S]^2}\\) help us control for processesthat take a while finish. An important note is that when\\(C &gt; 1\\) we say that running times of process arevariadic. We will note below that this rockets up wait response times for FCFS quadratically.    \\(ρ= \\frac{λ}{μ} &lt; 1\\) Otherwise, our queue would becomeinfinitely long   We will assume that there is one processor. This is known as anM/G/1 queue in queueing theory.    We’ll leave service time as an expectation \\(S\\) otherwise wemay run into over-simplifications with algebra. Plus it iseasier compare different queueing disciplines with a commonfactor of service time.  First Come First ServedAll results are from Jorma Virtamo’s lectures on matter(???).   first is expected waiting time. \\(E[W] = \\frac{(1 + C^2)}{2}\\frac{ρ}{(1 - ρ)} * E[S]\\) What does this say? When given as \\(ρ→1\\) or mean job arrivalrate equals mean job processing rate, then wait times getlong. Also, as variance of job increases, wait times goup.    Next is expected response time \\(E[R] = E[N] * E[S] = λ* E[W] * E[S]\\) response time issimple calculate, it is expected number of people ahead of process in queue times expected time service each ofthose processes. From Little’s Law above, we can substitute that forthis. Since we already know value of waiting time, we canreason about response time as well.    A discussion of results is shows something cool discovered byConway Al(???). Any scheduling discipline that isn’t preemptive doesn’t takeinto account run time of process or a priority will have same wait, response, turnaround time. We will often use this asa baseline.  Round Robin or Processor SharingIt is hard analyze Round Robin from a probabilistic sense because itis so state based. next job that scheduler schedules requires it remember previous jobs. Queueing theory developers have made anassumption that time quanta is roughly zero – ignoring contextswitching like. This leads way into processor sharing. Manydifferent tasks can get worked on at same time but experience aslowdown. All of these proofs will adapted from Harchol-Balter’s book(???). We highly recommend checking out books if you are interested. proofs are intuitive for people who don’t have a background in queueingtheory.   Before we jump answer let’s reason about this. With ournew-found abstraction, we essentially have an FCFS queue where weare going working on each job a little slower than before. Since we are always working on a job\\[E[W] = 0\\] Under a non-strict analysis of processor sharing though, numberof time that scheduler waits is best approximated by numberof times scheduler need wait. You’ll need\\(\\frac{E[S]}{Q}\\) service periods where \\(Q\\) is quanta, you’ll need about \\(E[N] * Q\\) time in between those periods. Leading an average time of \\(E[W] = E[S] * E[N]\\) reason this proof is non-rigorous is that we can’t assume thatthere will always \\(E[N] * Q\\) time on average in betweencycles because it depends on state of system. This means weneed factor in various variations in processing delay. We alsocan’t use Little’s Law in this case because there is no real steadystate of system. Otherwise, we’d able prove some weirdthings.  Interestingly, we don’t have worry about convoy effect or anynew processes coming in. total wait time remains bounded by number of people in queue. For those of you familiar with tailinequalities since processes arrive according a Poissondistribution, probability that we’ll get many processes dropsoff exponentially due Chernoff bounds (all arrivals areindependent of other arrivals). Meaning roughly we can assume lowvariance on number of processes. As long as service time isreasonable on average, wait time will too.    expected response time is \\(E[R] = 0\\) Under strict processor sharing, it is 0 because all jobs are workedon. In practice, response time is. \\(E[R] = E[N] * Q\\) Where \\(Q\\) is quanta. Using Little’s Law again, we can findout that \\(E[R] = λE[W] * Q\\)   A different variable is amount of service time let servicetime for processor sharing defined as \\(S_{PS}\\). slowdownis \\(E[S_{PS}] = \\frac{E[S]}{1 - ρ}\\) Which means as meanarrival rate equals mean processing time, then jobs willtake asymptotically as long finish. In non-strict analysis ofprocessor sharing, we assume that\\(E[S_{RR}] = E[S] + Q * ϵ, ϵ&gt; 0\\) \\(ϵ\\) is amount of timea context switch takes.    That naturally leads comparison, what is better? responsetime is roughly same comparing non-strict versions, waittime is roughly same, but notice that nothing about variation of jobs is put in. That’s because RR doesn’t have deal with convoy effect any variances associated, otherwiseFCFS is faster in a strict sense. It also takes more time for jobs finish, but overall turnaround time is lower under highvariance loads.  Non Preemptive PriorityWe will introduce notation that there are \\(k\\) differentpriorities \\(ρ_i &gt; 0\\) is average load contribution forpriority \\(i\\) We are constrained by\\(\\sum\\limits_{i=0}^k ρ_i = ρ\\). We will also denote\\(ρ(x) = \\sum\\limits_{i=0}^x ρ_i\\) which is load contribution forall higher similar priority processes \\(x\\). last bit ofnotation is that we will assume that probability of getting aprocess of priority \\(i\\) is \\(p_i\\) naturally\\(\\sum\\limits_{j=0}^k p_j = 1\\)  If \\(E[W_i]\\) is wait time for priority \\(i\\),\\(E[W_x] = \\frac{(1 + C)}{2}\\frac{ρ}{(1 - ρ(x))*( 1 - ρ(x-1))} * E[S_i]\\) full derivation is as always in book. A more usefulinequality is that.  \\(E[W_x] ≤\\frac{1 + C}{2}* \\frac{ρ}{(1 - ρ(x))^2} * E[S_i]\\)because addition of \\(ρ_x\\) can only increase sum,decrease denominator or increase overall function. Thismeans that if one is priority 0, then a process only need waitfor other P0 processes which there should \\(ρC/ (1 - ρ_0)\\)P0 processes arrived before process in FCFS order. Then nextpriority has wait for all others so on so forth.  expected overall wait time is now\\[E[W] = \\sum\\limits_{i=0}^k E[W_i] * p_i\\] Now that we have notational soup, let’s factor out importantterms. \\[\\sum\\limits_{i=0}^k \\frac{p_i}{(1-ρ(i))^2}\\] Which we compare with FCFS’ model of\\[\\frac{1}{1-ρ}\\] In words – you can work this out with experimenting distributions –if system has a lot of low priority processes who don’tcontribute a lot average load, your average wait time becomesmuch lower.    average per process response time is\\[E[R_i] = \\sum\\limits_{j = 0}^i E[N_j] * E[S_j]\\] Which says that scheduler needs wait for all jobs with ahigher priority same go before a process can go. Imaginea series of FCFS queues that a process needs wait your turn. Using Little’s Law for different colored jobs formula abovewe can simplify this\\[E[R_i] = \\sum\\limits_{j=0}^i λ_j E[W_j] * E[S_j]\\] we can find average response time by looking at distribution ofjobs\\[E[R] = \\sum\\limits_{i=0}^k p_i [\\sum\\limits_{j=0}^k λ_j E[W_j] * E[S_j] ]\\] Meaning that we are tied wait times service times of allother processes. If we break down this equation, we see again if wehave a lot of high priority jobs that don’t contribute a lot load then our entire sum goes down. We won’t make too manyassumptions about service time for a job because that wouldinterfere with our analysis from FCFS where we left it as anexpression.    As for a comparison with FCFS in average case, it usually doesbetter assuming that we have a smooth probability distribution –i. e. probability of getting any particular priority is zero. Inall of our formulas, we still have some probability mass put onlower priority processes, bringing expectation down. Thisstatement doesn’t hold for all smooth distributions but for mostreal-world smoothed distributions (which tend smooth) they do.    This isn’t even mention idea of utility. Utility means thatif we gain an amount of happiness by having certain jobs finish,priority preemptive priority maximize that while balancing outother measures of efficiency.  Shortest Job FirstThis is a wonderful reduction priority. Instead of having discretepriorities, we’ll introduce a process that takes \\(S_t\\) time getserviced. \\(T\\) is maximum amount of time a process can run for,our processes cannot run infinitely long. That means followingdefinitions hold, overriding previous definitions in priority  Let \\(ρ(x) = \\int_0^x ρ_u du\\) average load contribution up this point.    \\(\\int_0^k p_u du = 1\\) Probability constraint.    Etc, replace all summations above with integrals   only notational difference is we don’t have make anyassumptions about service times of jobs because they aredenoted by service times subscript, all other analyses are same.    This means if you want low wait times on average compared FCFS,your distribution needs right-skewed.  Preemptive PriorityWe will describe priority SJF’s preemptive version in samesection because it is essentially same as we’ve shown above. We’lluse same notation as before. We will also introduce an additionalterm \\(C_i\\) which denotes variation among a particular class\\[C_i = \\frac{var(S_i)}{E[S_i]}\\]  Response Time. Just a head’s up, this isn’t going pretty. \\(E[R_i] = \\frac{\\sum\\limits_{j=0}^i\\frac{(1 + C_j)}{2}}{(1 - ρ(x))*( 1 - ρ(x-1))} * E[S_i]\\) If this looks familiar it should. This is average wait time in nonpreemptive case with a small change. Instead of using variance of entire distribution, we are looking at varianceof each job coming in. whole response times are\\[E[R] = \\sum\\limits_{i = 0}^k p_i * E[R_i]\\] If lower priorities jobs come in at a higher service time variance,that means our average response times could go down, unless theymake up most of jobs that come in. Think of extreme cases. If 99% of jobs are high priority rest make up otherpercent, then other jobs will get frequently interrupted, buthigh priority jobs will make up most of jobs, so expectationis still low. other extreme is if one percent of jobs are highpriority they come in a low variance. That means chances system getting a high priority jobs that will take a long time islow, thus making our response times lower on average. We only runinto trouble if high priority jobs make up a non-negligible amount, they have a high variance in service times. This brings downresponse times as well as wait times.    Waiting Time \\(E[W_i] = E[R_i] + \\frac{E[S_i]}{1 - ρ(i)}\\) Taking expectation among all processes weget\\[E[W] = \\sum\\limits_{i = 0}^k p_i (E[R_i] + \\frac{E[S_i]}{1 - ρ(i)})\\] We can simplify \\[E[W] = E[R] + \\sum\\limits_{i=0}^k \\frac{E[S_i]p_i}{(1 - ρ(i))}\\] We incur same cost on response time then we have sufferan additional cost based on what probabilities are of lowerpriority jobs coming in taking this job out. That is what wecall average interruption time. This follows same laws asbefore. Since we have a variadic, pyramid summation if we have a lotof jobs with small service times then wait time goes down forboth additive pieces. It can analytically shown that this isbetter given certain probability distributions. For example, trywith uniform versus FCFS or non preemptive version. Whathappens? As always proof is left reader.    Turnaround Time is same formula \\(E[T] = E[S] + E[W]\\). Thismeans that given a distribution of jobs that has either low waitingtime as described above, we will get low turnaround time – we can’tcontrol distribution of service times.  Preemptive Shortest Job FirstUnfortunately, we can’t use same trick as before because aninfinitesimal point doesn’t have a controlled variance. Imagine comparisons though as same as previous section. Networking ExtraIn-depth IPv4 Specification Internet Protocol deals with routing, fragmentation, reassemblyof fragments. Datagrams are formatted as such  first octet is version number, either 4 or 6   next octet is how long header is. Although it may seem that header is a constant size, you can include optional parameters augment path that is taken or other instructions.    next two octets specify total length of datagram. Thismeans this is header, data, footer, padding. This is given in multiple of octets, meaning that a value of 20means 20 octets.    next two are Identification number. IP handles taking packetsthat are too big sent over physical wire chunks themup. As such, this number identifies what datagram this originallybelonged to.    next octet is various bit flags that can set.    next octet half is fragment number. If this packet wasfragmented, this is number this fragment represents   next octet is time live. So this is number of “hops”(travels over a wire) a packet is allowed go. This is set becausedifferent routing protocols could cause packets go in circles, packets must dropped at some point.    next octet is protocol number. Although protocols betweendifferent layers of OCI model are supposed black boxes,this is included, so that hardware can peer into underlyingprotocol efficiently. Take for example IP over IP (yes you can dothat!). Your ISP wraps IPv4 packets sent from your computer ISP in another IP layer sends packet off delivered website. On reverse trip, packet is “unwrapped” original IP datagram is sent your computer. This was done becausewe ran out of IP addresses, this adds additional overhead but itis a necessary fix. Other common protocols are TCP, UDP, etc.    next two octets is an internet checksum. This is a CRC that iscalculated make sure that a wide variety of bit errors aredetected.    source address is what people generally refer as IPaddress. There is no verification of this, so one host can pretend any IP address possible   destination address is where you want packet sent to. Destinations are crucial routing process.    Additional options: Hosts of additional options, this is variadic insize.    Footer: A bit of padding make sure your data is a multiple of 4octets.    After: Your data! All data of higher-order protocols are putfollowing header.  Routing Internet Protocol routing is an amazing intersection of theory application. We can imagine entire Internet as a set of graphs. Mostpeers are connected what we call “peering points” – these are WiFi routers Ethernet ports that one finds at home, at work, inpublic. These peering points are then connected a wired network ofrouters, switches, servers that all route themselves. At a highlevel there are two types of routing  Internal Routing Protocols. Internal protocols are routing designedfor within an ISP’s network. These protocols are meant fast more trusting because all computers, switches, routers arepart of an ISP. communication between two routers.    External Routing Protocols. These typically happen ISP ISPprotocol. Certain routers are designated as border routers. Theserouters talk routers from ISPs who have different policies fromaccepting or receiving packets. If an evil ISP is trying dump allnetwork traffic onto your ISP, these routers would deal with that. These protocols also deal with gathering information about outside world each router. In most routing protocols using linkstate or OSPF, a router must necessarily calculate shortest path destination. This means it needs information about “foreign” routers which is disseminated according theseprotocols.  These two protocols have interplay with each other nicely makesure that packets are mostly delivered. Also, ISPs need nice each other. Theoretically, an ISP can handle a smaller load byforwarding all packets another ISP. If everyone does that then, nopackets get delivered at all which won’t make customers happy at all. These two protocols need fair so result worksIf you want read more about this, look at Wikipedia page forrouting here. Fragmentation/ReassemblyLower layers like WiFi Ethernet have maximum transmission sizes. reason being is  One host shouldn’t crowd medium for too long   If an error occurs, we want some sort of “progress bar” on how far communication has gone instead of retransmitting entirestream.    There are physical limitations, keeping a laser beam in opticsworking continuously may cause bit errors.  If Internet Protocol receives a packet that is too big for maximum size, it must chunk it up. TCP calculates how many datagramsthat it needs construct a packet ensures that they are alltransmitted reconstructed at end receiver. reason that webarely use this feature is that if any fragment is lost, entirepacket is lost. Meaning that, assuming probability of receiving apacket assuming each fragment is lost with an independent percentage, probability of successfully sending a packet drops off exponentiallyas packet size increases. As such, TCP slices its packets so that it fits inside on IP datagram. only time that this applies is when sending UDP packets that are toobig, but most people who are using UDP optimize set same packetsize as well. IP MulticastA little known feature is that using IP protocol one can send adatagram all devices connected a router in what is called amulticast. Multicasts can also configured with groups, so one canefficiently slice up all connected routers send a piece ofinformation all of them efficiently. access this in a higherprotocol, you need use UDP specify a few more options. Note thatthis will cause undue stress on network, so a series of multicastscould flood network fast. kqueueWhen it comes Event-Driven IO, name of game is fast. One extra system call is considered slow. OpenBSD FreeBSD have anarguably better model of asynchronous IO from kqueue model. Kqueueis a system call that is exclusive BSDs MacOs. It allows you modify file descriptor events read file descriptors all in a singlecall under a unified interface. So what are benefits?  No more differentiation between file descriptors kernel objects. In epoll section, we had discuss this distinction otherwiseyou may wonder why closed file descriptors are getting returned onepoll. No problem here.    How often do you call epoll read file descriptors, get a serversocket, need add another file descriptor? In ahigh-performance server, this can easily happen 1000s of times asecond. As such, having one system call register grab eventssaves overhead of having a system call.    unified system call for all types. kqueue is truest sense ofunderlying descriptor agnostic. One can add files, sockets, pipes it get full or near full performance. You can add same epoll, but Linux’s whole ecosystem with async file input-output hasbeen messed up with aio, meaning that since there is no unifiedinterface, you run into weird edge cases.  Assorted Man PagesMallocSystem Programming Jokes0x43 0x61 0x74 0xe0 0xf9 0xbf 0x5f 0xff 0x7f 0x00Warning: Authors are not responsible for any neuro-apoptosis caused bythese “jokes. ” - Groaners are allowed. Light bulb jokesQ. How many system programmers does it take change a lightbulb?A. Just one but they keep changing it until it returns zero. A. None they prefer an empty socket. A. Well you start with one but actually it waits for a child do allof work. GroanersWhy did baby system programmer like their new colorful blankie? Itwas multithreaded. Why are your programs so fine soft? I only use 400-thread-count orhigher programs. Where do bad student shell processes go when they die? Forking Hell. Why are C programmers so messy? They store everything in one big heap. System Programmer (Definition)A system programmer is…Someone who knows sleepsort is a bad idea but still dreams of anexcuse use it. Someone who never lets their code deadlock… but when it does, it causesmore problems than everyone else combined. Someone who believes zombies are real. Someone who doesn’t trust their process run correctly without testingwith same data, kernel, compiler, RAM, filesystem size,file systemformat, disk brand, core count, CPU load, weather, magnetic flux,orientation, pixie dust, horoscope sign, wall color, wall gloss reflectance, motherboard, vibration, illumination, backup battery, timeof day, temperature, humidity, lunar position, sun-moon, co-position…A system program …Evolves until it can send email. Evolves until it has potential create, connect kill otherprograms consume all possible CPU, memory, network, … resources onall possible devices but chooses not to. Today. ","url":"/coursebook/Appendix"},{"title":"$ ./a.out","content":"                                                          BackgroundSometimes journey of a thousand steps begins by learning walk   Systems ArchitectureThis section is a short review of System Architecture topics that you’llneed for System Programming. AssemblyWhat is assembly? Assembly is lowest that you’ll get machinelanguage without writing 1’s 0’s. Each computer has an architecture, that architecture has an associated assembly language. Each assemblycommand has a 1:1 mapping a set of 1’s 0’s that tell computerexactly what do. For example, following in widely used x86Assembly language add one memory address 20 (Wikibooks) – you can also look in (Guide) Section 2A under add instruction though it is more verbose. Why do we mention this? Because it is important that although you aregoing doing most of this class in C, that this is what code istranslated into. Serious implications arise for race conditions atomic operations. Atomic OperationsAn operation is atomic if no other processor should interrupt it. Takefor example above assembly code add one a register. In architecture, it may actually have a few different steps on circuit. operation may start by fetching value of memory from stick of ram, then storing it in cache or a register, thenfinally writing back (Schweizer, Besta, Hoefler)– under description for fetch-and-add though yourmicro-architecture may vary. Or depending on performance operations, itmay keep that value in cache or in a register which is local thatprocess – try dumping -O2 optimized assembly of incrementing avariable. problem comes in if two processors try do it at same time. two processors could at same time copy value of memory address, add one, store same result back, resultingin value only being incremented once. That is why we have a specialset of instructions on modern systems called atomic operations. If aninstruction is atomic, it makes sure that only one processor or threadperforms any intermediate step at a time. With x86 this is done by lock prefix (Guide, 1120). Why don’t we do this for everything? It makes commands slower! If everytime a computer does something it has make sure that other coresor processors aren’t doing anything, it’ll much slower. Most of time we differentiate these with special consideration. Meaning, we willtell you when we use something like this. Most of time you canassume instructions are unlocked. CachingAh yes, Caching. One of computer science’s greatest problems. caching that we are referring is processor caching. If a particularaddress is already in cache when reading or writing, processorwill perform operation on cache, such as adding update actual memory, later because updating memory is slow (Intel Section3. 4). If it isn’t, processor requests a chunk of memory from memory chip stores it in cache, kicking out least recentlyused page – this depends on caching policy, but Intel’s does use this. This is done because l3 processor cache is roughly three timesfaster reach than memory in terms of time (Levinthal,22) though exact speeds will vary based on clock speed architecture. Naturally, this leads problems because there are twodifferent copies of same value, in cited paper this refers anunshared line. This isn’t a class about caching, but you should know howthis could impact your code. A short but non-complete list could   Race Conditions! If a value is stored in two different processorcaches, then that value should accessed by a single thread.    Speed. With a cache, your program may look faster mysteriously. Justassume that reads writes that either happened recently or arenext each other in memory are fast.    Side effects. Every read or write affects cache state. Whilemost of time this doesn’t help or hurt, it is important know. Check Intel programmer guide on lock prefix for moreinformation.  InterruptsInterrupts are an important part of system programming. An interrupt isinternally an electrical signal that is delivered processor whensomething happens – this is a hardware interrupt (“Chapter 3. HardwareInterrupts,”). Then hardware decides if this is something that it should handle (e. g. ,handling keyboard or mouse input for older keyboard mouses) or itshould pass operating system. operating system then decidesif this is something that it should handle (e. g. , paging a memory tablefrom disk) or something application should handle (e. g. , aSEGFAULT). If operating system decides that this is something that process or program should take care of, it sends a softwarefault that software fault is then propagated. application thendecides if it is an error (SEGFAULT) or not (SIGPIPE for example) reports user. Applications can also send signals kernel hardware as well. This is an oversimplification because thereare certain hardware faults that can’t ignored or masked away, butthis class isn’t about teaching you build an operating system. An important application of this is how system calls are served! Thereis a well-established set of registers that arguments go inaccording kernel as well as a system call “number” again definedby kernel. Then operating system triggers an interrupt which kernel catches serves system call (Garg). Operating system developers instruction set developers alike didn’tlike overhead of causing an interrupt on a system call. Now, systemsuse SYSENTER SYSEXIT which has a cleaner way of transferringcontrol safely kernel safely back. What safely means isobvious out of scope for this class, but it persists. Optional: HyperthreadingHyperthreading is a new technology is in no way shape or formmultithreading. Hyperthreading allows one physical core appear asmany virtual cores operating system (Guide, P. 51). operating system can then schedule processes on these virtual cores one core will execute them. Each core interleaves processes or threads. While core is waiting for one memory access complete, it mayperform a few instructions of another process thread. overall resultis more instructions executed in a shorter time. This potentially meansthat you can divide number of cores you need power smallerdevices. There dragons here, though. With hyperthreading, you must wary ofoptimizations. A famous hyperthreading bug caused programs crash ifat least two processes were scheduled on a physical core, using specificregisters, in a tight loop. actual problem is better explainedthrough an architecture lens. But, actual application was foundthrough systems programmers working on OCaml’s mainline (Leroy). Debugging EnvironmentsI’m going tell you a secret about this course: it is about workingsmarter not harder. course can time-consuming but reasonthat so many people see it as such (and why so many students don’t seeit as such) is relative familiarity of people with their tools. Let’s go through some of common tools that you’ll working on need familiar with. sshssh is short for Secure Shell (“Ssh(1),”). It is a networkprotocol that allows you spawn a shell on a remote machine. Most of times in this class you will need ssh into your VM like thisIf you don’t want type your password out every time, you can generatean ssh key that uniquely identifies your machine. If you already have akey pair, you can skip copy id stage. If you still think that that is too much typing, you can always aliashosts. You may need restart your VM or reload sshd for this takeeffect. config file is available on Linux Mac distros. ForWindows, you’ll have use Windows Linux Subsystem or configure anyaliases in PuTTYgitWhat is ‘git‘? Git is a version control system. What that means is gitstores entire history of a directory. We refer directory as arepository. So what do you need know is a few things. First, createyour repository with repo creator. If you haven’t already signedinto enterprise GitHub, make sure do so otherwise your repositorywon’t created for you. After that, your repository is created on server. Git is a decentralized version control system, meaning thatyou’ll need get a repository onto your VM. We can do this with aclone. Whatever you do, do not go through README. md tutorial. This will create a local repository. workflow is you make a changeon your local repository, add changes a current commit, actuallycommit, push changes server. Now explain git well, you need understand that git for ourpurposes will look like a linked list. You will always at head ofmaster, you will do edit-add-commit-push loop. We have aseparate branch on Github that we push feedback under a specificbranch which you can view on Github website. markdown file will haveinformation on test cases results (like standard out). Every so often git can break. Here is a list of commands you probablywon’t need fix your repo  git-cherry-pick   git-pack   git-gc   git-clean   git-rebase   git-stash/git-apply/git-pop   git-branch If you are currently on a branch, you don’t see eitheror something likeDon’t panic, but your repository may in an unworkable state. If youaren’t nearing a deadline, come office hours or ask your question onEdstem, we’d happy help. In an emergency scenario, delete yourrepository re-clone (you’ll have add release as above). This will lose any local uncommitted changes. Make sure copy anyfiles you were working on outside directory, remove copy themback inIf you want learn more about git, there are all but an endless numberof tutorials resources online that can help you. Here are some linksthat can help you out         EditorsSome people take this as an opportunity learn a new editor, othersnot so much. first part is those of you who want learn a neweditor. In editor war that spans decades, we have come battleof vim vs emacs. Vim is a text editor a Unix-like utility. You enter vim by typingvim [file], which takes you into editor. There are three mostcommonly used modes: normal mode, insert mode, command mode. Youstart off in normal mode. In this mode, you can move around with manykeys with most common ones being hjkl (corresponding left,down, up, right, respectively). run commands in vim, you canfirst type : then a command after it. For instance, quit vim,simply type :q (q stands for quit). If you have any unsaved edits, youmust either save them :w, save quit :wq, or quit discardchanges :q!. make edits you can either type i change you intoinsert mode or a change insert mode after cursor. Thisis basics when it comes vim. In addition countless greatresources out there on internet, vim also has its own built-intutorials set up for beginners. access interactive tutorial,enter vimtutor in command line (not inside of vim), you areall set!Emacs is more of a way of life, I don’t mean that figuratively. Alot of people say that emacs is a powerful operating system lacking adecent text editor. This means emacs can house a terminal, gdb session,ssh session, code a whole lot more. It would not fitting anyother way introduce you gnu-emacs any other way than gnu-docs. Just note that emacs is insanely powerful. You can do almost anythingwith it. There are a fair number of students who like IDE-aspect ofother programming languages. Know that you can set up emacs anIDE, but you have learn a bit of Lisp. Then there are those of you who like use your own editors. That iscompletely fine. For this, we require sshfs which has ports on manydifferent machines.   Windows   Mac   Linux At that point, files on your VM are synced with files on yourmachine edits can made will synced. At time of writing, an author likes use spacemacs which marriesboth vim emacs both of their difficulties. I’ll give my soapboxfor why I like it, but warned that if you are starting fromabsolutely no vim or emacs experience learning curve along with thiscourse may too much.   Extensible. Spacemacs has a clean design written in lisp. There are100s of packages ready installed by editing your spacemacsconfig reloading that do everything from syntax checking,automatic static analyzing, etc.    Most of good parts from vim emacs. Emacs is good at doingeverything by being a fast editor. Vim is good at making fast edits moving around. Spacemacs is best of both worlds allowing vimkeybindings all emacs goodness underneath.    Lots of preconfiguration done. As opposed with a fresh emacsinstall, a lot of configurations with language projects aredone for you like neotree, helm, various language layers. All thatyou have do is navigate neotree base of your project emacs will turn into an IDE for that programming language.  But obviously each his or her own. Many people will argue that editorgurus spend more time editing their editors actually editing. Clean CodeMake your code modular using helper functions. If there is a repeatedtask (getting pointers contiguous blocks in malloc MP, forexample), make them helper functions. make sure each function doesone thing well so that you don’t have debug twice. Let’s say that weare doing selection sort by finding minimum element each iterationlike so,Many can see bug in code, but it can help refactor abovemethod into error is specifically in one function. In end, this class isabout writing system programs, not a class about refactoring/debuggingyour code. In fact, most kernel code is so atrocious that you don’t want read it – defense there is that it needs be. But for sakeof debugging, it may benefit you in long run adopt some of thesepractices. AssertsUse assertions make sure your code works up a certain point – importantly, make sure you don’t break it later. For example, if yourdata structure is a doubly-linked list, you can do something likeassert(node == node-&gt;next-&gt;prev) assert that next node has apointer current node. You can also check pointer is pointing an expected range of memory address, non-null, -&gt;size is reasonable,etc. DEBUG macro will disable all assertions, so don’t forget set that once you finish debugging (“Assert,”). Here is a quick example with an assert. Let’s say that we are writingcode using memcpy. We would want put an assert before that checkswhether my two memory regions overlap. If they do overlap, memcpy runsinto undefined behavior, so we want discover that problem soonerrather thanlater. This check can turned off at compile-time, but will save you tonsof trouble debugging!ValgrindValgrind is a suite of tools designed provide debugging profilingtools make your programs more correct detect some runtime issues(“4. Memcheck: A Memory Error Detector,”). most used of these toolsis Memcheck, which can detect many memory-related errors that are commonin C C++ programs that can lead crashes unpredictablebehavior (for example, unfreed memory buffers). run Valgrind on yourprogram:Arguments are optional default tool that will run is Memcheck. output will presented in form: number of allocations,frees, errors. Suppose we have a simple program like this:This program compiles runs with no errors. Let’s see what Valgrindwill output. Invalid write: It detected our heap block overrun, writing outsideof an allocated block. Definitely lost: Memory leak — you probably forgot free a memoryblock. Valgrind is a effective tool check for errors at runtime. C isspecial when it comes such behavior, so after compiling your programyou can use Valgrind fix errors that your compiler may miss thatusually happens when your program is running. For more information, you can refer manual (“4. Memcheck: AMemory Error Detector,” )TSANThreadSanitizer is a tool from Google, built into clang gcc, helpyou detect race conditions in your code (“ThreadSanitizerCppManual”). Note, that running with tsan will slow your code down a bit. Consider following code. We can see that there is a race condition on variable global. Both main thread created thread will try change value at same time. But, does ThreadSantizer catch it?If we compiled with debug flag, then it would give us variablename as well. GDBGDB is short for GNU Debugger. GDB is a program that helps you trackdown errors by interactively debugging them (“GDB: Gnu ProjectDebugger” ). It can start stop yourprogram, look around, put in ad hoc constraints checks. Here area few examples. Setting breakpoints programmaticallyA breakpoint is a line of code where you want execution stop give control back debugger. A useful trick when debugging complexC programs with GDB is setting breakpoints in source code. You can also set breakpoints programmatically. Assume that we have nooptimization line numbers are as followsWe can now set breakpoint before program starts. Checking memory contentWe can also use gdb check content of different pieces of memory. For example,Compiled we getWe can now use gdb look at specific bytes of string reasonabout when program should’ve stopped runningHere, by using x command with parameters 16xb, we can see thatstarting at memory address 0x7fff5fbff9c (value of bad_string),printf would actually see following sequence of bytes as a stringbecause we provided a malformed string without a null terminator. Involved gdb exampleHere is how one of your TAs would go through debug a simple programthat is going wrong. First, source code of program. If you cansee error immediately, please bear with us. How can we use gdb debug? First we ought load GDB. Want take a look at source?From running code, breakpoint didn’t even trigger, meaning code never got that point. That’s because of comparison! Okay,flip sign it should work now right?That was only bare minimum, though most of you will get by withthat. There are a whole load more resources on web, here are a fewspecific ones that can help you get started.          ShellWhat do you actually use run your program? A shell! A shell is aprogramming language that is running inside your terminal. A terminal ismerely a window input commands. Now, on POSIX we usually have oneshell called sh that is linked a POSIX compliant shell calleddash. Most of time, you use a shell called bash that is somewhatPOSIX compliant but has some nifty built-in features. If you want even more advanced, zsh has some more powerful features like tabcomplete on programs fuzzy patterns. Undefined Behavior Sanitizer undefined behavior sanitizer is a wonderful tool provided by llvm project. It allows you compile code with a runtime checker make sure that you don’t do undefined behavior for various categories. We will try include it into our projects, but requires support formall external libraries that we use so we may not get around allof them. Undefined behavior - why we can’t solve it in generalAlso please please read Chris Lattner’s 3 Part blog post on undefinedbehavior. It can shed light on debug builds mystery of compileroptimization. Clang Static Build ToolsClang provides a great drop-in replacement tools for compiling programs. If you want see if there is an error that may cause a race condition,casting error, etc, all you need do is following.  in addition make output, you will get static build warnings. strace ltracestrace ltrace are two programs that trace system calls library calls, respectively, of a running program or command. These may missing on your system, so install, run following:Debugging with ltrace can as simple as figuring out what was return call of last library call that failed. ltrace output can clue you in weird things your program is doinglive. Unfortunately, ltrace can’t used inject faults, meaning thatltrace can tell you what is happening, but it can’t tamper with what isalready happening. strace on other hand could modify your program. Debugging withstrace is amazing. basic usage is running strace with a program, it’ll get you a complete list of system call parameters. If output is too verbose, you can use trace= with a commanddelimited list of syscalls filter all but those calls. You can also trace files or targets. Newer versions of strace can actually inject faults into your program. This is useful when you want occasionally make reads writes failfor example in a networking application, which your program shouldhandle. problem is as of early 2019, that version is missing fromUbuntu repositories. Meaning that you’ll have install it from source. printfsWhen all else fails, print! Each of your functions should have an ideaof what it is going do. You want test that each of your functionsis doing what it set out do see exactly where your code breaks. In case with race conditions, tsan may able help, but havingeach thread print out data at certain times could help you identify race condition.  make printfs useful, try have a macro that fills in context bywhich printf was called – a log statement if you will. A simpleuseful but untested log statement could as follows. Try make atest figure out something that is going wrong, then log state ofyour variables.  then use as appropriately. Check out compiling linkingsection in appendix if you have any questions on how a C programgets translated machinecode. Homework 0So you want master System Programming? get a better grade than B?Watch videos write up your answers following questionsImportant! virtual machine-in-your-browser videos you need for HW0 arehere:Questions? Comments? Use current semester’s CS341 Edstem: in-browser virtual machine runs entirely in JavaScript isfastest in Chrome. Note VM any code you write is reset when youreload page, so copy your code a separate document. post-video challenges are not part of homework 0, but you learn mostby doing rather than passively watching. You have some fun with eachend-of-video challenge. HW0 questions are below. Copy your answers into a text document becauseyou’ll need submit them later in course. Chapter 1In which our intrepid hero battles standard out, standard error, filedescriptors writing files  Hello, World! (system call style) Write a program that useswrite() print out “Hi! My name is &lt;Your Name&gt;”.    Hello, Standard Error Stream! Write a function print out atriangle of height n standard error. Your function should have signature void write_triangle(int n) should use write(). triangle should look like this, for n = 3:    Writing files Take your program from “Hello, World!” modifyit write a file called hello_world. txt. Make sure usecorrect flags a correct mode for open() (man 2 open is yourfriend).    Not everything is a system call Take your program from “Writing files” replace write() with printf(). Make sure print file instead of standard out!   What are some differences between write() printf()? Chapter 2Sizing up C types their limits, int char arrays, incrementing pointers  How many bits are there in a byte?   How many bytes are there in a char?   How many bytes following are on your machine? int, double,float, long, long long   On a machine with 8 byte integers, declaration for variabledata is int data[8]. If address of data is 0x7fbd9d40,then what is address of data+2?   What is data[3] equivalent in C? Hint: what does C convertdata[3] before dereferencing address? Remember, type ofa string constant \"abc\" is an array.    Why does this SEGFAULT?    What is value of variable str_size?    What is value of variable str_len    Give an example of X such that sizeof(X) is 3.    Give an example of Y such that sizeof(Y) might 4 or 8 dependingon machine.  Chapter 3Program arguments, environment variables, working with characterarrays (strings)  What are at least two ways find length of argv?   What does argv[0] represent?   Where are pointers environment variables stored (on stack, heap, somewhere else)?   On a machine where pointers are 8 bytes, with followingcode:  What are values of sizeof(ptr) sizeof(array)? Why?   What data structure manages lifetime of automatic variables? Chapter 4Heap stack memory, working with structs  If I want use data after lifetime of function it wascreated in ends, where should I put it? How do I put it there?   What are differences between heap stack memory?   Are there other kinds of memory in a process?   Fill in blank: “In a good C program, for every malloc, there isa ___”.    What is one reason malloc can fail?   What are some differences between time() ctime()?   What is wrong with this code snippet?    What is wrong with this code snippet?    How can one avoid previous two mistakes?   Create a struct that represents a Person. Then make a typedef,so that struct Person can replaced with a single word. A personshould contain following information: their name (a string),their age (an integer), a list of their friends (stored as apointer an array of pointers Persons).    Now, make two persons on heap, “Agent Smith” “Sonny Moore”,who are 128 256 years old respectively are friends with eachother. Create functions create destroy a Person (Person’s their names should live on heap).    create() should take a name age. name should copiedonto heap. Use malloc reserve sufficient memory for everyonehaving up ten friends. sure initialize all fields (why?).    destroy() should free up both memory of person struct all of its attributes that are stored on heap. Destroying oneperson keeps other people in tact any other.  Chapter 5Text input output parsing using getchar, gets, getline.   What functions can used for getting characters from stdin writing them stdout?   Name one issue with gets().    Write code that parses string “Hello 5 World” initializes 3variables “Hello”, 5, “World”.    What does one need define before including getline()?   Write a C program print out content of a file line-by-lineusing getline().  C DevelopmentThese are general tips for compiling developing using a compiler git. Some web searches will useful here  What compiler flag is used generate a debug build?   You fix a problem in Makefile type make again. Explain whythis may insufficient generate a new build.    Are tabs or spaces used indent commands after rule in aMakefile?   What does git commit do? What’s a sha in context of git?   What does git log show you?   What does git status tell you how would contents of. gitignore change its output?   What does git push do? Why is it insufficient commit with ` gitcommit -m ’fixed all bugs’ `?   What does a non-fast-forward error git push reject mean? What is most common way of dealing with this? Optional: Just for fun  Convert a song lyrics into System Programming C code covered inthis wiki book share on class forum.    Find, in your opinion, best worst C code on web post link class forum.    Write a short C program with a deliberate subtle C bug post iton class forum see if others can spot your bug.    Do you have any cool/disastrous system programming bugs you’ve heardabout? Feel free share with your peers course staff on class forum.  University of Illinois Specific Guidelines class forumTAs student assistants get a ton of questions. Some arewell-researched, some are not. This is a handy guide that’ll helpyou move away from latter towards former. Oh, did Imention that this is an easy way score points with your internshipmanagers? Ask yourself…  Am I running on my Virtual Machine?   Did I check man pages?   Have I searched for similar questions/followups on class forum?   Have I read MP/Lab specification completely?   Have I watched all of videos?   Did I Google error message a few permutations thereof ifnecessary? How about StackOverflow.    Did I try commenting out, printing, and/or stepping through parts of code bit by bit find out precisely where error occurs?   Did I commit my code git in case TAs need more context?   Did I include console/GDB/Valgrind output **AND** codesurrounding bug in my class forum post?   Have I fixed other segmentation faults unrelated issue I’mhaving?   Am I following good programming practice? (i. e. encapsulation,functions limit repetition, etc)  biggest tip that we can give you when asking a question on classforum if you want a swift answer is ask your question like you weretrying answer it. Like before you ask a question, try answer ityourself. If you are thinking about posting Hi, My code got a 50Sounds good courteous, but course staff would much much prefer apost resembling following Hi, I recently failed test X, Y, Z which is about half tests onthis current assignment. I noticed that they all have something dowith networking epoll, but couldn’t figure out what was linkingthem together, or I may completely off track. So test my idea, Itried spawning 1000 clients with various get put requests verifying files matched their originals. I couldn’t get it failwhile running normally, debug build, or valgrind or tsan. I haveno warnings none of pre-syntax checks showed me anything. Could you tell me if my understanding of failure is correct what I could do modify my tests better reflect X, Y, Z? netid:bvenkat2You don’t need as courteous, though we’d appreciate it, this willget a faster response time hand over foot. If you were trying answerthis question, you’d have everything you need in question body. “4. Memcheck: A Memory Error Detector. ” n. d. *Valgrind*. . “Assert. ” n. d. *Cplusplus. com*. cplusplus. com. . “Chapter 3. Hardware Interrupts. ” n. d. *Chapter 3. Hardware Interrupts*. Red Hat. . Garg, Manu. 2006. “Sysenter Based System Call Mechanism in Linux 2. 6. ”*Manu’s Public Articles Projects*. . “GDB: Gnu Project Debugger. ” 2019. *GDB: GNU Project Debugger*. Free Software Foundation. . Guide, Part. 2011. “Intel 64 Ia-32 Architectures SoftwareDeveloper’s Manual. ” *Volume 3B: System Programming Guide, Part* 2. Intel, CAT. 2015. “Improving Real-Time Performance by Utilizing CacheAllocation Technology. ” *Intel Corporation, April*. Leroy, Xavier. 2017. “How I Found a Bug in Intel Skylake Processors. ”*How I Found a Bug in Intel Skylake Processors*. . Levinthal, David. 2009. “Performance Analysis Guide for Intel Core I7Processor Intel Xeon 5500 Processors. ” *Intel Performance AnalysisGuide* 30: 18. Schweizer, Hermann, Maciej Besta, Torsten Hoefler. 2015. “Evaluating Cost of Atomic Operations on Modern Architectures. ” In *2015International Conference on Parallel Architecture Compilation(Pact)*, 445–56. IEEE. “Ssh(1). ” n. d. *OpenBSD Manual Pages*. OpenBSD. . “ThreadSanitizerCppManual. ” 2018. *ThreadSanitizerCppManual*. Google. . Wikibooks. 2018. “X86 Assembly — Wikibooks, Free Textbook Project. ”. ","url":"/coursebook/Background"},{"title":"Deadlock","content":"                     DeadlockNo, you can’t always get what you wantYou can’t always get what you wantYou can’t always get what you wantBut if you try sometimes you findYou get what you need - philosophers Jagger &amp; RichardsDeadlock is defined as when a system cannot make any forward progress. We define a system for rest of chapter as a set of rules bywhich a set of processes can move from one state another, where astate is either working or waiting for a particular resource. Forwardprogress is defined as if there is at least one process working or wecan award a process waiting for a resource that resource. In a lot ofsystems, Deadlock is avoided by ignoring entire concept(Silberschatz, Galvin, Gagne,P. 237). Have you heard about turn it on off again? For productswhere stakes are low (User Operating Systems, Phones), it may more efficient allow deadlock. But in cases where “failure is notan option” - Apollo 13, you need a system that tracks, breaks, orprevents deadlocks. Apollo 13 didn’t fail because of deadlock, but itwouldn’t good restart system on liftoff. Mission-critical operating systems need this guarantee formally becauseplaying odds with people’s lives isn’t a good idea. Okay so how dowe do this? We model problem. Even though it is a common statisticalphrase that all models are wrong, more accurate model is system higher chance method will work. Resource Allocation GraphsOne such way is modeling system with a resource allocation graph(RAG). A resource allocation graph tracks which resource is held bywhich process which process is waiting for a resource of aparticular type. It is a simple yet powerful tool illustrate howinteracting processes can deadlock. If a process is using a resource,an arrow is drawn from resource node process node. If aprocess is requesting a resource, an arrow is drawn from processnode resource node. If there is a cycle in ResourceAllocation Graph each resource in cycle provides only oneinstance, then processes will deadlock. For example, if process 1holds resource A, process 2 holds resource B process 1 is waitingfor B process 2 is waiting for A, then processes 1 2 will deadlocked . We’ll make distinction that system is in deadlock by definition if all workerscannot perform an operation other than waiting. We can detect a deadlockby traversing graph searching for a cycle using a graphtraversal algorithm, such as Depth First Search (DFS). This graph isconsidered as a directed graph we can treat both processes resources as nodes. Coffman ConditionsSurely cycles in RAGs happen all time in an OS, so why doesn’t itgrind a halt? You may not see deadlock because OS may preemptsome processes breaking cycle but there is still a chance that yourthree lonely processes could deadlock. There are four necessary sufficient conditions for deadlock –meaning if these conditions hold then there is a non-zero probabilitythat system will deadlock at any given iteration. These are known as Coffman Conditions (Coffman, Elphick, Shoshani).   Mutual Exclusion: No two processes can obtain a resource at sametime.    Circular Wait: There exists a cycle in Resource AllocationGraph, or there exists a set of processes {P1, P2,…} such that P1 iswaiting for resources held by P2, which is waiting for P3,…, whichis waiting for P1.    Hold Wait: Once a resource is obtained, a process keeps resource locked.    No pre-emption: Nothing can force process give up a resource.  (Optional) Proof:Deadlock can happen if only if four Coffman conditions aresatisfied. \\(→\\) If system is deadlocked, four Coffman conditions areapparent.   For contradiction, assume that there is no circular wait. If notthen that means resource allocation graph is acyclic, meaningthat there is at least one process that is not waiting on anyresource freed. Since system can move forward, systemis not deadlocked.    For contradiction, assume that there is no mutual exclusion. If not,that means that no process is waiting on any other process for aresource. This breaks circular wait previous argument provescorrectness.    For contradiction, assume that processes don’t hold wait but oursystem still deadlocks. Since we have circular wait from firstcondition at least one process must waiting on another process. If that processes don’t hold wait, that means one processmust let go of a resource. Since system has moved forward, itcannot deadlocked.    For contradiction, assume that we have preemption, but systemcannot un-deadlocked. Have one process, or create one process,that recognizes circular wait that must apparent from above break one of links. By first branch, we must not havedeadlocked.  \\(←\\) If four conditions are apparent, system is deadlocked. We will prove that if system is not deadlocked, four conditionsare not apparent. Though this proof is not formal, let us build a systemwith three requirements not including circular wait. Let assume thatthere is a set of processes \\(P = \\{p_1, p_2, . . . , p_n\\}\\) thereis a set of resources \\(R = \\{r_1, r_2, . . . , r_m\\}\\). For simplicity,a process can only request one resource at a time but proof can generalized multiple. Let assume that system is a state at time\\(t\\). Let us assume that state of system is a tuple\\((h_t, w_t)\\) where there are two functions\\(h_t: R →P ∪\\{\\text{unassigned}\\}\\) that maps resources processes that own them (this is a function, meaning that we have mutualexclusion) or unassigned \\(w_t: P →R ∪\\{\\text{satisfied}\\}\\)that maps requests that each process makes a resource or if process is satisfied. If process is satisfied, we consider worktrivial process exits, releasing all resources – this can also generalized. Let \\(L_t ⊆P ×R\\) a set of lists of requests that aprocess uses release a resource at any given time. evolution of system is at each step at every time.   Release all resources in \\(L_t\\).    Find a process that is requesting a resource   If that resource is available give it that process, generating anew \\((h_{t+1}, w_{t+1})\\) exit current iteration.    Else find another process try same resource allocationprocedure in previous step.  If all processes have been surveyed if all are requesting a resource none can granted a resource, consider it deadlocked. Moreformally, this system is deadlocked means if\\(∃t_0, ∀t ≥t_0, ∀p ∈P, w_t(p) ≠\\text{satisfied} \\text{ } ∃q, q ≠p →h_t(w_t(p)) = q\\)(which is what we need prove). Mutual exclusion no pre-emption are encoded into system. Circular wait implies second condition, a resource is owned byanother process which is owned by another process meaning at this state\\(∀p ∈P, ∃q ≠p →h_t(w_t(p)) = q\\). Circular wait also implies that atthis current state, no process is satisfied, meaning at this state\\(∀p ∈P, w_t(p) ≠\\text{satisfied}\\). Hold wait simply proves condition that from this point onward, system will not change, whichis all conditions that we needed show. (Optional) ■If a system breaks any of them, it cannot have deadlock! Consider scenario where two students need write both pen paper thereis only one of each. Breaking mutual exclusion means that studentsshare pen paper. Breaking circular wait could that students agree grab pen then paper. As proof bycontradiction, say that deadlock occurs under rule conditions. Without loss of generality, that means a student would have waiting on a pen while holding paper other waiting ona pen holding paper. We have contradicted ourselves because onestudent grabbed paper without grabbing pen, so deadlock fails occur. Breaking hold wait could that students try get pen then paper if a student fails grab paper thenthey release pen. This introduces a new problem called livelockwhich will discussed later. Breaking preemption means that if twostudents are in deadlock teacher can come in break up deadlock by giving one of students a held item or tell both students put items down. livelock relates deadlock. Consider breaking hold-and-waitsolution as above. Though deadlock is avoided, if philosopher picksup same device again again in same pattern, no work will done. Livelock is generally harder detect because processesgenerally look like they are working outside operating systemwhereas in deadlock operating system generally knows when twoprocesses are waiting on a system-wide resource. Another problem is thatthere are necessary conditions for livelock (i. e. deadlock fails occur) but not sufficient conditions – meaning there is no set of ruleswhere livelock has occur. You must formally prove in a system by whatis known as an invariant. One has enumerate each of steps of asystem if each of steps eventually – after some finite number ofsteps – leads forward progress, system fails livelock. Thereare even better systems that prove bounded waits; a system can only livelocked for at most \\(n\\) cycles which may important forsomething like stock exchanges. Approaches Solving Livelock DeadlockIgnoring deadlock is most obvious approach. Quite humorously, name for this approach is called ostrich algorithm. Though there isno apparent source, idea for algorithm comes from concept ofan ostrich sticking its head in sand. When operating systemdetects deadlock, it does nothing out of ordinary, any deadlockusually goes away. An operating system preempts processes when stoppingthem for context switches. operating system can interrupt any systemcall, potentially breaking a deadlock scenario. OS also makes somefiles read-only thus making resource shareable. What algorithmrefers is that if there is an adversary that specifically crafts aprogram – or equivalently a user who poorly writes a program – that OS deadlocks. For everyday life, this tends fine. When it is notwe can turn following method. Deadlock detection allows system enter a deadlocked state. Afterentering, system uses information break deadlock. As anexample, consider multiple processes accessing files. operatingsystem can keep track of all of files/resources through filedescriptors at some level either abstracted through an API or directly. If operating system detects a directed cycle in operating systemfile descriptor table it may break one process’ hold through schedulingfor example let system proceed. Why this is a popular choice inthis realm is that there is no way of knowing which resources a programwill select without running program. This is an extension of Rice’stheorem (Rice ) that says that wecannot know any semantic feature without running program (semanticmeaning like what files it tries open). So theoretically, it issound. problem then gets introduced that we could reach a livelockscenario if we preempt a set of resources again again. wayaround this is mostly probabilistic. operating system chooses arandom resource break hold-and-wait. Now even though a user cancraft a program where breaking hold wait on each resource willresult in a livelock, this doesn’t happen as often on machines that runprograms in practice or livelock that does happen happens for acouple of cycles. These systems are good for products that need maintain a non-deadlocked state but can tolerate a small chance oflivelock for a short time. In addition, we have Banker’s Algorithm. Which basic premiseis bank never runs dry, which prevents livelock. Feel free checkout appendix for more details. Dining Philosophers Dining Philosophers problem is a classic synchronization problem. Imagine we invite \\(n\\) (let’s say 6) philosophers a meal. We willsit them at a table with 6 chopsticks, one between each philosopher. Aphilosopher alternates between wanting eat or think. eat philosopher must pick up two chopsticks either side of theirposition. original problem required each philosopher have twoforks, but one can eat with a single fork so we rule this out. However,these chopsticks are shared with his neighbor. Is it possible design an efficient solution such that allphilosophers get eat? Or, will some philosophers starve, neverobtaining a second chopstick? Or will all of them deadlock? For example,imagine each guest picks up chopstick on their left then waitsfor chopstick on their right free. Oops - our philosophershave deadlocked! Each philosopher is essentially same, meaning thateach philosopher has same instruction set based on otherphilosopher i. e. you can’t tell every even philosopher do one thing every odd philosopher do another thing. Failed SolutionsThis looks good but. What if everyone picks up their left fork iswaiting on their right fork? We have deadlocked program. It isimportant note that deadlock doesn’t happen all time probability that this solution deadlock goes down as number ofphilosophers goes up. What is important note is that eventually thatthis solution will deadlock, letting threads starve which is bad. Hereis a simple resource allocation graph that shows how system could deadlockedSo now you are thinking about breaking one of Coffman Conditions. Let’s break Hold Wait!Now our philosopher picks up left fork tries grab right. If it’s available, they eat. If it’s not available, they put leftfork down try again. No deadlock! But, there is a problem. What ifall philosophers pick up their left at same time, try grabtheir right, put their left down, pick up their left, try grab theirright so on. Here is what a time evolution of system would looklike. We have now livelocked our solution! Our poor philosophers are stillstarving, so let’s give them some proper solutions. Viable Solutions naive arbitrator solution has one arbitrator a mutex for example. Have each of philosophers ask arbitrator for permission eator trylock an arbitrator mutex. This solution allows one philosopher eat at a time. When they are done, another philosopher can ask forpermission eat. This prevents deadlock because there is no circularwait! No philosopher has wait for any other philosopher. advanced arbitrator solution is implement a class that determines if philosopher’s forks are in arbitrator’s possession. If they are,they give them philosopher, let him eat, take forks back. This has bonus of being able have multiple philosophers eat at same time. There are a lot of problems with these solutions. One is that they areslow have a single point of failure. Assuming that all philosophers are good-willed, arbitrator needs fair. Inpractical systems, arbitrator tends give forks sameprocesses because of scheduling or pseudo-randomness. Another importantthing note is that this prevents deadlock for entire system. Butin our model of dining philosophers, philosopher has release lock themselves. Then, you can consider case of maliciousphilosopher (let’s say Descartes because of his Evil Demons) could holdon arbitrator forever. He would make forward progress system would make forward progress but there is no way of ensuring thateach process makes forward progress without assuming something about processes or having true preemption – meaning that a higher authority(let’s say Steve Jobs) tells them stop eating forcibly. (Optional) Proof: arbitrator solution doesn’t deadlock proof is about as simple as it gets. Only one philosopher canrequest resources at a time. There is no way make a cycle in resource allocation graph with only one philosopher acting in pickup left then right fork which is what we needed show. (Optional) ■Leaving Table (Stallings’ Solution)Why does first solution deadlock? Well, there are \\(n\\)philosophers \\(n\\) chopsticks. What if there is only 1 philosopherat table? Can we deadlock? No. How about 2 philosophers? 3? You cansee where this is going. Stallings’ (Stallings P. 280) solution removesphilosophers from table until deadlock is not possible – think aboutwhat magic number of philosophers at table. way do thisin actual system is through semaphores letting a certain numberof philosophers through. This has benefit that multiple philosopherscan eating. In case that philosophers aren’t evil, this solution requires alot of time-consuming context switching. There is also no reliable way know number of resources beforehand. In dining philosopherscase, this is solved because everything is known but trying specifyan operating system where a system doesn’t know which file is going get opened by what process can lead a faulty solution. againsince semaphores are system constructs, they obey system timing clockswhich means that same processes tend get added back into queue again. Now if a philosopher becomes evil, then problem becomesthat there is no preemption. A philosopher can eat for as long as theywant system will continue function but that means fairness of this solution can low in worst case. This works bestwith timeouts or forced context switches ensure bounded wait times. (Optional) Proof:Stallings’ Solution Doesn’t Deadlock. Let’s number philosophers\\(\\{p_0, p_1, . . , p_{n-1}\\}\\) resources\\(\\{r_0, r_1, . . , r_{n-1}\\}\\). A philosopher \\(p_i\\) needs resource\\(r_{i-1 \\mod n}\\) \\(r_{i + 1 \\mod n}\\). Without loss ofgenerality, let us take \\(p_i\\) out of picture. Each resource hadexactly two philosophers that could use it. Now resources\\(r_{i-1 \\mod n}\\) \\(r_{i + 1 \\mod n}\\) only have on philosopherwaiting on it. Even if hold wait, no preemption, mutualexclusion or present, resources can never enter a state where onephilosopher requests them they are held by another philosopherbecause only one philosopher can request them. Since there is no way generate a cycle otherwise, circular wait cannot hold. Since circularwait cannot hold, deadlock cannot happen. (Optional) ■Here is a visualization of worst-case. system is about deadlock, but approach resolves it. Partial Ordering (Dijkstra’s Solution)This is Dijkstra’s solution (Dijkstra, P. 20). He was one propose this problem on an exam. Why does first solution deadlock?Dijkstra thought that last philosopher who picks up his left fork(causing solution deadlock) should pick up his right. Heaccomplishes it by number forks \\(1. . n\\), tells each of philosophers pick up his lower number fork. Let’s run through deadlock condition again. Everyone tries pick up their lower numberfork first. Philosopher \\(1\\) gets fork \\(1\\), Philosopher \\(2\\)gets fork \\(2\\), so on until we get Philosopher \\(n\\). Theyhave choose between fork \\(1\\) \\(n\\). fork \\(1\\) is alreadyheld up by philosopher \\(1\\), so they can’t pick up that fork, meaninghe won’t pick up fork \\(n\\). We have broken circular wait! Meaningdeadlock isn’t possible. Some problems are that an entity either needs know finite set ofresources in advance or able produce a consistent partial ordersuch that circular wait cannot happen. This also implies that thereneeds some entity, either operating system or another process,deciding on number all of philosophers need agree on number as new resources come in. As we have also seen with previoussolutions, this relies on context switching. This prioritizesphilosophers that have already eaten but can made fairer byintroducing random sleeps waits. (Optional) Proof:Dijkstra’s Solution Doesn’t Deadlock proof is similar previous proof. Let’s number philosophers \\(\\{p_0, p_1, . . , p_{n-1}\\}\\) resources\\(\\{r_0, r_1, . . , r_{n-1}\\}\\). A philosopher \\(p_i\\) needs resource\\(r_{i-1 \\mod n}\\) \\(r_{i + 1 \\mod n}\\). Each philosopher willgrab \\(r_{i-1 \\mod n}\\) then \\(r_{i + 1 \\mod n}\\) but lastphilosopher will grab in reverse order. Even if hold wait, nopreemption, mutual exclusion or present. Since last philosopherwill grab \\(r_{n-1}\\) then \\(r_0\\) there are two cases either philosopher has first lock or philosopher doesn’t. If last philosopher \\(p_{n-1}\\) holds first lock meaning previous philosopher \\(p_{n-2}\\) is waiting on \\(r_{n-1}\\) meaning\\(r_{n-2}\\) is available. Since no other blockers, philosopherprevious \\(p_{n-3}\\) will grab her first lock. This is now a reduction previous proof of stalling because we now have \\(n\\) resourcesbut only \\(n-1\\) philosophers, meaning this cannot deadlock. If philosopher doesn’t obtain that first lock, then we have areduction Stalling’s proof above because now have \\(n-1\\)philosophers vying for \\(n\\) resources. Since we can’t reach deadlockin either case, this solution cannot deadlock which is what we needed show. (Optional) ■There are a few other solutions (clean/dirty forks actor model)in appendix. Topics  Coffman Conditions   Resource Allocation Graphs   Dining Philosophers   Failed DP Solutions   Livelocking DP Solutions   Working DP Solutions:Benefits/Drawbacks    Questions  What are Coffman conditions?   What does each of Coffman conditions mean? Define each one.    Give a real-life example of breaking each Coffman condition in turn. A situation consider: Painters, Paint, Paint Brushes etc. Howwould you assure that work would get done?   Which Coffman condition is unsatisfied in following snippet?    following calls are made  What happens why? What happens if a third thread callspthread_mutex_lock(m1) ?   How many processes are blocked? As usual, assume that a process cancomplete if it can acquire all of resources listed below.    P1 acquires R1   P2 acquires R2   P1 acquires R3   P2 waits for R3   P3 acquires R5   P1 waits for R4   P3 waits for R1   P4 waits for R5   P5 waits for R1   Draw out resource graph!Coffman, Edward G, Melanie Elphick, Arie Shoshani. 1971. “SystemDeadlocks. ” *ACM Computing Surveys (CSUR)* 3 (2): 67–78. Dijkstra, Edsger W. n. d. “Hierarchical Ordering of SequentialProcesses. ”. Rice, H. G. 1953. “Classes of Recursively Enumerable Sets TheirDecision Problems. ” *Transactions of American Mathematical Society*74 (2): 358–66. . Silberschatz, A. , P. B. Galvin, G. Gagne. 2006. *OPERATING SystemPrinciples, 7TH Ed*. Wiley Student Ed. Wiley India Pvt. Limited. . Stallings, William. 2011. *Operating Systems: Internals DesignPrinciples 7th Ed. By Stallings (International Economy Edition)*. PE. . ","url":"/coursebook/Deadlock"},{"title":"Filesystems","content":"                                                         Filesystems/home is where heart is - **Filesystems are important because they allow you persist data after acomputer is shut down, crashes, or has memory corruption. Back in day, filesystems were expensive use. Writing filesystem (FS)involved writing magnetic tape reading from that tape(“International,” ). It was slow,heavy, prone errors. Nowadays most of our files are stored on disk – though not all of them! disk is still slower than memory by an order of magnitude at least. Some terminology before we begin this chapter. A filesystem, aswe’ll define more concretely later, is anything that satisfies APIof a filesystem. A filesystem is backed by a storage medium, such as ahard disk drive, solid state drive, RAM, etc. A disk is either a harddisk drive (HDD) which includes a spinning metallic platter a headwhich can zap platter encode a 1 or a 0, or a solid-state drive(SSD) that can flip certain NAND gates on a chip or standalone drive store a 1 or a 0. As of 2019, SSDs are an order of magnitude faster than standard HDD. These are typical backings for a filesystem. Afilesystem is implemented on top of this backing, meaning that we caneither implement something like EXT, MinixFS, NTFS, FAT32, etc. on acommercially available hard disk. This filesystem tells operatingsystem how organize 1s 0s store file information as wellas directory information, but more on that later. avoid beingpedantic, we’ll say that a filesystem like EXT or NTFS implements filesystem API directly (open, close, etc). Often, operating systemswill add a layer of abstraction require that operating systemsatisfy its API instead (think imaginary functions linux_open,linux_close etc). two benefits are that one filesystem can implemented for multiple operating system APIs adding a new OSfilesystem call doesn’t require all of underlying file systems change their API. For example, in next iteration of linux if therewas a new system call create a backup of a file, OS can implementthat with internal API rather than requiring all filesystem drivers change their code.  last piece of background is an important one. In this chapter,we will refer sizes of files in ISO-compliant KiB or Kibibyte. *iB family is short for power of two storage. That means following:   Prefix Byte Value     KiB 1024B   MiB 1024 * 1024 B   GiB 1024 3̂ B  Kibibyte Values standard notational prefixes mean following:   Prefix Byte Value     KB 1000B   MB 1000 * 1000 B   GB 1000 3̂ B  Kilobyte ValuesWe will do this in book in Networking chapter for sakeof consistency not confuse anyone. Confusingly in realworld, there is a different convention. That convention is that when afile is displayed in operating system, KB is same as KiB. When we are talking about computer networks, CDs, other storage KB isnot same as KiB is ISO / Metric Definition above. This isa historical quirk was brought by a clash between network developers memory/hard storage developers. Hard storage memory developers foundthat if a bit could take one of two states, it would natural calla Kilo- prefix 1024 because it was about 1000. Network developers had deal with bits, real-time signal processing, various other factors,so they went with already accepted convention that Kilo- means 1000of something (“International,” ). Whatyou need know is if you see KB in wild, that it may 1024 basedon context. If any time in this class you see KB or any of family refer a filesystems question, you can safely infer that theyare referring 1024 as base unit. Though when you are pushingproduction code, make sure ask about difference!What is a filesystem?You may have encountered old UNIX adage, “everything is a file”. Inmost UNIX systems, file operations provide an interface abstract manydifferent operations. Network sockets, hardware devices, data on disk are all represented by file-like objects. A file-like object mustfollow following conventions:  It must present itself filesystem.    It must support common filesystem operations, such as open,read, write. At a minimum, it needs opened closed.  A filesystem is an implementation of file interface. In thischapter, we will exploring various callbacks a filesystemprovides, some typical functionality associated implementationdetails. In this class, we will mostly talk about filesystems that serve allow users access data on disk, which are integral moderncomputers. Here are some common features of a filesystem:  They deal with both storing local files handle special devicesthat allow for safe communication between kernel user space.    They deal with failures, scalability, indexing, encryption,compression, performance.    They handle abstraction between a file that contains data how exactly that data is stored on disk, partitioned, protected.  Before we dive into details of a filesystem, let’s take a look atsome examples. clarify, a mount point is simply a mapping of adirectory a filesystem represented in kernel.   ext4 Usually mounted at / on Linux systems, this is filesystemthat usually provides disk access as you’re used to.    procfs Usually mounted at /proc, provides information controlover processes.    sysfs Usually mounted at /sys, a more modern version of /proc thatalso allows control over various other hardware such as networksockets.    tmpfs Mounted at /tmp in some systems, an in-memory filesystem hold temporary files.    sshfs This syncs files across ssh protocol.  It tells you what filesystem directory-based system calls resolve to. For example, / is resolved by ext4 filesystem in our case, but/proc/2 is resolved by procfs system even though it contains /as a subsystem. As you may have noticed, some filesystems provide an interface thingsthat aren’t “files”. Filesystems such as procfs are usually referred as virtual filesystems, since they don’t provide data access in same sense as a traditional filesystem would. Technically, allfilesystems in kernel are represented by virtual filesystems, but wewill differentiate virtual filesystems as filesystems that actuallydon’t store anything on a hard disk.  File APIA filesystem must provide callback functions a variety of actions. Some of them are listed below:  open Opens a file for IO   read Read contents of a file   write Write a file   close Close a file free associated resources   chmod Modify permissions of a file   ioctl Interact with device parameters of character devices such asterminals Not every filesystem supports all possible callback functions. Forexample, many filesystems omit ioctl or link. Many filesystemsaren’t seekable meaning that they exclusively provide sequentialaccess. A program cannot move an arbitrary point in file. This isanalogous seekable streams. In this chapter, we will not examining each filesystem callback. If you would like learn moreabout this interface, try looking at documentation for Filesystemsat User Space Level (FUSE). Storing data on disk understand how a filesystem interacts with data on disk, there arethree key terms we will using.   disk block A disk block is a portion of disk that is reservedfor storing contents of a file or a directory.    inode An inode is a file or directory. This means that an inodecontains metadata about file as well as pointers disk blocksso that file can actually written or read from.    superblock A superblock contains metadata about inodes disk blocks. An example superblock can store how full each diskblock is, which inodes are being used etc. Modern filesystems mayactually contain multiple superblocks a sort-of super-superblock that keeps track of which sectors are governed by whichsuperblocks. This tends help with fragmentation.  It may seem overwhelming, but by end of this chapter, we will able make sense of every part of filesystem.  reason about data on some form of storage – spinning disks, solidstate drives, magnetic tape – it is common practice first consider medium of storage as a collection of blocks. A block can thought of as a contiguous region on disk. While its size is sometimesdetermined by some property of underlying hardware, it is morefrequently determined based on size of a page of memory for a givensystem, so that data from disk can cached in memory for fasteraccess – a important feature of many filesystems. A filesystem has a special block denoted as a superblock that storesmetadata about filesystem such as a journal (which logs changes filesystem), a table of inodes, location of first inode ondisk, etc. important thing about a superblock is that it is in aknown location on disk. If not, your computer may fail boot!Consider a simple ROM programmed into your motherboard. If yourprocessor can’t tell motherboard start reading decipher adisk block start boot sequence, you are out of luck.  inode is most important structure for our filesystem as itrepresents a file. Before we explore it in-depth, let’s list out keyinformation we need have a usable file.   Name   File size   Time created, last modified, last accessed   Permissions   Filepath   Checksum   File data File ContentsFrom: In a Unix-style file system, an index node, informally referred asan inode, is a data structure used represent a filesystem object,which can various things including a file or a directory. Eachinode stores attributes disk block location(s) of filesystem object’s data. Filesystem object attributes may includemanipulation metadata (e. g.  change, access, modify time), as well asowner permission data (e. g.  group-id, user-id, permissions).  superblock may store an array of inodes, each of which storesdirect, potentially several kinds of indirect pointers diskblocks. Since inodes are stored in superblock, most filesystems havea limit on how many inodes can exist. Since each inode corresponds afile, this is also a limit on how many files that filesystem can have. Trying overcome this problem by storing inodes in some other locationgreatly increases complexity of filesystem. Trying reallocatespace for inode table is also infeasible since every byte following end of inode array would have shifted, a highly expensiveoperation. This isn’t say there aren’t any solutions at all, althoughtypically there is no need increase number of inodes since number of inodes is usually sufficiently high. Big idea: Forget names of files. ‘inode’ is file. It is common think of file name as ‘actual’ file. It’s not!Instead, consider inode as file. inode holds meta-information (last accessed, ownership, size) points diskblocks used hold file contents. However, inode does notusually store a filename. Filenames are usually only stored indirectories (see below). For example, read first few bytes of file, follow firstdirect block pointer first direct block read first fewbytes. Writing follows same process. If a program wants read entire file, keep reading direct blocks until you’ve read several bytesequal size of file. If total size of file is lessthan that of number of direct blocks multiplied by size of ablock, then unused block pointers will undefined. Similarly, if size of a file is not a multiple of size of a block, data past end of last byte in last block will garbage. What if a file is bigger than maximum space addressable by itsdirect blocks? that, we present a motto programmers take tooseriously.  “All problems in computer science can solved by another level ofindirection. ” - David WheelerExcept for problem of too many layers of indirection.  solve this problem, we introduce indirect blocks. A single indirectblock is a block that stores pointers more data blocks. Similarly, adouble indirect block stores pointers single indirect blocks, concept can generalized arbitrary levels of indirection. This is aimportant concept, as inodes are stored in superblock, or some otherstructure in a well known location with a constant amount of space,indirection allows exponential increases in amount of space an inodecan keep track of. As a worked example, suppose we divide disk into 4KiB blocks wewant address up \\(2^{32}\\) blocks. maximum disk size is\\(4KiB *2^{32} = 16TiB\\) remember \\(2^{10} = 1024\\). A disk blockcan store \\(\\frac{4KiB}{4B}\\) possible pointers or 1024 pointers. Fourbyte wide pointers are needed because we want address 32 bits worthof blocks. Each pointer refers a 4KiB disk block, so you can refer up \\(1024*4KiB = 4MiB\\) of data. For same disk configuration, adouble indirect block stores 1024 pointers 1024 indirection tables. Thus a double-indirect block can refer up \\(1024 * 4MiB = 4GiB\\) ofdata. Similarly, a triple indirect block can refer up 4TiB of data. This is three times as slow for reading between blocks, due increasedlevels of indirection. actual intra-block reading times don’tchange. Directory ImplementationA directory is a mapping of names inode numbers. It is typically anormal file, but with some special bits set in its inode a specificstructure for its contents. POSIX provides a small set of functions read filename inode number for each entry, which we will talkabout in depth later in this chapter. Let’s think about what directories looks like in actual file system. Theoretically, they are files. disk blocks will contain directoryentries or dirents. What that means is that our disk block can looklike thisEach directory entry could either a fixed size, or a variable lengthC-string. It depends on how particular filesystem implements it at lower level. see a mapping of filenames inode numbers on aPOSIX system, from a shell, use ls with -i optionYou can see later that this is a powerful abstraction. One can have afile multiple different names in a directory, or exist in multipledirectories. UNIX Directory ConventionsIn standard UNIX filesystems, following entries are specially addedon requests read a directory.   . represents current directory   . . represents parent directory Counterintuitively, . . . could name of a file or directory ondisk (You can try this with mkdir . . . ), not grandparent directory. Only current directory parent directory have special aliasesinvolving . (namely , . . . ). Confusingly, shell zsh doesinterpret . . . as a handy shortcut grandparent directory (shouldit exist) while expanding shell commands. Additional facts about name-related conventions:  ~ is usually expanded home directory by shell   Files that start with ’. ’ (a period) on disk are conventionallyconsidered ’hidden’ will omitted by programs like lswithout additional flags (-a). This is not a feature of filesystem, programs may choose ignore this.    Some files may also start with a NUL byte. These are usuallyabstract UNIX sockets are used prevent cluttering up filesystem since they will effectively hidden by any unexpectingprogram. They will, however, listed by tools that detailinformation about sockets, so this is not a feature providingsecurity.    If you want annoy your neighbor, create a file with terminalbell character. Every single time file is listed (by calling‘ls’, for example), an audible bell will heard.  Directory APIWhile interacting with a file in C is typically done by using open open file then read or write interact with filebefore calling close release resources, directories have specialcalls such as, opendir, closedir readdir. There is no functionwritedir since typically that implies creating a file or link. program would use something like open or mkdir.  explore these functions, let’s write a program search contentsof a directory for a particular file. code below has a bug, try spot it!Did you find bug? It leaks resources! If a matching filename isfound then ‘closedir’ is never called as part of early return. Anyfile descriptors opened any memory allocated by opendir are neverreleased. This means eventually process will run out of resources an open or opendir call will fail.  fix is ensure we free up resources in every possible code path. In above code, this means calling closedir before return 1. Forgetting release resources is a common C programming bug becausethere is no support in C language ensure resources are alwaysreleased with all code paths. Given an open directory, after a call fork(), either (XOR), parent or child can use readdir(), rewinddir() or seekdir(). If both parent child use above, behavior isundefined. There are two main gotchas one consideration. readdir functionreturns “. ” (current directory) “. . ” (parent directory). otheris programs need explicity exclude subdirectories from a search,otherwise search may take a long time. For many applications, it’s reasonable check current directoryfirst before recursively searching sub-directories. This can achievedby storing results in a linked list, or resetting directorystruct restart from beginning.  following code attempts list all files in a directoryrecursively. As an exercise, try identify bugs it introduces. Did you find all 5bugs?One final note of caution. readdir is not thread-safe! You shouldn’tuse re-entrant version of function. Synchronizing filesystemwithin a process is important, so use locks around readdir. See for more details. LinkingLinks are what force us model a filesystem as a graph rather than atree. While modeling filesystem as a tree would imply that every inode hasa unique parent directory, links allow inodes present themselves asfiles in multiple places, potentially with different names, thus leading an inode having multiple parent directories. There are two kinds oflinks:  Hard Links A hard link is simply an entry in a directory assigningsome name an inode number that already has a different name mapping in either same directory or a different one. If wealready have a file on a file system we can create another link same inode using ‘ln’ command:  However, blip. txt is same file. If we edit blip, I’m editing same file as ‘file1. txt!’. We can prove this by showing thatboth file names refer same inode.   equivalent C call is link  For simplicity, above examples made hard links inside samedirectory. Hard links can created anywhere inside samefilesystem.    Soft Links second kind of link is called a soft link, symboliclink, or symlink. A symbolic link is different because it is a filewith a special bit set stores a path another file. Quitesimply, without special bit, it is nothing more than a text filewith a file path inside. Note when people generally talk about alink without specifying hard or soft, they are referring a hardlink.  create a symbolic link in shell, use ln -s. read contents of link as a file, use readlink. These are bothdemonstrated below.   Note that file2. txt file1. txt have different inode numbers,unlike hard link, blip. txt.  There is a C library call create symlinks which is similar link.   Some advantages of symbolic links are   Can refer files that don’t exist yet   Unlike hard links, can refer directories as well as regularfiles   Can refer files (and directories) that exist outside of current file system   However, symlinks have a key disadvantage, they as slower thanregular files directories. When link’s contents are read,they must interpreted as a new path target file, resultingin an additional call open read since real file must opened read. Another disadvantage is that POSIX forbids hardlinking directories where as soft links are allowed. lncommand will only allow root do this only if you provide -d option. However, even root may not able perform thisbecause most filesystems prevent it!  integrity of file system assumes directory structure is anacyclic tree that is reachable from root directory. It becomesexpensive enforce or verify this constraint if directory linking isallowed. Breaking these assumptions can leave file integrity toolsunable repair file system. Recursive searches potentially neverterminate directories can have more than one parent but “. . ” canonly refer a single parent. All in all, a bad idea. Soft links aremerely ignored, which is why we can use them reference directories. When you remove a file using rm or unlink, you are removing an inodereference from a directory. However, inode may still referencedfrom other directories. determine if contents of file arestill required, each inode keeps a reference count that is updatedwhenever a new link is created or destroyed. This count only tracks hardlinks, symlinks are allowed refer a non-existent file thus, donot matter. An example use of hard links is efficiently create multiple archivesof a file system at different points in time. Once archive area hasa copy of a particular file, then future archives can re-use thesearchive files rather than creating a duplicate file. This is called anincremental backup. Apple’s “Time Machine” software does this. PathingNow that we have definitions, have talked about directories, we comeacross concept of a path. A path is a sequence of directories thatprovide one with a “path” in graph that is a filesystem. However,there are some nuances. It is possible have a path calleda/b/. . /c/. /. Since . . . are special entries in directories,this is a valid path that actually refers a/c. Most filesystemfunctions will allow uncompressed paths passed in. C libraryprovides a function realpath compress path or get absolutepath. simplify by hand, remember that . . means ‘parent folder’ that . means ‘current folder’. Below is an example that illustrates simplification of a/b/. . /c/. by using cd in a shell navigate a filesystem.   cd a (in a)   cd b (in a/b)   cd . . (in a, because . . represents ‘parent folder’)   cd c (in a/c)   cd . (in a/c, because . represents ‘current folder’) Thus, this path can simplified a/c. MetadataHow can we distinguish between a regular file a directory? For thatmatter, there are many other attributes that files also might contain. We distinguish a file type – different from file extension i. e. png,svg, pdf – using fields inside inode. How does system know whattype file is?This information is stored within an inode. access it, use statcalls. For example, find out when my ‘notes. txt’ file was lastaccessed. There are actually three versions of stat;For example, a program can use fstat learn about file metadata ifit already has a file descriptor associated with that file. lstat is almost same as stat but handles symbolic linksdifferently. From stat man page.  lstat() is identical stat(), except that if pathname is a symboliclink, then it returns information about link itself, not filethat it refers to.  stat functions make use of struct stat. From stat man page: st_mode field can used distinguish between regular files directories. accomplish this, use macros, S_ISDIR S_ISREG. Permissions bitsPermissions are a key part of way UNIX systems provide security in afilesystem. You may have noticed that st_mode field in structstat contains more than file type. It also contains mode, adescription detailing what a user can can’t do with a given file. There are usually three sets of permissions for any file. Permissionsfor user, group other (every user falling outside first two categories). For each of three categories, we need keeptrack of whetherthe user is allowed read file, write file, execute file. Since there are three categories threepermissions, permissions are usually represented as a 3-digit octalnumber. For each digit, least significant byte corresponds readprivileges, middle one write privileges final byte execute privileges. They are always presented as User, Group,Other (UGO). Below are some common examples. Here are bitconventions:  r means that set of people can read   w means that set of people can write   x means that set of people can execute    Octal Code User Group Others     755 rwx r-x r-x   644 rw- r– r–  Permissions TableIt is worth noting that rwx bits have a slightly different meaningfor directories. Write access a directory that will allow a program create or delete new files or directories inside. You can think aboutthis as having write access directory entry (dirent) mappings. Read-access a directory will allow a program list a directory’scontents. This is read access directory entry (dirent) mapping. Execute will allow a program enter directory using cd. Without execute bit, it any attempt create or remove files or directorieswill fail since you cannot access them. You can, however, list contents of directory. There are several command line utilities for interacting with a file’smode. mknod changes type of file. chmod takes a number afile changes permission bits. However, before we can discusschmod in detail, we must also understand user ID (uid) groupid (gid) as well. User ID / Group IDEvery user in a UNIX system has a user ID. This is a unique number thatcan identify a user. Similarly, users can added collections calledgroups, every group also has a unique identifying number. Groupshave a variety of uses on UNIX systems. They can assignedcapabilities - a way of describing level of control a user has overa system. For example, a group you may have run into is sudoersgroup, a set of trusted users who are allowed use command sudo temporarily gain higher privileges. We’ll talk more about how sudoworks in this chapter. Every file, upon creation, an owner, creatorof file. This owner’s user ID (uid) can found inside st_mode file of a struct stat with a call stat. Similarly, group ID (gid) is set as well. Every process can determine its uid gid with getuid getgid. When a process tries open a file with a specific mode, it’suid gid are compared with uid gid of file. If uids match, then process’s request open file will compared with bits on user field of file’s permissions. If gids match, then process’s request will compared with group field of permissions. If none of IDs match, then otherfield will apply. Reading / Changing file permissionsBefore we discuss how change permission bits, we should able read them. In C, stat family of library calls can used. readpermission bits from command line, use ls -l. Note, permissions will output in format ‘trwxrwxrwx’. first characterindicates type of file type. Possible values for first characterinclude but aren’t limited to.   (-) regular file   (d) directory   (c) character device file   (l) symbolic link   (p) named pipe (also called FIFO)   (b) block device   (s) socket Alternatively, use program stat which presents all informationthat one could retrieve from stat library call.  change permission bits, there is a system call, int chmod(constchar *path, mode_t mode);. simplify our examples, we will using command line utility of same name chmod short of “changemode”. There are two common ways use chmod, with either an octalvalue or with a symbolic string.  base-8 (‘octal’) digits describe permissions for each role: user who owns file, group everyone else. octal number is sum of three values given three types of permission: read(4),write(2), execute(1)Example: chmod 755 myfile  r + w + x = digit * user has 4+2+1, full permission   group has 4+0+1, read execute permission   all users have 4+0+1, read execute permission Understanding ‘umask’ umask subtracts (reduces) permission bits from 777 is usedwhen new files new directories are created by open, mkdir etc. Bydefault, umask is set 022 (octal), which means that group other privileges will exclusively readable. Each process has acurrent umask value. When forking, child inherits parent’s umaskvalue. For example, by setting umask 077 in shell, ensures thatfuture file directory creation will only accessible current user,As a code example, suppose a new file is created with open() modebits 666 (write read bits for user, group other):If umask is octal 022, then permissions of created file will 0666 &amp; ~022 for example.  ‘setuid’ bitYou may have noticed an additional bit that files with executepermission may have set. This bit is setuid bit. It indicated thatwhen run, program will set uid of user that of ownerof file. Similar, there is a setgid bit which sets gid of executor gid of owner. canonical example of a programwith setuid set is sudo. sudo is usually a program that is owned by root user - a user thathas all capabilities. By using sudo, an otherwise unprivileged usercan gain access most parts of system. This is useful for runningprograms that may require elevated privileges, such as using chown change ownership of a file, or use mount mount or unmountfilesystems (an action we will discuss later in this chapter). Here aresome examples:When executing a process with setuid bit, it is still possible determine a user’s original uid with getuid. real action of setuid bit is set effective user ID (euid) which can determined with geteuid. actions of getuid geteuid aredescribed below.   getuid returns real user id (zero if logged in as root)   geteuid returns effective user id (zero if acting as root,e. g.  due setuid flag set on a program) These functions can allow one write a program that can only run bya privileged user by checking geteuid or go a step further ensurethat only user who can run code is root by using getuid.  ‘sticky’ bitSticky bits as we use them today serve a different purpose from initialintroduction. Sticky bits were a bit that could set on an executablefile that would allow a program’s text segment remain in swap evenafter end of program’s execution. This made subsequentexecutions of same program faster. Today, this behavior is no longersupported sticky bit only holds meaning when set on a directory,When a directory’s sticky bit is set only file’s owner, directory’s owner, root user can rename or delete file. Thisis useful when multiple users have write access a common directory. Acommon use of sticky bit is for shared writable /tmpdirectory where many users’ files may stored, but users should not able access files belonging other users.  set sticky bit, use chmod +t. Note that in example above, username is prepended prompt, command su is used switch users. Virtual filesystems other filesystemsPOSIX systems, such as Linux Mac OS X (which is based on BSD)include several virtual filesystems that are mounted (available) as partof file-system. Files inside these virtual filesystems may generated dynamically or stored in ram. Linux provides 3 main virtualfilesystems.    Device Use Case     /dev A list of physical virtual devices (for example network card, cdrom, random number generator   /proc A list of resources used by each process (by tradition) set of system information   /sys An organized list of internal kernel entities  Virtual Filesystem listIf we want a continuous stream of 0s, we can run cat /dev/zero. Another example is file /dev/null, a great place store bitsthat you never need read. Bytes sent /dev/null/ are never stored simply discarded. A common use of /dev/null is discard standardoutput. For example,Managing files filesystemsGiven multitude of operations that are available you from filesystem, let’s explore some tools techniques that can used manage files filesystems. One example is creating a secure directory. Suppose you created your owndirectory in /tmp then set permissions so that only you can use directory (see below). Is this secure?There is a window of opportunity between when directory is created when it’s permissions are changed. This leads severalvulnerabilities that are based on a race condition. Another user replaces mystuff with a hard link an existing file ordirectory owned by second user, then they would able read control contents of mystuff directory. Oh no - our secrets areno longer secret!However in this specific example, /tmp directory has stickybit set, so only owner may delete mystuff directory, simple attack scenario described above is impossible. This does not meanthat creating directory then later making directory privateis secure! A better version is atomically create directory with correct permissions from its inception. Obtaining Random Data/dev/random is a file that contains a random number generator where entropy is determined from environmental noise. Random willblock/wait until enough entropy is collected from environment. /dev/urandom is like random, but differs in fact that it allowsfor repetition (lower entropy threshold), thus won’t block. One can think of both of these as streams of characters from which aprogram can read as opposed files with a start end. touch on amisconception, most of time one should using /dev/urandom. only specific use case of /dev/random is when one needscryptographically secure data on bootup system should block. Otherwise, there are following reasons.   Empirically, they both produce numbers that look random enough.    /dev/random may block at an inconvenient time. If one isprogramming a service for high scalability relies on/dev/random, an attacker can reliably exhaust entropy pool cause service block.    Manual page authors pose a hypothetical attack where an attackerexhausts entropy pool guesses seeding bits, but thatattack has yet implemented.    Some operating system don’t have a true /dev/random like MacOS.    Security experts will talk about Computational Security vsInformation Theoretic security, more on this article. Most encryption is computationally secure, which means/dev/urandom is as well.  Copying FilesUse versatile dd command. For example, following commandcopies 1 MiB of data from file /dev/urandom file/dev/null. data is copied as 1024 blocks of block size 1024 bytes. Both input output files in example above are virtual - theydon’t exist on a disk. This means speed of transfer isunaffected by hardware power. dd is also commonly used make a copy of a disk or an entirefilesystem create images that can either burned on other disksor distribute data other users. Updating Modification Time touch executable creates a file if it is non-existant alsoupdates file’s last modified time current time. Forexample, we can make a new private file with currenttime:An example use of touch is force make recompile a file that isunchanged after modifying compiler options inside makefile. Remember that make is ‘lazy’ - it will compare modified time of source file with corresponding output file see if file needs recompiled. Managing Filesystems manage filesystems on your machine, use mount. Using mount withoutany options generates a list (one filesystem per line) of mountedfilesystems including networked, virtual local (spinning disk /SSD-based) filesystems. Here is a typical output of mountNotice that each line includes filesystem type source of filesystem mount point. reduce this output, we can pipe it intogrep only see lines that match a regular expression. Filesystem MountingSuppose you had downloaded a bootable Linux disk image from Before putting filesystem on a CD, we can mount file as afilesystem explore its contents. Note: mount requires root access,so let’s run it using sudoBefore mount command, arch directory is new obviously empty. After mounting, contents of arch/ will drawn from files directories stored in filesystem stored inside archlinux-2014. 11. 01-dual. iso file. loop option is requiredbecause we want mount a regular file, not a block device such as aphysical disk.  loop option wraps original file as a block device. In thisexample, we will find out below that file system is provided under/dev/loop0. We can check filesystem type mount options byrunning mount command without any parameters. We will pipe output into grep so that we only see relevant output line(s) thatcontain ‘arch’.  iso9660 filesystem is a read-only filesystem originally designed foroptical storage media (i. e.  CDRoms). Attempting change contentsof filesystem will failMemory Mapped IOWhile we traditionally think of reading writing from a file as anoperation that happens by using read write calls, there isan alternative, mapping a file into memory using mmap. mmap can also used for IPC, you can see more about mmap as a system call thatenables shared memory in IPC chapter. In this chapter, we’ll brieflyexplore mmap as a filesystem operation. mmap takes a file maps its contents into memory. This allows auser treat entire file as a buffer in memory for easier semanticswhile programming, avoid having read a file as discrete chunksexplicitly. Not all filesystems support using mmap for IO. Those that do havevarying behavior. Some will simply implement mmap as a wrapper aroundread write. Others will add additional optimizations by takingadvantage of kernel’s page cache. Of course, such optimization can used in implementation of read write as well, so oftenusing mmap has identical performance. mmap is used perform some operations such as loading libraries processes into memory. If many programs only need read-access same file, then same physical memory can shared between multipleprocesses. This is used for common libraries like C standardlibrary.  process map a file into memory is as follows.   mmap requires a file descriptor, so we need open filefirst   We seek our desired size write one byte ensure that file is sufficient length   When finished call munmap unmap file from memory.  Here is a quick example.  careful reader may notice that our integers were written inleast-significant-byte format because that is endianness of CPUthat we ran this example on. We also allocated a file that is one bytetoo many! PROT_READ | PROT_WRITE options specify virtualmemory protection. option PROT_EXEC (not used here) can set allow CPU execution of instructions in memory. Reliable Single Disk FilesystemsMost filesystems cache significant amounts of disk data in physicalmemory. Linux, in this respect, is extreme. All unused memory is used asa giant disk cache. disk cache can have a significant impact onoverall system performance because disk I/O is slow. This is especiallytrue for random access requests on spinning disks where diskread-write latency is dominated by seek time required move read-write disk head correct position. For efficiency, kernel caches recently used disk blocks. Forwriting, we have choose a trade-off between performance reliability. Disk writes can also cached (“Write-back cache”) wheremodified disk blocks are stored in memory until evicted. Alternatively,a ‘write-through cache’ policy can employed where disk writes aresent immediately disk. latter is safer as filesystemmodifications are quickly stored persistent media but slower than awrite-back cache. If writes are cached then they can delayed efficiently scheduled based on physical position of each disk block. Note, this is a simplified description because solid state drives (SSDs)can used as a secondary write-back cache. Both solid state disks (SSD) spinning disks have improvedperformance when reading or writing sequential data. Thus, operatingsystems can often use a read-ahead strategy amortize read-requestcosts request several contiguous disk blocks per request. By issuingan I/O request for next disk block before user applicationrequires next disk block, apparent disk I/O latency can reduced. If your data is important needs force written disk, callsync request that a filesystem’s changes written (flushed) disk. However, operating systems may ignore this request. Even if data is evicted from kernel buffers, disk firmware may use aninternal on-disk cache or may not yet have finished changing physical media. Note, you can also request that all changes associatedwith a particular file descriptor are flushed disk using fsync(intfd). There is a fiery debate about this call being useless, initiatedby PostgresQL’s teamIf your operating system fails in middle of an operation, mostmodern file systems do something called journaling work aroundthis. What file system does is before it completes a potentiallyexpensive operation, is that it writes what it is going do down in ajournal. In case of a crash or failure, one can step through journal see which files are corrupt fix them. This is a way salvage hard disks in cases there is critical data there is noapparent backup. Even though it is unlikely for your computer, programming for datacenters means that disks fail every few seconds. Disk failures aremeasured using “Mean-Time-To-Failure (MTTF)”. For large arrays, meanfailure time can surprisingly short. If MTTF(single disk) =30,000 hours, then MTTF(1000 disks)= 30000/1000=30 hours or about aday a half! That’s also assuming that failures between disks are independent, which they often aren’t. RAID - Redundant Array of Inexpensive DisksOne way protect against this is store data twice! This is main principle of a “RAID-1” disk array. By duplicating writes adisk with writes another backup disk, there are exactly two copies of data. If one disk fails, other disk serves as only copyuntil it can re-cloned. Reading data is faster since data can requested from either disk, but writes are potentially twice as slowbecause now two write commands need issued for every disk blockwrite. Compared using a single disk, cost of storage per byte hasdoubled. Another common RAID scheme is RAID-0, meaning that a file could splitup among two disks, but if any disk fails then files areirrecoverable. This has benefit of halving write times because onepart of file could writing hard disk one another part hard disk two. It is also common combine these systems. If you have a lot of harddisks, consider RAID-10. This is where you have two systems of RAID-1,but systems are hooked up in RAID-0 each other. This means youwould get roughly same speed from slowdowns but now any one diskcan fail you can recover that disk. If two disks from opposing raidpartitions fail, there is a chance that you can recover though we don’tcould on it most of time. Higher Levels of RAIDRAID-3 uses parity codes instead of mirroring data. For each N-bitswritten, we will write one extra bit, ‘Parity bit’ that ensures total number of 1s written is even. parity bit is written anadditional disk. If any disk including parity disk is lost, then itscontents can still computed using contents of other disks. One disadvantage of RAID-3 is that whenever a disk block is written, parity block will always written too. This means that there iseffectively a bottleneck in a separate disk. In practice, this is morelikely cause a failure because one disk is being used 100% of time once that disk fails then other disks are more prone failure. A single disk failure is recoverable because there is sufficient data rebuild array from remaining disks. Data-loss will occur whentwo disks are unusable because there is no longer sufficient data rebuild array. We can calculate probability of a two diskfailure based on repair time which factors both time insert anew disk time required rebuild entire contents of array. Using typical numbers (MTTR=1day, MTTF=1000days, N-1 = 9, p=0. 009)There is a 1% chance that another drive will fail during rebuildprocess (at that point you had better hope you still have an accessiblebackup of your original data. In practice, probability of a secondfailure during repair process is likely higher because rebuilding array is I/O-intensive (and on top of normal I/O request activity). This higher I/O load will also stress disk array. RAID-5 is similar RAID-3 except that check block (parityinformation) is assigned different disks for different blocks. check-block is ‘rotated’ through disk array. RAID-5 provides betterread write performance than RAID-3 because there is no longer bottleneck of single parity disk. one drawback is that you needmore disks have this setup, there are more complicated algorithmsthat need used. Failure is common. Google reports 2-10% of disks fail per year. Multiplying that by 60,000+ disks in a single warehouse. Services mustsurvive single disk, rack of servers, or whole data center failures. SolutionsSimple redundancy (2 or 3 copies of each file) e. g. , Google GFS (2001). More efficient redundancy (analogous RAID 3++) e. g. , (~2010):customizable replication including Reed-Solomon codes with 1. 5xredundancySimple Filesystem ModelSoftware developers need implement filesystems all time. If thatis surprising you, we encourage you take a look at Hadoop,GlusterFS, Qumulo, etc. Filesystems are hot areas of research as of 2018because people have realized that software models that we havedevised don’t take full advantage of our current hardware. Additionally, hardware that we use for storing information is getting better all time. As such, you may end up designing a filesystem yourselfsomeday. In this section, we will go over one of a fake filesystems “walk through” some examples of how things work. So, what does our hypothetical filesystem look like? We will base it offof minixfs, a simple filesystem that happens firstfilesystem that Linux ran on. It is laid out sequentially on disk, first section is superblock. superblock stores importantmetadata about entire filesystem. Since we want able readthis block before we know anything else about data on disk, thisneeds in a well-known location so start of disk is a goodchoice. After superblock, we’ll keep a map of which inodes are beingused. nth bit is set if nth inode – \\(0\\) being inode root– is being used. Similarly, we store a map recording which data blocksare used. Finally, we have an array of inodes followed by rest of disk - implicitly partitioned into data blocks. One data block may identical next from perspective of hardware componentsof disk. Thinking about disk as an array of data blocks issimply something we do so that we have a way describe where fileslive on disk. Below, we have an example of how an inode that describes a file maylook. Note that for sake of simplicity, we have drawn arrows mappingdata block numbers in inode their locations on disk. These aren’tpointers so much as indices into an array. We will assume that a data block is 4 KiB. Note that a file will fill up each of its data blocks completely beforerequesting an additional data block. We will refer this property as file being compact. file presented above is interesting sinceit uses all of its direct blocks, one of entries for its indirectblock partially uses another indirect block.  following subsections will all refer file presented above. File Size vs Space on DiskOur file’s size must stored in inode. filesystem isn’t awareof actual contents of what is in a file - that data is considered user’s should only manipulated by user. However, we cancompute upper lower bounds on filesize by only looking at howmany blocks file uses. There are two full direct blocks, which together store\\(2*sizeof(data\\_block)=2*4KiB=8KiB\\). There are two used blocks referenced by indirect block, which canstore up \\(8KiB\\) as calculated above. We can now add these values get an upper bound on file size of\\(16KiB\\). What about a lower bound? We know that we must use two directblocks, one block referenced by indirect block at least 1 byteof a second block referenced by indirect block. With thisinformation, we can work out lower bound \\(2*4KiB+4KiB+1=12KiB+1B\\). Note that our calculations so far have been determine how much data user is storing on disk. What about overhead of storing thisdata incurred while using this filesystem? You’ll notice that we use anindirect block store disk block numbers of blocks used beyond two direct blocks. While doing our above calculations, we omitted thisblock. This would instead counted as overhead of file, thus total overhead of storing this file on disk is\\(sizeof(indirect\\_block)=4KiB)\\). Thinking about overhead, a related calculation could determine max/min disk usage per file in this filesystem. Trivially a file of size \\(0\\) has no associated data blocks takesup no space on disk (ignoring space required for inode sincethese are located in a fixed size array somewhere on disk). How about disk usage of smallest non-empty file? That is, consider a fileof size \\(1B\\). Note that when a user writes first byte, a datablock will allocated. Since each data block is \\(4KiB\\), we findthat \\(4KiB\\) is minimum disk usage for a non-empty file. Here, weobserve that file size will only \\(1B\\), despite that\\(4KiB\\) of disk is used – there is a distinction between filesize disk usage because of overhead!Finding maximum is slightly more involved. As we saw earlier in thischapter, a filesystem with this structure can have \\(1024\\) data blocknumbers in one indirect block. This implies that maximum filesizecan \\(2*4KiB + 1024*4KiB = 4MiB + 8KiB\\) (after accounting for direct blocks as well). However, on disk we also store indirectblock itself. This means that an additional \\(4KiB\\) of overhead will used account for indirect block, so total disk usage will \\(4MiB + 12KiB\\). Note that when only using direct blocks, completely filling up a directblock implies that our filesize our disk usage are same thing!While it would seem like we always want this ideal scenario, it puts arestrictive limit on maximum filesize. Attempting remedy this byincreasing number of direct blocks seems promising, but note thatthis requires increasing size of an inode reducing amount ofspace available store user data – a tradeoff you will have evaluate for yourself. Alternatively always trying split your data upinto chunks that never use indirect blocks is may exhaust limitedpool of available inodes. Performing ReadsPerforming reads tend pretty easy in our filesystem because ourfiles are compact. Let’s say that we want read entirety of thisparticular file. What we’d start by doing is go inode’s directstruct find first direct data block number. In our case, it is#7. Then we find 7th data block from start of all datablocks. Then we read all of those bytes. We do same thing for all of direct nodes. What do we do after? We go indirect block read indirect block. We know that every 4 bytes of indirectblock is either a sentinel node (-1) or number of another datablock. In our particular example, first four bytes evaluate integer 5, meaning that our data continues on 5th data block from beginning. We do same for data block #4 we stop afterbecause we exceed size of inodeNow, let’s think about edge cases. How would a program start read starting at an arbitrary offset of \\(n\\) bytes given that blocksizes are \\(4 KiBs\\). How many indirect blocks should there if filesystem is correct? (Hint: think about using size of inode)Performing WritesWriting filesPerforming writes fall into two categories, writes files writes directories. First we’ll focus on files assume that we arewriting a byte \\(6\\)th KiB of our file. perform a write on afile at a particular offset, first filesystem must go datablock would start at that offset. For this particular example we wouldhave go 2nd or indexed number 1 inode perform our write. Wewould once again fetch this number from inode, go root of data blocks, go \\(5\\)th data block perform our write at \\(2\\)KiB offset from this block because we skipped first fourkibibytes of file in block 7. We perform our write go on ourmerry way. Some questions consider.   How would a program perform a write go across data block boundaries?   How would a program perform a write after adding offset wouldextend length of file?   How would a program perform a write where offset is greater than length of original file? Writing directoriesPerforming a write a directory implies that an inode needs added a directory. If we pretend that example above is adirectory. We know that we will adding at most one directory entry ata time. Meaning that we have have enough space for one directoryentry in our data blocks. Luckily last data block that we have hasenough free space. This means we need find number of lastdata block as we did above, go where data ends, write onedirectory entry. Don’t forget update size of directory sothat next creation doesn’t overwrite your file!Some more questions:  How would would a program perform a write when last data blockis already full?   How about when all direct blocks have been filled up inode doesn’t have an indirect block?   What about when first indirect entry (#4) is full? Adding DeletesIf inode is a file, then remove directory entry in parentdirectory by marking it as invalid (maybe making it point inode -1) skip it in your reads. A filesystem decreases hard link count of inode if count reaches zero, free inode in inode map free all associated data blocks so they are reclaimed by filesystem. In many operating systems, several fields in inode getoverwritten. If inode is a directory, filesystem checks if it is empty. Ifnot, then kernel will most likely mark an error.  sure check out appendix for modern cutting edgefilesystems. Topics  Superblock   Data Block   Inode   Relative Path   File Metadata   Hard Soft Links   Permission Bits   Mode bits   Working with Directories   Virtual File System   Reliable File Systems   RAID Questions  How big can files on a file system with 15 Direct blocks, 2double, 3 triple indirect, 4kb blocks 4byte entries? (Assumeenough infinite blocks)   What is a superblock? Inode? Data block?   How do we simplify /. /proc/. . /dev/. /random/   In ext2, what is stored in an inode, what is stored in adirectory entry?   What are /sys, /proc, /dev/random, /dev/urandom?   What are permission bits?   How does one use chmod set user/group/owner read/write/executepermissions?   What does “dd” command do?   What is difference between a hard link a symbolic link? Does file need exist?   “ls -l” shows size of each file in a directory. Is sizestored in directory or in file’s inode? “International. ” n. d. *IEC*. IEC. . ","url":"/coursebook/Filesystems"},{"title":"Honors","content":"                   Honors topicsIf I have seen further it is by standing on sholders [sic] ofGiants - Sir Isaac NewtonThis chapter contains contents of some of honors lectures (CS296-41). These topics are aimed at students who want dive deeper into topics of CS 341.  Linux KernelThroughout course of CS 341, you become familiar with system calls - userspace interface interacting with kernel. How does thiskernel actually work? What is a kernel? In this section, we will explorethese questions in more detail shed some light on various blackboxes that you have encountered in this course. We will mostly focusing on Linux kernel in this chapter, so please assume that allexamples pertain Linux kernel unless otherwise specified. What kinds of kernels are there?As it stands, most of you are probably familiar with Linux kernel,at least in terms of interacting with it via system calls. Some of youmay also have explored Windows kernel, which we won’t talk about toomuch in this chapter. or Darwin, UNIX-like kernel for macOS (aderivative of BSD). Those of you who might have done a bit more diggingmight have also encountered projects such a GNU HURD or zircon. Kernels can generally classified into one of two categories, amonolithic kernel or a micro-kernel. A monolithic kernel is essentiallya kernel all of it’s associated services as a single program. Amicro-kernel on other hand is designed have a main componentwhich provides bare-minimum functionality that a kernel needs. Thisinvolves setting up important device drivers, root filesystem,paging or other functionality that is imperative for other higher-levelfeatures implemented. higher-level features (such as anetworking stack, other filesystems, non-critical device drivers)are then implemented as separate programs that can interact with kernel by some form of IPC, typically RPC. As a result of this design,micro-kernels have traditionally been slower than monolithic kernels due IPC overhead. We will devote our discussion from here onwards focusing onmonolithic kernels unless specified otherwise, specifically Linux kernel. System Calls DemystifiedSystem Calls use an instruction that can run by a program operatingin userspace that traps kernel (by use of a signal) complete call. This includes actions such as writing data disk,interacting directly with hardware in general or operations related gaining or relinquishing privileges (e. g. becoming root user gaining all capabilities). In order fulfill a user’s request, kernel will rely on kernelcalls. Kernel calls are essentially “public” functions of kernel - functions implemented by other developers for use in otherparts of kernel. Here is a snippet for a kernel call man page:You’ll note that some flags are marked as potentially causing sleeps. This tells us whetherwe can use those flags in special scenarios, likeinterrupt contexts, where speed is of essence, operations thatmay block or wait for another process may never complete. ContainerizationAs we enter an era of unprecedented scale with around 20 billion devicesconnected internet in 2018, we need technologies that help usdevelop maintain software capable of scaling upwards. Additionally,as software increases in complexity, designing secure softwarebecomes harder, we find that we have new constraints imposed on us as wedevelop applications. As if that wasn’t enough, efforts simplifysoftware distribution development, like package manager systems canoften lead headaches of their own, leading broken packages,dependencies that are impossible resolve other such environmentalnightmares that have become all common today. While these seem likedisjoint problems at first, all of these more can solved bythrowing containerization at problem. What is a container?A container is almost like a virtual machine. In some senses, containersare virtual machines as threads are processes. A container is alightweight environment that shares resources a kernel with a hostmachine, while isolating itself from other containers or processes on host. You may have encountered containers while working withtechnologies such as Docker, perhaps most well-knownimplementation of containers out there. Linux NamespacesBuilding a container from scratchContainers in wild: Software distribution is a Snap","url":"/coursebook/Honors"},{"title":"Introc","content":"                                                                              C Programming LanguageIf you want teach systems, don’t drum up programmers, sort issues, make PRs. Instead, teach them yearn for vast endless C. - Antoine de Saint-Exupéry (With edits)Note: This chapter is long goes into a lot of detail. Feel free gloss over parts with which you have experience in. C is de-facto programming language do serious system seriousprogramming. Why? Most kernels have their API accessible through C. Linux kernel (Love ) XNU kernel(Inc. ) of which MacOS isbased on are written in C have C API - Application ProgrammingInterface. Windows Kernel uses C++, but doing system programming onthat is much harder on windows that UNIX for novice system programmers. C doesn’t have abstractions like classes Resource Acquisition IsInitialization (RAII) clean up memory. C also gives you much more ofan opportunity shoot yourself in foot, but it lets you do thingsat a much more fine-grained level. History of CC was developed by Dennis Ritchie Ken Thompson at Bell Labs back in1973 (Ritchie). Back then, we had gems of programming languages like Fortran, ALGOL, LISP. goal of C was two-fold. Firstly, it was made target most popular computers at time, such as PDP-7. Secondly, ittried remove some of lower-level constructs (managing registers, programming assembly for jumps), create a language that had power express programs procedurally (as opposed mathematicallylike LISP) with readable code. All this while still having ability interface with operating system. It sounded like a tough feat. Atfirst, it was only used internally at Bell Labs along with UNIXoperating system.  first “real” standardization was with Brian Kernighan DennisRitchie’s book (Kernighan Ritchie). It is stillwidely regarded today as only portable set of C instructions. K\\&amp;R book is known as de-facto standard for learning C. There weredifferent standards of C from ANSI ISO, though ISO largely won out asa language specification. We will mainly focusing on is POSIX Clibrary which extends ISO. Now get elephant out of room, Linux kernel is fails POSIX compliant. Mostly, this is so because Linux developers didn’t want pay fee for compliance. It isalso because they did not want fully compliant with a multitude ofdifferent standards because that meant increased development costs maintain compliance. We will aim use C99, as it is standard that most computersrecognize, but sometimes use some of newer C11 features. We willalso talk about some off-hand features like getline because they areso widely used with GNU C library. We’ll begin by providing a fairlycomprehensive overview of language with language facilities. Feelfree gloss over if you have already worked with a C based language. Features  Speed. There is little separating a program system.    Simplicity. C its standard library comprise a simple set ofportable functions.    Manual Memory Management. C gives a program ability manageits memory. However, this can a downside if a program has memoryerrors.    Ubiquity. Through foreign function interfaces (FFI) languagebindings of various types, most other languages can call C functions vice versa. standard library is also everywhere. C has stood test of time as a popular language, it doesn’t look like itis going anywhere.  Crash course introduction C canonical way start learning C is by starting with helloworld program. original example that Kernighan Ritchie proposedway back when hasn’t changed.   #include directive takes file stdio. h (which stands forstandard input output) located somewhere in youroperating system, copies text, substitutes it where #include was.    int main(void) is a function declaration. first word inttells compiler return type of function. part before parenthesis (main) is function name. In C, no twofunctions can have same name in a single compiled program,although shared libraries may able. Then, parameter listcomes after. When we provide parameter list for regularfunctions (void) that means that compiler should produce anerror if function is called with a non-zero number of arguments. For regular functions having a declaration like void func() meansthat function can called like func(1, 2, 3), because thereis no delimiter. main is a special function. There are many waysof declaring main but standard ones are int main(void), intmain(), int main(int argc, char *argv[]).    printf(\"Hello World\"); is what a function call. printf isdefined as a part of stdio. h. function has been compiled lives somewhere else on our machine - location of C standardlibrary. Just remember include header call functionwith appropriate parameters (a string literal \"Hello World\"). If newline isn’t included, buffer will not flushed (i. e. write will not complete immediately).    return 0. main has return an integer. By convention,return 0 means success anything else means failure. Here aresome exit codes / statuses with special meaning:. In general, assume 0 means success.    gcc is short for GNU Compiler Collection which has a host ofcompilers ready for use. compiler infers from extension thatyou are trying compile a . c file.    . /main tells your shell execute program in currentdirectory called main. program then prints out “hello world”.  If systems programming was as easy as writing hello world though, ourjobs would much easier. PreprocessorWhat is preprocessor? Preprocessing is a copy paste operationthat compiler performs before actually compiling program. following is an example of substitutionThere are side effects preprocessor though. One problem is that preprocessor needs able tokenize properly, meaning trying redefine internals of C language with a preprocessor may impossible. Another problem is that they can’t nested infinitely -there is a bounded depth where they need stop. Macros are also simpletext substitutions, without semantics. For example, look at what canhappen if a macro tries perform an inline modification. Macros are simple text substitution so above example expands In this case, it is opaque what gets printed out, but it will 6. Canyou try figure out why? Also, consider edge case when operatorprecedence comes into play. There are also logical problems with flexibility of certainparameters. One common source of confusion is with static arrays sizeof operator. What is wrong with macro? Well, it works if a static array is passedin because sizeof a static array returns number of bytes thatarray takes up dividing it by sizeof(an_element) would give number of entries. But if passed a pointer a piece of memory,taking sizeof pointer dividing it by size of firstentry won’t always give us size of array. Language FacilitiesKeywordsC has an assortment of keywords. Here are some constructs that youshould know briefly as of C99.   break is a keyword that is used in case statements or loopingstatements. When used in a case statement, program jumps end of block.   In context of a loop, using it breaks out of inner-mostloop. loop can either a for, while, or do-whileconstruct    const is a language level construct that tells compiler thatthis data should remain constant. If one tries change a constvariable, program will fail compile. const works a littledifferently when put before type, compiler re-orders first type const. Then compiler uses a. Meaning that whatever is left of pointer is constant. This isknown as const-correctness.   But, it is important know that this is a compiler imposedrestriction only. There are ways of getting around this, program will run fine with defined behavior. In systems programming, only type of memory that you can’t write is systemwrite-protected memory.     continue is a control flow statement that exists only in loopconstructions. Continue will skip rest of loop body set program counter back start of loop before.     do {} while(); is another loop construct. These loops execute body then check condition at bottom of loop. If condition is zero, next statement is executed – programcounter is set first instruction after loop. Otherwise, loop body is executed.     enum is declare an enumeration. An enumeration is a type thatcan take on many, finite values. If you have an enum don’tspecify any numerics, C compiler will generate a unique numberfor that enum (within context of current enum) use thatfor comparisons. syntax declare an instance of an enum isenum &lt;type&gt; varname. added benefit this is that compiler can type check these expressions make sure that you areonly comparing alike types.   It is completely possible assign enum values either different or same. It is not advisable rely on compilerfor consistent numbering, if you assign numbers. If you are going use this abstraction, try not break it.     extern is a special keyword that tells compiler that variable may defined in another object file or a library, so program compiles on missing variable because program willreference a variable in system or another file.     for is a keyword that allows you iterate with an initializationcondition, a loop invariant, an update condition. This is meant equivalent a while loop, but with differing syntax.   As of C89 standard, one cannot declare variables inside for loop initialization block. This is because there was adisagreement in standard for how scoping rules of a variabledefined in loop would work. It has since been resolved with morerecent standards, so people can use for loop that they know love today  order of evaluation for a for loop is as follows   Perform initialization statement.    Check invariant. If false, terminate loop execute next statement. If true, continue body of loop.    Perform body of loop.    Perform update statement.    Jump checking invariant step.      goto is a keyword that allows you do conditional jumps. Do notuse goto in your programs. reason being is that it makes yourcode infinitely more hard understand when strung together withmultiple chains, which is called spaghetti code. It is acceptable use in some contexts though, for example, error checking code in Linux kernel. keyword is usually used in kernel contexts whenadding another stack frame for cleanup isn’t a good idea. canonical example of kernel cleanup is as below.     if else else-if are control flow keywords. There are a few ways use these (1) A bare if (2) An if with an else (3) an if with anelse-if (4) an if with an else if else. Note that an else ismatched with most recent if. A subtle bug related amismatched if else statement, is . statements are always executed from if else. If anyof intermediate conditions are true, if block performs thataction goes end of that block.     inline is a compiler keyword that tells compiler it’s okay omit C function call procedure “paste” code in callee. Instead, compiler is hinted at substituting functionbody directly into calling function. This is not alwaysrecommended explicitly as compiler is usually smart enough know when inline a function for you.     restrict is a keyword that tells compiler that this particularmemory region shouldn’t overlap with all other memory regions. use case for this is tell users of program that it isundefined behavior if memory regions overlap. Note that memcpyhas undefined behavior when memory regions overlap. If this might case in your program, consider usingmemmove.     return is a control flow operator that exits current function. If function is void then it simply exits functions. Otherwise, another parameter follows as return value.     signed is a modifier which is rarely used, but it forces a type signed instead of unsigned. reason that this is so rarelyused is because types are signed by default need have unsigned modifier make them unsigned but it may useful incases where you want compiler default a signed type suchas below.     sizeof is an operator that is evaluated at compile-time, whichevaluates number of bytes that expression contains. When compiler infers type following code changes as follows.    Which then compiler is allowed operate on further. compiler must have a complete definition of type at compile-time  not link time - or else you may get an odd error. Consider following   This code will not compile because sizeof is not able compilefile. c without knowing full declaration of personstruct. That is typically why programmers either put fulldeclaration in a header file or we abstract creation interaction away so that users cannot access internals of ourstruct. Additionally, if compiler knows full length of anarray object, it will use that in expression instead of havingit decay into a pointer.   careful, using sizeof for length of a string!   static is a type specifier with three meanings.    When used with a global variable or function declaration itmeans that scope of variable or function is onlylimited file.    When used with a function variable, that declares that variable has static allocation – meaning that variable isallocated once at program startup not every time program isrun, its lifetime is extended that of program.        struct is a keyword that allows you pair multiple typestogether into a new structure. C-structs are contiguous regions ofmemory that one can access specific elements of each memory as ifthey were separate variables. Note that there might paddingbetween elements, such that each variable is memory-aligned (startsat a memory address that is a multiple of its size).     switch case default Switches are essentially glorified jumpstatements. Meaning that you take either a byte or an integer control flow of program jumps that location. Note that, various cases of a switch statement fall through. It means thatif execution starts in one case, flow of control will continue all subsequent cases, until a break statement.   If we give a value of 2 then  One of more famous examples of this is Duff’s device whichallows for loop unrolling. You don’t need understand this codefor purposes of this class, but it is fun look at (Duff,).   This piece of code highlights that switch statements are gotostatements, you can put any code on other end of a switchcase. Most of time it doesn’t make sense, some of time itjust makes too much sense.    typedef declares an alias for a type. Often used with structs reduce visual clutter of having write ‘struct’ as part of type.   In this class, we regularly typedef functions. A typedef for afunction can this for example  This declares a function type comparator that accepts two void*params returns an integer.    union is a new type specifier. A union is one piece of memory thatmany variables occupy. It is used maintain consistency whilehaving flexibility switch between types without maintainingfunctions keep track of bits. Consider an example where wehave different pixel values.     unsigned is a type modifier that forces unsigned behavior in variables they modify. Unsigned can only used with primitive inttypes (like int long). There is a lot of behavior associatedwith unsigned arithmetic. For most part, unless your codeinvolves bit shifting, it isn’t essential know difference inbehavior with regards unsigned signed arithmetic.    void is a double meaning keyword. When used in terms of functionor parameter definition, it means that function explicitlyreturns no value or accepts no parameter, respectively. following declares a function that accepts no parameters returnsnothing.   other use of void is when you are defining an lvalue. Avoid * pointer is just a memory address. It is specified as anincomplete type meaning that you cannot dereference it but it can promoted any time any other type. Pointer arithmetic with thispointer is undefined behavior.     volatile is a compiler keyword. This means that compilershould not optimize its value out. Consider following simplefunction.   compiler may, since internals of while loop have nothing do with flag, optimize it following even though afunction may alter data.   If you use volatile keyword, compiler is forced keep variable in perform that check. This is useful for cases whereyou are doing multi-process or multi-threaded programs so that wecan affect running of one sequence of execution with another.    ` while ` represents traditional while loop. There is acondition at top of loop, which is checked before everyexecution of loop body. If condition evaluates a non-zerovalue, loop body will run.  C data typesThere are many data types in C. As you may realize, all of them areeither integers or floating point numbers other types are variationsof these.   char Represents exactly one byte of data. number of bits in abyte might vary. unsigned char signed char are always same size, which is true for unsigned signed versions ofall data types. This must aligned on a boundary (meaning youcannot use bits in between two addresses). rest of typeswill assume 8 bits in a byte.    short (short int) must at least two bytes. This is aligned on atwo byte boundary, meaning that address must divisible bytwo.    int must at least two bytes. Again aligned a two byteboundary (“ISO C Standard” P. 34). On most machines this will 4 bytes.    long (long int) must at least four bytes, which are aligned a four byte boundary. On some machines this can 8 bytes.    long long must at least eight bytes, aligned an eight byteboundary.    float represents an IEEE-754 single precision floating pointnumber tightly specified by IEEE (“IEEE Standard for Floating-PointArithmetic” ). This will four bytes aligned a four byte boundary on most machines.    double represents an IEEE-754 double precision floating pointnumber specified by same standard, which is aligned nearest eight byte boundary.  If you want a fixed width integer type, for more portable code, you mayuse types defined in stdint. h, which are of form[u]intwidth_t, where u (which is optional) represents signedness, width is any of 8, 16, 32, 64. OperatorsOperators are language constructs in C that are defined as part of grammar of language. These operators are listed in order ofprecedence.   [] is subscript operator. a[n] == *(a + n) where n is anumber type a is a pointer type.    -&gt; is structure dereference (or arrow) operator. If you have apointer a struct *p, you can use this access one of itselements. p-&gt;element.    . is structure reference operator. If you have an object athen you can access an element a. element.    +/-a is unary plus minus operator. They either keep ornegate sign, respectively, of integer or float typeunderneath.    *a is dereference operator. If you have a pointer *p, youcan use this access element located at this memory address. If you are reading, return value will size of underlying type. If you are writing, value will written withan offset.    &amp;a is address-of operator. This takes an element returnsits address.    ++ is increment operator. You can use it as a prefix orpostfix, meaning that variable that is being incremented caneither before or after operator. a = 0; ++a == 1 a= 1; a++ == 0.    -- is decrement operator. This has same semantics as increment operator except that it decreases value of variable by one.    sizeof is sizeof operator, that is evaluated at time ofcompilation. This is also mentioned in keywords section.    a &lt;mop&gt; b where &lt;mop&gt; in {+, -, *, %, /} are arithmeticbinary operators. If operands are both number types, then operations are plus, minus, times, modulo, divisionrespectively. If left operand is a pointer right operandis an integer type, then only plus or minus may used rules for pointer arithmetic are invoked.    &gt;&gt;/&lt;&lt; are bit shift operators. operand on right has an integer type whose signedness is ignored unless it is signednegative in which case behavior is undefined. operator on left decides a lot of semantics. If we are left shifting, therewill always zeros introduced on right. If we are rightshifting there are a few different cases   If operand on left is signed, then integer issign-extended. This means that if number has sign bitset, then any shift right will introduce ones on left. If number does not have sign bit set, any shift right willintroduce zeros on left.    If operand is unsigned, zeros will introduced on lefteither way.      Note that shifting by word size (e. g. by 64 in a 64-bitarchitecture) results in undefined behavior.    &lt;=/&gt;= are greater than equal to/less than equal to, relationaloperators. They work as their name implies.    &lt;/&gt; are greater than/less than relational operators. Theyagain do as name implies.    ==/= are equal/not equal relational operators. They onceagain do as name implies.    &amp;&amp; is logical AND operator. If first operand is zero, second won’t evaluated expression will evaluate 0. Otherwise, it yields a 1-0 value of second operand.   || is logical OR operator. If first operand is not zero,then second won’t evaluated expression will evaluate  Otherwise, it yields a 1-0 value of second operand.     ! is logical NOT operator. If operand is zero, then thiswill return 1. Otherwise, it will return 0.    &amp; is bitwise AND operator. If a bit is set in both operands,it is set in output. Otherwise, it is not.    | is bitwise OR operator. If a bit is set in either operand,it is set in output. Otherwise, it is not.       is bitwise NOT operator. If a bit is set in input, itwill not set in output vice versa.     ?: is ternary / conditional operator. You put a boolean condition before if it evaluates non-zero element before colon is returned otherwise element after is. `1 ? a b == a 0 ? a : b == b`.    a, b is comma operator. a is evaluated then b isevaluated b is returned. In a sequence of multiple statementsdelimited by commas, all statements are evaluated from left right, right-most expression is returned.  C LinuxUp until this point, we’ve covered C’s language fundamentals. We’ll now focusing our attention C POSIX variety of functionsavailable us interact with operating systems. We will talkabout portable functions, for example fwrite printf. We will evaluating internals scrutinizing them under POSIX models more specifically GNU/Linux. There are several things thatphilosophy that makes rest of this easier know, so we’ll putthose things here. Everything is a fileOne POSIX mantra is that everything is a file. Although that has becomerecently outdated, moreover wrong, it is convention we still usetoday. What this statement means is that everything is a filedescriptor, which is an integer. For example, here is a file object, anetwork socket, a kernel object. These are all references recordsin kernel’s file descriptor table.  operations on those objects are done through system calls. One lastthing note before we move on is that file descriptors are merelypointers. Imagine that each of file descriptors in exampleactually refers an entry in a table of objects that operatingsystem picks chooses from (that is, file descriptor table). Objects can allocated deallocated, closed opened, etc. program interacts with these objects by using API specified throughsystem calls, library functions. System CallsBefore we dive into common C functions, we need know what a systemcall is. If you are a student have completed HW0, feel free glossover this section. A system call is an operation that kernel carries out. First, operating system prepares a system call. Next, kernel executes system call best of its ability in kernel space is aprivileged operation. In previous example, we got access a filedescriptor object. We can now also write some bytes filedescriptor object that represents a file, operating system willdo its best get bytes written disk. When we say kernel tries its best, this includes possibilitythat operation could fail for several reasons. Some of them are: file is no longer valid, hard drive failed, system wasinterrupted etc. way that a programmer communicates with outsidesystem is with system calls. An important thing note is that systemcalls are expensive. Their cost in terms of time CPU cycles hasrecently been decreased, but try use them as sparingly as possible. C System CallsMany C functions that will discussed in next sections areabstractions that call correct underlying system call, based on current platform. Their Windows implementation, for example, may entirely different from that of other operating systems. Nevertheless,we will studying these in context of their Linux implementation. Common C Functions find more information about any functions, please use man pages. Note man pages are organized into sections. Section 2 are Systemcalls. Section 3 are C libraries. On web, Google man 7 open. In shell, man -S2 open or man -S3 printfHandling ErrorsBefore we get into nitty gritty of all functions, know that mostfunctions in C handle errors return oriented. This is at odds withprogramming languages like C++ or Java where errors are handled withexceptions. There are a number of arguments against exceptions.   Exceptions make control flow harder understand.    Exception oriented languages need keep stack traces maintainjump tables.    Exceptions may complex objects.  There are a few arguments for exceptions as well  Exceptions can come from several layers deep.    Exceptions help reduce global state.    Exceptions differentiate business logic normal flow.  Whatever pros/cons are, we use former because of backwardscompatibility with languages like FORTRAN (“FORTRAN IV PROGRAMMER’SREFERENCE MANUAL” P. 84). Each thread will get a copy of errno because it is stored at topof each thread’s stack – more on threads later. One makes a call afunction that could return an error if that function returns anerror according man pages, it is up programmer checkerrno. There is a shortcut function perror that prints englishdescription of errno. Also, a function may return error code in return value itself.  sure check man page for return code characteristics. Input / OutputIn this section we will cover all basic input output functionsin standard library with references system calls. Every processhas three streams of data when it starts execution: standard input (forprogram input), standard output (for program output), standard error(for error debug messages). Usually, standard input is sourced from terminal in which program is being run in, standard out is same terminal. However, a programmer can use redirection such thattheir program can send output and/or receive input, from a file,or other programs. They are designated by file descriptors 0 1 respectively. 2 isreserved for standard error which by library convention is unbuffered(i. e. IO operations are performed immediately). stdout oriented streamsStandard output or stdout oriented streams are streams whose onlyoptions are write stdout. printf is function with which mostpeople are familiar in this category. first parameter is a formatstring that includes placeholders for data printed. Commonformat specifiers are following  %s treat argument as a c string pointer, keep printing allcharacters until NULL-character is reached   %d prints argument as an integer   %p print argument as a memory address.  For performance, printf buffers data until its cache is full or anewline is printed. Here is an example of printing things out. From previous section, printf calls system call write. printf is a C library function, while write is a system call system.  buffering semantics of printf is a little complicated. ISO definesthree types of streams (“ISO C Standard” P. 278)  Unbuffered, where contents of stream reach their destinationas soon as possible.    Line Buffered, where contents of stream reach theirdestination as soon as a newline is provided.    Fully Buffered, where contents of stream reach theirdestination as soon as buffer is full.  Standard Error is defined as “not fully buffered” (“ISO C Standard” P. 279). Standard Output Input are merely defined fully buffered if only if streamdestination is not an interactive device. Usually, standard error will unbuffered, standard input output will line buffered if output is a terminal otherwise fully buffered. This relates printfbecause printf merely uses abstraction provided by FILEinterface uses above semantics determine when write. Onecan force a write by calling fflush() on stream.  print strings single characters, use puts(char name ) putchar(char c )Other streams print other file streams, usefprintf( _file_ , \"Hello %s, score: %d\", name, score); Where_file_ is either predefined (‘stdout’ or ‘stderr’) or a FILE pointerthat was returned by fopen or fdopen. There is a printf equivalentthat works with file descriptors, called dprintf. Just usedprintf(int fd, char* format_string, . . . );.  print data into a C string, use sprintf or better snprintf. snprintf returns number of characters written excluding terminating byte. We would use sprintf size of printed stringis less than provided buffer – think about printing an integer, itwill never more than 11 characters with NUL byte. If printf isdealing with variadic input, it is safer use former function asshown in following snippet. stdin oriented functionsStandard input or stdin oriented functions read from stdin directly. Most of these functions have been deprecated due them being poorlydesigned. These functions treat stdin as a file from which we can readbytes. One of most notorious offenders is gets. gets isdeprecated in C99 standard has been removed from latest Cstandard (C11). reason that it was deprecated was that there is noway control length being read, therefore buffers could getoverrun easily. When this is done maliciously hijack program controlflow, this is known as a buffer overflow. Programs should use fgets or getline instead. Here is a quickexample of reading at most 10 characters from standard input. Note that, unlike gets, fgets copies newline into buffer. On other hand, one of advantages of getline is that willautomatically allocate reallocate a buffer on heap of sufficientsize. In addition those functions, we have perror that has a two-foldmeaning. Let’s say that a function call failed using errnoconvention. perror(const char* message) will print English versionof error stderr.  have a library function parse input in addition reading it, usescanf (or fscanf or sscanf) get input from default inputstream, an arbitrary file stream or a C string, respectively. All ofthose functions will return how many items were parsed. It is a goodidea check if number is equal amount expected. Alsonaturally like printf, scanf functions require valid pointers. Instead of pointing valid memory, they need also writable. It’sa common source of error pass in an incorrect pointer value. Forexample,We wanted write character value into c integer value into malloc’d memory. However, we passed address of data pointer,not what pointer is pointing to! So sscanf will change pointer itself. pointer will now point address 10 so this codewill later fail when free(data) is called. Now, scanf will keep reading characters until string ends. stopscanf from causing a buffer overflow, use a format specifier. Make sure pass one less than size of buffer. One last thing note is if system calls are expensive, scanffamily is much more expensive due compatibility reasons. Since itneeds able process all of printf specifiers correctly, code isn’t efficient TODO: citation needed. For highly performantprograms, one should write parsing themselves. If it is a one-offprogram or script, feel free use scanf. string. hString. h functions are a series of functions that deal with how manipulate check pieces of memory. Most of them deal with C-strings. A C-string is a series of bytes delimited by a NUL character which isequal byte 0x00. . Any behavior missing from documentation, such as result ofstrlen(NULL) is considered undefined behavior.   int strlen(const char *s) returns length of string.    int strcmp(const char *s1, const char *s2) returns an integerdetermining lexicographic order of strings. If s1 where come before s2 in a dictionary, then a -1 is returned. If twostrings are equal, then 0. Else, 1.    char *strcpy(char *dest, const char *src) Copies string atsrc dest. This function assumes dest has enough space forsrc otherwise undefined behavior   char *strcat(char *dest, const char *src) Concatenates stringat src end of destination. This function assumes thatthere is enough space for src at end of destination including NUL byte   char *strdup(const char *dest) Returns a malloc’d copy of string.    char *strchr(const char *haystack, int needle) Returns a pointer first occurrence of needle in haystack. If nonefound, NULL is returned.    char *strstr(const char *haystack, const char *needle) Same asabove but this time a string!   char *strtok(const char *str, const char *delims) A dangerous but useful function strtok takes a string tokenizesit. Meaning that it will transform strings into separatestrings. This function has a lot of specs so please read manpages a contrived example is below.   Output  Why is it tricky? Well what happens when upped is changed following?    For integer parsing use long int strtol(const char *nptr, char**endptr, int base); or long long int strtoll(const char *nptr,char **endptr, int base);.  What these functions do is take pointer your string *nptr a base (i. e. binary, octal, decimal, hexadecimal etc) anoptional pointer endptr returns a parsed value.   careful though! Error handling is tricky because functionwon’t return an error code. If passed an invalid number string, itwill return 0. caller has careful from a valid 0 anerror. This often involves an errno trampoline as shown below.     void *memcpy(void *dest, const void *src, size_t n) moves nbytes starting at src dest. careful, there isundefined behavior when memory regions overlap. This is one of classic “This works on my machine!” examples because many timesValgrind won’t able pick it up because it will look like itworks on your machine. Consider safer version memmove.    void *memmove(void *dest, const void *src, size_t n) does samething as above, but if memory regions overlap then it isguaranteed that all bytes will get copied over correctly. memcpy memmove both in string. h? C Memory Model C memory model is probably unlike most that you’ve seen before. Instead of allocating an object with type safety, we either use anautomatic variable or request a sequence of bytes with malloc oranother family member later we free it. StructsIn low-level terms, a struct is a piece of contiguous memory, nothingmore. Just like an array, a struct has enough space keep all of itsmembers. But unlike an array, it can store different types. Consider contact struct declared above. We will often use following typedef, so we can write use structname as full type. If you compile code without any optimizations reordering, youcan expect addresses of each of variables look like this. All your compiler does is say “reserve this much space”. Whenever a reador write occurs in code, compiler will calculate offsets of variable. offsets are where variable starts at. phonevariables starts at 0x128th bytes continues for sizeof(int)bytes with this compiler. Offsets don’t determine where variableends though. Consider following hack seen in a lot of kernel code. Currently, our memory looks like following image. There is nothingin those boxesSo what happens when we assign length? first four boxes are filledwith value of variable at length. rest of space is leftuntouched. We will assume that our machine is big endian. This meansthat least significant byte is last. Now, we can write a string end of our struct with followingcall. We can even do a sanity check make sure that strings are equal. What that zero length array does is point end of structthis means that compiler will leave room for all of elementscalculated with respect their size on operating system (ints,chars, etc). zero length array will take up no bytes of space. Sincestructs are continuous pieces of memory, we can allocate more spacethan required use extra space as a place store extra bytes. Although this seems like a parlor trick, it is an important optimizationbecause have a variable length string any other way, one would need have two different memory allocation calls. This is highlyinefficient for doing something as common in programming as is stringmanipulation. Strings in CIn C, we havestrings rather thanfor historical reasons. For everyday programmers, remember NULterminate your string! A string in C is defined as a bunch of bytesended by ‘’ or NUL Byte. Places for stringsWhenever you define a string literal - one in formchar* str = \"constant\" – that string is stored in datasection. Depending on your architecture, it is read-only, meaningthat any attempt modify string will cause a SEGFAULT. One canalso declare strings either in writable data segment or stack. do so, specify a length for string or put brackets insteadof a pointer char str[] = \"mutable\" put in global scope or function scope for data segment or stack respectively. If one,however, malloc’s space, one can change that string whateverthey want. Forgetting NUL terminate a string has a big effect on strings! Bounds checking is important. heartbleed bug mentionedearlier in book is partially because of this. Strings in C are represented as characters in memory. end of string includes a NUL (0) byte. So “ABC” requires four(4) bytes. only way find out length of a C string is keep reading memoryuntil you find NUL byte. C characters are always exactly one byteeach. String literals are constantA string literal is naturally constant. Any write will cause operating system produce a SEGFAULT. String literals are character arrays stored in read-only datasegment of program, which is immutable. Two string literals mayshare same space in memory. An example follows.  strings pointed by str1 str2 may actually reside in same location in memory. Char arrays, however, contain literal value which has been copiedfrom code segment into either stack or static memory. Thesefollowing char arrays reside in different memory locations. Here are some common ways initialize a string include. Where do theyreside in memory?We can also print out pointer contents of a C-string easily. Here is some boilerplate code illustrate this. As mentioned before, char array is mutable, so we can change itscontents. careful write within bounds of array. C doesnot do bounds checking at compile-time, but invalid reads/writes canget your program crash. Unlike array, however, we can change ptr point another pieceof memory,Unlike pointers, that hold addresses variables on heap, or stack,char arrays (string literals) point read-only memory located in data section of program. This means that pointers are more flexiblethan arrays, even though name of an array is a pointer itsstarting address. In a more common case, pointers will point heap memory in which case memory referred by pointer can modified. PointersPointers are variables that hold addresses. These addresses have anumeric value, but usually, programmers are interested in value of contents at that memory address. In this section, we will try take you through a basic introduction pointers. Pointer BasicsDeclaring a PointerA pointer refers a memory address. type of pointer is useful– it tells compiler how many bytes need read/written delineates semantics for pointer arithmetic (addition subtraction). Due C’s syntax, an int* or any pointer is not actually its owntype. You have precede each pointer variable with an asterisk. As acommon gotcha, followingWill only declare *ptr3 as a pointer. ptr4 will actually aregular int variable. fix this declaration, ensure * precedes pointer. Keep this in mind for structs as well. If one declares without atypedef, then pointer goes after type. Reading / Writing with pointersLet’s say that int ptr was declared. For sake of discussion, letus assume that ptr contains memory address 0x1000. write pointer, it must dereferenced assigned a value. What C does is take type of pointer which is an int writesizeof(int) bytes from start of pointer, meaning that bytes0x1000, 0x1001, 0x1002, 0x1003 will all zero. number ofbytes written depends on pointer type. It is same for allprimitive types but structs are a little different. Reading works roughly same way, except you put variable in spot that it needs value. Reading writing non-primitive types gets tricky. compilationunit - usually file or a header - needs have size of datastructure readily available. This means that opaque data structurescan’t copied. Here is an example of assigning a struct pointer:As for reading structure pointers, don’t do it directly. Instead,programmers create abstractions for creating, copying, destroyingstructs. If this sounds familiar, it is what C++ originally intended do before standards committee went off deep end. Pointer ArithmeticIn addition adding an integer, pointers can added to. However, pointer type is used determine how much increment pointer. A pointer is moved over by value added times size of underlying type. For char pointers, this is trivial because charactersare always one byte. If an int is 4 bytes then ptr+1 points 4 bytes after whatever ptr ispointing at. Notice how only ’EFGH’ is printed. Why is that? Well as mentioned above,when performing ’bna+=1’ we are increasing **integer** pointerby 1, (translates 4 bytes on most systems) which is equivalent 4characters (each character is only 1 byte) Because pointer arithmetic inC is always automatically scaled by size of type that is pointedto, POSIX standards forbid arithmetic on void pointers. Having saidthat, compilers will often treat underlying type as char. Here isa machine translation. following two pointer arithmetic operationsare equalEvery time you do pointer arithmetic, take a deep breath make surethat you are shifting over number of bytes you think you areshifting over. So what is a void pointer?A void pointer is a pointer without a type. Void pointers are used wheneither datatype is unknown or when interfacing C code with otherprogramming languages without APIs. You can think of this as a rawpointer, or a memory address. malloc by default returns a void pointerthat can safely promoted any other type. C automatically promotes void* its appropriate type. gcc clang are not totally ISO C compliant, meaning that they will permitarithmetic on a void pointer. They will treat it as a char pointer. Donot do this because it is not portable - it is not guaranteed workwith all compilers!Common BugsNul BytesWhat’s wrong with this code?In above code it simply changes dest pointer point sourcestring. Also NUL bytes are not copied. Here is a better version -Note that it is also common see following kind of implementation,which does everything inside expression test, including copying NUL byte. However, this is bad style, as a result of doing multipleoperations in same line. Double FreesA double free error is when a program accidentally attempt free same allocation twice.  fix is first write correct programs! Secondly, it is a goodhabit set pointers NULL, once memory has been freed. Thisensures that pointer cannot used incorrectly without programcrashing. Returning pointers automatic variablesAutomatic variables are bound stack memory only for lifetime of function. After function returns, it is an error continue use memory. Insufficient memory allocationIn above example, we needed allocate enough bytes for struct. Instead, we allocated enough bytes hold a pointer. Once we startusing user pointer we will corrupt memory. correct code is shownbelow. Buffer overflow/ underflowA famous example: Heart Bleed performed a memcpy into a buffer that wasof insufficient size. A simple example: implement a strcpy forget add one strlen, when determining size of memory required. C fails check if pointers are valid. above example writes intoarray[10] which is outside array bounds. This can cause memorycorruption because that memory location is probably being used forsomething else. In practice, this can harder spot because overflow/underflow may occur in a library call. Here is our old friendgets. Strings require strlen(s)+1 bytesEvery string must have a NUL byte after last characters. store string “Hi” it takes 3 bytes: [H] [i] [\\0]. Using uninitialized variablesAutomatic variables hold garbage or bit pattern that happened inmemory or register. It is an error assume that it will always initialized zero. Assuming Uninitialized memory will zeroedAutomatic (temporary variables) heap allocations may contain randombytes or garbage. Logic Program flow mistakesThese are a set of mistakes that may let program compile but performunintended functionality. Equal vs. EqualityConfusingly in C, assignment operator also returns assignedvalue. Most of time it is ignored. We can use it initializemultiple things on same line. More confusingly, if we forget an equals sign in equality operatorwe will end up assigning that variable. Most of time this isn’t whatwe want do.  quick way fix that is get in habit of putting constantsfirst. This mistake is common enough in while loop conditions. Mostmodern compilers disallows assigning variables a condition withoutparenthesis. There are cases where we want do it. A common example is getline. This piece of code calls getline, assigns return value or number of bytes read nread. It also in same line checks if thatvalue is -1 if so terminates loop. It is always good practice put parentheses around any assignment condition. Undeclared or incorrectly prototyped functionsSome snippets of code may do following.  system function ‘time’ actually takes a parameter a pointer somememory that can receive time_t structure or NULL. compilerfails catch this error because programmer omitted validfunction prototype by including time. h. More confusingly this could compile, work for decades then crash. reason for that is that time would found at link time, notcompile-time in C standard library which almost surely is already inmemory. Since a parameter isn’t being passed, we are hoping arguments on stack (any garbage) is zeroed out because if it isn’t,time will try write result of function that garbage whichwill cause program SEGFAULT. Extra SemicolonsThis is a pretty simple one, don’t put semicolons when unneeded. However, following code is perfectly OK. It is OK have this kind of code because C language usessemicolons (;) separate statements. If there is no statement inbetween semicolons, then there is nothing do compiler moveson next statement save a lot of confusion, always usebraces. It increases number of lines of code, which is a greatproductivity metric. Topics  C-strings representation   C-strings as pointers   char p[]vs char* p   Simple C string functions (strcmp, strcat, strcpy)   sizeof char   sizeof x vs x*   Heap memory lifetime   Calls heap allocation   Dereferencing pointers   Address-of operator   Pointer arithmetic   String duplication   String truncation   double-free error   String literals   Print formatting.    memory out of bounds errors   static memory   file input / output. POSIX vs. C library   C input output: fprintf printf   POSIX file IO (read, write, open)   Buffering of stdout Questions/Exercises  What does following print out?    What are differences between following two declarations?What does sizeof return for one of them?    What is a string in C?   Code up a simple my_strcmp. How about my_strcat, my_strcpy, ormy_strdup? Bonus: Code functions while only going through strings once.    What should each of following lines usually return?    What is malloc? How is it different from calloc. Once memory isallocated how can we use realloc?   What is &amp; operator? How about *?   Pointer Arithmetic. Assume following addresses. What are following shifts?    ptr + 2   ptr + 4   ptr[0] + 4   ptr[1] + 2000   *((int)(ptr + 1)) + 3     How do we prevent double free errors?   What is printf specifier print a string, int, or char?   Is following code valid? Why? Where is output located?    Write a function that accepts a path as a string, opens thatfile, prints file contents 40 bytes at a time but, every otherprint reverses string (try using POSIX API for this).    What are some differences between POSIX file descriptor model C’s FILE* (i. e. what function calls are used which isbuffered)? Does POSIX use C’s FILE* internally or vice versa? Rapid Fire: Pointer ArithmeticPointer arithmetic is important! Take a deep breath figure out howmany bytes each operation moves a pointer. following is a rapid firesection. We’ll use following definitions:How many bytes are moved over from following additions?  int_ + 1   long_ + 7   short_ - 6   short_ - sizeof(long)   long_ - sizeof(long) + sizeof(int_)   long_ - sizeof(long) / sizeof(int)   (char*)(int_ptr + sizeof(long)) + sizeof(int_) Rapid Fire Solutions  4   56   -12   -16   0   -16   72 Duff, Tom. n. d. “Tom Duff on Duff’s Device. ” *Tom Duff on Duff’sDevice*. . “FORTRAN IV PROGRAMMER’S REFERENCE MANUAL. ” 1972. Manual. Maynard,MASSACHUSETTS: DIGITAL EQUIPMENT CORPORATION. . “IEEE Standard for Floating-Point Arithmetic. ” 2008. *IEEE Std754-2008*, August, 1–70. . Inc. , Apple. 2017. “XNU Kernel. ” *GitHub Repository*. ;GitHub. “ISO C Standard. ” 2005. Standard. Geneva, CH: International Organizationfor Standardization. . Kernighan, B. W. , D. M. Ritchie. 1988. *The c Programming Language*. Prentice-Hall Computer software Series. Prentice Hall. . Love, Robert. 2010. *Linux Kernel Development*. 3rd ed. Addison-WesleyProfessional. Ritchie, Dennis M. 1993. “The Development of c Language. ” *SIGPLANNot. * 28 (3): 201–8. . ","url":"/coursebook/Introc"},{"title":"Introduction","content":"      Introduction thy happy children of future, those of past sendgreetings. - Alma MaterAt University of Illinois at Urbana-Champaign, We fundamentallybelieve that we have a right make university better for allfuture students. It is a message etched into our Alma Mater makes up DNA of our course staff. As such, we created coursebook. coursebook is a free open systems programming textbook that anyonecan read, contribute to, modify for now forever. We don’t thinkinformation should behind a walled garden, we truly believe thatcomplex concepts can explained simply fully, for anyone understand. goal of this book is teach you basics giveyou some intuition into complexities of systems programming. Like any good book, it isn’t complete. We still have plenty of examples,ideas, typos, chapters work on. If you find any issues, pleasefile anor email a list of typos , we’ll happy work on it. We are constantly trying make book better for students a year ten years from now. This work is based on original coursebook located at. All these peoples’ hard work is included in section below. Oh duck? Keep reading until synchronization :). Thanks again happy reading!– BhuvyAuthors","url":"/coursebook/Introduction"},{"title":"Ipc","content":"                                               Virtual Memory Interprocess CommunicationAbbott: Now you’ve got it. Costello: I throw ball Naturally. Abbott: You don’t! You throw it Who!Costello: Naturally. Abbott: Well, that’s it - say it that way. Costello: That’s what I said. - Abbott Costello on EffectiveCommunicationIn simple embedded systems early computers, processes directlyaccess memory – “Address 1234” corresponds a particular byte storedin a particular part of physical memory. For example, IBM 709 had read write directly tape with no level of abstraction ((IBM),August 1958 P. 65). Even in systems after that, it was hard adoptvirtual memory because virtual memory required whole fetch cycle altered through hardware – a change many manufacturers still thoughtwas expensive. In PDP-10, a workaround was used by using differentregisters for each process then virtual memory was added later (“DECPdp-10 Ka10 Control Panel,” ). Inmodern systems, this is no longer case. Instead, each process isisolated, there is a translation process between address of aparticular CPU instruction or piece of data of a process actualbyte of physical memory (“RAM”). Memory addresses no longer map physical addresses process runs inside virtual memory. Virtualmemory keeps processes safe because one process cannot directly read ormodify another process’s memory. Virtual memory also allows system efficiently allocate reallocate portions of memory differentprocesses. modern process of translating memory is as follows.   A process makes a memory request   circuit first checks Translation Lookaside Buffer (TLB) if address page is cached into memory. It skips readingfrom/writing phase if found otherwise request goes MMU.    Memory Management Unit (MMU) performs address translation. If translation succeeds, page gets pulled from RAM –conceptually entire page isn’t loaded up. result is cachedin TLB.    CPU performs operation by either reading from physicaladdress or writing address.  Translating Addresses Memory Management Unit is part of CPU, it converts a virtualmemory address into a physical address. First, we’ll talk about what virtual memory abstraction is how translate addresses illustrate, consider a 32-bit machine, meaning pointers are 32-bits. They can address \\(2^{32}\\) different locations or 4GB of memory whereone address is one byte. Imagine we had a large table for every possibleaddress where we will store ‘real’ i. e.  physical address. Eachphysical address will need 4 bytes – hold 32-bits. Naturally,This scheme would require 16 billion bytes store all of entries. It should painfully obvious that our lookup scheme would consume allof memory that we could buy for our 4GB machine. Our lookup tableshould smaller than memory we have otherwise we will have nospace left for our actual programs operating system data. solution is chunk memory into small regions called ‘pages’ ‘frames’ use a lookup table for each page. TerminologyA page is a block of virtual memory. A typical block size on Linuxis 4KiB or \\(2^{12}\\) addresses, though one can find examples oflarger blocks. So rather than talking about individual bytes, we cantalk about blocks of 4KiBs, each block is called a page. We can alsonumber our pages (“Page 0” “Page 1” etc). Let’s do a sample calculationof how many pages are there assume page size of 4KiB. For a 32-bitmachine,\\[2^{32} \\text{address} / 2^{12} \\text{(address/page)} = 2^{20} \\text{pages}. \\]For a 64-bitmachine,\\[2^{64} \\text{address} / 2^{12} \\text{(address/page)} = 2^{52} \\text{pages} ≈10^{15} \\text{pages}. \\]We also call this a frame or sometimes called a ‘page frame’ is ablock of physical memory or RAM – Random Access Memory. A frame is same number of bytes as a virtual page or 4KiB on our machine. It stores bytes of interest. access a particular byte in a frame, an MMUgoes from start of frame adds offset – discussed later. A page table is a map from a number a particular frame. Forexample Page 1 might mapped frame 45, page 2 mapped frame 30. Other frames might currently unused or assigned other runningprocesses or used internally by operating system. Implied from name, imagine a page table as a table. In practice, we will omit first column because it will always sequentially 0, 1, 2, etc instead we’ll use offset from start of table as entry number. Now go through actual calculations. We will assume that a 32-bitmachine has 4KiB pages Naturally, address all possible entries,there are \\(2^{20}\\) frames. Since there are \\(2^{20}\\) possibleframes, we will need 20 bits number all of possible framesmeaning Frame Number must 2. 5 bytes long. In practice, we’ll roundthat up 4 bytes do something interesting with rest of bits. With 4 bytes per entry x \\(2^{20}\\) entries = 4 MiB of physicalmemory are required hold entire page table for a process. Remember our page table maps pages frames, but each frame is a blockof contiguous addresses. How do we calculate which particular byte use inside a particular frame? solution is re-use lowest bitsof virtual memory address directly. For example, suppose our processis reading following address- VirtualAddress= 11110000111100001111000010101010 (binary)So give an example say we have virtual address above. How wouldwe split it up using a one-page table frame scheme?We can imagine steps dereference as one process. In general, itlooks like following.  way read from a particular address above is visualized below.  if we were reading from it, ’return’ that value. This sounds like aperfect solution. Take each address map it a virtual address insequential order. process will believe that address lookscontinuous, but top 20 bits are used figure out page_num, whichwill allow us find frame number, find frame, add offset – derived from last 12 bits – do read or write. There are other ways split it as well. On a machine with page size256 Bytes, then lowest 8 bits (10101010) will used as offset. remaining upper bits will page number(111100001111000011110000). This offset is treated as a binary number is added start of frame when we get it. We do have a problem with 64-bit operating systems. For a 64-bit machinewith 4KiB pages, each entry needs 52 bits. Meaning we need roughly With\\(2^{52}\\) entries, that’s \\(2^{55}\\) bytes (roughly 40 petabytes). So our page table is too large. In 64-bit architecture, memory addressesare sparse, so we need a mechanism reduce page table size, giventhat most of entries will never used. We’ll take about thisbelow. There is one last piece of terminology that needs covered. Multi-level page tablesMulti-level pages are one solution page table size issue for64-bit architectures. We’ll look at simplest implementation - atwo-level page table. Each table is a list of pointers that point next level of tables, som sub-tables may omitted. An example, atwo-level page table for a 32-bit architecture is shown below. So what is intuition for dereferencing an address? First, MMUtakes top-level page table find Index1’th entry. That willcontain a number that will lead MMU appropriate sub-tableThen go Index2’th entry of that table. That will contain aframe number. This is good old fashioned 4KiB RAM that we weretalking about earlier. Then, MMU adds offset do read orwrite. Visualizing DereferenceIn one diagram, dereference looks like following image. Following our example, here is what dereference would look like. Calculating Size ConcernsNow some calculations on size. Each page_table_num index is 10 bitswide because there are only \\(2^{10}\\) possible sub-tables, so weneed 10 bits store each directory index. We’ll round up 2 bytesfor sake of reasoning. If 2 bytes are used for each entry in top-level table there are only \\(2^{10}\\) entries, we only need2KiB store this entire first level page table. Each subtable willpoint physical frames, each of their entries needs required 4 bytes able address all frames as mentionedearlier. However, for processes with only tiny memory needs, we onlyneed specify entries for low memory addresses for heap program code high memory addresses for stack. Thus, total memory overhead for our multi-level page table hasshrunk from 4MiB for single-level implementation three pagetables of memory or 2KiB for top-level 4KiB for twointermediate levels of size 10KiB. Here’s why. We need at least oneframe for high-level directory two frames for two sub-tables. One sub-table is necessary for low addresses – program code,constants possibly a tiny heap. other sub-table is for higheraddresses used by environment stack. In practice, real programswill likely need more sub-table entries, as each subtable can onlyreference 1024*4KiB = 4MiB of address space. main point stillstands. We have significantly reduced memory overhead required perform page table lookups. Page Table DisadvantagesThere are lots of problems with page tables – one of big problems isthat they are slow. For a single page table, our machine is now twice asslow! Two memory accesses are required. For a two-level page table,memory access is now three times as slow – three memory accesses arerequired.  overcome this overhead, MMU includes an associative cache ofrecently-used virtual-page-to-frame lookups. This cache is called TLB (“translation lookaside buffer”). Every time a virtual address needs translated into a physical memory location, TLB is queried inparallel page table. For most memory accesses of most programs,there is a significant chance that TLB has cached results. However, if a program has inadequate cache coherence, address will missing in TLB, meaning MMU must use much slower pagetable translation. MMU AlgorithmThere is a sort of pseudocode associated with MMU. We will assumethat this is for a single-level page table.   Receive address   Try translate address according programmed scheme   If translation fails, report an invalid address   Otherwise,   If TLB contains physical memory, get physical framefrom TLB perform read write.    If page exists in memory, check if process haspermissions perform operation on page meaning process has access page, it is reading from page/writing a page that it has permission do so.    If so then do dereference provide address, cache results in TLB   Otherwise, trigger a hardware interrupt. kernel willmost likely send a SIGSEGV or a Segmentation Violation.      If page doesn’t exist in memory, generate an Interrupt.    kernel could realize that this page could either notallocated or on disk. If it fits mapping, allocate page try operation again.    Otherwise, this is invalid access kernel will mostlikely send a SIGSEGV process.      How would you alter this for a multi-level page table?Frames Page ProtectionsFrames can shared between processes, this is where heart of chapter comes into play. We can use these tables communicate withprocesses. In addition storing frame number, page table can used store whether a process can write or only read a particularframe. Read-only frames can then safely shared between multipleprocesses. For example, C-library instruction code can sharedbetween all processes that dynamically load code into processmemory. Each process can only read that memory. Meaning that if aprogram tries write a read-only page in memory, it willSEGFAULT. That is why sometimes memory accesses SEGFAULT sometimesthey don’t, it all depends on if your hardware says that a program canaccess. Also, processes can share a page with a child process using mmapsystem call. mmap is an interesting call because instead of tying eachvirtual address a physical frame, it ties it something else. It isan important distinction that we are talking about mmap notmemory-mapped IO in general. mmap system call can’t reliably used do other memory-mapped operations like communicate with GPUs write pixels screen – this is mainly hardware dependent. Bits on PagesThis is heavily dependent on chipset. We will include some bitsthat have historically been popular in chipsets.   read-only bit marks page as read-only. Attempts write page will cause a page fault. page fault will then handled by Kernel. Two examples of read-only page includesharing C standard library between multiple processes forsecurity you wouldn’t want allow one process modify library Copy-On-Write where cost of duplicating a page can delayed until first write occurs.    execution bit defines whether bytes in a page can executed asCPU instructions. Processors may merge these bits into one deema page either writable or executable. This bit is useful because itprevents stack overflow or code injection attacks when writing userdata into heap or stack because those are not read-only thus not executable. Further reading:   dirty bit allows for performance optimization. A pageexclusively read from can discarded without syncing disk,since page hasn’t changed. However, if page was written after it’s paged in, its dirty bit will set, indicating that page must written back backing store. This strategyrequires that backing store retain a copy of page after itis paged into memory. When a dirty bit is omitted, backing storeneed only as large as instantaneous total size of allpaged-out pages at any moment. When a dirty bit is used, at alltimes some pages will exist in both physical memory backingstore.    There are plenty of other bits. Take a look at your favoritearchitecture see what other bits are associated! Page FaultsA page fault may happen when a process accesses an address in a framemissing in memory. There are three types of Page Faults  Minor If there is no mapping yet for page, but it is a validaddress. This could memory asked for by sbrk(2) but not written yet meaning that operating system can wait for firstwrite before allocating space – if it was read from, operatingsystem could short circuit operation read 0. OS simplymakes page, loads it into memory, moves on.    Major If mapping page is exclusively on disk. operating system will swap page into memory swap anotherpage out. If this happens frequently enough, your program is said thrash MMU.    Invalid When a program tries write a non-writable memoryaddress or read a non-readable memory address. MMU generatesan invalid fault OS will usually generate a SIGSEGVmeaning segmentation violation meaning that program wroteoutside segment that it could write to.  Link Back IPCWhat does this have do with IPC? Before, you knew that processes hadisolation. One, you didn’t know how that isolation mapped. Two, you maynot know how you can break this isolation. break any memory levelisolation you have two avenues. One is ask kernel provide somekind of interface. other is ask kernel map two pages ofmemory same virtual memory area handle all synchronization yourself. mmapmmap is a trick of virtual memory of instead of mapping a page aframe, that frame can backed by a file on disk, or frame can shared among processes. We can use that read from a file on diskefficiently or sync changes file. One of big optimizations isa file may lazily allocated memory. Take following code forexample.  kernel sees that program wants mmap file into memory, soit will reserve some space in your address space that is length of file. That means when program writes addr[0] that it writes first byte of file. kernel can do some optimizations too. Instead of loading whole file into memory, it may only load pages ata time. A program may only access 3 or 4 pages making loading entirefile a waste of time. Page faults are so powerful because let operating system take control of when a file is used. mmap Definitionsmmap does more than take a file map it memory. It is general interface for creating shared memory among processes. Currentlyit only supports regular files POSIX shmem (“Mmap”). Naturally, you can readall about it in reference above, which references currentworking group POSIX standard. Some other options note in pagewill follow.  first option is that flags argument of mmap can take manyoptions.   PROT_READ This means process can read memory. This isn’t only flag that gives process read permission, however! underlying file descriptor, in this case, must opened with readprivileges.    PROT_WRITE This means process can write memory. Thishas supplied for a process write a mapping. If this issupplied PROT_NONE is also supplied, latter wins nowrites can performed. underlying file descriptor, in thiscase, must either opened with write privileges or a privatemapping must supplied below   PROT_EXEC This means process can execute this piece of memory. Although this is not stated in POSIX documents, this shouldn’t supplied with WRITE or NONE because that would make this invalidunder NX bit or not being able execute (respectively)   PROT_NONE This means process can’t do anything with mapping. This could useful if you implement guard pages in termsof security. If you surround critical data with many more pages thatcan’t accessed, that decreases chance of various attacks.    MAP_SHARED This mapping will synchronized underlyingfile object. file descriptor must’ve been opened with writepermissions in this case.    MAP_PRIVATE This mapping will only visible processitself. Useful not thrash operating system.  Remember that once a program is done mmapping that program mustmunmap tell operating system that it is no longer using pages allocated, so OS can write it back disk give back addresses in case another mmap needs occur. There are accompanyingcalls msync that take a piece of mmap’ed memory sync changesback filesystem though we won’t cover that in-depth. otherparameters mmap are described in annotated walkthrough below. Annotated mmap WalkthroughBelow is an annotated walkthrough of example code in man pages. Our command-line utility will take a file, offset, length print. We can assume that these are initialized correctly offset +length is less than length of file. We’ll assume that all system calls succeed. First, we have open file get size. Then, we need introduce another variable known as page_offset. mmapdoesn’t let program pass in any value as an offset, it needs amultiple of page size. In our case, we will round down. Then, we make call mmap, here is order of arguments.   NULL, this tells mmap we don’t need any particular address startfrom   length + offset - page_offset, mmaps “rest” of file intomemory (starting from offset)   PROT_READ, we want read file   MAP_PRIVATE, tell OS, we don’t want share our mapping   fd, object descriptor that we refer   pa_offset, page aligned offset start from Now, we can interact with address as if it were a normal buffer. After, we have unmap file close file descriptor makesure other system resources are freed. Check out full listing in man pages. MMAP CommunicationSo how would we use mmap communicate across processes? Conceptually,it would same as using threading. Let’s go through a broken downexample. First, we need allocate some space. We can do that with mmap call. We’ll also allocate space for 100 integersThen, we need fork perform some communication. Our parent willstore some values, our child will read those values. Now, there is no assurance that values will communicated because process used sleep, not a mutex. Most of time this will work. This piece of code allocates space for a 100 integers creates apiece of memory that is shared between all processes. code thenforks. parent process writes two integers first two slots. avoid a data race, child sleeps for a second then prints out stored values. This is an imperfect way protect against data races. We could use a mutex across processes mentioned in synchronization section. But for this simple example, it works fine. Note that each process should call munmap when done using piece ofmemory. Sharing anonymous memory is an efficient form of inter-processcommunication because there is no copying, system call, or disk-accessoverhead - two processes share same physical frame of mainmemory. On other hand, shared memory, like in a multithreadingcontext, creates room for data races. Processes that share writablememory might need use synchronization primitives like mutexes prevent these from happening. PipesYou’ve seen virtual memory way of IPC, but there are more standardversions of IPC that are provided by kernel. One of bigutilities is POSIX pipes. A pipe simply takes in a stream of bytes spits out a sequence of bytes. One of big starting points of pipes was way back in PDP-10 days. In those days, a write disk or even your terminal was slow as itmay have printed out. Unix programmers still wanted createsmall, portable programs that did one thing well could composed. As such, pipes were invented take output of one program feedit input of another program though they have other uses today –you can read moreConsider if you type following into your terminal. What does following code do? First, it lists current directory. -1 means that it outputs one entry per line. cut command thentakes everything before first period. sort sorts all inputlines, uniq makes sure all lines are unique. Finally, teeoutputs contents file dir_contents terminal foryour perusal. important part is that bash creates 5 separateprocesses connects their standard outs/stdins with pipes traillooks something like this.  numbers in pipes are file descriptors for each process arrow represents redirect or where output of pipe isgoing. A POSIX pipe is almost like its real counterpart - a program canstuff bytes down one end they will appear at other end in same order. Unlike real pipes, however, flow is always in samedirection, one file descriptor is used for reading other forwriting. pipe system call is used create a pipe. These filedescriptors can used with read write. A common method ofusing pipes is create pipe before forking communicate with achild processThere are two file descriptors that pipe creates. filedes[0] contains read end. filedes[1] contains write end. How your friendlyneighborhood TAs remember it is one can read before they can write, orreading comes before writing. You can groan all you want at it, but itis helpful remember what is read end what is write end. One can use pipes inside of same process, but there tends noadded benefit. Here’s an example program that sends a message itself.  problem with using a pipe in this fashion is that writing a pipecan block meaning pipe only has a limited buffering capacity. maximum size of buffer is system-dependent; typical values from 4KiBup 128KiB though they can changed. Pipe GotchasHere’s a complete example that doesn’t work! child reads one byteat a time from pipe prints it out - but we never see message! Can you see why? parent sends bytes H,i,(space),C. . . ! into pipe. childstarts reading pipe one byte at a time. In above case, childprocess will read print each character. However, it never leaves while loop! When there are no characters left read it simply blocks waits for more unless All writers close their ends Anothersolution could also exit loop by checking for an end-of-messagemarker,We know that when a process tries read from a pipe where there arestill writers, process blocks. If no pipe has no writers, readreturns 0. If a process tries write with some reader’s read goesthrough, or fails – partially or completely – if pipe is full. Whyhappens when a process tries write when there are no readersleft?Tip: Notice only writer (not a reader) can use this signal. inform reader that a writer is closing their end of pipe, aprogram could write your special byte (e. g.  0xff) or a message(\"Bye!\")Here’s an example of catching this signal that fails! Can you see why? mistake in above code is that there is still a reader for pipe! child still has pipe’s first file descriptor open remember specification? All readers must closedWhen forking, It is common practice close unnecessary (unused)end of each pipe in child parent process. For example, parent might close reading end child might close writingend.  last addendum is that a program can set file descriptor return when there is no one listening instead of SIGPIPE because bydefault SIGPIPE terminates your program. reason that this is defaultbehavior is it makes pipe example above work. Consider this uselessuse of catWhich grabs 20 lines of input from urandom. head will terminate after20 newline characters have been read. What about cat? cat needs receive a SIGPIPE informing it that program tried write a pipethat no one is listening on. Other pipe factsA pipe gets filled up when writer writes too much pipewithout reader reading any of it. When pipes become full, allwrites fail until a read occurs. Even then, a write may partially failif pipe has a little bit of space left but not enough for entiremessage. Usually, two things are done avoid this. Either increase size of pipe. Or more commonly, fix your program design so that pipe is constantly being read from. As hinted at before, Pipe writes are atomic up size of pipe. Meaning that if two processes try write same pipe, kernelhas internal mutexes with pipe that it will lock, do write, return. only gotcha is when pipe is about become full. If twoprocesses are trying write pipe can only satisfy a partialwrite, that pipe write is not atomic – careful about that!Unnamed pipes live in memory are a simple efficient form ofinter-process communication (IPC) that is useful for streaming data simple messages. Once all processes have closed, pipe resources arefreed. It is also common design for a pipe one way – meaning one processshould do writing one process do reading. Otherwise, child would attempt read its data intended for parent (and viceversa)!Pipes DupOften, you’ll want use pipe2 in combination with dup. Take forexample simple program in command line. This command takes output of ls -1 which lists content of current directory on one line each pipes it cut. Cut take adelimiter, in this case, a dot, a field position, in our case 1, outputs per line nth field by each delimiter. At a high level, thisgrabs file names without extension of our current directory. Underneath hood, this is how bash does it internally.  results of two programs should same. Remember as youencounter more complicated examples of piping processes up, a programneeds close all unused ends of pipes otherwise program willdeadlock waiting for your processes finish. Pipe ConveniencesIf program already has a file descriptor, it can ‘wrap’ it yourselfinto a FILE pointer using fdopen. For writing files, this is unnecessary. Use fopen which does same as open fdopen. However for pipes, we already have a filedescriptor, so this is a great time use fdopenHere’s a complete example using pipes that almost works! Can you spot error? Hint: parent never prints anything!Note unnamed pipe resource will disappear once both child parent have exited. In above example, child will send bytes parent will receive bytes from pipe. However, noend-of-line character is ever sent, so fscanf will continue ask forbytes because it is waiting for end of line i. e.  it will waitforever! fix is ensure we send a newline character so thatfscanf will return. If you want your bytes sent pipe immediately, you’ll need fflush! Remember back introduction section that shows difference between terminal vs non-terminal outputs of stdout. Even though we have a section on it, it is highly not recommended use file descriptor API for non-seekable files. reason beingis that while we get conveniences we also get annoyances like buffering example we mentioned, caching, etc. basic C library mottois that any device a program can properly fseek or move anarbitrary position, it should able fdopen. Files satisfy thisbehavior, shared memory also, terminals, etc. When it comes pipes,sockets, epoll objects, etc, don’t do it. Named PipesAn alternative unnamed pipes is named pipes created usingmkfifo. From command line: mkfifo From C:int mkfifo(const char pathname, mode_t mode);You give it pathname operation mode, it will ready go! Named pipes take up virtually no space on a file system. This means actual contents of pipe aren’t printed file read fromthat same file. What operating system tells you when you have anamed pipe is that it will create an unnamed pipe that refers named pipe, that’s it! There is no additional magic. This is forprogramming convenience if processes are started without forking meaningthat there would no way get file descriptor childprocess for an unnamed pipe. Hanging Named PipesA named pipe mkfifo is a pipe that a program calls open(2) on withread and/or write permissions. This is useful if you want have a pipebetween two processes without one processing having fork otherprocess. There are some gotchas with named pipes. There is more downbelow, but we’ll introduce it here for a simple example. Reads writes hang on Named Pipes until there is at least one reader onewriter, take this. Any open is called on a named pipe kernel blocks until anotherprocess calls opposite open. Meaning, echo callsopen(. . , O_RDONLY) but that blocks until cat callsopen(. . , O_WRONLY), then programs are allowed continue. Race condition with named pipesWhat is wrong with following program?This may never print hello because of a race condition. Since a programopened pipe in first process under both permissions, open won’twait for a reader because program told operating system that itis a reader! Sometimes it looks like it works because execution of code looks something like this.      Process 1 Process 2     Time 1 open(O_RDWR) &amp; write()     Time 2   open(O_RDONLY) &amp; read()   Time 3 close() &amp; exit()     Time 4 print() &amp; exit()    Fine Pipe Access PatternBut here is an invalid series of operations that cause a racecondition.      Process 1 Process 2     Time 1 open(O_RDWR) &amp; write()     Time 2 close() &amp; exit()     Time 3   open(O_RDONLY) (Blocks Indefinitely)  Pipe Race ConditionFilesOn Linux, there are two abstractions with files. first is Linuxfd level abstraction.   open takes a path a file creates a file descriptor entry in process table. If file is inaccessible, it errors out.    read takes a certain number of bytes that kernel has received reads them into a user-space buffer. If file is not open inread mode, this will break.    write outputs a certain number of bytes a file descriptor. If file is not open in write mode, this will break. This may buffered internally.    close removes a file descriptor from a process’ file descriptors. This always succeeds for a valid file descriptor.    lseek takes a file descriptor moves it a certain position. It can fail if seek is out of bounds.    fcntl is catch-all function for file descriptors. Set filelocks, read, write, edit permissions, etc.   Linux interface is powerful expressive, but sometimes we needportability for example if we are writing for a Macintosh or windows. This is where C’s abstraction comes into play. On different operatingsystems, C uses low-level functions create a wrapper around filesused everywhere, meaning that C on Linux uses above calls.   fopen opens a file returns an object. null is returned if program doesn’t have permission for file.    fread reads a certain number of bytes from a file. An error isreturned if already at end of file when which programmust call feof() check if program attempted read past end of file.    fgetc/fgets Get a char or a string from a file   fscanf Read a format string from file   fwrite Write some objects a file   fprintf Write a formatted string a file   fclose Close a file handle   fflush Take any buffered changes flush them a file   feof Returns true if you are at end of a file   ferror Returns true if an error occured reading, writing orseeking.    setvbuf Sets buffering (None,Line or Full) memory usedfor buffering But programs don’t get expressiveness that Linux gives with systemcalls. A program can convert back forth between them withint fileno(FILE* stream) FILE* fdopen(int fd. . . ). Also, C filesare buffered meaning that their contents may written backing after call returns. You can change that with C options. Determining File LengthFor files less than size of a long, using fseek ftell is asimple way accomplish this. Move end of file find out current position. This tells us current position in file in bytes - i. e.  thelength of file!fseek can also used set absolute position. All future reads writes in parent or child processes will honorthis position. Note writing or reading from file will change current position. See man pages for fseek ftell for moreinformation. Use stat insteadThis only works on some architectures compilers That quirk is thatlongs only need 4 Bytes big meaning that maximum size thatftell can return is a little under 2 Gibibytes. Nowadays, our filescould hundreds of gibibytes or even terabytes on a distributed filesystem. What should we do instead? Use stat! We will cover stat in alater part but here is some code that will tell a program size of filebuf. st_size is of type off_t which is big enough for large files. Gotchas with filesWhat happens when file streams are closed by two different processes?Closing a file stream is unique each process. Other processes cancontinue use their file handles. Remember, everything is copied overwhen a child is created, even relative positions of files. Asyou might have observed with using fork, there is a quirk of implementation of files their caches on Ubuntu that will rewind afile descriptor once a file has been closed. As such, make sure closebefore forking or at least don’t trigger a cache inconsistency which ismuch harder. IPC AlternativesOkay so now you have a list of tools in your toolbox tacklecommunicating between processes, so what should you use?There is no hard answer, though this is most interesting question. Generally, we have retained pipes for legacy reasons. This means that weonly use them redirect stdin, stdout, stderr for collectionof logs similar programs. You may find processes trying communicate with unnamed or named pipes as well. Most of time youwon’t dealing with this interaction directly though. Files are used almost all time as a form of IPC. Hadoop is a greatexample where processes will write append-only tables then otherprocesses will read from those tables. We generally use files under afew cases. One case is if we want save intermediate results of anoperation a file for future use. Another case is if putting it inmemory would cause an out of memory error. On Linux, file operations aregenerally pretty cheap, so most programmers use it for largerintermediate storage. mmap is used for two scenarios. One is a linear or near-linear readthrough of file. Meaning, a program reads file front back orback front. key is that program doesn’t jump around too much. Jumping around too much causes thrashing loses all benefits ofusing mmap. other usage of mmap is for direct memory inter-processcommunication. This means that a program can store structures in a pieceof mmap’ed memory share them between two processes. Python Rubyuse this mapping all time utilize copy on write semantics. Topics  Virtual Memory   Page Table   MMU/TLB   Address Translation   Page Faults   Frames/Pages   Single-level vs multi-level page table   Calculating offsets for multi-level page table   Pipes   Pipe read write ends   Writing a zero reader pipe   Reading from a zero writer pipe   Named pipe Unnamed Pipes   Buffer Size/Atomicity   Scheduling Algorithms   Measures of Efficiency Questions  What is virtual memory?   What are following what is their purpose?   Translation Lookaside Buffer   Physical Address   Memory Management Unit. Multilevel page table. Frame number. Page number page offset.    dirty bit   NX Bit     What is a page table? How about a physical frame? Does a page alwaysneed point a physical frame?   What is a page fault? What are types? When does it result in aSEGFAULT?   What are advantages a single-level page table? Disadvantages?How about a multi-level table?   What does a multi-leveled table look like in memory?   How do you determine how many bits are used in page offset?   Given a 64-bit address space, 4kb pages frames, a 3 levelpage table, how many bits are Virtual page number 1, VPN2, VPN3 offset?   What is a pipe? How do we create pipes?   When is SIGPIPE delivered a process?   Under what conditions will calling read() on a pipe block? Underwhat conditions will read() immediately return 0   What is difference between a named pipe an unnamed pipe?   Is a pipe thread-safe?   Write a function that uses fseek ftell replace middlecharacter of a file with an ’X’   Write a function that creates a pipe uses write send 5 bytes,“HELLO” pipe. Return read file descriptor of pipe.    What happens when you mmap a file?   Why is getting file size with ftell not recommended? How shouldyou do it instead? “DEC Pdp-10 Ka10 Control Panel. ” n. d. *RICM*. RICM. . (IBM), International Business Machines Corporation. August 1958. *IBM709 Data Processing System Reference Manual*. International BusinessMachines Corporation (IBM). . “Mmap. ” 2018. *Mmap*. Open Group. . ","url":"/coursebook/Ipc"},{"title":"Malloc","content":"                               Memory AllocatorsMemory memory everywhere but not an allocation made - Afragmented heapIntroductionMemory allocation is important! Allocating deallocating heap memoryis one of most common operations in any application. heap at system level is contiguous series of addresses that program canexpand or contract use as its accord (“Overview of Malloc”). In POSIX, thisis called system break. We use sbrk move system break. Mostprograms don’t interact directly with this call, they use a memoryallocation system around it handle chunking up keeping track ofwhich memory is allocated which is freed. We will mainly looking into simple allocators. Just know that thereare other ways of dividing up memory like with mmap or otherallocation schemes methods like jemalloc. C Memory Allocation API  malloc(size_t bytes) is a C library call is used reserve acontiguous block of memory that may uninitialized (Jones P. 348). Unlikestack memory, memory remains allocated until free is calledwith same pointer. If malloc can either return a pointer atleast that much free space requested or NULL. That means thatmalloc can return NULL even if there is some space. Robust programsshould check return value. If your code assumes mallocsucceeds, it does not, then your program will likely crash(segfault) when it tries write address 0. Also, malloc leavesgarbage in memory because of performance – check your code makesure that a program all program values are initialized.    realloc(void *space, size_t bytes) allows a program resize anexisting memory allocation that was previously allocated on heap(via malloc, calloc, or realloc) (Jones P. 349). most common use of realloc is resize memory used hold an arrayof values. There are two gotchas with realloc. One, a new pointermay returned. Two, it can fail. A naive but readable version ofrealloc is suggested below with sample usage.   above code is fragile. If realloc fails then program leaksmemory. Robust code checks for return value only reassigns original pointer if not NULL.     calloc(size_t nmemb, size_t size) initializes memory contents zero also takes two arguments: number of items sizein bytes of each item. An advanced discussion of these limitationsis. Programmers often use calloc rather than explicitly callingmemset after malloc, set memory contents zero becausecertain performance considerations are taken into account. Notecalloc(x,y) is identical calloc(y,x), but you should follow conventions of manual. A naive implementation of calloc isbelow.     free takes a pointer start of a piece of memory makesit available for use in subsequent calls other allocationfunctions. This is important because we don’t want every process inour address space take an enormous amount of memory. Once we aredone using memory, we stop using it with ‘free‘. A simple usage isbelow.   If a program uses a piece of memory after it is freed - that isundefined behavior.  Heaps sbrk heap is part of process memory varies in size. Heap memoryallocation is performed by C library when a program calls malloc(calloc, realloc) free. By calling sbrk C library canincrease size of heap as your program demands more heap memory. As heap stack need grow, we put them at opposite ends of address space. Stacks don’t grow like a heap, new parts of stack areallocated for new threads. For typical architectures, heap will growupwards stack grows downwards. Nowadays, Modern operating system memory allocators no longer needsbrk. Instead, they can request independent regions of virtual memory maintain multiple memory regions. For example, gibibyte requests may placed in a different memory region than small allocation requests. However, this detail is an unwanted complexity. Programs don’t need call brk or sbrk typically, though callingsbrk(0) can interesting because it tells a program where your heapcurrently ends. Instead programs use malloc, calloc, realloc free which are part of C library. internal implementation ofthese functions may call sbrk when additional heap memory is required. Note that memory that was newly obtained by operating systemmust zeroed out. If operating system left contents ofphysical RAM as-is, it might possible for one process learn about memory of another process that had previously used memory. Thiswould a security leak. Unfortunately, this means that for mallocrequests before any memory has been freed is often zero. This isunfortunate because many programmers mistakenly write C programs thatassume allocated memory will always zero. Intro AllocatingLet’s try write Malloc. Here is our first attempt at it – naiveversion. Above is simplest implementation of malloc, there are a fewdrawbacks though.   System calls are slow compared library calls. We should reserve alarge amount of memory only occasionally ask for more from system.    No reuse of freed memory. Our program never re-uses heap memory - itkeeps asking for a bigger heap.  If this allocator was used in a typical program, process wouldquickly exhaust all available memory. Instead, we need an allocator thatcan efficiently use heap space only ask for more memory whennecessary. Some programs use this type of allocator. Consider a videogame allocating objects load next scene. It is considerablyfaster do above throw entire block of memory away than itis do following placement strategies. Placement StrategiesDuring program execution, memory is allocated deallocated, so therewill a gap in heap memory that can re-used for future memoryrequests. memory allocator needs keep track of which parts of heap are currently allocated which are parts are available. Supposeour current heap size is 64K. Let’s say that our heap looks like following table. If a new malloc request for 2KiB is executed (malloc(2048)), whereshould malloc reserve memory? It could use last 2KiB hole,which happens perfect size! Or it could split one of other two free holes. These choices represent different placementstrategies. Whichever hole is chosen, allocator will need split hole into two. newly allocated space, which will returned program a smaller hole if there is spare space left over. Aperfect-fit strategy finds smallest hole that is of sufficient size(at least 2KiB):A worst-fit strategy finds largest hole that is of sufficient sizeso break 30KiB hole into two:A first-fit strategy finds first available hole that is ofsufficient size so break 16KiB hole into two. We don’t even have look through entire heap!One thing keep in mind is those placement strategies don’t need replace block. For example, our first fit allocator could’vereturned original block unbroken. Notice that this would lead about 14KiB of space unused by user allocator. We callthis internal fragmentation. In contrast, external fragmentation is that even though we have enoughmemory in heap, it may divided up in a way so a continuous blockof that size is unavailable. In our previous example, of 64KiB ofheap memory, 17KiB is allocated, 47KiB is free. However, largestavailable block is only 30KiB because our available unallocated heapmemory is fragmented into smaller pieces. Placement Strategy Pros Cons challenges of writing a heap allocator are  Need minimize fragmentation (i. e.  maximize memory utilization)   Need high performance   Fiddly implementation – lots of pointer manipulation using linkedlists pointer arithmetic.    Both fragmentation performance depend on applicationallocation profile, which can evaluated but not predicted inpractice, under-specific usage conditions, a special-purposeallocator can often out-perform a general-purpose implementation.    allocator doesn’t know program’s memory allocation requestsin advance. Even if we did, this is which is known NP-hard! Different strategies affect fragmentation of heap memory innon-obvious ways, which only are discovered by mathematical analysis orcareful simulations under real-world conditions (for example simulating memory allocation requests of a database or webserver). First, we will have a more mathematical, one-shot approach each ofthese algorithms (Garey, Graham, Ullman). paper describes a scenario where you have a certain number of bins a certain number of allocations, you are trying fit allocations in as few bins as possible, hence using as little memory aspossible. paper discusses theoretical implications puts a nicelimit on ratios in long run between ideal memory usage actual memory usage. For those who are interested, paperconcludes that actual memory usage over ideal memory usage as numberof bins increases – bins can have any distribution – is about 1. 7for First-Fit lower bounded by 1. 7 for best fit. problem withthis analysis is that few real-world applications need this type ofone-shot allocation. Video game object allocations will typicallydesignate a different subheap for each level fill up that subheap ifthey need a quick memory allocation scheme that they can throw away. In practice, we’ll using result from a more rigorous surveyconducted in 2005 (Wilson et al. ). survey makes sure note that memory allocation is a moving target. A good allocation scheme one program may not a good allocationscheme for another program. Programs don’t uniformly follow distribution of allocations. survey talks about all allocationschemes that we have introduced as well as a few extra ones. Here aresome summarized takeaways  Best fit may have problems when a block is chosen that is almost right size, remaining space is split so small that a programprobably won’t use it. A way get around this could set athreshold for splitting. This small splitting isn’t observed asfrequently under a regular workload. Also, worst-case behaviorof Best-Fit is bad, but it doesn’t usually happen [p. 43].    survey also talks about an important distinction of First-Fit. There are multiple notions of first. First could ordered in termsof time of ‘free‘’ing, or it could ordered through addresses of start of block, or it could ordered by time of last free – first being least recently used. surveydidn’t go too in-depth into performance of each but did make anote that address-ordered Least Recently Used (LRU) lists endedup with better performance than most recently used first.    survey concludes by first saying that under simulated random(assuming uniform at random) workloads, best fit first fit do aswell. Even in practice, both best address ordered first fit doabout as equally as well with a splitting threshold coalescing. reasons why aren’t entirely known.  Some additional notes we make  Best fit may take less time than a full heap scan. When a block ofperfect size or perfect size within a threshold is found, that can returned, depending on what edge-case policy you have.    Worst fit follows this as well. Your heap could represented with max-heap data structure each allocation call could simplypop top off, re-heapify, possibly insert a split memoryblock. Using Fibonacci heaps, however, could extremelyinefficient.    First-Fit needs have a block order. Most of time programmerswill default linked lists which is a fine choice. There aren’ttoo many improvements you can make with a least recently used most recently used linked list policy, but with address orderedlinked lists you can speed up insertion from O(n) O(log(n)) byusing a randomized skip-list in conjunction with your singly-linkedlist. An insert would use skip list as shortcuts find right place insert block removal would go through list as normal.    There are many placement strategies that we haven’t talked about,one is next-fit which is first fit on next fit block. This addsdeterministic randomness – pardon oxymoron. You won’t expected know this algorithm, know as you are implementing amemory allocator as part of a machine problem, there are more thanthese.  Memory Allocator TutorialA memory allocator needs keep track of which bytes are currentlyallocated which are available for use. This section introduces implementation conceptual details of building an allocator, or actual code that implements malloc free. Conceptually, we are thinking about creating linked lists lists ofblocks! Please enjoy following ASCII art. bt is short for boundarytag. We will have implicit pointers in our next block, meaning that we canget from one block another using addition. This is in contrast anexplicit metadata *next field in our meta block. One can grab next block by finding end of current one. Thatis what we mean by “implicit list”.  actual spacing may different. metadata can contain differentthings. A minimal metadata implementation would simply have size of block. Since we write integers pointers into memory that we alreadycontrol, we can later consistently hop from one address next. This internal information represents some overhead. Meaning even if wehad requested 1024 KiB of contiguous memory from system, we anallocation of that size will fail. Our heap memory is a list of blocks where each block is either allocatedor unallocated. Thus there is conceptually a list of free blocks, but itis implicit in form of block size information that we store as partof each block. Let’s think of it in terms of a simple implementation. We could navigate from one block next block by adding block’ssize. Make sure get your casting right! Otherwise, program will movean extreme amount of bytes over.  calling program never sees these values. They are internal implementation of memory allocator. As an example, suppose yourallocator is asked reserve 80 bytes (malloc(80)) requires 8bytes of internal header data. allocator would need find anunallocated space of at least 88 bytes. After updating heap data itwould return a pointer block. However, returned pointerpoints usable space, not internal data! Instead, we wouldreturn start of block + 8 bytes. In implementation, rememberthat pointer arithmetic depends on type. For example, p += 8 adds8  sizeof(p), not necessarily 8 bytes!Implementing a Memory Allocator simplest implementation uses First-Fit. Start at first block,assuming it exists, iterate until a block that represents anunallocated space of sufficient size is found, or we’ve checked all blocks. If no suitable block is found, it’s time call sbrk() again sufficiently extend size of heap. For this class, we will try serve every memory request until operating system tells us we aregoing run out of heap space. Other applications may limit themselves a certain heap size cause requests intermittently fail. Besides, a fast implementation might extend it a significant amount sothat we will not need request more heap memory soon. When a free block is found, it may larger than space we need. Ifso, we will create two entries in our implicit list. first entry is allocated block, second entry is remaining space. There areways do this if program wants keep overhead small. Werecommend first for going with readability. If program wants certain bits hold different pieces ofinformation, use bit fields! compiler will handle shifting. After setting up your fields thenit becomes simply looping through each of blocks checking appropriate fieldsHere is a visual representation of what happens. If we assume that wehave a block that looks like this, we want spit if allocation islet’s say 16 bytes split we’ll have do is following. This is before alignment concerns as well. Alignment rounding up considerationsMany architectures expect multibyte primitives aligned somemultiple of 2 (4, 16, etc). For example, it’s common require 4-bytetypes aligned 4-byte boundaries 8-byte types on 8-byteboundaries. If multi-byte primitives are stored on an unreasonableboundary, performance can significantly impacted because it mayrequire an additional memory read. On some architectures penalty iseven greater - program will crash with a. Most of you have experienced this in your architecture classes if therewas no memory protection. As malloc does not know how user will use allocated memory, pointer returned program needs aligned for worstcase, which is architecture-dependent. From glibc documentation, glibc malloc uses followingheuristic (“Virtual Memory Allocation Paging”) block that malloc gives you is guaranteed aligned so that itcan hold any type of data. On GNU systems, address is always amultiple of eight on most systems a multiple of 16 on 64-bitsystems. ” For example, if you need calculate how many 16 byte unitsare required, don’t forget round up. This is what math would look like in C.  additional constant ensures incomplete units are rounded up. Note,real code is more likely symbol sizes e. g. sizeof(x) - 1, ratherthan coding numerical constant 15. Another added effect could internal fragmentation happens when given block is larger than their allocation size. Let’s say that we havea free block of size 16B (not including metadata). If they allocate 7bytes, allocator may want round up 16B return entireblock. This gets sinister when implementing coalescing splitting. If allocator doesn’t implement either, it may end up returning a blockof size 64B for a 7B allocation! There is a lot of overhead for thatallocation which is what we are trying avoid. Implementing freeWhen free is called we need re-apply offset get back ‘real’ start of block – where we stored size information. Anaive implementation would simply mark block as unused. If we arestoring block allocation status in a bitfield, then we need clear bit:However, we have a bit more work do. If current block next block (if it exists) are both free we need coalesce these blocksinto a single block. Similarly, we also need check previousblock, too. If that exists represents an unallocated memory, then weneed coalesce blocks into a single large block.  able coalesce a free block with a previous free block we willalso need find previous block, so we store block’s size at end of block, too. These are called “boundary tags” (Knuth). These are Knuth’ssolution coalescing problem both ways. As blocks arecontiguous, end of one block sits right next start of next block. So current block (apart from first one) can look afew bytes further back look up size of previous block. Withthis information, allocator can now jump backward!Take for example a double coalesce. If we wanted free middleblock we need turn surrounding blocks into one big blocksPerformanceWith above description, it’s possible build a memory allocator. Its main advantage is simplicity - at least simple compared otherallocators! Allocating memory is a worst-case linear time operation –search linked lists for a sufficiently large free block. De-allocationis constant time. No more than 3 blocks will need coalesce into asingle block, using a most recently used block scheme only onelinked list entry. Using this allocator it is possible experiment with differentplacement strategies. For example, allocator could start searchingfrom last deallocated block. If allocator stores pointers blocks, it needs update pointers so that they always remainvalid. Explicit Free Lists AllocatorsBetter performance can achieved by implementing an explicitdoubly-linked list of free nodes. In that case, we can immediatelytraverse next free block previous free block. This canreduce search time because linked list only includes unallocatedblocks. A second advantage is that we now have some control over ordering of linked list. For example, when a block is deallocated,we could choose insert it into beginning of linked listrather than always between its neighbors. We may update our struct look like thisHere is what that would look like along with our implicit linked listWhere do we store pointers of our linked list? A simple trick is realize that block itself is not being used store next previous pointers as part of block, though you have ensure that free blocks are always sufficiently large hold two pointers. Westill need implement Boundary Tags, so we can correctly free blocks coalesce them with their two neighbors. Consequently, explicit freelists require more code complexity. With explicitly linked lists afast simple ‘Find-First’ algorithm is used find firstsufficiently large link. However, since link order can modified,this corresponds different placement strategies. If links aremaintained from largest smallest, then this produces a ‘Worst-Fit’placement strategy. There are edge cases though, consider how maintain your free list ifalso double coalescing. We’ve included a figure with a common mistake. We recommend when trying implement malloc that you draw out all cases conceptually then write code. Explicit linked list insertion policy newly deallocated block can inserted easily into two possiblepositions: at beginning or in address order. Inserting at beginning creates a LIFO (last-in, first-out) policy. most recentlydeallocated spaces will reused. Studies suggest fragmentation isworse than using address order (Wilson et al. ). Inserting in address order (“Address ordered policy”) insertsdeallocated blocks so that blocks are visited in increasing addressorder. This policy required more time free a block because boundary tags (size data) must used find next previousunallocated blocks. However, there is less fragmentation. Case Study: Buddy Allocator, an example of a segregated listA segregated allocator is one that divides heap into different areasthat are handled by different sub-allocators dependent on size of allocation request. Sizes are grouped into powers of two eachsize is handled by a different sub-allocator each size maintains itsfree list. A well-known allocator of this type is buddy allocator (Rangan,Raman, Ramanujam P. 85). We’ll discuss binary buddy allocator which splits allocationinto blocks of size \\(2^n; n = 1, 2, 3, . . . \\) times some base unitnumber of bytes, but others also exist like Fibonacci split where allocation is rounded up next Fibonacci number. basic conceptis simple: If there are no free blocks of size \\(2^n\\), go nextlevel steal that block split it into two. If two neighboringblocks of same size become unallocated, they can coalesce togetherinto a single large block of twice size. Buddy allocators are fast because neighboring blocks coalescewith can calculated from deallocated block’s address, rather thantraversing size tags. Ultimate performance often requires a smallamount of assembler code use a specialized CPU instruction find lowest non-zero bit.  main disadvantage of Buddy allocator is that they suffer frominternal fragmentation because allocations are rounded up nearest block size. For example, a 68-byte allocation will require a128-byte block. Case Study: SLUB Allocator, Slab allocation SLUB allocator is a slab allocator that serves different needs for Linux kernel. Imagine you are creating an allocator for kernel, what are yourrequirements? Here is a hypothetical shortlist.   First foremost is you want a low memory footprint have kernel able installed on all types of hardware: embedded,desktop, supercomputer, etc.    Then, you want actual memory as contiguous as possible make use of caching. Every time a system call is performed, kernel’s pages need get loaded into memory. This means that ifthey are all contiguous, processor will able cache themmore efficiently   Lastly, you want your allocations fast.  Enter SLUB allocator kmalloc. SLUB allocator is a segregatedlist allocator with minimal splitting coalescing. differencehere is that segregated list focuses on more realistic allocationsizes, instead of powers of two. SLUB also focuses on a low overallmemory footprint while keeping pages in cache. There are blocks ofdifferent sizes kernel rounds up each allocation request lowest block size that satisfies it. One of big differences betweenthis allocator others is that it usually conforms page sizes. We’ll talk about virtual memory pages in another chapter, but kernel will working with direct memory pages in spans of 4Kib or 4096Bytes. Further ReadingGuiding questions  Is malloc’ed memory initialized? How about calloc’ed or realloc’edmemory?   Does realloc accept, as its argument, number of elements orspace (in bytes)?   Why may allocation functions error? Seeor appendix of book !      Topics  Best Fit   Worst Fit   First Fit   Buddy Allocator   Internal Fragmentation   External Fragmentation   sbrk   Natural Alignment   Boundary Tag   Coalescing   Splitting   Slab Allocation/Memory Pool Questions/Exercises  What is Internal Fragmentation? When does it become an issue?   What is External Fragmentation? When does it become an issue?   What is a Best Fit placement strategy? How is it with ExternalFragmentation? Time Complexity?   What is a Worst Fit placement strategy? Is it any better withExternal Fragmentation? Time Complexity?   What is First Fit Placement strategy? It’s a little bit betterwith Fragmentation, right? Expected Time Complexity?   Let’s say that we are using a buddy allocator with a new slab of64kb. How does it go about allocating 1. 5kb?   When does 5 line sbrk implementation of malloc have a use?   What is natural alignment?   What is Coalescing/Splitting? How do they increase/decreasefragmentation? When can you coalesce or split?   How do boundary tags work? How can they used coalesce orsplit? Garey, M. R. , R. L. Graham, J. D. Ullman. 1972. “Worst-Case Analysisof Memory Allocation Algorithms. ” In *Proceedings of Fourth AnnualAcm Symposium on Theory of Computing*, 143–50. STOC ’72. New York, NY,USA: ACM. . Jones, Larry. 2010. “WG14 N1539 Committee Draft Iso/Iec 9899: 201x. ”International Standards Organization. Knuth, D. E. 1973. *The Art of Computer Programming: FundamentalAlgorithms*. Addison-Wesley Series in Computer Science InformationProcessing, v. 1-2. Addison-Wesley. . “Overview of Malloc. ” 2018. *MallocInternals - Glibc Wiki*. FreeSoftware Foundation. . Rangan, C. P. , V. Raman, R. Ramanujam. 1999. *Foundations of SoftwareTechnology Theoretical Computer Science: 19th Conference, Chennai,India, December 13-15, 1999 Proceedings*. FOUNDATIONS of Computersoftware Technology Theoretical Computer Science. Springer. . “Virtual Memory Allocation Paging. ” 2001. *The GNU C Library -Virtual Memory Allocation Paging*. Free Software Foundation. . Wilson, Paul R. , Mark S. Johnstone, Michael Neely, David Boles. 1995. “Dynamic Storage Allocation: A Survey Critical Review. ” In*Memory Management*, edited by Henry G. Baler, 1–116. Berlin,Heidelberg: Springer Berlin Heidelberg. ","url":"/coursebook/Malloc"},{"title":"Networking","content":"                                                      Networking Web as I envisaged it, we have not seen it yet. future isstill so much bigger than past - Tim Berners-LeeNetworking has become arguably most important use of computers in past 10-20 years. Most of us nowadays can’t stand a place withoutWiFi or any connectivity, so it is crucial as programmers that you havean understanding of networking how program communicate acrossnetworks. Although it may sound complicated, POSIX has defined nicestandards that make connecting outside world easy. POSIX alsolets you peer underneath hood optimize all little parts ofeach connection write highly performant programs. As an addendum that you’ll read more about in next chapter, we will strict in our notation for sizes. That means that when we refer SI prefixes of Kilo-, Mega-, etc, then we are always referring apower of 10. A kilobyte is one thousand bytes, a megabyte is a thousandkilobytes so on. If we need refer 1024 bytes, we will use more accurate term Kibibyte. Mibibyte Gibibyte are analogsof Megabyte Gigabyte respectively. We make this distinction makesure that we aren’t off by 24. reasons for this misnomer will explained in filesystems chapter.  OSI Model Open Source Interconnection 7 layer model (OSI Model) is a sequenceof segments that define standards for both infrastructure protocolsfor forms of radio communication, in our case Internet. 7 layermodel is as follows  Layer 1: Physical Layer. These are actual waves that carry bauds across wire. As an aside, bits don’t cross wirebecause in most mediums you can alter two characteristics of a wave– amplitude frequency – get more bits per clockcycle.    Layer 2: Link Layer. This is how each of agents reacts certain events (error detection, noisy channels, etc). This is whereEthernet WiFi live.    Layer 3: Network Layer. This is heart of Internet. bottom two protocols deal with communication between two differentcomputers that are directly connected. This layer deals with routingpackets from one endpoint another.    Layer 4: Transport Layer. This layer specifies how slices ofdata are received. bottom three layers make no guarantee about order that packets are received what happens when a packetis dropped. Using different protocols, this layer can.    Layer 5: Session Layer. This layer makes sure that if aconnection in previous layers is dropped, a new connection in lower layers can established, it looks like nothinghappened end-user.    Layer 6: Presentation Layer. This layer deals with encryption,compression, data translation. For example, portability betweendifferent operating systems like translating newlines windowsnewlines.    Layer 7: Application Layer. HTTP FTP are both defined atthis level. This is typically where we define protocols across Internet. As programmers, we only go lower when we think we cancreate algorithms that are more suited our needs than all of below.  This book won’t cover networking in depth. We will focus on some aspectsof layers 3, 4, 7 because they are essential know if you aregoing doing something with Internet, which at some point inyour career you will be. As for another definition, a protocol is a setof specifications put forward by Internet Engineering Task Forcethat govern how implementers of a protocol have their program or circuitbehave under specific circumstances. Layer 3: Internet Protocol following is a short introduction internet protocol (IP), primary way send datagrams of information from one machine another. “IP4”, or more precisely, IPv4 is version 4 of InternetProtocol that describes how send packets of information across anetwork from one machine another. Even as of 2018, IPv4 stilldominates Internet traffic, but google reports that 24 countries nowsupply 15% of their traffic through IPv6 (“State of Ipv6 Deployment2018”). Asignificant limitation of IPv4 is that source destination addressesare limited 32 bits. IPv4 was designed at a time when idea of 4billion devices connected same network was unthinkable or atleast not worth making packet size larger. IPv4 addresses arewritten typically in a sequence of four octets delimited by periods“255. 255. 255. 0” for example. Each IPv4 datagram includes a small header - typically 20 octets, thatincludes a source destination address. Conceptually source destination addresses can split into two: a network number upperbits lower bits represent a particular host number on that network. A newer packet protocol IPv6 solves many of limitations of IPv4 likemaking routing tables simpler 128-bit addresses. However, little webtraffic is IPv6 based on comparison as of 2018 (“State of Ipv6Deployment 2018”) Wewrite IPv6 addresses in a sequence of eight, four hexadecimal delimiterslike “1F45:0000:0000:0000:0000:0000:0000:0000”. Since that can getunruly, we can omit zeros “1F45::”. A machine can have an IPv6address an IPv4 address. There are special IP Addresses. One such in IPv4 is 127. 0. 0. 1, IPv6 as0:0:0:0:0:0:0:1 or ::1 also known as localhost. Packets sent 127. 0. 0. 1 will never leave machine; address is specified same machine. There are a lot of others that are denoted by certainoctets being zeros or 255, maximum value. You won’t need know all terminology, keep in mind that actual number of IP addressesthat a machine can have globally over Internet is smaller than number of “raw” addresses. This book covers how IP deals with routing,fragmenting, reassembling upper-level protocols. A more in-depthaside follows. What’s deal with IPv6?One of big features of IPv6 is address space. world ran outof IP addresses a while ago has been using hacks get around that. With IPv6 there are enough internal external addresses so even if wediscover alien civilizations, we probably won’t run out. otherbenefit is that these addresses are leased not bought, meaning that ifsomething drastic happens in let’s say Internet of things thereneeds a change in block addressing scheme, it can done. Another big feature is security through IPsec. IPv4 was designed withlittle no security in mind. As such, now there is a key exchangesimilar TLS in higher layers that allows you encryptcommunication. Another feature is simplified processing. make Internet fast,IPv4 IPv6 headers are verified in hardware. That means that allheader options are processed in circuits as they come in. problem isthat as IPv4 spec grew include a copious amount of headers, hardware had become more more advanced support those headers. IPv6 reorders headers so that packets can dropped routed withfewer hardware cycles. In case of Internet, every cycle matterswhen trying route world’s traffic. What’s My Address? obtain a linked list of IP addresses of current machine usegetifaddrs which will return a linked list of IPv4 IPv6 IPaddresses among other interfaces as well. We can examine each entry use getnameinfo print host’s IP address. ifaddrs structincludes family but does not include sizeof struct. Therefore we need manually determine struct sized based on family.  complete code is shown below.  get your IP Address from command line use ifconfig or Windows’ipconfig. However, this command generates a lot of output for each interface, sowe can filter output using grep.  grab IP Address of a remote website, function getaddrinfocan convert a human-readable domain name (e. g. www. illinois. edu) intoan IPv4 IPv6 address. It will return a linked-list of addrinfostructs:For example, suppose you wanted find out numeric IPv4 address ofa web server at www. bbc. com. We do this in two stages. First, usegetaddrinfo build a linked-list of possible connections. Secondly,use getnameinfo convert binary address of one of those into areadable form. Possible output. One can specify IPv4 or IPv6 with AF_UNSPEC. Just replace ai_family attribute in above code with following. If you are wondering how computer maps hostnames addresses, wewill talk about that in Layer 7. Spoiler: It is a service called DNS. Before we move onto next section, it is important note that asingle website can have multiple IP addresses. This may efficient with machines. If Google or Facebook has a single serverrouting all of their incoming requests other computers, they’d have spend massive amounts of money on that computer or data center. Instead, they can give different regions different IP addresses havea computer pick. It isn’t bad access a website through non-preferred IP address. page may load slower. Layer 4: TCP ClientMost services on Internet today use TCP because it efficiently hides complexity of lower, packet-level nature of Internet. TCP orTransport Control Protocol is a connection-based protocol that is builton top of IPv4 IPv6 therefore can described as “TCP/IP” or“TCP over IP”. TCP creates a pipe between two machines abstractsaway low-level packet-nature of Internet. Thus, under mostconditions, bytes sent over a TCP connection delivered uncorrupted. High performance error-prone code won’t even assume that!TCP has many features that set it apart from other transportprotocol UDP.   Ports With IP, you are only allowed send packets a machine. Ifyou want one machine handle multiple flows of data, you have do it manually with IP. TCP gives programmer a set of virtualsockets. Clients specify socket that you want packet sent TCP protocol makes sure that applications that are waitingfor packets on that port receive that. A process can listen forincoming packets on a particular port. However, only processes withsuper-user (root) access can listen on ports less than 1024. Anyprocess can listen on ports 1024 or higher. A frequently used portis number 80. It is used for unencrypted HTTP requests or web pages. For example, if a web browser connects http://www. bbc. com/ thenit will connecting port 80.    Retransmission Packets can get dropped due network errors orcongestion. As such, they need retransmitted. At sametime, retransmission shouldn’t cause packets more packets dropped. This needs balance tradeoff between flooding network speed.    Out of order packets. Packets may get routed more favorably due various reasons in IP. If a later packet arrives before anotherpacket, protocol should detect reorder them.    Duplicate packets. Packets can arrive twice. Packets can arrivetwice. As such, a protocol needs able differentiate betweentwo packets given a sequence number subject overflow.    Error correction. There is a TCP checksum that handles bit errors. This is rarely used though.    Flow Control. Flow control is performed on receiver side. Thismay done so that a slow receiver doesn’t get overwhelmed withpackets. Servers that handle 10000 or 10 million concurrentconnections may need tell receivers slow down but remainconnected due load. There is also problem of making sure local network’s traffic is stable.    Congestion control. Congestion control is performed on sender’sside. Congestion control is avoid a sender from flooding network with too many packets. This is important make sure thateach TCP connection is treated fairly. Meaning that two connectionsleaving a computer google youtube receive same bandwidth ping as each other. One can easily define a protocol that takesall bandwidth leaves other protocols in dust, but thistends malicious because many times limiting a computer asingle TCP connection will yield same result.    Connection-Oriented/life cycle oriented. You can imagine a TCPconnection as a series of bytes sent through a pipe. There is a“lifecycle” a TCP connection though. TCP handles setting up connection through SYN SYN-ACK ACK. This means client will senda SYNchronization packet that tells TCP what starting sequence start on. Then receiver will send a SYN-ACK messageacknowledging synchronization number. Then client willACKnowledge that with one last packet. connection is now openfor both reading writing on both ends TCP will send data receiver of data will acknowledge that it received a packet. Then every so often if a packet is not sent, TCP will tradezero-length packets make sure connection is still alive. Atany point, client server can send a FIN packet meaning that server will not transmit. This packet can altered with bitsthat only close read or write end of a particular connection. When all ends are closed then connection is over.  TCP doesn’t provide many things, though.   Security. Connecting an IP address claiming a certainwebsite does not verify claim (like in TLS). You could sending packets a malicious computer.    Encryption. Anybody can listen in on plain TCP. packets intransport are in plain text. Important things like your passwordscould easily skimmed by onlookers.    Session Reconnection. If a TCP connection dies then a whole new onemust created, transmission has started over again. This is handled by a higher protocol.    Delimiting Requests. TCP is naturally connection-oriented. Applications that are communicating over TCP need find a uniqueway of telling each other that this request or response is over. HTTP delimits header through two carriage returns useseither a length field or one keeps listening until connectioncloses Note on network ordersIntegers can represented in least significant byte first or mostsignificant byte first. Either approach is reasonable as long as machine itself is internally consistent. For network communications, weneed standardize on agreed format. htons(xyz) returns 16-bit unsigned integer ‘short’ value xyz innetwork byte order. htonl(xyz) returns 32-bit unsigned integer‘long’ value xyz in network byte order. Any longer integers need have computers specify order. These functions are read as ‘host network’. inverse functions(ntohs, ntohl) convert network ordered byte values host-orderedordering. So, is host-ordering little-endian or big-endian? answeris - it depends on your machine! It depends on actual architectureof host running code. If architecture happens sameas network ordering then functions return identical integers. Forx86 machines, host network order are different. Unless agreed otherwise, whenever you read or write low-level Cnetwork structures, i. e. port address information, remember use above functions ensure correct conversion to/from a machineformat. Otherwise, displayed or specified value may incorrect. This doesn’t apply protocols that negotiate endiannessbefore-hand. If two computers are CPU bound by converting messagesbetween network orders – this happens with RPCs in high-performancesystems – it may worth it negotiate if they are on similarendianness send in little-endian order. Why is network order defined big-endian? simple answer is thatRFC1700 says so (Reynolds Postel). If you want more information,we’ll cite famous article located that argued for a particularversion (Cohen ). mostimportant part is that it is standard. What happens when we don’t haveone standard? We have 4 different USB plug types (Regular, Micro, Mini, USB-C) that don’t interact well with each other. Include relevantXKCD here . TCP ClientThere are three basic system calls connect a remote machine.   int getaddrinfo(const char *node, const char *service, const structaddrinfo *hints, struct addrinfo **res); getaddrinfo call if successful, creates a linked-list ofaddrinfo structs sets given pointer point firstone.  Also, you can use hints struct only grab certain entries likecertain IP protocols, etc. addrinfo structure that is passedinto getaddrinfo define kind of connection you’d like. Forexample, specify stream-based protocols over IPv6, you can use following snippet.   other modes for ‘family‘ are AF_INET4 AF_UNSPEC whichmean IPv4 unspecified respectively. This could useful if youare searching for a service that you aren’t entirely sure which IPversion. Naturally, you get version in field back if youspecified UNSPEC.  Error handling with getaddrinfo is a little different. returnvalue is error code. convert a human-readable error usegai_strerror get equivalent short English error text.     int socket(int domain, int socket_type, int protocol); socket call creates a network socket returns a descriptorthat can used with read write. In this sense, it is network analog of open that opens a file stream – except that wehaven’t connected socket anything yet! Sockets are created with a domain AF_INET for IPv4 or AF_INET6for IPv6, socket_type is whether use UDP, TCP, or other someother socket type, protocol is an optional choice of protocolconfiguration for our examples this we can leave this as 0 fordefault. This call creates a socket object in kernel with whichone can communicate with outside world/network. You can use result of getaddressinfo fill in socket parameters, orprovide them manually.  socket call returns an integer - a file descriptor - and, forTCP clients, you can use it as a regular file descriptor. You canuse read write receive or send packets.  TCP sockets are similar pipes are often used in situationsthat require IPC. We don’t mention it in previous chaptersbecause it is overkill using a device suited for networks simplycommunicate between processes on a single thread.    connect(int sockfd, const struct sockaddr *addr, socklen_taddrlen); Finally, connect call attempts connection remotemachine. We pass original socket descriptor also socketaddress information which is stored inside addrinfo structure. There are different kinds of socket address structures that canrequire more memory. So in addition passing pointer, sizeof structure is also passed. help identify errors mistakes it is good practice check return value of allnetworking calls, including connect    (Optional) clean up code call freeaddrinfo(struct addrinfo *ai)on first level addrinfo struct.  There is an old function gethostbyname is deprecated. It’s old wayconvert a hostname into an IP address. port address still needs manually set using htons function. It’s much easier write code support IPv4 AND IPv6 using newer getaddrinfoThis is all that is needed create a simple TCP client. However,network communications offer many different levels of abstraction several attributes options that can set at each level. Forexample, we haven’t talked about setsockopt which can manipulateoptions for socket. You can also mess around with lower protocols as kernel provides primitives that contribute this. Note that youneed root create a raw socket. Also, you need have a lot of“set up” or starter code, prepared have your datagrams dropped due bad form as well. For more information see this. Sending some dataOnce we have a successful connection we can read or write like any oldfile descriptor. Keep in mind if you are connected a website, youwant conform HTTP protocol specification get any sort ofmeaningful results back. There are libraries do this. Usually, youdon’t connect at socket level. number of bytes read or writtenmay smaller than expected. Thus, it is important check returnvalue of write. A simple HTTP client that sends a request acompliant URL is below. First, we’ll start with boring stuff parsing code.  code that sends request is below. first thing that we have do is connect an address.  next piece of code sends request. Here is what each headermeans.   “GET %s HTTP/1. 0” This is request verb interpolated with path. This means perform GET verb on path using HTTP/1. 0 method.    “Connection: close” Means that as soon as request is over,please close connection. This line won’t used for any otherconnections. This is a little redundant given that HTTP 1. 0 doesn’tallow you send multiple requests, but it is better explicitgiven there are non-conformant technologies.    “Accept: */*” This means that client is willing acceptanything.  A more robust piece of code would also check if write fails or if call was interrupted.  last piece of code is driver code that sends request. Feelfree use following code if you want open file descriptoras a FILE object for convenience functions. Just careful not forget set buffering zero otherwise you may double buffer input, which would lead performance problems.  example above demonstrates a request server using HyperText Transfer Protocol. In general, there are six parts  method. GET, POST, etc.    resource. “/” “/index. html” “/image. png”   protocol “HTTP/1. 0”   A new line ( r n ). Requests always have a carriage return.    Any other knobs or switch parameters   actual body of request delimited by two new lines. bodyof request is either if size is specified or until receiver closes their connection.   server’s first response line describes HTTP version used whether request is successful using a 3 digit response code. If client had requested a non-existent path, e. g. GET/nosuchfile. html HTTP/1. 0 Then first line includes responsecode is well-known 404 response code. For more information, RFC 7231 has most current specifications on most common HTTP method today (Fielding Reschke). Layer 4: TCP Server four system calls required create a minimal TCP server aresocket, bind, listen, accept. Each has a specific purpose should called in roughly above order  int socket(int domain, int socket_type, int protocol) create an endpoint for networking communication. A new socket byitself is stores bytes. Though we’ve specified either a packet orstream-based connections, it is unbound a particular networkinterface or port. Instead, socket returns a network descriptor thatcan used with later calls bind, listen accept.  As one gotcha, these sockets must declared passive. Passiveserver sockets wait for another host connect. Instead, they waitfor incoming connections. Additionally, server sockets remain openwhen peer disconnects. Instead, client communicates with aseparate active socket on server that is specific thatconnection.  Since a TCP connection is defined by sender address portalong with a receiver address port, a particular server portthere can one passive server socket but multiple active sockets. One for each currently open connection. server’s operatingsystem maintains a lookup table that associates a unique tuple withactive sockets so that incoming packets can correctly routed correct socket.    int bind(int sockfd, const struct sockaddr *addr, socklen_taddrlen); bind call associates an abstract socket with an actual networkinterface port. It is possible call bind on a TCP client. port information used by bind can set manually (many olderIPv4-only C code examples do this), or created usinggetaddrinfo.  By default, a port is released after some time when serversocket is closed. Instead, port enters a “TIMED-WAIT” state. This can lead significant confusion during development because timeout can make valid networking code appear fail.  able immediately reuse a port, specify SO_REUSEPORTbefore binding port.   Here’s.    int listen(int sockfd, int backlog); listen call specifies queue size for number ofincoming, unhandled connections. There are connectionsunassigned a file descriptor by accept. Typical values for ahigh-performance server are 128 or more.    int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); Once server socket has been initialized server callsaccept wait for new connections. Unlike socket bind listen, this call will block, unless nonblocking option hasbeen set. If there are no new connections, this call will block only return when a new client connects. returned TCP socket isassociated with a particular tuple (client IP, client port, serverIP, server port) will used for all future incoming outgoing TCP packets that match this tuple.  Note accept call returns a new file descriptor. This filedescriptor is specific a particular client. It is a commonprogramming mistake use original server socket descriptor for server I/O then wonder why networking code has failed.  accept system call can optionally provide information about remote client, by passing in a sockaddr struct. Differentprotocols have different variants of struct sockaddr, whichare different sizes. simplest struct use is sockaddr_storage which is sufficiently large represent allpossible types of sockaddr. Notice that C does not have any model ofinheritance. Therefore we need explicitly cast our struct ‘base type’ struct sockaddr.   We’ve already seen getaddrinfo that can build a linked list ofaddrinfo entries each one of these can include socketconfiguration data. What if we wanted turn socket data into IP port addresses? Enter getnameinfo that can used convertlocal or remote socket information into a domain name or numeric IP. Similarly, port number can represented as a service name. Forexample, port 80 is commonly used as incoming connection portfor incoming HTTP requests. In example below, we request numericversions for client IP address client port number.   One can use macros NI_MAXHOST denote maximum length ofa hostname, NI_MAXSERV denote maximum length of a port. NI_NUMERICHOST gets hostname as a numeric IP address similarly for NI_NUMERICSERV although port is usually numeric, begin with.    int close(int fd) int shutdown(int fd, int how) Use shutdown call when you no longer need read any moredata from socket, write more data, or have finished doing both. When you call shutdown on socket on read and/or write ends,that information is also sent other end of connection. Ifyou shut down socket for further writing at server end, thena moment later, a blocked read call could return 0 indicatethat no more bytes are expected. Similarly, a write a TCPconnection that has been shut down for reading will generate aSIGPIPE Use close when your process no longer needs socket filedescriptor.  If you fork-ed after creating a socket file descriptor, allprocesses need close socket before socket resources can reused. If you shut down a socket for further read, all processesare affected because you’ve changed socket, not filedescriptor. Well written code will shutdown a socket beforecalling close it.  There are a few gotchas creating a server.   Using socket descriptor of passive server socket (describedabove)   Not specifying SOCK_STREAM requirement for getaddrinfo   Not being able reuse an existing port.    Not initializing unused struct entries   bind call will fail if port is currently in use. Ports areper machine – not per process or user. In other words, you cannotuse port 1234 while another process is using that port. Worse, portsare by default ‘tied up’ after a process has finished.  Example ServerA working simple server example is shown below. Note: this example isincomplete. For example, socket file descriptor remains open memory created by getaddrinfo remains allocated. First, we get address info for our current machine. Then we set up socket, bind it, listen. We are finally ready listen for connections, so we’ll tell user accept our firstclient. After that, we can treat new file descriptor as a stream of bytesmuch like a pipe. [language=C]Sorry InterruptOne concept that we need make clear is that you need handleinterrupts in your networking code. That means that sockets oraccepted file descriptors that you read or write may have theircalls interrupted – most of time you will get an interrupt or two. In reality, any of your system calls could get interrupted. reasonwe bring this up now is that you are usually waiting for network. Which is an order of magnitude slower than processes. Meaning a higherprobability of getting interrupted. How would you handle interrupts? Let’s try a quick example. We can assure you that following code experience errors. Can yousee why? On surface, it does restart a call after a read or write. But what else happens when error is EINTR? Are contents of buffer correct? What other problems can you spot?Layer 4: UDPUDP is a connectionless protocol that is built on top of IPv4 IPv6. It’s simple use. Decide destination address port sendyour data packet! However, network makes no guarantee about whether packets will arrive. Packets may dropped if network iscongested. Packets may duplicated or arrive out of order. A typical use case for UDP is when receiving up date data is moreimportant than receiving all of data. For example, a game may sendcontinuous updates of player positions. A streaming video signal maysend picture updates using UDPUDP Attributes  Unreliable Datagram Protocol Packets sent through UDP may droppedon their way destination. This can especially confusingbecause if you only test on your loop-back device – this islocalhost or 127. 0. 0. 1 for most users – then packets will seldom lost because no network packets are sent.    Simple UDP protocol is supposed have much less fluff thanTCP. Meaning that for TCP there are a lot of configurable parameters a lot of edge cases in implementation. UDP is fire forget.    Stateless/Transaction UDP protocol is stateless. This makes protocol more simple lets protocol represent simpletransactions like requesting or responding queries. There is alsoless overhead sending a UDP message because there is no three-wayhandshake.    Manual Flow/Congestion Control You have manually manage flow congestion control which is a double-edged sword. On one hand,you have full control over everything. On other hand, TCP hasdecades of optimization, meaning your protocol for its use casesneeds more efficient that more beneficial use it.    Multicast This is one thing that you can only do with UDP. Thismeans that you can send a message every peer connected aparticular router that is part of a particular group.   full gory description is available at original RFC (“UserDatagram Protocol” ). While it may seem that you never want use UDP for situations that youdon’t want lose data, a lot of protocols base their communicationbased on UDP that requires complete data. Take a look at TrivialFile Transfer Protocol that reliably transmits a file over wireusing UDP only. Of course, there is more configuration involved, butchoosing between UDP over TCP involves more than above factors. UDP ClientUDP Clients are pretty versatile below is a simple client that sends apacket a server specified through command line. Note that thisclient sends a packet doesn’t wait for an acknowledgment. It fires forgets. example below also uses gethostbyname because somelegacy functionality still works pretty well for setting up a client.  previous code grabs an entry hostent that matches by hostname. Even though this isn’t portable, it gets job done. First is connect it make it reusable – same as a TCP socket. Note thatwe pass SOCK_DGRAM instead of SOCK_STREAM. Then, we can copy over our hostent struct into sockaddr_instruct. Full definitions are provided in man pages so it is safe copy them over. Then a final useful part of UDP is that we can time out receiving apacket as opposed TCP because UDP isn’t connection-oriented. snippet do that is below. Now, socket is connected ready use. We can use sendto send a packet. We should also check return value. Note that we won’tget an error if packet isn’t delivered because that is a part of UDP protocol. We will, however, get error codes for invalid structs, badaddresses, etc.  above code simply sends “Hello” through a UDP. There is no idea ofif packet arrives, is processed, etc. UDP ServerThere are a variety of function calls available send UDP sockets. Wewill use newer getaddrinfo help set up a socket structure. Remember that UDP is a simple packet-based (‘datagram’) protocol. Thereis no connection set up between two hosts. First, initialize hints addrinfo struct request an IPv6, passive datagram socket. Next, use getaddrinfo specify port number. We don’t need specify a host as we are creating a server socket, not sending a packet a remote host. careful not send “localhost” or any othersynonym for loop-back address. We may end up trying passivelylisten ourselves resulting in bind errors.  port number is less than 1024, so program will need rootprivileges. We could have also specified a service name instead of anumeric port value. So far, calls have been similar a TCP server. For a stream-basedservice, we would call listen accept. For our UDP-server, program can start waiting for arrival of a packet.  addr struct will hold sender (source) information about arriving packet. Note sockaddr_storage type is sufficiently largeenough hold all possible types of socket addresses – IPv4, IPv6 orany other Internet Protocol. full UDP server code is below. Note that if you perform a partial read from a packet, rest of thatdata is discarded. One call recvfrom is one packet. make sure thatyou have enough space, use 64 KiB as storage space. Layer 7: HTTPLayer 7 of OSI layer deals with application-level interfaces. Meaning that you can ignore everything below this layer treat Internet as a way of communicating with another computer than can secure session may reconnect. Common layer 7 protocols are following  HTTP(S) - Hypertext Transfer Protocol. Sends arbitrary data executes remote actions on a web server. S standards for securewhere TCP connection uses TLS protocol ensure that communication can’t read easily by an onlooker.    FTP - File Transfer Protocol. Transfers a file from one computer another   TFTP - Trivial File Transfer Protocol. Same as above but using UDP.    DNS - Domain Name Service. Translates hostnames IP addresses   SMTP - Simple Mail Transfer Protocol. Allows one send plain textemails an email server   SSH - Secure SHell. Allows one computer connect anothercomputer execute commands remotely.    Bitcoin - Decentralized cryptocurrency   BitTorrent - Peer peer file sharing protocol   NTP - Network Time Protocol. This protocol helps keep yourcomputer’s clock synced with outside world What’s my name?Remember when we were talking before about converting a website an IPaddress? A system called “DNS” (Domain Name Service) is used. If IPaddress is missing form a machine’s cache then it sends a UDP packet a local DNS server. This server may query other upstream DNS servers. DNS by itself is fast but insecure. DNS requests are unencrypted susceptible ‘man-in-the-middle’ attacks. For example, a coffee shopinternet connection could easily subvert your DNS requests send backdifferent IP addresses for a particular domain. way this is usuallysubverted is that after IP address is obtained then a connection isusually made over HTTPS. HTTPS uses what is called TLS (formerlyknown as SSL) secure transmissions verify that hostname isrecognized by a Certificate Authority. Certificate Authorities often gethacked so careful of equating a green lock secure. Even with thisadded layer of security, united states government has recentlyissued a request for everyone upgrade their DNS DNSSec whichincludes additional security-focused technologies verify with highprobability that an IP address is truly associated with a hostname. Digression aside, DNS works like this in a nutshell  Send a UDP packet your DNS server   If that DNS server has packet cached return result   If not, ask higher-level DNS servers for answer. Cache send result   If either packet is not answered from within a guessed timeout,resend request.  If you want full bits pieces, feel free look at Wikipediapage. In essence, there is a hierarchy of DNS servers. First, there is dot hierarchy. This hierarchy first resolves top-level domains. edu . gov etc. Next, it resolves next level i. e. illinois. edu. Then local resolvers can resolve any number of URLs. For example, Illinois DNS server handles both cs. illinois. edu cs341. cs. illinois. edu. There is a limit on how many subdomains you canhave, but this is often used route requests different servers avoid having buy many high performant servers route requests. Non-Blocking IOWhen you call read() if data is unavailable, it will wait until data is ready before function returns. When you’re reading datafrom a disk, that delay is short, but when you’re reading from a slownetwork connection, requests take a long time. data may neverarrive, leading an unexpected close. POSIX lets you set a flag on a file descriptor such that any call read() on that file descriptor will return immediately, whether it hasfinished or not. With your file descriptor in this mode, your call read() will start read operation, while it’s working you cando other useful work. This is called “non-blocking” mode since call read() doesn’t block.  set a file descriptor non-blocking. For a socket, you can create it in non-blocking mode by addingSOCK_NONBLOCK second argument socket():When a file is in non-blocking mode you call read(), it willreturn immediately with whatever bytes are available. Say 100 bytes havearrived from server at other end of your socket you callread(fd, buf, 150). ‘read‘ will return immediately with a value of100, meaning it read 100 of 150 bytes you asked for. Say you tried read remaining data with a call read(fd, buf+100, 50), but last 50 bytes still hadn’t arrived yet. read() would return -1 set global error variable errno either EAGAIN orEWOULDBLOCK. That’s system’s way of telling you data isn’tready yet. write() also works in non-blocking mode. Say you want send 40,000bytes a remote server using a socket. system can only send somany bytes at a time. In non-blocking mode, write(fd, buf, 40000)would return number of bytes it was able send immediately, orabout 23,000. If you called write() right away again, it would return-1 set errno EAGAIN or EWOULDBLOCK. That’s system’s wayof telling you that it’s still busy sending last chunk of data isn’t ready send more yet. There are a few ways check that your IO has arrived. Let’s see how do it using select epoll. first interface we have is select. It isn’t preferred by many in POSIX community if they have analternative it, in most cases there is an alternative it. Given three sets of file descriptors, select() will wait for any ofthose file descriptors become ‘ready’.   readfds - a file descriptor in readfds is ready when there isdata that can read or EOF has been reached.    writefds - a file descriptor in writefds is ready when a call write() will succeed.    exceptfds - system-specific, not well-defined. Just pass NULL forthis.  select() returns total number of ready file descriptors. If noneof them become ready during time defined by timeout, it willreturn 0. After select() returns, caller will need loop through file descriptors in readfds and/or writefds see which ones areready. As readfds writefds act as both input output parameters,when select() indicates that there are ready file descriptors, itwould have overwritten them reflect only ready file descriptors. Unless caller intends call select() only once, it would agood idea save a copy of readfds writefds before calling it. Hereis a comprehensive snippet.  problem with select why a lot of users don’t use this or poll isthat select must linearly go through each of objects. If at anypoint in going through objects, previous objects change state,select must restart. This is highly inefficient if we have a largenumber of file descriptors in each of our sets. There is an alternative,that isn’t much better. epollepoll is not part of POSIX, but it is supported by Linux. It is a moreefficient way wait for many file descriptors. It will tell youexactly which descriptors are ready. It even gives you a way store asmall amount of data with each descriptor, like an array index or apointer, making it easier access your data associated with thatdescriptor. First, you must create a special file descriptor with. You won’t read or write this file descriptor. You’ll pass it other epoll_xxx functions call close() on it at end. For each file descriptor that you want monitor with epoll, you’llneed add it epoll data structures usingwith EPOLL_CTL_ADD option. You can add any number of filedescriptors it.  wait for some of file descriptors become ready, use. epoll_event struct that it fills out will contain data youprovided in event. data when you added this file descriptor. This makesit easy for you look up your data associated with this filedescriptor. Say you were waiting write data a file descriptor, but now youwant wait read data from it. Just use epoll_ctl() with EPOLL_CTL_MOD option change type of operation you’remonitoring.  unsubscribe one file descriptor from epoll while leaving othersactive, use epoll_ctl() with EPOLL_CTL_DEL option.  shut down an epoll instance, close its file descriptor. Also non-blocking read() write(), any calls connect() ona non-blocking socket will also non-blocking. wait for connection complete, use select() or epoll wait for socket writable. There are reasons use epoll over select but due interface, there are fundamental problems with doingso. Epoll ExampleLet’s break down epoll code in man page. We’ll assume that wehave a prepared TCP server socket int listen_sock. first thing wehave do is create epoll device.  next step is add listen socket in level triggeredmode. Then in a loop, we wait see if epoll has any events. If we get an event on a client socket, that means that client hasdata ready read, we perform that operation. Otherwise, we need update our epoll structure with a new client.  function above is missing some error checking for brevity as well. Note that this code is performant because we added server socket inlevel-triggered mode we add each of client file descriptors inedge-triggered. Edge triggered mode leaves more calculations on partof application – application must keep reading or writing until file descriptor is out of bytes – but it prevents starvation. A moreefficient implementation would also add listening socket inedge-triggered clear out backlog of connections as well. Please read through most of man 7 epoll before starting program. There are a lot of gotchas. Some of more common ones will detailed below. Assorted Epoll GotchasThere are several problems with using epoll. Here we will detail a few.   There are two modes. Level triggered edge-triggered. Leveltriggered means that while file descriptor has events on it, itwill returned by epoll when calling ctl function. Inedge-triggered, caller will only get file descriptor once itgoes from zero events an event. This means if you forget read,write, accept etc on file descriptor until you get aEWOULDBLOCK, that file descriptor will dropped.    If at any point you duplicate a file descriptor add it epoll,you will get an event from that file descriptor duplicatedone.    You can add an epoll object epoll. Edge triggered level-triggered modes are same because ctl will reset state zero events   Depending on conditions, you may get a file descriptor that wasclosed from Epoll. This isn’t a bug. reason that this happens isepoll works on kernel object level, not file descriptorlevel. If kernel object lives longer right flags areset, a process could get a closed file descriptor. This also meansthat if you close file descriptor, there is no way remove kernel object.    Epoll has EPOLLONESHOT flag which will remove a filedescriptor after it has been returned in epoll_wait   Epoll using level-triggered mode could starve certain filedescriptors because it is unknown how much data application willread from each descriptor.  Read more at man 7 epoll or check out a better version called kqueuein appendix. Remote Procedure CallsRPC or Remote Procedure Call is idea that we can execute a procedureon a different machine. In practice, procedure may execute on same machine. However, it may in a different context. For example, operation under a different user with different permissions different lifecycles. An example of this is you may send a remote procedure call a dockerdaemon change state of container. Not every application needs have access entire system machine, but they should have access containers that they’ve created. Privilege Separation remote code will execute under a different user with differentprivileges from caller. In practice, remote call may executewith more or fewer privileges than caller. This in principle can used improve security of a system by ensuring components operatewith least privilege. Unfortunately, security concerns need carefully assessed ensure that RPC mechanisms cannot subverted perform unwanted actions. For example, an RPC implementation mayimplicitly trust any connected client perform any action, rather thana subset of actions on a subset of data. Stub Code Marshaling stub code is necessary code hide complexity of performinga remote procedure call. One of roles of stub code is marshal necessary data into a format that can sent as a bytestream a remote server. Using a string format may a little inefficient. A good example ofthis marshaling is Golang’s gRPC or Google RPC. There is a version in Cas well if you want check that out.  server stub code will receive request, unmarshal requestinto a valid in-memory data call underlying implementation send result back caller. Often underlying library will do thisfor you.  implement RPC you need decide document which conventions youwill use serialize data into a byte sequence. Even a simpleinteger has several common choices.   Signed or unsigned?   ASCII, Unicode Text Format 8, some other encoding?   Fixed number of bytes or variable depending on magnitude.    Little or Big endian binary format if using binary?  marshal a struct, decide which fields need serialized. It may unnecessary send all data items. For example, some items may irrelevant specific RPC or can re-computed by server from other data items present.  marshal a linked list, it is unnecessary send link pointers,stream values. As part of unmarshaling, server can recreate alinked list structure from byte sequence. By starting at head node/vertex, a simple tree can recursivelyvisited create a serialized version of data. A cyclic graph willusually require additional memory ensure that each edge vertex isprocessed exactly once. Interface Description LanguageWriting stub code by hand is painful, tedious, error-prone, difficult maintain difficult reverse engineer wire protocol from implemented code. A better approach is specify data objects,messages, services automatically generate client servercode. A modern example of an Interface Description Language is Google’sProtocol Buffer . proto files. Even then, Remote Procedure Calls are significantly slower (10x 100x) more complex than local calls. An RPC must marshal data into awire-compatible format. This may require multiple passes through data structure, temporary memory allocation, transformation of data representation. Robust RPC stub code must intelligently handle network failures versioning. For example, a server may have process requests fromclients that are still running an early version of stub code. A secure RPC will need implement additional security checks includingauthentication authorization, validate data encryptcommunication between client host. A lot of time, RPCsystem can do this efficiently for you. Consider if you have both an RPCclient server on same machine. Starting up a thrift or GoogleRPC server could validate route request a local socket whichwouldn’t sent over network. Transferring Structured DataLet’s examine three methods of transferring data using 3 differentformats - JSON, XML, Google Protocol Buffers. JSON XML aretext-based protocols. Examples of JSON XML messages arebelow. Google Protocol Buffers is an open-source efficient binary protocol thatplaces a strong emphasis on high throughput with low CPU overhead minimal memory copying. This means client server stub code inmultiple languages can generated from . proto specification file marshal data from a binarystream. reduces versioning problem by ignoring unknown fields that arepresent in a message. See introduction Protocol Buffers for moreinformation.  general chain is abstract away actual business logic various marshaling code. If your application ever becomes CPU boundparsing XML, JSON or YAML, switch protocol buffers!Topics  IPv4 vs IPv6   TCP vs UDP   Packet Loss/Connection Based   Get address info   DNS   TCP client calls   TCP server calls   shutdown   recvfrom   epoll vs select   RPC Questions  What is IPv4? IPv6? What are differences between them?   What is TCP? UDP? Give me advantages disadvantagesof both of them. What is a scenario of using one over other?   Which protocol is connectionless which one is connection based?   What is DNS? What is route that DNS takes?   What does socket do?   What are calls set up a TCP client?   What are calls set up a TCP server?   What is difference between a socket shutdown closing?   When can you use read write? How about recvfrom sendto?   What are some advantages epoll over select? How aboutselect over epoll?   What is a remote procedure call? When should one use it versus HTTPor running code locally?   What is marshaling/unmarshaling? Why is HTTP not an RPC? Cohen, Danny. 1980. “ON Holy Wars a Plea for Peace. ” *IETF*. IETF. . Fielding, Roy T. , Julian Reschke. 2014. “Hypertext Transfer Protocol(HTTP/1. 1): Semantics Content. ” Request for Comments. RFC 7231; RFCEditor. . Reynolds, J. , J. Postel. 1994. “Assigned Numbers. ” RFC 1700. RFCEditor; Internet Requests for Comments; RFC Editor. “State of Ipv6 Deployment 2018. ” 2018. *Internet Society*. InternetSociety. . “User Datagram Protocol. ” 1980. Request for Comments. RFC 768; RFCEditor. . ","url":"/coursebook/Networking"},{"title":"Post_Mortems","content":"                     Post MortemsHindsight is 20-20 - UnknownThis chapter is meant serve as a big “why are we learning all ofthis”. In all of your previous classes, you were learning what do. How program a data structure, how code a for loop, how provesomething. This is first class that is largely focused on what not do. As a result, we draw experience from our past in real ways. Sitback scroll through this chapter as we tell you about problemsof past programmers. Even if you are dealing with something much higherlevel like web-development, everything relates back system. Shell ShockRequired: Appendix/ShellThis was a back door into most shells. bug allowed an attacker exploit an environment variable execute arbitrary code. This meant that in any system that uses environment variables doesn’t sanitize their input (hint no one sanitized environmentvariable input because they saw it as safe) you can execute whatevercode you want on other’s machines including setting up a web server. Lessons Learned: On production machines make sure that there is aminimal operating system (something like BusyBox with DietLibc) so thatyou can understand most of code in systems theireffectiveness. Put in multiple layers of abstraction checks makesure that data isn’t leaked. For example above is a problem insofaras getting information back attackers if it is allowed communicate with them. This means that you can harden your machine portsby disallowing connections on all but a few ports. Also, you can hardenyour system never perform exec calls perform tasks (i. e. performan exec call update a value) instead do it in C or your favoriteprogramming language of choice. Although you don’t have flexibility, youhave peace of mind what you allow users do. HeartbleedRequired: Intro C put it simply, there were no bounds on buffer checking. SSLHeartbeat is super simple. A server sends a string of a certain length, second server is supposed send string of length back. problem is someone can maliciously change size of request larger than what they sent (i. e. send “cat” but request 500 bytes) get crucial information like passwords from server. There is a on it. Lessons Learned: Check your buffers! Know difference between abuffer a string. Dirty CowRequired: Processes/VirtualMemoryA process usually has access a set of read-only mappings of memorythat if they try write they get a segfault. Dirty COW is avulnerability where a bunch of threads attempts access same pieceof memory at same time hoping that one of threads flips NXbit writable bit. After that, an attacker can modify page. This can done effective user id bit process canpretend it was running as root spawn a root shell, allowing access system from a normal shell. Lessons Learned: Spinlocks in kernel are hard. MeltdownThere is an example of this in background sectionSpectreCheck in security section. Mars PathfinderRequired sections: Synchronization a bit ofScheduling mars pathfinder was a mission that tried collect climate data onMars. finder uses a single bus communicate with different parts. Since this was 1997, hardware itself didn’t have advanced featureslike efficient locking so it was up operating system developers regulate that with mutexes. architecture was pretty simple. Therewas a thread that controlled data along information bus,communications thread, data collection thread in with high, regular, low priorities with respect scheduling. other caveat is thatif an interrupt happened at some interval a task is running atask is scheduled, task that has higher priority wins.  pattern that caused everything start failing was datacollection thread starts writing bus, information bus threadis waiting on data. Then out communication thread comes in preempt other lower priority thread while lower prioritythread still held mutex. This means when regular prioritythread tried lock bus, rover would deadlock. After some time system would reset but isn’t good leave chance. Moral of lesson? Don’t have applications themselves deal with synchronization. Define a module that handles mutex locking have module communicate through files, IPC, etc. Mars AgainRequired Sections:Malloc short of it is that they ran out of memory. long of it is thatthey ran out of memory, disk space, swap space. moral of story? Make sure write code that can handle file failures canhandle files when they close go out of memory, so operatingsystem can hot swap files free up memory. Also clean up files, assumethat your temp directory is roughly a hundredth or a thousandth of total size use that. Year 2038Required sections: Intro CThis is issue that hasn’t happened yet. Unix timestamps are kept as number of seconds from a particular day (Jan 1st 1970). This is storedas a 32 bit signed integer. In March of 2038, this number will overflow. This isn’t a problem for most modern operating system who store 64 bitsigned integers which is enough keep us going until end of time,but it is a problem for embedded devices that we can’t change internal hardware to. Stay tuned see what happens. Lessons learned: Plan like your application will huge one day. Northeast Blackout of 2003Required Sections:SynchronizationA race condition triggered a series of undefined events in a system thatcaused blackout of most of northeastern part of North Americafor quite some time. This bug also turned off or caused backupsystem logging systems fail so people didn’t even know of bugfor an hour. exact bits that were flipped are unknown, but patcheshave been put into place. Lessons Learned: Modularize your code localize failures (i. e. keepingrace conditions different between processes). If you need synchronizeamong processes make sure your failure detection system is notinterlaced with your system. Apple IOS Unicode HandlingRequired Sections: Intro CWonder why we teach string parsing? Because it is a hard thing doeven for professional software developers. This bug allowed a lot ofundefined behavior when trying parse a series of unicode characters. Apple probably knows why this happened, but our guess is that parsing of string happens somewhere inside kernel a segfaultis reached. When you get a segfault in kernel, your kernel panics, entire device reboots. Undefined behavior means anything though, a lot of varied things did happen with this bug. Lessons Learned: Fuzz your kernelApple SSL VerificationRequired Sections: Intro CDue a stray goto in Apple’s code, a function always returned that anSSL certificate was valid. Naturally, hackers were able get away withsome pretty crazy site names. Lessons Learned: Always bracket if statements, use gotos sparingly. Chances are if you need use a goto, write another function or aswitch statement with fall throughs (still bad). Sony Rootkit InstallationRequired Sections: Intro C/ProcessesPicture this. It’s 2005, Limewire came a few years prior, internetwas a growing pool of illegal activities – not say that is fixed now. Sony knew that it didn’t have computing power police all interwebs or get around various technologies people were using get around copyright protection. So what did they do? With 22 millionMusic CDs, they required users install a rootkit on their operatingsystem, so Sony can monitor device for unethical activities. Privacy concerns aside, believe me there are a lot of them, bigproblem was that this rootkit is a backdoor for everyone’s systems ifprogrammed incorrectly. A rootkit is a piece of code usually installedkernel-side that keeps track of almost anything that a user does. Whatwebsites visited, what clicks or keys typed etc. If a hacker finds outabout this there is a way access that API from user spacelevel, that means any program can find out important information aboutyour device. Needless say, people were angry. Lessons Learned: Get an antivirus and/or apparmor make sure that anapplication is only requesting permissions that make sense. If you aretorn, try something like Windows sandbox or keep a Sacrificial VM around see if installing it makes your computer horrible. Don’t trustcertificates trust code. Civilization GhandiRequired Sections: Intro CThis is probably well known gamers why someone as (in real life)non-violent as Ghandi was aggressive in video game civilization. In original, game kept aggressiveness as an unsigned integer. During game, integer could decremented then problemensued because Ghandi was already at zero. This caused him become most aggressive character in game. Lessons Learned: take away from this is never use unsignednumbers unless you have an express written reason for it (reasonsinclude you need know about overflow behavior, you are bitshifting, you are bit masking). In every other case, cast it.  Woes of Shell ScriptingRequired Sections: Intro C/AppendingThere was a simple bug in Steam that caused Steam remove all of yourfiles in form of something like thisWhat happens if $0 or first parameter passed into a script doesn’texist? You move root, you delete your entire computer. Lessons Learned: Do parameter checks, always always always set -e on ascript if you expect a command fail, explicitly list it. You canalso alias rm mv then delete trash later. Appnexus Double FreeRequired Sections: Intro C/MallocAppnexus uses an asynchronous garbage collector that reclaims differentparts of heap when it believes that objects are unused. architecture is that an element is in unavailable list then itis taken out a to-be-freed list. After a certain time if that elementwas unused, it is freed added free list. This is fine untiltwo thread try delete same object at once, adding listtwice. After less time, one of objects was deleted, delete wasannounced other computers. Lessons Learned: Avoid making hacky software if you need to. Modularize, set memory limits, monitor different parts of your code optimize by hand. There is no general catch-all garbage collector thatfits everyone. Even highly tested ones like JVM need some nudges ifyou want get performance out of them. ATT Cascading Failures - 1990Required Sections: Intro C bug is explained well at link above. We recommend reading learn more. A series of network delays that caused some telephoneswitches across country think that other switches were operablewhen they weren’t. When switches came back online, they realizedthey had a huge backlog of calls route began doing so. Otherrouting failures restarts only compounded problem. Lessons Learned: Not using C would’ve actually helped here because ofmore rigorous fuzzing (though C++ in this day age would worsewith its language constructs). real moral of story is networksare random expect any jump at any point in your code. That meanswriting simulations running them with random delays figure outbugs before they happen. ","url":"/coursebook/Post_Mortems"},{"title":"Processes","content":"                                               ProcessesWho needs process isolation? - Intel Marketing on Meltdown Spectre understand what a process is, you need understand what anoperating system is. An operating system is a program that provides aninterface between hardware user software as well as providing a setof tools that software can use. operating system manageshardware gives user programs a uniform way of interacting withhardware as long as operating system can installed on thathardware. Although this idea sounds like it is end-all, we know thatthere are many different operating systems with their own quirks standards. As a solution that, there is another layer of abstraction:POSIX or portable operating systems interface. This is a standard (ormany standards now) that an operating system must implement POSIXcompatible – most systems that we’ll studying are almost POSIXcompatible due more political reasons. Before we talk about POSIX systems, we should understand what ideaof a kernel is generally. In an operating system (OS), there are twospaces: kernel space user space. Kernel space is a power operatingmode that allows system interact with hardware has potential destroy your machine. User space is where most applicationsrun because they don’t need this level of power for every operation. When a user space program needs additional power, it interacts with hardware through a system call that is conducted by kernel. Thisadds a layer of security so that normal user programs can’t destroy yourentire operating system. For purposes of our class, we’ll talk aboutsingle machine multiple user operating systems. This is where there is acentral clock on a standard laptop or desktop. Other OSes relax central clock requirement (distributed) or “standardness” of hardware (embedded systems). Other invariants make sure events happen atparticular times too.  operating system is made up of many different pieces. There may aprogram running handle incoming USB connections, another one stayconnected network, etc. most important one is kernel –although it might a set of processes – which is heart of operating system. kernel has many important tasks. first ofwhich is booting.   computer hardware executes code from read-only memory, calledfirmware.    firmware executes a bootloader, which often conforms Extensible Firmware Interface (EFI), which is an interface between system firmware operating system.    bootloader’s boot manager loads operating system kernels,based on boot settings.    Your kernel executes init itself from nothing.    kernel executes startup scripts like starting networking USBhandling.    kernel executes userland scripts like starting a desktop, you get use your computer! When a program is executing in user space, kernel provides someimportant services programs in User space.   Scheduling processes threads   Handling synchronization primitives (futexes, mutexes, semaphores,etc. )   Providing system calls such as write or read   Managing virtual memory low-level binary devices such as USBdrivers   Managing filesystems   Handling communication over networks   Handling communication between processes   Dynamically linking libraries   list goes on on.   kernel creates first process init. d (an alternative issystem. d). init. d boots up programs such as graphical user interfaces,terminals, etc – by default, this is only process explicitly createdby system. All other processes are instantiated by using systemcalls fork exec from that single process. File DescriptorsAlthough these were mentioned in last chapter, we are going givea quick reminder about file descriptors. A zine from Julia Evans givessome more details (Evans ).  kernel keeps track of file descriptors what they point to. Later we will learn two things: that file descriptors point more thanfiles that operating system keeps track of them. Notice that file descriptors may reused between processes, but insideof a process, they are unique. File descriptors may have a notion ofposition. These are known as seekable streams. A program can read a fileon disk completely because OS keeps track of position in file, an attribute that belongs your process as well. Other file descriptors point network sockets various other piecesof information, that are unseekable streams. ProcessesA process is an instance of a computer program that may running. Processes have many resources at their disposal. At start of eachprogram, a program gets one process, but each program can make moreprocesses. A program consists of following:  A binary format: This tells operating system about varioussections of bits in binary – which parts are executable, whichparts are constants, which libraries include etc.    A set of machine instructions   A number denoting which instruction start from   Constants   Libraries link where fill in address of thoselibraries Processes are powerful, but they are isolated!That means that by default, no process can communicate with anotherprocess. This is important because in complex systems (like University ofIllinois Engineering Workstations), it is likely that differentprocesses will have different privileges. One certainly doesn’t want average user able bring down entire system, by eitherpurposely or accidentally modifying a process. As most of you haverealized by now, if you stuck following code snippet into a program, variables are unshared between two parallel invocations of program. On two different terminals, they would both print out 1 not 2. Even ifwe changed code attempt affect other process instances, therewould no way change another process’ state unintentionally. However, there are other intentional ways change program statesof other processes. Process ContentsMemory LayoutWhen a process starts, it gets its own address space. Each process gets following.   A Stack stack is place where automatically allocated variables function call return addresses are stored. Every time a new variableis declared, program moves stack pointer down reservespace for variable. This segment of stack is writable butnot executable. This behavior is controlled by no-execute (NX)bit, sometimes called W^X (write XOR execute) bit, which helpsprevent malicious code, such as shellcode from being run on stack.  If stack grows too far – meaning that it either grows beyond apreset boundary or intersects heap – program will stackoverflow error, most likely resulting in a SEGFAULT. stack isstatically allocated by default; there is only a certain amount ofspace which one can write.    A Heap heap is a contiguous, expanding region of memory (“Overview ofMalloc” ). Ifa program wants allocate an object whose lifetime is manuallycontrolled or whose size cannot determined at compile-time, itwould want create a heap variable.  heap starts at top of text segment grows upward,meaning malloc may push heap boundary – called programbreak – upward.  We will explore this in more depth in our chapter on memoryallocation. This area is also writable but not executable. One canrun out of heap memory if system is constrained or if a programrun out of addresses, a phenomenon that is more common on a 32-bitsystem.    A Data Segment This segment contains two parts, an initialized data segment, anuninitialized segment. Furthermore, initialized data segment isdivided into a readable writable section.    Initialized Data Segment This contains all of a program’sglobals any other static variables.  This section starts at end of text segment starts ata constant size because number of globals is known atcompile time. end of data segment is called programbreak can extended via use of brk / sbrk.  This section is writable (Van der Linden P. 124). Most notably, this section contains variables that wereinitialized with a static initializer, as follows:    Uninitialized Data Segment / BSS BSS stands for an oldassembler operator known as Block Started by Symbol.  This contains all of your globals any other static durationvariables that are implicitly zeroed out.  Example:  This variable will zeroed; otherwise, we would have asecurity risk involving isolation from other processes. They getput in a different section speed up process start up time. This section starts at end of data segment is alsostatic in size because amount of globals is known at compiletime. Currently, both initialized BSS data segments arecombined referred as data segment (Van der Linden P. 124),despite being somewhat different in purpose.      A Text Segment This is where all executable instructions are stored, isreadable (function pointers) but not writable. program countermoves through this segment executing instructions one after other. It is important note that this is only executablesection of program, by default. If a program’s code while it’srunning, program most likely will SEGFAULT. There are waysaround it, but we will not exploring these in this course. Whydoesn’t it always start at zero? This is because of a securityfeature called. reasons for explanation about this is outside scope ofthis class, but it is good know about its existence. Having saidthat, this address can made constant, if a program is compiledwith DEBUG flag.  Other Contents keep track of all these processes, your operating system gives eachprocess a number called process ID (PID). Processes are also given PID of their parent process, called parent process ID (PPID). Every process has a parent, that parent could init. d. Processes could also contain following information:  Running State - Whether a process is getting ready, running,stopped, terminated, etc. (more on this is covered in chapter onScheduling).    File Descriptors - A list of mappings from integers realdevices (files, USB flash drives, sockets)   Permissions - What user file is running on whatgroup process belongs to. process can then only performoperations based on permissions given user or group,such as accessing files. There are tricks make a program take adifferent user than who started program (e. g. , sudo takes aprogram that a user starts executes it as root). Morespecifically, a process has a real user ID (identifies owner of process), an effective user ID (used for non-privileged userstrying access files only accessible by superusers), a saveduser ID (used when privileged users perform non-privileged actions).    Arguments - a list of strings that tell your program whatparameters run under.    Environment Variables - a list of key-value pair strings in form NAME=VALUE that one can modify. These are often used specify paths libraries binaries, program configurationsettings, etc.  According POSIX specification, a process only needs a thread address space, but most kernel developers users know that only thesearen’t enough (“Definitions”). Intro ForkA word of warningProcess forking is a powerful dangerous tool. If you make a mistakeresulting in a fork bomb, you can bring down an entire system. reduce chances of this, limit your maximum number of processes asmall number e. g. 40 by typing ulimit -u 40 into a command line. Note,this limit is only for user, which means if you fork bomb, then youwon’t able kill all created process since calling killallrequires your shell fork(). Quite unfortunate. One solution is spawn another shell instance as another user (for example root)beforehand kill processes from there. Another is use built-in exec command kill all userprocesses (you only have one attempt at this). Finally, you could reboot system, but you only have one shot at thiswith exec function. When testing fork() code, ensure that you have either root and/orphysical access machine involved. If you must work on fork() coderemotely, remember that kill -9 -1 will save you in event of anemergency. Fork can extremely dangerous if you aren’t preparedfor it. You have been warned. Fork Functionality fork system call clones current process create a newprocess, called a child process. This occurs by duplicating state of existing process with a few minor differences.   child process executes next line after fork() as parent process does.    Just as a side remark, in older UNIX systems, entire addressspace of parent process was directly copied regardless ofwhether resource was modified or not. current behavior isfor kernel perform a,which saves a lot of resources, while being time efficient (Bovet CesatiCopy-on-write section).  Here is a simple example:Here is a simple example of this address space cloning. followingprogram may print out 42 twice - but fork() is after printf!? Why? printf line is executed only once however notice that printed contents are not flushed standard out. There’s no newlineprinted, we didn’t call fflush, or change buffering mode. output text is therefore still in process memory waiting sent. When fork() is executed entire process memory is duplicatedincluding buffer. Thus, child process starts with a non-emptyoutput buffer which may flushed when program exits. We say maybecause contents may unwritten given a bad program exit as well.  write code that is different for parent child process, check return value of fork(). If fork() returns -1, that impliessomething went wrong in process of creating a new child. One shouldcheck value stored in errno determine what kind of erroroccurred. Common errors include EAGAIN ENOENT Which areessentially “try again – resource temporarily unavailable”, “no suchfile or directory”. Similarly, a return value of 0 indicates that we are operating in context of child process, whereas a positive integer shows that weare in context of parent process.  positive value returned by fork() is process id (pid) of child. A way remember what is represented by return value of fork is,that child process can find its parent - original process thatwas duplicated - by calling getppid() - so does not need anyadditional return information from fork(). However, parent processmay have many child processes, therefore needs explicitlyinformed of its child PIDs. According POSIX standard, every process only has a single parentprocess.  parent process can only know PID of new child process from return value of fork:A slightly silly example is shown below. What will it print? Try runningthis program with multiple arguments. Another example is below. This is amazing parallel apparent-O(N)sleepsort is today’s silly winner. First published on. A version of this awful but amusing sorting algorithm is shown below. This sorting algorithm may fail produce correct output. Imagine that we ran this program like so algorithm isn’t actually O(N) because of how system schedulerworks. In essence, this program outsources actual sorting operating system. Fork BombA ‘fork bomb’ is what we warned you about earlier. This occurs whenthere is an attempt create an infinite number of processes. This willoften bring a system a near-standstill, as it attempts allocateCPU time memory a large number of processes that are ready run. System administrators don’t like them may set upper limits on number of processes each user can have, or revoke login rightsbecause they create disturbances in Force for other users’ programs. A program can limit number of child processes created by usingsetrlimit(). Fork bombs are not necessarily malicious - they occasionally occur due programming errors. Below is a simple example that is malicious. It is easy cause one, if you are careless while calling fork,especially in a loop. Can you spot fork bomb here?We misspelled ehco, so exec call fails. What does this mean?Instead of creating 10 processes, we created 1024 processes, forkbombing our machine. How could we prevent this? Add an exit rightafter exec, so that if exec fails, we won’t end up calling fork anunbounded number of times. There are various other ways. What if weremoved echo binary? What if binary itself creates a forkbomb?SignalsWe won’t fully explore signals until end of course, but it isrelevant broach subject now because various semantics related fork other function calls detail what a signal is. A signal can thought of as a software interrupt. This means that aprocess that receives a signal stops execution of currentprogram makes program respond signal. There are various signals defined by operating system, two of whichyou may already know: SIGSEGV SIGINT. first is caused by anillegal memory access, second is sent by a user wanting terminate a program. In each case, program jumps from currentline being executed signal handler. If no signal handler issupplied by program, a default handler is executed – such asterminating program, or ignoring signal. Here is an example of a simple user-defined signal handler:A signal has four stages in its life cycle: generated, pending, blocked, received state. These refer when a process generates a signal, kernel is about deliver a signal, signal is blocked, when kernel delivers a signal, each of which requires some time complete. Read more in introduction Signals chapter.  terminology is important because fork exec require differentoperations based on state a signal is in.  note, it is generally poor programming practice use signals inprogram logic, which is send a signal perform a certain operation. reason: signals have no time frame of delivery no assurance thatthey will delivered. There are better ways communicate between twoprocesses. If you want read more, feel free skip ahead chapter onPOSIX signals read it over. It isn’t long gives you long short about how deal with signals in processes. POSIX Fork DetailsPOSIX determines standards of fork (“Fork”). You can read previouscitation, but do note that it can quite verbose. Here is a summary ofwhat is relevant:  Fork will return a non-negative integer on success.    A child will inherit any open file descriptors of parent. Thatmeans if a parent reads half of file forks, child willstart at that offset. A read on child’s end will shift parent’s offset by same amount. Any other flags are also carriedover.    Pending signals are not inherited. This means that if a parent has apending signal creates a child, child will not receive thatsignal unless another process signals child.    process will created with one thread (more on that later. general consensus is not create processes threads at sametime).    Since we have copy on write (COW), read-only memory addresses areshared between processes.    If a program sets up certain regions of memory, they can sharedbetween processes.    Signal handlers are inherited but can changed.    process’ current working directory (often abbreviated CWD) isinherited but can changed.    Environment variables are inherited but can changed.  Key differences between parent child include:  process id returned by getpid(). parent process idreturned by getppid().    parent is notified via a signal, SIGCHLD, when child processfinishes but not vice versa.    child does not inherit pending signals or timer alarms. For acomplete list see    child has its own set of environment variables.  Fork FILEsThere are some tricky edge cases when it comes using FILE forking. First, we have make a technical distinction. A FileDescription is struct that a file descriptor points to. Filedescriptors can point many different structs, but for our purposes,they’ll point a struct that represents a file on a filesystem. Thisfile description contains elements like paths, how far descriptorhas read into file, etc. A file descriptor points a filedescription. This is important because when a process is forked, only file descriptor is cloned, not description. followingsnippet contains only one description. One process will read one part of file, other process will readanother part of file. In following example, there are twodescriptions caused by two different file handles. Let’s consider our motivating example. Take a look at this code, what does it do? initial thought may that it prints file line by line withsome extra forking. It is actually undefined behavior because we didn’tprepare file descriptors. make a long story short, here is what do avoid example.   You as programmer need make sure that all of your filedescriptors are prepared before forking.    If it is a file descriptor or an unbuffered FILE*, it is alreadyprepared.    If FILE* is open for reading has been read fully, it isalready prepared.    Otherwise, FILE* must fflush’ed or closed prepared.    If file descriptor is prepared, it must unactive in parentprocess if child process is using it or vice versa. A process isusing it if it is read or written or if that process for whateverreason calls exit. If a process uses it when other process isas well, whole application’s behavior is undefined.  So how would we fix code? We would have flush file beforeforking refrain from using it until after wait call – more on specifics of this next section. What if parent process child process need performasynchronously need keep file handle open? Due eventordering, we need make sure that parent process knows that childis finished using wait. We’ll talk about Inter-Process communicationin a later chapter, but now we can use double fork method. If you are interested in how this works, check out appendix for adescription of Fork-file problem. Waiting ExecutingIf parent process wants wait for child finish, it must usewaitpid (or wait), both of which wait for a child change processstates, which can one of following:  child terminated   child was stopped by a signal   child was resumed by a signal Note that waitpid can set non-blocking, which means they willreturn immediately, letting a program know if child has exited. wait is a simpler version of waitpid. wait accepts a pointer aninteger waits on any child process. After first one changesstate, wait returns. Here is behavior of waitpid:A program can wait on a specific process, or it can pass in specialvalues for pid do different things (check man pages).  last parameter waitpid is an option parameter. options arelisted below:WNOHANG - Return whetherthe searched process has exitedWNOWAIT - Wait, but leave child wait-able by another wait callWEXITED - Wait for exited childrenWSTOPPED - Wait for stopped childrenWCONTINUED - Wait for continued childrenExit statuses or value stored in integer pointer for both of calls above are explained below. Exit statuses find return value of main() or value included in exit() froma child process, use Wait macros. Typically, a program will useWIFEXITED WEXITSTATUS. See wait/waitpid man page for moreinformation. A process can only have 256 return values, rest of bits areinformational, information is extracted with bit shifting. However, kernel has an internal way of keeping track of signaled,exited, or stopped processes. This API is abstracted so that that kernel developers are free change it at will. Remember: these macrosonly make sense if precondition is met. For example, a process’ exitstatus won’t defined if process isn’t signaled. macros willnot do checking for program, so it’s up programmer make sure logic is correct. As an example above, program shoulduse WIFSTOPPED check if a process was stopped then WSTOPSIG find signal that stopped it. As such, there is no need memorize following. This is a high-level overview of howinformation is stored inside status variables. From sys/wait. hof an old Berkeley Standard Distribution(BSD) kernel (“Source Sys/Wait. h,” ):There is a convention about exit codes. If process exited normally everything was successful, then a zero should returned. Beyondthat, there aren’t too many widely accepted conventions. If a programspecifies return codes mean certain conditions, it may able make more sense of 256 error codes. For example, a program couldreturn 1 if program went stage 1 (like writing a file) 2if it did something else, etc. Usually, UNIX programs are not designed follow this policy, for sake of simplicity. Zombies OrphansIt is good practice wait on your process’ children. If a parentdoesn’t wait on your children they become, what are called zombies. Zombies are created when a child terminates then takes up a spot in kernel process table for your process. process table keeps trackof following information about a process: PID, status, how itwas killed. only way get rid of a zombie is wait on yourchildren. If a long-running parent never waits for your children, it maylose ability fork. Having said that, a program doesn’t always need wait for yourchildren! Your parent process can continue execute code withouthaving wait for child process. If a parent dies without waitingon its children, a process can orphan its children. Once a parentprocess completes, any of its children will assigned init - first process, whose PID is 1. Therefore, these children would seegetppid() return a value of 1. These orphans will eventually finish for a brief moment become a zombie. init process automaticallywaits for all of its children, thus removing these zombies from system. Advanced: Asynchronously WaitingWarning: This section uses signals which are partially introduced. parent gets signal SIGCHLD when a child completes, so signalhandler can wait for process. A slightly simplified version is shownbelow. However, above example misses a couple of subtle points.   More than one child may have finished but parent will only getone SIGCHLD signal (signals are not queued)   SIGCHLD signals can sent for other reasons (e. g. a child processhas temporarily stopped)   It uses deprecated signal code, instead of more portablesigaction.  A more robust code reap zombies is shown below. exec make child process execute another program, use one of execfunctions after forking. exec set of functions replaces process image with that of specified program. This means that anylines of code after exec call are replaced with those of executed program. Any other work a program wants child process doshould done before exec call. naming schemes can shortened mnemonically.   e – An array of pointers environment variables is explicitlypassed new process image.    l – Command-line arguments are passed individually (a list) function.    p – Uses PATH environment variable find file named in file argument executed.    v – Command-line arguments are passed function as an array(vector) of pointers.  Note that if information is passed via an array, last elementmust followed by a NULL element terminate array. An example of this code is below. This code executes lsTry decode following example example writes “Captain’s Log” a file then prints everything in/usr/include same file. There’s no error checking in abovecode (we assume close, open, chdir etc. work as expected).   open – will use lowest available file descriptor (i. e. 1), sostandard out (stdout) is now redirected log file.    chdir – Change current directory /usr/include.    execl – Replace program image with /bin/ls call its main()method.    perror – We don’t expect get here - if we did then execfailed.    We need “return 0;” because compilers complain if we don’t haveit.  POSIX Exec DetailsPOSIX details all of semantics that exec needs cover (“Exec”). Note following:  File descriptors are preserved after an exec. That means if aprogram open a file doesn’t close it, it remains open in child. This is a problem because usually child doesn’t knowabout those file descriptors. Nevertheless, they take up a slot in file descriptor table could possibly prevent other processesfrom accessing file. one exception this is if filedescriptor has Close-On-Exec flag set (O_CLOEXEC) – we will goover setting flags later.    Various signal semantics: executed processes preserve signalmask pending signal set but do not preserve signalhandlers since it is a different program.    Environment variables are preserved unless using an environ versionof exec.    operating system may open up 0, 1, 2 – stdin, stdout, stderr, ifthey are closed after exec; most of time they leave them closed.    executed process runs as same PID has same parent process group as previous process.    executed process is run on same user group with sameworking directory.  Shortcutssystem pre-packs above code (Jones P. 371). following is a snippet of how use system.  system call will fork, execute command passed by parameter original parent process will wait for this finish. This alsomeans that system is a blocking call. parent process can’tcontinue until process started by system exits. Also, systemactually creates a shell that is then given string, which is moreoverhead than using exec directly. standard shell will use PATH environment variable search for a filename that matches command. Using system will usually sufficient for many simplerun-this-command problems but can quickly become limiting for morecomplex or subtle problems, it hides mechanics of fork-exec-wait pattern, so we encourage you learn use forkexec waitpid instead. It also tends a huge security risk. By allowing someone access a shell version of environment, program can run into all sorts of problems:Passing something along lines of argv[1] = “; sudo su” is a hugesecurity risk called.  fork-exec-wait PatternA common programming pattern is call fork followed by exec wait. original process calls fork, which creates a child process. child process then uses exec start execution of a newprogram. Meanwhile, parent uses wait (or waitpid) wait for child process finish. Why not execute ls directly? reason is that now we have a monitorprogram – our parent that can do other things. It can proceed execute another function, or it can also modify state of systemor read output of function call. Environment VariablesEnvironment variables are variables that system keeps for allprocesses use. Your system has these set up right now! In Bash, someare already defined. How would a program later these in C? They can call getenv setenv function respectively. Environment variables are important because they are inherited betweenprocesses can used specify a standard set of behaviors(“Environment Variables”), although you don’tneed memorize options. Another security related concern is thatenvironment variables cannot read by an outside process, whereas argvcan be. Further ReadingRead man pages POSIX groups above! Here are some guidingquestions. Note that we aren’t expecting you memorize man page.   What is one reason fork may fail?   Does fork copy all pages child?   Are file descriptors cloned between parent child?   Are file descriptions cloned between parent child?   What is difference between exec calls ending in an e?   What is difference between l v in an exec call? How aboutp?   When does exec error? What happens?   Does wait only notify if a child has exited?   Is it an error pass a negative value into wait?   How does one extract information out of status?   Why may wait fail?   What happens when a parent doesn’t wait on theirchildren?          Topics  Correct use of fork, exec waitpid   Using exec with a path   Understanding what fork exec waitpid do. E. g. how usetheir return values.    SIGKILL vs SIGSTOP vs SIGINT.    What signal is sent when press CTRL-C at a terminal?   Using kill from shell or kill POSIX call.    Process memory isolation.    Process memory layout (where is heap, stack etc; invalid memoryaddresses).    What is a fork bomb, zombie orphan? How create/remove them.    getpid vs getppid   How use WAIT exit status macros WIFEXITED etc.  Questions/Exercises  What is difference between execs with a p without a p? Whatdoes operating system   How does a program pass in command line arguments execl*? Howabout execv*? What should first command line argument byconvention?   How does a program know if exec or fork failed?   What is int status pointer passed into wait? When does waitfail?   What are some differences between SIGKILL, SIGSTOP, SIGCONT,SIGINT? What are default behaviors? Which ones can a programset up a signal handler for?   What signal is sent when you press CTRL-C?   My terminal is anchored PID = 1337 has become unresponsive. Write me terminal command C code send SIGQUIT it.    Can one process alter another processes memory through normal means?Why?   Where is heap, stack, data, text segment? Which segments cana program write to? What are invalid memory addresses?   Code up a fork bomb in C (please don’t run it).    What is an orphan? How does it become a zombie? What should a parentdo avoid this?   Don’t you hate it when your parents tell you that you can’t dosomething? Write a program that sends SIGSTOP a parent process.    Write a function that fork exec waits an executable, using wait macros tells me if process exited normally or if it wassignaled. If process exited normally, then print that with return value. If not, then print signal number that caused process terminate.  Bovet, Daniel, Marco Cesati. 2005. *Understanding Linux Kernel*. Oreilly &amp; Associates Inc. “Definitions. ” 2018. *The Open Group Base Specifications Issue 7, 2018Edition*. Open Group/IEEE. . “Environment Variables. ” 2018. *Environment Variables*. OpenGroup/IEEE. . Evans, Julia. 2018. “File Descriptors. ” *Julia’s Drawings*. Julia Evans. . “Exec. ” 2018. *Exec*. Open Group/IEEE. . “Fork. ” 2018. *Fork*. Open Group/IEEE. . Jones, Larry. 2010. “WG14 N1539 Committee Draft Iso/Iec 9899: 201x. ”International Standards Organization. “Overview of Malloc. ” 2018. *MallocInternals - Glibc Wiki*. FreeSoftware Foundation. . “Source Sys/Wait. h. ” n. d. *Sys/Wait. h Source*. superglobalmegacorp. . Van der Linden, Peter. 1994. *Expert c Programming: Deep c Secrets*. Prentice Hall Professional. ","url":"/coursebook/Processes"},{"title":"Review","content":"                     ReviewA non-comprehensive list of topics is below. CMemory Strings  In example below, which variables are guaranteed print value of zero?    In example below, which variables are guaranteed print value of zero?    Explain error in following attempt copy a string.     Why does following attempt copy a string sometimes work sometimes fail?    Explain two errors in following code that attempts copy astring.     Which of following is legal?    Complete function pointer typedef declare a pointer afunction that takes a void* argument returns a void*. Nameyour type ‘pthread_callback’    In addition function arguments what else is stored on athread’s stack?   Implement a version of char* strcat(char*dest, const char*src)using only strcpy strlen pointer arithmetic    Implement version of size_t strlen(const char*) using a loop no function calls.     Identify three bugs in following implementation of strcpy.   Printing  Spot two errors!    Complete following code print a file. Print name, acomma score file ‘result. txt’    How would you print values of variables a, mesg, val ptr a string? Print a as an integer, mesg as C string, valas a double val ptr as a hexadecimal pointer. You may assume mesg points a short C string(&lt;50 characters). Bonus: How wouldyou make this code more robust or able cope with?  Input parsing  Why should you check return value of sscanf scanf? ## Q5. 2 Why is ‘gets’ dangerous?   Write a complete program that uses getline. Ensure your programhas no memory leaks.    When would you use calloc instead of malloc? When would realloc useful?   What mistake did programmer make in following code? Is itpossible fix it i) using heap memory? ii) using global (static) memory?  Processes  What is a process?   What attributes are carried over from a process on fork? How abouton a successful exec call?   What is a fork bomb? How can we avoid one?   What is wait system call used for?   What is a zombie? How do we avoid them?   What is an orphan? What happens them?   How do we check status of a process that has exited?   What is a common pattern of processes? Memory  What are calls in C allocate memory?   What must malloc memory aligned to? Why is it important?   What is Knuth’s Allocation Scheme?   How would you handle a request in a buddy allocation scheme?   What is a free list?   What are some different ways of inserting into a free list?   What are benefits drawbacks first fit, worst fit, bestfit?   When would a trivial malloc implementation  acceptable? Threading Synchronization  What is a thread? What do threads share?   How does one create a thread?   Where are stacks for a thread located in memory?   What is a mutex? What problem does it solve?   What is a condition variable? What problem does it solve?   Write a thread safe linked list that supports insert front, back,pop front, pop back. Make sure it doesn’t busy wait!   What is Peterson’s Solution critical section problem? Howabout Dekker’s?   Is following code thread-safe? Redesign following code thread-safe. Hint: A mutex is unnecessary if message memory isunique each call.     Which one of following may leave a process in running?   Returning from pthread’s starting function in lastrunning thread.    original thread returning from main.    Any thread causing a segmentation fault.    Any thread calling exit.    Calling pthread_exit in main thread with other threadsstill running.      Write a mathematical expression for number of “W” charactersthat will printed by following program. Assume a,b,c,d aresmall positive integers. Your answer may use a ‘min’ function thatreturns its lowest valued argument.     Complete following code. following code is supposed printalternating A B. It represents two threads that take turns execute. Add condition variable calls func so that waiting thread need not continually check turn variable. Q:Is pthread_cond_broadcast necessary or is pthread_cond_signalsufficient?    Identify critical sections in given code. Add mutex locking make code thread safe. Add condition variable calls so thattotal never becomes negative or above 1000. Instead callshould block until it is safe proceed. Explain whypthread_cond_broadcast is necessary.     An thread unsafe data structure has size() enq deqmethods. Use condition variable mutex lock complete thread-safe, blocking versions.     Your startup offers path planning using latest trafficinformation. Your overpaid intern has created a thread unsafe datastructure with two functions: shortest (which uses but does notmodify graph) set_edge (which modifies graph).   For performance, multiple threads must able call shortest at same time but graph can only modified by one thread whenno threads other are executing inside shortest or set_edge.    Use mutex lock condition variables implement a reader-writersolution. An incomplete attempt is shown below. Though this attemptis thread safe (thus sufficient for demo day!), it does not allowmultiple threads calculate shortest path at same time will not have sufficient throughput.     How many of following statements are true for reader-writerproblem?   There can multiple active readers   There can multiple active writers   When there is an active writer number of active readers must zero   If there is an active reader number of active writers must zero   A writer must wait until current active readers havefinished   Deadlock  What do each of Coffman conditions what do they mean? Canyou provide a definition of each one an example of breaking themusing mutexes?   Give a real life example of breaking each Coffman condition in turn. A situation consider: Painters, paint paint brushes.    Hold wait   Circular wait   No preemption   Mutual exclusion     Identify when Dining Philosophers code causes a deadlock (or not). For example, if you saw following code snippet which Coffmancondition is not satisfied?    How many processes are blocked?   P1 acquires R1   P2 acquires R2   P1 acquires R3   P2 waits for R3   P3 acquires R5   P1 acquires R4   P3 waits for R1   P4 waits for R5   P5 waits for R1     What are pros cons for following solutions diningphilosophers   Arbitrator   Dijkstra   Stalling’s   Trylock   IPC  What are following what is their purpose?   Translation Lookaside Buffer   Physical Address   Memory Management Unit   dirty bit     How do you determine how many bits are used in page offset?   20 ms after a context switch TLB contains all logical addressesused by your numerical code which performs main memory access 100%of time. What is overhead (slowdown) of a two-level pagetable compared a single-level page table?   Explain why TLB must flushed when a context switch occurs(i. e.  the CPU is assigned work on a different process).    Fill in blanks make following program print 123456789. Ifcat is given no arguments it simply prints its input until EOF. Bonus: Explain why close call below is necessary.     Use POSIX calls fork pipe dup2 close implement anautograding program. Capture standard output of a child processinto a pipe. child process should exec program . /testwith no additional arguments (other than process name). In parent process read from pipe: Exit parent process as soonas captured output contains ! character. Before exiting parent process send SIGKILL child process. Exit 0 if output contained a !. Otherwise if child process exits causing pipe write end closed, then exit with a value of 1. sure close unused ends of pipe in parent childprocess   This advanced challenge uses pipes get an “AI player” playitself until game is complete. program tic tac toe acceptsa line of input - sequence of turns made so far, prints samesequence followed by another turn, then exits. A turn isspecified using two characters. For example “A1” “C3” are twoopposite corner positions. string B2A1A3 is a game of 3turns/plys. A valid response is B2A1A3C1 (the C1 response blocks diagonal B2 A3 threat). output line may also include asuffix -I win -You win -invalid or -draw Use pipes control input output of each child process created. When output contains a -, print final output line (the entire gamesequence result) exit.    Write a function that uses fseek ftell replace middlecharacter of a file with an ‘X’    What is an MMU? What are drawbacks using it versus a directmemory system?   What is a pipe?   What are pros cons between named unnamed pipes? Filesystems  What is file API?   Where are names of files stored?   What is contained in an inode?   What are two special file names in every directory   How do you resolve following path a/. . /b/. /c/. . /. . /c   What are rwx groups?   What is an UID? GID? What is difference between UID Effective UID?   What is umask?   What is sticky bit?   What is a virtual file system?   What is RAID?   In an ext2 filesystem how many inodes are read from disk access first byte of file /dir1/subdirA/notes. txt ? Assume directory names inode numbers in root directory (but not inodes themselves) are already in memory.    In an ext2 filesystem what is minimum number of disk blocksthat must read from disk access first byte of file/dir1/subdirA/notes. txt ? Assume directory names inodenumbers in root directory all inodes are already in memory.    In an ext2 filesystem with 32 bit addresses 4KiB disk blocks,an inode can store 10 direct disk block numbers. What is minimumfile size required require a single indirection table? ii) adouble direction table?   Fix shell command chmod below set permission of a filesecret. txt so that owner can read,write,and executepermissions group can read everyone else has no access.   Networking  What is a socket?   What are different layers of internet?   What is IP? What is an IP address?   What is TCP? What is UDP? What are differences?   Create a TCP client that send “Hello” a server.    Create a simple TCP echo server. This is a server that reads bytesfrom a client until it closes echoes bytes back client.    Create a UDP client that would send a flood of packets a hostnameat argv[1].    What is HTTP?   What is DNS?   Why do we use non-blocking IO for networking?   What is an RPC?   What is special about listening on port 1000 vs port 2000?   Port 2000 is twice as slow as port 1000   Port 2000 is twice as fast as port 1000   Port 1000 requires root privileges   Nothing     Describe one significant difference between IPv4 IPv6?   When why would you use ntohs?   If a host address is 32 bits which IP scheme am I most likely using?128 bits?   Which common network protocol is packet based may notsuccessfully deliver data?   Which common protocol is stream-based will resend data ifpackets are lost?   What is SYN ACK ACK-SYN handshake?   Which one of following is NOT a feature of TCP?   Packet reordering   Flow control   Packet retranmission   Simple error detection   Encryption     What protocol uses sequence numbers? What is their initial value? why?   What are minimum network calls are required build a TCPserver? What is their correct order?   What are minimum network calls are required build a TCPclient? What is their correct order?   When would you call bind on a TCP client?   What is purpose of socket bind listen accept ?   Which of above calls can block, waiting for a new client connect?   What is DNS? What does it do for you? Which of CS241 networkcalls will use it for you?   For getaddrinfo, how do you specify a server socket?   Why may getaddrinfo generate network packets?   Which network call specifies size of allowed backlog?   Which network call returns a new file descriptor?   When are passive sockets used?   When is epoll a better choice than select? When is select a betterchoice than epoll?   Will write(fd, data, 5000) always send 5000 bytes of data? Whencan it fail?   How does Network Address Translation (NAT) work?   Assuming a network has a 20ms One Way Transit Time between Client Server, how much time would it take establish a TCPConnection?   20ms   40ms   100ms   60ms     What are some of differences between HTTP 1. 0 HTTP 1. 1? Howmany ms will it take transmit 3 files from server client if network has a 20ms transmit time? How does time taken differbetween HTTP 1. 0 HTTP 1. 1?   Writing a network socket may not send all of bytes may interrupted due a signal. Check return value of write implement write_all that will repeatedly call write with anyremaining data. If write returns -1 then immediately return -1unless errno is EINTR - in which case repeat lastwrite attempt. You will need use pointerarithmetic.     Implement a multithreaded TCP server that listens on port 2000. Eachthread should read 128 bytes from client file descriptor echo it back client, before closing connection ending thread.    Implement a UDP server that listens on port 2000. Reserve a bufferof 200 bytes. Listen for an arriving packet. Valid packets are 200bytes or less start with four bytes 0x65 0x66 0x67 0x68. Ignoreinvalid packets. For valid packets add value of fifth byteas an unsigned value a running total print total so far. If running total is greater than 255 then exit.  Security  What are three measures for data security?   What is stack smashing?   What is buffer overflows?   How does an operating system provide security? What are someexamples from Networking Filesystems?   What security features does TCP provide?   Is DNS secure? Signals  Give names of two signals that are normally generated by kernel   Give name of a signal that can not caught by a signal   Why is it unsafe call any function (something that it is notsignal handler safe) in a signal handler?   Write brief code that uses SIGACTION a SIGNALSET create aSIGALRM handler.    What is difference between a disposition, mask, pendingsignal set?   What attributes are passed over process children? How aboutexececuted processes? ","url":"/coursebook/Review"},{"title":"Scheduling","content":"                            SchedulingI wish that I could flyThere’s danger if I dare stop here’s reason whyYou see I’m overdueI’m in a rabbit stewCan’t even say “Good-bye”, helloI’m late, I’m late, I’m lateNo, no, no, no, no, no, no! - Alice in WonderlandCPU Scheduling is problem of efficiently selecting which process run on a system’s CPU cores. In a busy system, there will moreready-to-run processes than there are CPU cores, so system kernelmust evaluate which processes should scheduled run whichprocesses should executed later. system must also decidewhetherit should take a particular process pause its execution –along with any associated threads. balance comes from stoppingprocesses often enough where you have a responsive computer butinfrequently enough where programs themselves are spending minimaltime context switching. It is a hard balance get right.  additional complexity of multi-threaded multiple CPU cores areconsidered a distraction this initial exposition so are ignored here. Another gotcha for non-native speakers is dual meaning of “Time”: word “Time” can used in both clock elapsed duration context. For example “The arrival time of first process was 9:00am. ” and,“The running time of algorithm is 3 seconds”. One clarification that we will make is that our scheduling will mainlydeal with short term or CPU scheduling. That means we will assume that processes are in memory ready go. other types ofscheduling are long medium term. Long term schedulers act asgatekeepers processing world. When a process requests anotherprocess executed, it can either tell process yes, no, or wait. medium term scheduler deals with caveats of moving a processfrom paused state in memory paused state on disk when thereare too many processes or some process are known use an insignificantamount of CPU cycles. Think about a process that only checks somethingonce an hour. High Level Scheduler OverviewSchedulers are pieces of software programs. In fact, you can implementschedulers yourself! If you are given a list of commands exec, aprogram can schedule them them with SIGSTOP SIGCONT. These arecalled user space schedulers. Hadoop python’s celery may do somesort of user space scheduling or deal with operating system. At operating system level, you generally have this type offlowchart, described in words first below. Note, please don’t memorizeall states.   New is initial state. A process has been requested schedule. All process requests come from fork or clone. At this point operating system knows it needs create a new process.    A process moves from new state ready. This means anystructs in kernel are allocated. From there, it can go intoready suspended or running.    Running is state that we hope most of our processes are in,meaning they are doing useful work. A process could either getpreempted, blocked, or terminate. Preemption brings process back ready state. If a process is blocked, that means it could waiting on a mutex lock, or it could’ve called sleep – either way,it willingly gave up control.    On blocked state operating system can either turn process ready or it can go into a deeper state called blockedsuspended.    There are so-called deep slumber states called blocked suspended blocked ready. You don’t need worry about these.  We will try pick a scheme that decides when a process should move running state, when it should moved back ready state. We won’t make much mention of how factor in voluntarily blockedstates when switch deep slumber states. MeasurementsScheduling affects performance of system, specifically latency throughput of system. throughput might measured by a system value, for example, I/O throughput - numberof bits written per second, or number of small processes that cancomplete per unit time. latency might measured by responsetime – elapse time before a process can start send a response – orwait time or turnaround time –the elapsed time complete a task. Different schedulers offer different optimization trade-offs that may appropriate for desired use. There is no optimal scheduler for allpossible environments goals. For example, Shortest Job First willminimize total wait time across all jobs but in interactive (UI)environments it would preferable minimize response time at expense of some throughput, while FCFS seems intuitively fair easy implement but suffers from Convoy Effect. Arrival time is time at which a process first arrives at ready queue, is ready start executing. If a CPU is idle, arrival time would also starting time of execution. What is preemption?Without preemption, processes will run until they are unable utilize CPU any further. For example following conditions would remove aprocess from CPU CPU would available scheduled forother processes. process terminates due a signal, is blockedwaiting for concurrency primitive, or exits normally. Thus once aprocess is scheduled it will continue even if another process with ahigh priority appears on ready queue. With preemption, existing processes may removed immediately if amore preferred process is added ready queue. For example, supposeat t=0 with a Shortest Job First scheduler there are two processes (P1P2) with 10 20 ms execution times. P1 is scheduled. P1 immediatelycreates a new process P3, with execution time of 5 ms, which is added ready queue. Without preemption, P3 will run 10ms later (after P1has completed). With preemption, P1 will immediately evicted from CPU instead placed back in ready queue, P3 will executedinstead by CPU. Any scheduler that doesn’t use some form of preemption can result instarvation because earlier processes may never scheduled run(assigned a CPU). For example with SJF, longer jobs may never scheduled if system continues have many short jobs schedule. It all depends on . Why might a process (or thread) placed on ready queue?A process is placed on ready queue when it can use a CPU. Someexamples include:  A process was blocked waiting for a read from storage or socket complete data is now available.    A new process has been created is ready start.    A process thread was blocked on a synchronization primitive(condition variable, semaphore, mutex lock) but is now able continue.    A process is blocked waiting for a system call complete but asignal has been delivered signal handler needs run.  Measures of EfficiencyFirst some definitions  start_time is wall-clock start time of process (CPU startsworking on it)   end_time is end wall-clock of process (CPU finishes process)   run_time is total amount of CPU time required   arrival_time is time process enters scheduler (CPU maystart working on it) Here are measures of efficiency their mathematical equations  Turnaround Time is total time from when process arrives when it ends. end_time - arrival_time   Response Time is total latency (time) that it takes from when process arrives when CPU actually starts working on it. start_time - arrival_time   Wait Time is total wait time or total time that aprocess is on ready queue. A common mistake is believe it isonly initial waiting time in ready queue. If a CPU intensiveprocess with no I/O takes 7 minutes of CPU time complete butrequired 9 minutes of wall-clock time complete we can concludethat it was placed on ready-queue for 2 minutes. For those 2minutes, process was ready run but had no CPU assigned. Itdoes not matter when job was waiting, wait time is 2minutes. end_time - arrival_time - run_time Convoy Effect convoy effect is when a process takes up a lot of CPU time,leaving all other processes with potentially smaller resource needsfollowing like a Convoy Behind them. Suppose CPU is currently assigned a CPU intensive task thereis a set of I/O intensive processes that are in ready queue. Theseprocesses require a tiny amount of CPU time but they are unable proceed because they are waiting for CPU-intensive task removed from processor. These processes are starved until CPUbound process releases CPU. But, CPU will rarely released. For example, in case of an FCFS scheduler, we must wait until process is blocked due an I/O request. I/O intensive process cannow finally satisfy their CPU needs, which they can do quickly becausetheir CPU needs are small CPU is assigned back CPU-intensive process again. Thus I/O performance of wholesystem suffers through an indirect effect of starvation of CPU needs ofall processes. This effect is usually discussed in context of FCFS scheduler;however, a Round Robin scheduler can also exhibit Convoy Effect forlong time-quanta. Scheduling AlgorithmsUnless otherwise stated  Process 1: Runtime 1000ms   Process 2: Runtime 2000ms   Process 3: Runtime 3000ms   Process 4: Runtime 4000ms   Process 5: Runtime 5000ms Shortest Job First (SJF)  P1 Arrival: 0ms   P2 Arrival: 0ms   P3 Arrival: 0ms   P4 Arrival: 0ms   P5 Arrival: 0ms  processes all arrive at start scheduler schedules job with shortest total CPU time. glaring problem is that thisscheduler needs know how long this program will run over time beforeit ran program. Technical Note: A realistic SJF implementation would not use totalexecution time of process but burst time or number of CPUcycles needed finish a program. expected burst time can estimated by using an exponentially decaying weighted rolling averagebased on previous burst time (Silberschatz, Galvin, GagneChapter 6). For this exposition, we will simplify this discussion use total running time of process as a proxy for burst time. Advantages  Shorter jobs tend get run first   On average wait times response times are down Disadvantages  Needs algorithm omniscient   Need estimate burstiness of a process which is harder thanlet’s say a computer network Preemptive Shortest Job First (PSJF)Preemptive shortest job first is like shortest job first but if a newjob comes in with a shorter runtime than total runtime of current job, it is run instead. If it is equal like our example ouralgorithm can choose. scheduler uses total runtime of process. If scheduler wants compare shortest remaining timeleft, that is a variant of PSJF called Shortest Remaining Time First(SRTF).   P2 at 0ms   P1 at 1000ms   P5 at 3000ms   P4 at 4000ms   P3 at 5000ms Here’s what our algorithm does. It runs P2 because it is only thing run. Then P1 comes in at 1000ms, P2 runs for 2000ms, so our schedulerpreemptively stops P2, let’s P1 run all way through. This iscompletely up algorithm because times are equal. Then, P5Comes in – since no processes running, scheduler will run process 5. P4 comes in, since runtimes are equal P5, scheduler stops P5 runs P4. Finally, P3 comes in, preempts P4, runs completion. Then P4 runs, then P5 runs. Advantages Ensures shorter jobs get run firstDisadvantages  Need know runtime again   Context switching jobs can get interrupted First Come First Served (FCFS)  P2 at 0ms   P1 at 1000ms   P5 at 3000ms   P4 at 4000ms   P3 at 5000ms Processes are scheduled in order of arrival. One advantage of FCFSis that scheduling algorithm is simple ready queue is a FIFO (firstin first out) queue. FCFS suffers from Convoy effect. Here P2Arrives, then P1 arrives, then P5, then P4, then P3. You can see convoy effect for P5. Advantages  Simple algorithm implementation   Context switches infrequent when there are long-running processes   No starvation if all processes are guaranteed terminate Disadvantages  Simple algorithm implementation   Context switches infrequent when there are long-running processes Round Robin (RR)Processes are scheduled in order of their arrival in ready queue. After a small time step though, a running process will forciblyremoved from running state placed back on ready queue. Thisensures long-running processes refrain from starving all other processesfrom running. maximum amount of time that a process can executebefore being returned ready queue is called time quanta. As time quanta approaches infinity, Round Robin will equivalent FCFS.   P1 Arrival: 0ms   P2 Arrival: 0ms   P3 Arrival: 0ms   P4 Arrival: 0ms   P5 Arrival: 0ms Quantum = 1000msHere all processes arrive at same time. P1 is run for 1 quantum is finished. P2 for one quantum; then, it is stopped for P3. After allother processes run for a quantum we cycle back P2 until all processes are finished. Advantages Ensures some notion of fairnessDisadvantages Large number of processes = Lots of switchingPriorityProcesses are scheduled in order of priority value. For example, anavigation process might more important execute than a loggingprocess. If you need a math-y way of comparing scheduling algorithms, pleasecheck out appendix section conceptually schedulingTopics  Scheduling Algorithms   Measures of Efficiency Questions  What is scheduling?   What is queueing? What are some different queueing methods?   What is Turnaround Time? Response Time? Wait Time?   What is convoy effect?   Which algorithms have best turnaround/response/wait time onaverage?   Do preemptive algorithms do better on average response time compared non preemptive? How about turnaround/wait time? Silberschatz, A. , P. B. Galvin, G. Gagne. 2005. *Operating SystemConcepts*. Wiley. . ","url":"/coursebook/Scheduling"},{"title":"Security","content":"                           SecurityHackers Are Like Artists, Who Wake Up In A Good Mood &amp; StartPainting - Vladimir PutinComputer security is protection of hardware software fromunauthorized access or modification. Even if you don’t work directly in computer security field, concepts are important learn becauseall systems will have attackers given enough time. Even though this isintroduced as a different chapter, it is important note that most ofthese concepts code examples have already been introduced atdifferent points in course. We won’t go in depth about all of common ways of attack defense nor will we go into how perform allof these attacks in an arbitrary system. Our goal is introduce you field of making programs do what you want do. Security Terminology EthicsThere is some terminology that needs explained get someone whohas little no experience in computer security up speed  An Attacker is typically user who is trying break into system. Breaking into system means performing an action that developer of system didn’t intend. It could also meanaccessing a system you shouldn’t have access to.    A Defender is typically user who is preventing attackerfrom breaking into system. This may developer of system.    There are different types of attackers. There are white hathackers who attempt hack a defender with their consent. This iscommonly a form of pre-emptive testing – in case a not-so-friendlyattack comes along. black hat hackers are hackers who hackwithout permission intent use information obtainedfor any purpose. Gray hat hacking differs because hacker’sintent is inform defender of vulnerability – though thiscan hard judge at times.  Danger Will Robinson Before we let you go much further, it isimportant that we talk about ethics. Before you skip over this section,know that your career quite literally can terminated over anunethical decision that you might make. computer fraud securityact is a broad, arguably terrible law, that casts any non-authorizeduse of a ‘protected computer’ of a computer as a felony. Since mostcomputers are involved in some interstate/international commerce (theinternet) most computers fall under this category. It is important think about your actions have some ladder of accountability beforeexecuting any attack or defense. more concrete, make suresupervisors in your organization have given you their blessing beforetrying execute an attack. First if at all possible, get written permission from one of yoursuperiors. We do realize that this is a cop-out this puts blameup a level, but at risk of sounding cynical organizations will oftenput blame on an individual employee avoid damages TODO: CitationNeeded. If not possible, try go through engineering steps  Figure out what problem is that you are trying solve. Youcan’t solve a problem that you don’t fully understand.    Determine whetheryou need “hack” system. A hack is definedgenerally as trying use a system unintendedly. First, you shoulddetermine if your use is intended or unintended or somewhere in middle – get a decision for them. If you can’t get that, make areasonable judgement as what intended use.    Figure out a reasonable estimate of what cost is “hacking” system. Get that reasonable estimate checked out with a fewengineers so they can highlight things that you may have missed. Try get someone sign off on plan.    Execute plan with caution. If at any point something seemswrong, weigh risks execute plan.  If there isn’t a certain ethical guideline for current application,then create some. This is often called a policy vacuum. This may seemlike busy work more on “business side” than computer scientistsare used to, but your career is at stake here. It is up you as acomputing professional assess risk decide whether execute. Courts generally like sitting on precedent, but you can easilysay that you aren’t a legal scholar. In lieu, you must able saythat you reacted as a “reasonable” engineer would react. TODO: Link some case studies of real engineers having decideCIA TriadThere are three commonly accepted goals help understand if a systemis secure.   Information Confidentiality means that only authorized parties areallowed see a piece of information   Information Integrity means that only authorized parties are allowed modify a piece of information, regardless of whether they areallowed see it. It ensures that information remains in completeduring transit.    Information Availability means information, or a service, isavailable when it is needed.    triad above forms Confidentiality, Integrity, Availability (CIA) triad, often authenticity is added as well.  If any of these are broken, security of a system (either a serviceor piece of information) has been compromised. Security in C ProgramsStack SmashingConsider following code snippetThere is no checking on bounds of strcpy! This means that we couldpotentially pass in a large string get program do somethingunintended, usually via replacing return address of functionwith address of malicious code. Most strings will cause program exit with a segmentation faultIf we manipulate bytes in certain ways program was compiledwith correct flags, we can actually get access a shell! Considerif that file is owned by root, we put in some valid bytecode (binaryinstructions) as string. What will happen is we’ll try executeexecve(’/bin/sh’, ’/bin/sh’, NULL , NULL) that is compiled bytecode of operating system pass it as part of our string. Withsome luck, we will get access a root shell.  question arises, which parts of triad does this break? Try answer that question yourself. So how would we go about fixing this? Wecould ingrain into most programmers at C level use strncpy orstrlcpy on OpenBSD systems. Turning on stack canaries as explainedlater will fix this issue as well. Buffer OverflowMost of you are already familiar with Buffer Overflows! A lot of timethey are fairly tame, leading simple program crashes or funnymistakes. Here is a complete exampleWhat happens here should clear if you recall c memory model. Out in are both next each other in memory. If you read in a stringfrom standard input that overflows in, then you end up printing aoo. Itgets a little more serious if snippet starts out asOut of order instructions &amp; SpectreOut of order execution is an amazing development that has been recentlyadopted by many hardware vendors (think 1990s) TODO: citationneeded. Processors now instead of executing a sequence of instructions(let’s say assigning a variable then another variable) executeinstructions before current one is done (Guide P. 45). This isbecause modern processors spend a lot of time waiting for memoryaccesses other I/O driven applications. This means that a processor,while it is waiting for an operation complete, will execute nextfew operations. If any of operations would possibly alter finalresult, there is a barrier, or if re-ordering violates datadependencies of instructions, processor keep instructions in stated order (Guide P. 296). Naturally, this allowed CPUs become more energy-efficient whileexecuting more instructions in real-time increased security risksfrom complex architectures. What system programmers are worried about isthat operation with mutex locks among threads are out of order – meaningthat a pure software implementation of a mutex will fail without copiousmemory barriers. Therefore, programmer has acknowledge thatupdates may missed among a series of threads, given that there is nobarrier, on modern processors. One of most prominent bugs concerning this is Spectre (Kocher et al. ). Spectre isa bug where instructions that otherwise wouldn’t executed arespeculatively executed due out-of-order instruction execution. following snippet is a high-level proof of concept. Let’s analyze this code. first loop allocates 9 elements through avalid malloc. last element is 0xCAFE, meaning a dereference shouldresult in a SEGFAULT. For first 9 iterations, branch is taken val is assigned a valid value. interesting part happens in last iteration. resulting behavior of program is skip last iteration. Therefore, val never gets assigned last value. But under right compilation conditions compiler flags, instructions will speculatively executed. processor thinks that branch will taken, since it has been taken in last 9iterations. As such, processor will fetch those instructions. Due out-of-order instruction execution, while value of i is beingfetched from memory, we have force it not in a register. Then, processor will try dereference that address. This should resultin a SEGFAULT. Since address was never logically reached by program, result is discarded. Now here is trick. Even though value of calculation wouldhave resulted in a SEGFAULT, bug doesn’t clear cache that refers physical memory where 0xCAFE is located. This is an inexactexplanation, but essentially how it works. Since it is still in cache, if you again trick processor read form cache usingval then you will read a memory value that you wouldn’t able read normally. This could include important information such aspasswords, payment information, etc. Operating Systems Security  Permissions. In POSIX systems, we have permissions everywhere. Thereare directories that you can can’t access, files that you can can’t access. Each user account is given access each file directory through read-write-execute (RWX) bits. user getsmatched with either owner, group, or ‘everyone else’, their access file is limited using these bits. Note thatpermissions work slightly differently on directories compared files.    Capabilities. In addition permissions on files, each user has acertain set of permissions that they can do. For a full list, youcan check capabilities(7). In short, allowing a capability allows auser perform a set of actions. Some examples include controllingnetworking devices, creating special files, peering into IPC orinterprocess communication.    Address Space Layout Randomization (ASLR). ASLR causes addressspaces of important sections of a process, including baseaddress of executable positions of stack, heap libraries, start at randomized values, on every run. This is sothat an attacker with a running executable has randomly guesswhere sensitive information could hidden. For example, anattacker may use this easily perform a return-to-libc attack.    Stack Protectors. Let’s say you’ve programmed a buffer overflow asabove. In most cases, what happens? Unless specifically turned off, compiler will put in stack protectors or stack canaries. This isa value that resides in stack must remain constant for duration of function call. If that protector is overwritten at end of function call, run time will abort report user that stack smashing was detected.    Write xor Execute, also known as Data Execution Prevention (DEP). This is a protection that was covered in IPC section thatdistinguishes code from data. A page can either written orexecuted but not both. This is prevent buffer overflows whereattackers write arbitrary code, often stored on stack or heap, execute with user’s permissions.    Firewall. Linux kernel provides netfilter module as a way ofdeciding whetheran incoming connection should allowed variousother restrictions on connections. This can help with a DDOS attack(explained later).    AppArmor. AppArmor is a suite of operating system tools at userspace level restrict applications certain operations.  OpenBSD is an arguably better system for security. It has many securityoriented features. Some of these features have been touched uponearlier. An exhaustive list of features is at  pledge. Pledge is a powerful command that restricts system calls. This means if you have a simple program like cat which only reads from files, one can reasonably restrict all network access,pipe access, write access files. This is known as processof “hardening” an executable or system, giving smallest amountof permissions least number of executables needed run asystem. Pledge is also useful in case one tries perform aninjection attack.    unveil. Unveil is a system call that restricts access of acurrent program a few directories. Those permissions apply allforked programs as well. This means if you have a suspiciousexecutable that you want run whose description is “creates a newfile outputs random words” one could use this call restrictaccess a safe subdirectory watch it receive SIGKILLsignal if it tries access system files in root directory, forexample. This could useful for your program as well. If you want ensure that no user data is lost during an update (which is whathappened with a Steam system update), then system could onlyreveal program’s installation directory. If an attacker manages find an exploit in executable, it can only compromise installation directory.    sudo. Sudo is an openBSD project that runs everywhere! Before run commands as root, one would have drop a root shell. Sometimes that would also mean giving users scary system capabilities. Sudo gives you access perform commands as root for one-offswithout giving a long list of capabilities all of your users.  Virtualization SecurityVirtualization is act of creating a virtual version of anenvironment for a program run on. Though that definition might bent a little with advent of new-age bare metal Virtual Machines, abstraction is still there. One can imagine a single OperatingSystem per motherboard. Virtualization in software sense isproviding “virtual” motherboard features like USB ports or monitors thatanother program (the bridge) communicates with actual hardware perform a task. A simple example is running a virtual machine on yourhost desktop! One can spin up an entirely different operating systemwhose instructions are fed through another program executed on host system. There are many forms of virtualization that we use today. We will discuss two popular forms below. One form is virtual machines. These programs emulate all forms of motherboard peripherals createa full machine. Another form is containers. Virtual machines are goodbut are often bulky programs only need a certain level ofprotection. Containers are virtual machines that don’t emulate allmotherboard peripherals instead share with host operatingsystem, adding in additional layers of security. Now, you can’t have proper virtualization without security. One of reasons have virtualization is ensure that virtualizedenvironment doesn’t maliciously leak back into host environment. Wesay maliciously because there are intended ways of communication that wewant keep in check. Here are some simple examples of securityprovided through virtualization  chroot is a contrived way of creating a virtualization environment. chroot is short for change root. This changes where a programbelieves that (/) is mounted on system. For example with chroot,one can make a hello world program believe /home/user/ is actually root directory. This is useful because no other files areexposed. This is contrived because Linux still needs additionaltools (think c standard library) come from differentdirectories such as /usr/lib which means those could still vulnerable.    namespaces are Linux’s better way create a virtualizationenvironment. We won’t go into this too much, just know that theyexist.    Hardware virtualization technology. Hardware vendors have becomeincreasingly aware that physical protections are needed whenemulating instructions. As such, there can switches enabled by user that allows operating system flip into avirtualization mode where instructions are run as normal but aremonitored for malicious activity. This helps performance increases security of virtualized environments.  Cyber SecurityCyber Security is arguably most popular area of security. More more of our systems are hacked over web, it is important understand how we can protect against these attacksSecurity at TCP Level  Encryption. TCP is unencrypted! This means any data that issent over a TCP connection is in plain text. If one needs sendencrypted data, one needs use a higher level protocol such asHTTPs or develop their own.    Identity Verification. In TCP, there is no way verify identity of who program is connecting to. There are no checks orfederated databases in place. One just has trust DNS servergave a reasonable response which is almost always incorrectanswer. Apart from systems that have an approved white list or a“secret” connection protocol, there is little at TCP levelthat one can do stop.    Syn-Ack Sequence Number. This is a security improvement. TCPfeatures what we call sequence numbers. That means that during SYN-SYN/ACK-ACK dance, a connection starts at a random integer. Thisis important because if an attacker is trying spoof packets(pretend those packets are coming from your program) that means that attacker must either correctly guess – which is hard – or in route that your packet takes destination – much morelikely. ISPs help out with destination problem because it maysend a connection through varying routers which makes it hard for anattacker sit anywhere sure that they will receive yourpackets – this is why security experts usually advise against usingcoffee shop wifi for sensitive tasks.    Syn-Flood. Before first synchronization packet is acknowledged,there is no connection. That means a malicious attacker can write abad TCP implementation that sends out a flood of SYN packets ahapless server. SYN flood is easily mitigated by using IPTABLESor another netfilter module drop all incoming connections from anIP address after a certain volume of traffic is reached for acertain period.    Denial of Service, Distributed Denial of Service is hardest formof attack stop. Companies today are still trying find goodways ease these attacks. This involves sending all sorts ofnetwork traffic forward servers in hopes that trafficwill clog them up slow down servers. In big systems, thiscan lead cascading failures. If a system is engineered poorly,one server’s failure causes all other servers pick up morework which increases probability that they will fail so on so forth.  Security at DNS LevelAs of 2019, United States Department of Homeland Security released adirective switch all services from DNS DNSSec. This directive is an inherent flaw of DNS system. First, DNS doesn’toffer any sort of verification on domain name requests. That is, it iseasy spoof DNS nameservers such that they point your browser potentially malicious servers. Remember that DNS requests are sent asunsecured UDP packets, which are prone tampering. This means that ifan attacker snags a plain-text request for a DNS server, that attackercan now send result back requester. More commonly instead ofjust attacking one person, they will connect a public wifi station poison cache of router – meaning that all who are connectedwill get a bad IP address when requesting a domain name. This can getinto serious spoofing attacks if one tries pretend they are a majorbank. Topics  Security Terminology   Security in local C programs   Security in CyberSpace Review  What is a chmod statement break only confidentiality of yourdata?   What is a chmod statement break only confidentiality availability of your data?   An attacker gains root access on a Linux system that you use store private information. Does this affect confidentiality,integrity, or availability of your information, or all three?   Hackers brute force your git username password. Who is affected?   Why is privilege separation useful in RPC applications?   Is it easier forge a UDP or TCP packet why?   Why are TCP sequence numbers initialized a random number?   What is impact if RAM used hold a shared library (e. g. C standard library) was writable by any process?   Is creating implementing client-server protocols that are secure invulnerable malicious attackers easy?   Which is harder defend against: Syn-Flooding or DistributedDenial of Service?   Does deadlock affect availability of a service?   Do buffer overflows / underflows affect integrity of a data?   Why shouldn’t stack memory executable.    HeartBleed is an example of what kind of security issue? Whichone(s) of triad does it break?   Meltdown Spectre is an example of what kind of security issue?Which one(s) of triad does it break? Guide, Part. 2011. “Intel 64 Ia-32 Architectures SoftwareDeveloper’s Manual. ” *Volume 3B: System Programming Guide, Part* 2. Kocher, Paul, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg,Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael Schwarz, YuvalYarom. 2018. “Spectre Attacks: Exploiting Speculative Execution. ” *arXivPreprint arXiv:1801. 01203*. ","url":"/coursebook/Security"},{"title":"Signals","content":"                    SignalsThat’s a signal, Jerry, that’s a signal! [snaps his fingers again]Signal! - George Costanza (Seinfeld)Signals are a convenient way deliver low-priority information forusers interact with their programs when other ways don’t work (forexample standard input being frozen). They allow a program clean upor perform an action in case of an event. Sometimes, a program canchoose ignore events which is supported. Crafting a program that usessignals well is tricky due how signals are handled. As such, signalsare usually for termination clean up. Rarely are they supposed used in programming logic. For those of you with an architecture background, interrupts usedhere aren’t interrupts generated by hardware. Those interruptsare almost always handled by kernel because they require higherlevels of privileges. Instead, we are talking about software interruptsthat are generated by kernel – though they can in response ahardware event like SIGSEGV. This chapter will go over how read information from a process thathas either exited or been signaled. Then, it will deep dive into whatare signals, how does kernel deal with a signal, variousways processes can handle signals both with without threads.  Deep Dive of SignalsA signal allows one process asynchronously send an event or message another process. If that process wants accept signal, it can, then, for most signals, decide what do with that signal. First, a bit of terminology. A signal disposition is a per-processattribute that determines how a signal is handled after it isdelivered. Think of it as a table of signal-action pairs. fulldiscussion is in . actions are  TERM, terminates process   IGN, ignore   CORE, generate a core dump   STOP, stops a process   CONT, continues a process   Execute a custom function.  A signal mask determines whether a particular signal is delivered ornot. overall process for how a kernel sends a signal are below.   If no signals have arrived, process can install its own signalhandlers. This tells kernel that when process gets signal Xthat it should jump function Y.    A signal that is created is in a “generated” state.    time between when a signal is generated kernel can apply mask rules is called pending state.    Then kernel then checks process’ signal mask. If masksays all threads in a process are blocking signal, then signal is currently blocked nothing happens until a threadunblocks it.    If a single thread can accept signal, then kernel executes action in disposition table. If action is a defaultaction, then no threads need paused.    Otherwise, kernel delivers signal by stopping whatever aparticular thread is doing currently, jumps that thread signal handler. signal is now in delivered phase. Moresignals can generated now, but they can’t delivered until signal handler is complete which is when delivered phase isover.    Finally, we consider a signal caught if process remains intactafter signal was delivered.  As a flowchartHere are some common signals that you will see thrown around. |c|c|c| Name &amp; Portable Number &amp; Default Action &amp; UsualUseSIGINT &amp; 2 &amp; Terminate (Can caught) &amp; Stop a process nicelySIGQUIT &amp; 3 &amp; Terminate (Can caught) &amp; Stop a process harshlySIGTERM &amp; 15 &amp; Terminate Process &amp; Stop a process even more harshlySIGSTOP &amp; N/A &amp; Stop Process (Cannot caught) &amp; Suspends a processSIGCONT &amp; N/A &amp; Continues a process &amp; Starts after a stopSIGKILL &amp; 9 &amp; Terminate Process (Cannot caught) &amp; You want process goneOne of our favorite anecdotes is never use kill -9 for a host ofreasons. following is an excerpt from No no no. Don’t use kill -9.  It doesn’t give process a chance cleanly: 1) shut down socket connections 2) clean up temp files 3) inform its children that it is going away 4) reset its terminal characteristics so on so on so on.  Generally, send 15, wait a second or two, if that doesn’twork, send 2, if that doesn’t work, send 1. If that doesn’t,REMOVE THE BINARY because program is badly behaved! Don’t use kill -9. Don’t bring out combine harvester just tidyup flower pot. We still keep kill -9 in there for extreme scenarios where processneeds gone. Sending SignalsSignals can generated in multiple ways.   user can send a signal. For example, you are at terminal, you press CTRL-C. One can also use built-in kill sendany signal.    system can send an event. For example, if a process accesses apage that it isn’t supposed to, hardware generates an interruptwhich gets intercepted by kernel. kernel finds processthat caused this sends a software interrupt signal SIGSEGV. There are other kernel events like a child being created or aprocess needs resumed.    Finally, another process can send a message. This could used inlow-stakes communication of events between processes. If you arerelying on signals driver in your program, you shouldrethink your application design. There are many drawbacks usingPOSIX/Real-Time signals for asynchronous communication. best way handle interprocess communication is use, well, interprocesscommunication methods specifically designed for your task at hand.  You or another process can temporarily pause a running process bysending it a SIGSTOP signal. If it succeeds, it will freeze a process. process will not allocated any more CPU time. allow a process resume execution, send it SIGCONT signal. For example, following is a program that slowly prints a dot every second, up 59dots. We will first start process in background (notice &amp; at end). Then, send it a signal from shell process by using killcommand. In C, a program can send a signal child using kill POSIX call,As we saw above there is also a kill command available in shell. Another command killall works exact same way but instead oflooking up by PID, it tries match name of process. ps is animportant utility that can help you find pid of aprocess.  send a signal running process, use raise or kill withgetpid(). For non-root processes, signals can only sent processes of same user. You can’t SIGKILL any process! man -s2 kill for moredetails. Handling SignalsThere are strict limitations on executable code inside a signalhandler. Most library system calls are async-signal-unsafe,meaning they may not used inside a signal handler because they arenot re-entrant. Re-entrant safety means that your function can frozenat any point executed again, can you guarantee that your functionwouldn’t fail? Let’s take following  We execute (func(“Hello”))   string gets copied over buffer completely (strcmp(buffer,“Hello”) == 0)   A signal is delivered function state freezes, we also stopaccepting any new signals until after handler (we do this forconvenience)   We execute func(\"World\")   Now (strcmp(buffer, “World”) == 0) buffer is printed out“World”.    We resume interrupted function now print out buffer onceagain “World” instead of what function call originally intended“Hello” Guaranteeing that your functions are signal handler safe can’t solvedby removing shared buffers. You must also think about multithreading synchronization – what happens when I double lock a mutex? You also have make sure that each function call is reentrant safe. Suppose youroriginal program was interrupted while executing library code ofmalloc. memory structures used by malloc will inconsistent. Calling printf, which uses malloc as part of signal handler, isunsafe will result in undefined behavior. A safe way avoidthis behavior is set a variable let program resume operating. design pattern also helps us in designing programs that can receivesignals twice operate correctly.  above code might appear correct on paper. However, we need provide a hint compiler CPU core that will execute main() loop. We need prevent compiler optimization. expressionpleaseStop doesn’t get changed in body of loop, so somecompilers will optimize it true TODO: citation needed. Secondly, we need ensure that value of pleaseStop is uncachedusing a CPU register instead always read from written mainmemory. sig_atomic_t type implies that all bits of variable can read or modified as an atomic operation - a singleuninterruptible operation. It is impossible read a value that iscomposed of some new bit values old bit values. By specifying pleaseStop with correct typevolatile sig_atomic_t, we can write portable code where main loopwill exited after signal handler returns. sig_atomic_t typecan as large as an int on most modern platforms but on embeddedsystems can as small as a char only able represent (-127 127) values. Two examples of this pattern can found in COMP a terminal based 1Hz4bit computer (Šorn ). Twoboolean flags are used. One mark delivery of SIGINT (CTRL-C), gracefully shutdown program, other mark SIGWINCHsignal detect terminal resize redraw entire display. You can also choose a handle pending signals asynchronously orsynchronously. install a signal handler asynchronously handlesignals, use sigaction. synchronously catch a pending signal usesigwait which blocks until a signal is delivered or signalfd whichalso blocks provides a file descriptor that can read() retrieve pending signals. SigactionYou should use sigaction instead of signal because it has betterdefined semantics. signal on different operating system does differentthings which is bad. sigaction is more portable is betterdefined for threads. You can use system call sigaction set current handler disposition for a signal or read current signalhandler for a particularsignal.  sigaction struct includes two callback functions (we will only lookat ‘handler’ version), a signal mask a flags field -Suppose you stumble upon legacy code that uses signal. followingsnippet installs myhandler as SIGALRM handler.  equivalent sigaction code is:However, we typically may also set mask flags field. mask is a temporary signal mask used during signal handlerexecution. If thread serving signal is interrupted in middleof a system call, SA_RESTART flag will automatically restart somesystem calls that otherwise would have returned early with EINTR error. latter means we can simplify rest of code somewhat because arestart loop may no longer required. It is often better have your code check for error restartitself due selective nature of flag. Blocking Signals block signals use sigprocmask! With sigprocmask you can set new mask, add new signals blocked process mask, unblockcurrently blocked signals. You can also determine existing mask (anduse it for later) by passing in a non-null value for oldset. From Linux man page of sigprocmask, here are possible values forhow TODO: cite.   SIG_BLOCK. set of blocked signals is union of currentset set argument.    SIG_UNBLOCK. signals in set are removed from current setof blocked signals. It is permissible attempt unblock a signalwhich is not blocked.    SIG_SETMASK. set of blocked signals is set argumentset.   sigset type behaves as a set. It is a common error forget initialize signal set before adding set. Correct code initializes set all on or all off. For example,If you block a signal with either sigprocmask or pthread_sigmask,then handler registered with sigaction is not delivered unlessexplicitly sigwait’ed on TODO: cite. SigwaitSigwait can used read one pending signal at a time. sigwait isused synchronously wait for signals, rather than handle them in acallback. A typical use of sigwait in a multi-threaded program is shownbelow. Notice that thread signal mask is set first (and will inherited by new threads). mask prevents signals from beingdelivered so they will remain in a pending state until sigwait iscalled. Also notice same set sigset_t variable is used by sigwait except rather than setting set of blocked signals it is used as set of signals that sigwait can catch return. One advantage of writing a custom signal handling thread (such as example below) rather than a callback function is that you can now usemany more C library system functions safely. Based on sigmask code()Signals in Child Processes ThreadsThis is a recap of processes chapter. After forking, childprocess inherits a copy of parent’s signal dispositions a copyof parent’s signal mask. If you have installed a SIGINT handlerbefore forking, then child process will also call handler if aSIGINT is delivered child. If SIGINT is blocked in parent,it will blocked in child as well. Note that pending signals for child are not inherited during forking. After exec though, only signal mask pending signals are carried over (“Executing aFile,” ). Signal handlers arereset their original action, because original handler code mayhave disappeared along with old process. Each thread has its own mask. A new thread inherits a copy of calling thread’s mask. On initialization, calling thread’s mask is exact same as processes mask. After a new thread is createdthough, processes signal mask turns into a gray area. Instead, kernel likes treat process as a collection of threads, each ofwhich can institute a signal mask receive signals. start settingyour mask, you can use,Blocking signals is similar in multi-threaded programs single-threaded programs with following translation.   Use pthread_sigmask instead of sigprocmask   Block a signal in all threads prevent its asynchronous delivery  easiest method ensure a signal is blocked in all threads is set signal mask in main thread before new threads are created. Just as we saw with sigprocmask, pthread_sigmask includes a ‘how’parameter that defines how signal set is used:A signal then can delivered any signal thread that is willing accept that signal. If two or more threads can receive signalthen which thread will interrupted is arbitrary! A common practiceis have one thread that can receive all signals or if there is acertain signal that requires special logic, have multiple threads formultiple signals. Even though programs from outside can’t sendsignals specific threads, you can do that internally withpthread_kill(pthread_t thread, int sig). In example below, newly created thread executing func will interrupted by SIGINTAs a word of warning pthread_kill(threadid, SIGKILL) will kill entire process. Though individual threads can set a signal mask, signal disposition is per-process not per-thread. This meanssigaction can called from any thread because you will setting asignal handler for all threads in process.  Linux man pages discuss signal system calls in section 2. There isalso a longer article in section 7 (though not in OSX/BSD):Topics  Signals   Signal Handler Safety   Signal Disposition   Signal States   Pending Signals when Forking/Exec   Signal Disposition when Forking/Exec   Raising Signals in C   Raising Signals in a multithreaded program Questions  What is a signal?   How are signals served under UNIX? (Bonus: How about Windows?)   What does it mean that a function is signal handler safe? How aboutreentrant?   What is a process signal disposition? How does it differ from amask?   What function changes signal disposition in a single threadedprogram? How about a multithreaded program?   What are some drawbacks using signals?   What are ways of asynchronously synchronously catching asignal?   What happens pending signals after a fork? exec? How about mysignal mask? How about signal disposition?   What is process kernel goes through from creation delivery/block? “Executing a File. ” n. d. *Executing a File (the GNU C Library)*. GNUProject. . Šorn, Jure. 2015. “Gto76/Comp-Cpp. ” *GitHub*. . n. d. IEEE. . ","url":"/coursebook/Signals"},{"title":"Synchronization","content":"                                                                 SynchronizationWhen multithreading gets interesting - **Synchronization coordinates various tasks so that they all finishin the correct state. In C, we have series of mechanisms control whatthreads are allowed perform at a given state. Most of time, threads can progress without having communicate, but every so oftentwo or more threads may want access a critical section. A criticalsection is a section of code that can only executed by one thread ata time if program is function correctly. If two threads (orprocesses) were execute code inside critical section at sametime, it is possible that program may no longer have correctbehavior. As we said in previous chapter, race conditions happen when anoperation touches a piece of memory at same time as another thread. If memory location is only accessible by one thread, for example automatic variable i below, then there is no possibility of a racecondition no Critical Section associated with i. However, sum variable is a global variable accessed by two threads. It ispossible that two threads may attempt increment variable at same time. A typical output of above code is ARGGGH sum is &lt;some number lessthan expected&gt; because there is a race condition. code allows twothreads read write sum at same time. For example, boththreads copy current value of sum into CPU that runs each thread(let’s pick 123). Both threads increment one their own copy. Boththreads write back value (124). If threads had accessed sumat different times then count would have been 125. A few of possible different orderings are below. Permissible Pattern   Thread 1 Thread 2     Load Addr, Add 1 (i=1 locally) …   Store (i=1 globally) …   … Load Addr, Add 1 (i=2 locally)   … Store (i=2 globally)  Good Thread Access PatternPartial Overlap   Thread 1 Thread 2     Load Addr, Add 1 (i=1 locally) …   Store (i=1 globally) Load Addr, Add 1 (i=1 locally)   … Store (i=1 globally)  Bad Thread Access PatternFull Overlap   Thread 1 Thread 2     Load Addr, Add 1 (i=1 locally) Load Addr, Add 1 (i=1 locally)   Store (i=1 globally) Store (i=1 globally)  Horrible Thread Access PatternWe would like first pattern of code being mutually exclusive. Which leads us our first synchronization primitive, a Mutex. Mutex ensure that only one thread at a time can access a global variable,use a mutex – short for Mutual Exclusion. If one thread is currentlyinside a critical section we would like another thread wait until first thread is complete. A mutex isn’t a primitive in truest sense,though it is one of smallest that has useful threading API. A mutexalso isn’t a data structure. It is an abstract data type. Let’s think about a duck satisfying mutex api. If someone has duck then they are allowed access a shared resource! We call it mutex duck. Everyone else has waddle around wait. Once someonelet’s go of duck, they have stop interacting with resource next grabber can interact with shared resource. Now you know origins of duck. There are many ways implement a mutex, we’ll give a few in thischapter. For right now let’s use black box that pthread librarygives us. Here is how we declare a mutex. Mutex LifetimeFor all mutexes, there are two ways of initializing a mutex:  PTHREAD_MUTEX_INITIALIZER   pthread_mutex_init(pthread_mutex_t *mutex, pthread_mutexattr_t*attr)  macro PTHREAD_MUTEX_INITIALIZER is functionally equivalent more general purpose pthread_mutex_init(&amp;m,NULL). In other words,PTHREAD_MUTEX_INITIALIZER will create a mutex with default properties. attr in init version includes options trade performance foradditional error-checking, advanced sharing, more. While werecommend using init function inside of a program for a mutexlocated on heap, you can use either method. Once we are finished with mutex we should also callpthread_mutex_destroy(&amp;m) too. Note, a program can only destroy anunlocked mutex, destroy on a locked mutex is undefined behavior. Things keep in mind about initializing destroying mutexes:  Initializing an already initialized mutex is undefined behavior   Destroying a locked mutex is undefined behavior   Keep pattern of one only one thread initializing a mutex.    Copying bytes of mutex a new memory location thenusing copy is not supported. reference a mutex, a programmust have a pointer that memory address.    Global/Static mutexes need not destroyed.  Mutex UsagesHow does one use a mutex? Here is a complete example in spirit of earlier piece of code. In code above, thread gets lock counting house beforeentering. critical section is only sum+=1 so followingversion is also correct. This process runs slower because we lock unlock mutex a milliontimes, which is expensive - at least compared with incrementing avariable. In this simple example, we didn’t need threads - we could haveadded up twice! A faster multi-thread example would add onemillion using an automatic (local) variable only then adding it ashared total after calculation loop has finished:Starting with gotchas. Firstly, C Mutexes do not lock variables. Amutex is a simple data structure. It works with code, not data. If amutex is locked, other threads will continue. It’s only when athread attempts lock a mutex that is already locked, will threadhave wait. As soon as original thread unlocks mutex, second (waiting) thread will acquire lock able continue. following code creates a mutex that does effectively nothing. Here are some other gotchas in no particular order  Don’t cross streams! If using threads, don’t fork in middleof your program. This means any time after your mutexes have beeninitialized.    thread that locks a mutex is only thread that can unlock it.    Each program can have multiple mutex locks. A thread safe designmight include a lock with each data structure, one lock per heap, orone lock per set of data structures If a program has only one lock,then there may significant contention for lock. If twothreads were updating two different counters, it isn’t necessary use same lock.    Locks are only tools. They don’t spot critical sections!   There will always a small amount of overhead of callingpthread_mutex_lock pthread_mutex_unlock. However, this is price pay for correctly functioning programs!   Not unlocking a mutex due an early return during an errorcondition   Resource leak (not calling pthread_mutex_destroy)   Using an uninitialized mutex or using a mutex that has already beendestroyed   Locking a mutex twice on a thread without unlocking first   Deadlock Mutex ImplementationSo we have this cool data structure. How do we implement it? A naive,incorrect implementation is shown below. unlock function simplyunlocks mutex returns. lock function first checks see if lock is already locked. If it is currently locked, it will keepchecking again until another thread has unlocked mutex. For timebeing, we’ll avoid condition that other threads are able unlock alock they don’t own focus on mutual exclusion aspect. Version 1 uses ‘busy-waiting’ unnecessarily wasting CPU resources. However, there is a more serious problem. We have a race-condition! Iftwo threads both called lock concurrently, it is possible that boththreads would read m_locked as zero. Thus both threads would believethey have exclusive access lock both threads will continue. We might attempt reduce CPU overhead a little by callingpthread_yield() inside loop - pthread_yield suggests operating system that thread does not use CPU for a short while,so CPU may assigned threads that are waiting run. Thisstill leaves race-condition. We need a better implementation. Wewill talk about this later in critical section part of this chapter. For now, we will talk about semaphores. Advanced: Implementing a Mutex with hardwareWe can use C11 Atomics do that perfectly! A complete solution isdetailed here. This is a spinlock mutex,implementations can found online. First data structure initialization code. This is initialization code, nothing fancy here. We set state of mutex unlocked set owner locked. What does this code do? It initializes a variable that we will keep as unlocked state. is an instruction supported by most modern architectures (on x86 it’slock cmpxchg). pseudocode for this operation looks like thisExcept it is all done atomically meaning in one uninterruptibleoperation. What does weak part mean? Atomic instructions are prone spurious failures meaning that there are two versions theseatomic functions a strong a weak part, strong guarantees success or failure while weak may fail even when operation succeeds. These are same spurious failures that you’ll see in conditionvariables below. We are using weak because weak is faster, we are ina loop! That means we are okay if it fails a little bit more oftenbecause we will keep spinning around anyway. Inside while loop, we have failed grab lock! We reset zero unlocked sleep for a little while. When we wake up we try grab lock again. Once we successfully swap, we are in criticalsection! We set mutex’s owner current thread for unlockmethod return successfully. How does this guarantee mutual exclusion? When working with atomics weare unsure! But in this simple example, we can because thread thatcan successfully expect lock UNLOCKED (0) swap it aLOCKED (1) state is considered winner. How do we implement unlock? satisfy API, a thread can’t unlock mutex unless thread is one who owns it. Then we unassign mutex owner, because criticalsection is over after atomic. We want a strong exchange because wedon’t want block. We expect mutex locked, we swap it unlock. If swap was successful, we unlocked mutex. If swapwasn’t, that means that mutex was UNLOCKED we tried switch itfrom UNLOCKED UNLOCKED, preserving behavior of unlock. What is this memory order business? We were talking about memory fencesearlier, here it is! We won’t go into detail because it is outside scope of this course but in scope of. We need consistency make sure no loads or stores are ordered beforeor after. A program need create dependency chains for more efficientordering. SemaphoreA semaphore is another synchronization primitive. It is initialized some value. Threads can either sem_wait or sem_post which lowers orincreases value. If value reaches zero a wait is called, thread will blocked until a post is called. Using a semaphore is as easy as using a mutex. First, decide if on initial value, for example number of remaining spaces in an array. Unlike pthread mutex there are no shortcuts creating a semaphore -use sem_init. When using a semaphore, wait post can called from differentthreads! Unlike a mutex, increment decrement can fromdifferent threads. This becomes especially useful if you want use a semaphore implement a mutex. A mutex is a semaphore that always waits before itposts. Some textbooks will refer a mutex as a binary semaphore. Youdo have careful never add more than one a semaphore orotherwise your mutex abstraction breaks. That is usually why a mutex isused implement a semaphore vice versa.   Initialize semaphore with a count of one.    Replace pthread_mutex_lock with sem_wait   Replace pthread_mutex_unlock with sem_post But warned, it isn’t same! A mutex can handle what we call lockinversion well. Meaning following code breaks with a traditionalmutex, but produces a race condition with threads. If we replace it with mutex lock, it won’t work now. Also, binary semaphores are different than mutexes because one threadcan unlock a mutex from a different thread. Signal SafetyAlso, sem_post is one of a handful of functions that can correctlyused inside a signal handler pthread_mutex_unlock is not. We canrelease a waiting thread that can now make all of calls that wedisallowed call inside signal handler itself e. g. printf. Hereis some code that utilizes this;Other uses for semaphores are keeping track of empty spaces in arrays. We will discuss these in thread-safe data structures section. Condition VariablesCondition variables allow a set of threads sleep until woken up. API allows either one or all threads woken up. If a program onlywakes one thread, operating system will decide which thread wakeup. Threads don’t wake threads other directly like by id. Instead, athread ‘signal’s condition variable, which then will wake up one (orall) threads that are sleeping inside condition variable. Condition variables are also used with a mutex with a loop, so whenwoken up they have check a condition in a critical section. If athread needs woken up outside of a critical section, there areother ways do this in POSIX. Threads sleeping inside a conditionvariable are woken up by calling pthread_cond_broadcast (wake up all)or pthread_cond_signal (wake up one). Note despite function name,this has nothing do with POSIX signals!Occasionally, a waiting thread may appear wake up for no reason. Thisis called a spurious wakeup. If you read hardware implementationof a mutex section, this is similar atomic failure of samename. Why do spurious wakeups happen? For performance. On multi-CPU systems,it is possible that a race condition could cause a wake-up (signal)request unnoticed. kernel may not detect this lost wake-upcall but can detect when it might occur. avoid potentially lostsignal, thread is woken up so that program code can test condition again. If you want know why, check out appendix. Thread-Safe Data StructuresNaturally, we want our data structures thread-safe as well! Wecan use mutexes synchronization primitives make that happen. First a few definitions. Atomicity is when an operation is thread-safe. We have atomic instructions in hardware by providing lock prefixBut Atomicity also applies higher orders of operations. We say a datastructure operation is atomic if it happens all at once successfullyor not at all. As such, we can use synchronization primitives make our datastructures thread-safe. For most part, we will using mutexesbecause they carry more semantic meaning than a binary semaphore. Note,this is an introduction. Writing high-performance thread-safe datastructures requires its own book! Take for example followingthread-unsafe stack. Version 1 of stack is thread-unsafe because if two threads call pushor pop at same time then results or stack can inconsistent. For example, imagine if two threads call pop at sametime then both threads may read same value, both may read original count value.  turn this into a thread-safe data structure we need identify critical sections of our code, meaning we need ask which section(s)of code must only have one thread at a time. In above example push, pop, is_empty functions access same memory all critical sections for stack. While push (and pop) isexecuting, data structure is an inconsistent state, for example count may not have been written to, so it may still contain originalvalue. By wrapping these methods with a mutex we can ensure that onlyone thread at a time can update (or read) stack. A candidate‘solution’ is shown below. Is it correct? If not, how will it fail?Version 2 contains at least one error. Take a moment see if you can error(s) work out consequence(s). If three threads called push() at same time, lock m1 ensuresthat only one thread at time manipulates stack on push or is_empty– Two threads will need wait until first thread completes Asimilar argument applies concurrent calls pop. However, Version2 does not prevent push pop from running at same time becausepush pop use two different mutex locks. fix is simple inthis case - use same mutex lock for both push pop functions.  code has a second error. is_empty returns after comparison leaves mutex unlocked. However, error would not spottedimmediately. For example, suppose one thread calls is_empty asecond thread later calls push. This thread would mysteriously stop. Using debugger, you can discover that thread is stuck at lock()method inside push method because lock was never unlocked by earlier is_empty call. Thus an oversight in one thread led problems much later in time in an arbitrary other thread. Let’s try rectify these problemsVersion 3 is thread-safe. We have ensured mutual exclusion for all of critical sections. There are a few things note.   is_empty is thread-safe but its result may already out-of-date. stack may no longer empty by time thread gets result! This is usually why in thread-safe data structures,functions that return sizes are removed or deprecated.    There is no protection against underflow (popping on an empty stack)or overflow (pushing onto an already-full stack)  last point can fixed using counting semaphores. implementation assumes a single stack. A more general-purpose versionmight include mutex as part of memory structure usepthread_mutex_init initialize mutex. For example,Before we fix problems with semaphores. How would we fix problems with condition variables? Try it out before you look at code in previous section. We need wait in push pop if ourstack is full or empty respectively. Attempted solution:Does following solution work? Take a second before looking at answer spot errors. So did you catch all of them?  first one is a simple one. In push, our check should against total capacity, not zero.    We only have if statement checks. wait() could spuriously wake up   We never signal any of threads! Threads could get stuck waitingindefinitely.  Let’s fix those errors Does this solution work?This solution doesn’t work either! problem is with signal. Canyou see why? What would you do fix it?Now, how would we use counting semaphores prevent over underflow?Let’s discuss it in next section. Using SemaphoresLet’s use a counting semaphore keep track of how many spaces remain another semaphore track number of items in stack. We willcall these two semaphores sremain sitems. Remember sem_waitwill wait if semaphore’s count has been decremented zero (byanother thread calling sem_post). Sketch #2 has implemented post too early. Another thread waitingin push can erroneously attempt write into a full stack. Similarly, athread waiting in pop() is allowed continue too early. Sketch 3 implements correct semaphore logic, but can you spot error?Sketch 3 correctly enforces buffer full buffer empty conditionsusing semaphores. However, there is no mutual exclusion. Two threadscan in critical section at same time, which would corrupt data structure or least lead data loss. fix is wrap amutex around criticalsection:What happens when we start inverting lock wait orders?Rather than giving you answer, we’ll let you think about this. Isthis a permissible way lock unlock? Is there a series ofoperations that could cause a race condition? How about deadlock? Ifthere is, provide it. If there isn’t, provide a short justificationproof of why that won’t happen. Software Solutions Critical SectionAs already discussed, there are critical parts of our code that can only executed by one thread at a time. We describe this requirement as‘mutual exclusion’. Only one thread (or process) may have access shared resource. In multi-threaded programs, we can wrap a criticalsection with mutex lock unlockcalls:How would we implement these lock unlock calls? Can we create a puresoftware algorithm that assures mutual exclusion? Here is our attemptfrom earlier. As we touched on earlier, this implementation does not satisfy MutualExclusion even considering that threads can unlock other threads locks. Let’s take a close look at this ‘implementation’ from two threadsrunning around same time.  simplify discussion, we consider only two threads. Note thesearguments work for threads processes classic CS literaturediscusses these problems in terms of two processes that need exclusiveaccess a critical section or shared resource. Raising a flagrepresents a thread/process’s intention enter critical section. There are three main desirable properties that we desire in a solution critical section problem.   Mutual Exclusion. thread/process gets exclusive access. Othersmust wait until it exits critical section.    Bounded Wait. A thread/process cannot get superseded by anotherthread infinite amounts of time.    Progress. If no thread/process is inside critical section, thread/process should able proceed without having wait.  With these ideas in mind, let’s examine another candidate solution thatuses a turn-based flag only if two threads both required access at same time. Naive SolutionsRemember that pseudo-code outlined below is part of a largerprogram. thread or process will typically need enter criticalsection many times during lifetime of process. So, imagine eachexample as wrapped inside a loop where for a random amount of time thread or process is working on something else. Is there anything wrong with candidate solution described below?Answer: Candidate solution #1 also suffers from a race conditionbecause both threads/processes could read each other’s flag value aslowered continue. This suggests we should raise flag before checking otherthread’s flag, which is candidate solution #2 below. Candidate #2 satisfies mutual exclusion. It is impossible for twothreads inside critical section at same time. However,this code suffers from deadlock! Suppose two threads wish enter critical section at same time.    Time Thread 1 Thread 2     1 Raise Flag     2   Raise Flag   3 Wait Wait  Candidate Solution #2 AnalysisBoth processes are now waiting for other one lower their flags. Neither one will enter critical section as both are now stuckforever! This suggests we should use a turn-based variable try resolve who should proceed. Turn-based solutions following candidate solution #3 uses a turn-based variable politely allow one thread then other continueCandidate #3 satisfies mutual exclusion. Each thread or process getsexclusive access Critical Section. However, boththreads/processes must take a strict turn-based approach use critical section. They are forced into an alternating critical sectionaccess pattern. If thread 1 wishes read a hash table everymillisecond, but another thread writes a hash table every second,then reading thread would have wait another 999ms before beingable read from hash table again. This ‘solution’ is ineffectivebecause our threads should able make progress enter critical section if no other thread is currently in criticalsection. Turn Flag solutionsIs following a correct solution CSP?Analyzing these solutions is tricky. Even peer-reviewed papers on thisspecific subject contain incorrect solutions(???)!At first glance, it appears satisfy Mutual Exclusion, Bounded Wait Progress turn-based flag is only used in event of a tie, soProgress Bounded Wait is allowed mutual exclusion appears satisfied. Perhaps you can find a counter-example?Candidate #4 fails because a thread does not wait until otherthread lowers its flag. After some thought or inspiration, followingscenario can created demonstrate how Mutual Exclusion is notsatisfied. Imagine first thread runs this code twice. turn flag now points second thread. While first thread is still inside Critical Section, second thread arrives. second thread canimmediately continue into CriticalSection!   Time Turn Thread # 1 Thread # 2     1 2 Raise my flag     2 2 If your flag is raised, wait until my turn Raise my flag   3 2 // Do Critical Section Stuff If your flag is raised, wait until my turn (TRUE!)   4 2 // Do Critical Section Stuff Do Critical Section Stuff - OOPS  Candidate Solution #4Working Solutions first solution problem was Dekker’s Solution. Dekker’sAlgorithm (1962) was first provably correct solution. Though, it wasin an unpublished paper, so it was not discovered until later (Dekker Dijkstra) (thisis an English transcribed version released in 1965). A version of algorithm is below. Notice how process’s flag is always raised during criticalsection no matter if loop is iterated zero, once or more times. Further, flag can interpreted as an immediate intent enter critical section. Only if other process has also raised flagwill one process defer, lower their intent flag wait. Let’s check conditions.   Mutual Exclusion. Let’s try sketch a simple proof. loopinvariant is that at start of checking condition, your flaghas raised – this is by exhaustion. Since only way that athread can leave loop is by having condition false, flag must raised for entirety of critical section. Since loop prevents a thread from exiting while other thread’sflag is raised a thread has its flag raised in criticalsection, other thread can’t enter critical section at same time.    Bounded Wait. Assuming that critical section ends in finitetime, a thread once it has left critical section cannot then get critical section back. reason being is turn variable isset other thread, meaning that that thread now has priority. That means a thread cannot superseded infinitely by anotherthread.    Progress. If other thread isn’t in critical section, it willsimply continue with a simple check. We didn’t make any statementabout if threads are randomly stopped by system scheduler. Thisis an idealized scenario where threads will keep executinginstructions.  Peterson’s SolutionPeterson published his novel surprisingly simple solution in 1981(Peterson). Aversion of his algorithm is shown below that uses a shared variableturn. This solution satisfies Mutual Exclusion, Bounded Wait Progress. Ifthread #2 has set turn 2 is currently inside criticalsection. Thread #1 arrives, sets turn back 1 now waitsuntil thread 2 lowers flag.   Mutual Exclusion. Let’s try sketch a simple proof again. A threaddoesn’t get into critical section until turn variable isyours or other thread’s flag isn’t up. If other thread’sflag isn’t up, it isn’t trying enter critical section. Thatis first action thread does last action threadundoes. If turn variable is set this thread, that means that other thread has given control this thread. Since my flagis raised turn variable is set, other thread has waitin loop until current thread is done.    Bounded Wait. After one thread lowers, a thread waiting in whileloop will leave because first condition is broken. This meansthat threads cannot win all time.    Progress. If no other thread is contesting, other thread’s flags arenot up. That means that a thread can go past while loop docritical section items.  Unfortunately, we can’t implement a software mutex in same way todaybecause of out of order instructions. Check appendix for a solution problem. Implementing Counting SemaphoreNow that we have a solution critical section problem, We canreasonably implement a mutex. How would we implement othersynchronization primitives? Let’s start with a semaphore. implement asemaphore with efficient CPU usage, we will say that we have implementeda condition variable. Implementing an O(1) space condition variableusing only a mutex is not trivial, or at least an O(1) heap conditionvariable is not trivial. We don’t want call malloc while implementinga primitive, or we may deadlock!  We can implement a counting semaphore using condition variables.    Each semaphore needs a count, a condition variable a mutex  Implement sem_init initialize mutex condition variableOur implementation of sem_post needs increment count. We willalso wake up any threads sleeping inside condition variable. Noticewe lock unlock mutex so only one thread can inside critical section at a time. Our implementation of sem_wait may need sleep if semaphore’scount is zero. Just like sem_post, we wrap critical section using lock, so only one thread can executing our code at a time. Noticeif thread does need wait then mutex will unlocked,allowing another thread enter sem_post awaken us from oursleep!Also notice that even if a thread is woken up before it returns frompthread_cond_wait, it must re-acquire lock, so it will have wait until sem_post finishes. That is a complete implementation of a counting semaphore Notice that weare calling sem_post every single time. In practice, this meanssem_post would unnecessary call pthread_cond_signal even if thereare no waiting threads. A more efficient implementation would only callpthread_cond_signal when necessaryi. e. Other semaphore considerations  A production semaphore implementation may include a queue ensurefairness priority. Meaning, we wake up highest-priorityand/or longest sleeping thread.    An advanced use of sem_init allows semaphores shared acrossprocesses. Our implementation only works for threads inside sameprocess. We could fix this by setting condition variable mutex attributes.  Implementing a condition variable with a mutex is complex, so we’ve leftthat in appendix. BarriersSuppose we wanted perform a multi-threaded calculation that has twostages, but we don’t want advance second stage until firststage is completed. We could use a synchronization method called abarrier. When a thread reaches a barrier, it will wait at barrier until all threads reach barrier, then they’ll allproceed together. Think of it like being out for a hike with some friends. You make amental note of how many friends you have agree wait for eachother at top of each hill. Say you’re first one reach topof first hill. You’ll wait there at top for your friends. One byone, they’ll arrive at top, but nobody will continue until lastperson in your group arrives. Once they do, you’ll all proceed. Pthreads has a function pthread_barrier_wait() that implements this. You’ll need declare a pthread_barrier_t variable initialize itwith pthread_barrier_init(). pthread_barrier_init() takes numberof threads that will participating in barrier as an argument. Here is a sample program using barriers. Now let’s implement our own barrier use it keep all threadsin sync in a large calculation. Here is our thought process,  Threads do first calculation (use change values in data)   Barrier! Wait for all threads finish first calculation beforecontinuing   Threads do second calculation (use change values in data)  thread function has four main parts-Our main thread will create 16 threads, we will divide eachcalculation into 16 separate pieces. Each thread will given a uniquevalue (0,1,2,. . 15), so it can work on its own block. Since a (void*)type can hold small integers, we will pass value of i by castingit a void pointer. Note, we will never dereference this pointer value as an actual memorylocation. We will cast it straight back an integer. After calculation 1 completes, we need wait for slower threadsunless we are last thread! So, keep track of number of threadsthat have arrived at our barrier ‘checkpoint’. However, code has a few flaws. One is two threads might try decrement remain. other is loop is a busy loop. We can dobetter! Let’s use a condition variable then we will use abroadcast/signal functions wake up sleeping threads. A reminder, a condition variable is similar a house! Threads gothere sleep (pthread_cond_wait). A thread can choose wake up onethread (pthread_cond_signal) or all of them(pthread_cond_broadcast). If there are no threads currently waitingthen these two calls have no effect. A condition variable version is usually similar a busy loop incorrectsolution - as we will show next. First, let’s add a mutex conditionglobal variables don’t forget initialize them in main. We will use mutex ensure that only one thread modifies remainat a time. last arriving thread needs wake up all sleepingthreads - so we will use pthread_cond_broadcast(&amp;cv) notpthread_cond_signalWhen a thread enters pthread_cond_wait, it releases mutex sleeps. After, thread will woken up. Once we bring a thread backfrom its sleep, before returning it must wait until it can lock mutex. Notice that even if a sleeping thread wakes up early, it willcheck while loop condition re-enter wait if necessary.  above barrier is not reusable. Meaning that if we stick it intoany old calculation loop there is a good chance that code willencounter a condition where barrier either deadlocks or thread racesahead one iteration faster. Why is that? Because of ambitiousthread. We will assume that one thread is much faster than all otherthreads. With barrier API, this thread should waiting, but it maynot be. make it concrete, let’s look at this codeWhat happens if a thread becomes ambitious. Well  Many other threads wait on condition variable   last thread broadcasts.    A single thread leaves while loop.    This single thread performs its calculation before any other threadseven wake up   Reset number of remaining threads goes back sleep.  All other threads who should’ve woken up never do ourimplementation deadlocks. How would you go about solving this? Hint: Ifmultiple threads call barrier_wait in a loop then one can guaranteethat they are on same iteration. Reader Writer ProblemImagine you had a key-value map data structure that is used by manythreads. Multiple threads should able look up (read) values at same time provided data structure is not being written to. writers are not so gregarious. avoid data corruption, only one threadat a time may modify (write) data structure no readers may reading at that time. This is an example of Reader Writer Problem. Namely, how can weefficiently synchronize multiple readers writers such that multiplereaders can read together, but a writer gets exclusive access?An incorrect attempt is shown below (“lock” is a shorthand forpthread_mutex_lock):Attempt #1At least our first attempt does not suffer from data corruption. Readersmust wait while a writer is writing vice versa! However, readersmust also wait for other readers. Let’s try another implementation. Attempt #2:Our second attempt suffers from a race condition. Imagine if two threadsboth called read write or both called write at same time. Both threads would able proceed! Secondly, we can have multiplereaders multiple writers, so let’s keep track of total number ofreaders or writers Which brings us attempt #3. Attempt #3Remember that pthread_cond_wait performs Three actions. Firstly, itatomically unlocks mutex then sleeps (until it is woken bypthread_cond_signal or pthread_cond_broadcast). Thirdly, awokenthread must re-acquire mutex lock before returning. Thus only onethread can actually running inside critical section defined by lock unlock() methods. Implementation #3 below ensures that a reader will enter cond_wait if any writers are writing. However, only one reader a time can read because candidate #3 did notunlock mutex. A better version unlocks before reading. Does this mean that a writer read could read write at sametime? No! First of all, remember cond_wait requires threadre-acquire mutex lock before returning. Thus only one thread can executing code inside critical section (marked with **) at atime!Writers must wait for everyone. Mutual exclusion is assured by lock. Candidate #3 above also uses pthread_cond_signal. This will only wakeup one thread. If many readers are waiting for writer complete,only one sleeping reader will awoken from their slumber. reader writer should use cond_broadcast so that all threads should wakeup check their while-loop condition. Starving writersCandidate #3 above suffers from starvation. If readers are constantlyarriving then a writer will never able proceed (the ‘reading’count never reduces zero). This is known as starvation would discovered under heavy loads. Our fix is implement a bounded-wait for writer. If a writer arrives they will still need wait forexisting readers however future readers must placed in a “holdingpen” wait for writer finish. “holding pen” can implemented using a variable a condition variable so that we canwake up threads once writer has finished.  plan is that when a writer arrives, before waiting for currentreaders finish, register our intent write by incrementing acounter ‘writer’ incoming readers will not allowed continue while writer isnonzero. Notice ‘writer’ indicates a writer has arrived, while ‘reading’ ‘writing’ counters indicate there is an active reader or writer. Attempt #4Below is our first working solution Reader-Writer problem. Noteif you continue read about “Reader Writer problem” then you willdiscover that we solved “Second Reader Writer problem” by givingwriters preferential access lock. This solution is not optimal. However, it satisfies our original problem of N active readers, singleactive writer, avoiding starvation of writer if there is aconstant stream of readers. Can you identify any improvements? For example, how would you improve code so that we only woke up readers or onewriter?Ring BufferA ring buffer is a simple, usually fixed-sized, storage mechanism wherecontiguous memory is treated as if it is circular, two indexcounters keep track of current beginning end of queue. Asarray indexing is not circular, index counters must wrap around zero when moved past end of array. As data is added (enqueued) front of queue or removed (dequeued) from tail of queue, current items in buffer form a train that appears circle trackA simple (single-threaded) implementation is shown below. Note, enqueue dequeue do not guard against underflow or overflow. It’s possible add an item when queue is full possible remove an item when queue is empty. If we added 20 integers (1, 2, 3, …, 20) queue did not dequeue any items then values, 17,18,19,20 wouldoverwrite 1,2,3,4. We won’t fix this problem right now, instead ofwhen we create multi-threaded version we will ensure enqueue-ing dequeue-ing threads are blocked while ring buffer is full or emptyrespectively. Ring Buffer GotchasIt’s tempting write enqueue or dequeue method in followingcompact form. This method would appear work but contains a subtle bug. With morethan four billion enqueue operations, int value of in willoverflow wrap around 0! Thus, you might end up writing intob[0] for example!A compact form is correct uses bit masking provided N is a power of two. (16,32,64,…)This buffer does not yet prevent overwrites. For that, we’ll turn ourmulti-threaded attempt that will block a thread until there is space orthere is at least one item remove. Multithreaded Correctness following code is an incorrect implementation. What will happen?Will enqueue and/or dequeue block? Is mutual exclusion satisfied?Can buffer underflow? Can buffer overflow? For clarity,pthread_mutex is shortened p_m we assume sem_wait cannot interrupted. AnalysisBefore reading on, see how many mistakes you can find. Then determinewhat would happen if threads called enqueue dequeue methods.   enqueue method waits posts on same semaphore (s1) similarly with enqueue (s2) i. e.  we decrement value thenimmediately increment value, so by end of function semaphore value is unchanged!  initial value of s1 is 16, so semaphore will never reduced zero - enqueue will not block if ring buffer is full  so overflow is possible.     initial value of s2 is zero, so calls dequeue will alwaysblock never return!  order of mutex lock sem_wait will need swapped;however, this example is so broken that this bug has no effect!Another Analysis following code is an incorrect implementation. What will happen?Will enqueue and/or dequeue block? Is mutual exclusion satisfied?Can buffer underflow? Can buffer overflow? For claritypthread_mutex is shortened p_m we assume sem_wait cannot interrupted. Here are a few problems that we hope you’ve found.   initial value of s2 is 0. Thus enqueue will block on firstcall sem_wait even though buffer is empty!   initial value of s1 is 16. Thus dequeue will not block on first call sem_wait even though buffer is empty -Underflow! dequeue method will return invalid data.    code does not satisfy Mutual Exclusion. Two threads can modifyin or out at same time! code appears use mutex lock. Unfortunately, lock was never initialized withpthread_mutex_init() or PTHREAD_MUTEX_INITIALIZER - so lockmay not work (pthread_mutex_lock may simply do nothing) Correct implementation of a ring bufferAs mutex lock is stored in global (static) memory it can initialized with PTHREAD_MUTEX_INITIALIZER. If we had allocated spacefor mutex on heap, then we would have usedpthread_mutex_init(ptr, NULL) enqueue method is shown below. Make sure note.   lock is only held during critical section (access data structure).    A complete implementation would need guard against early returnsfrom sem_wait due POSIX signals.   dequeue implementation is shown below. Notice symmetry of synchronization calls enqueue. In both cases, functions firstwait if count of spaces or count of items is zero. Food for thought:  What would happen if order of pthread_mutex_unlock sem_post calls were swapped?   What would happen if order of sem_wait pthread_mutex_lock calls were swapped? Extra: Process SynchronizationYou thought that you were using different processes, so you don’t have synchronize? Think again! You may not have race conditions within aprocess but what if your process needs interact with systemaround it? Let’s consider a motivating exampleIf none of system calls fail then we should get something that lookslike this given file was empty begin with. InterruptionBut, there is a hidden nuance. Most system calls can interruptedmeaning that operating system can stop an ongoing system callbecause it needs stop process. So barring fork wait open close from failing – they typically go completion – whathappens if write fails? If write fails no bytes are written, wecan get something like key1: value1 or key2: value2. This is dataloss which is incorrect but won’t corrupt file. What happens ifwrite gets interrupted after a partial write? We get all sorts ofmadness. For example,SolutionA program can create a mutex before fork-ing - however child parent process will not share virtual memory each one will have amutex independent of other. Advanced note: There are advancedoptions using shared memory that allow a child parent share amutex if it’s created with correct options uses a shared memorysegment. SeeSo what should we do? We should use a shared mutex! Consider following code. What code does in main is initialize a process shared mutex using apiece of shared memory. You will find out what this call mmapdoes later – assume for time being that it creates memory that isshared between processes. We can initialize a pthread_mutex_t in thatspecial piece of memory use it as normal. counter writefailing, we have put write call inside a while loop that keepswriting so long as there are bytes left write. Now if all othersystem calls function, there should more race conditions. Most programs try avoid this problem entirely by writing separatefiles, but it is good know that there are mutexes across processes, they are useful. A program can use all of primitives that werementioned previouslty! Barriers, semaphores, condition variablescan all initialized on a shared piece of memory used in similarways their multithreading counterparts.   You don’t have worry about arbitrary memory addresses becomingrace condition candidates. Only areas that specifically mapped arein danger.    You get nice isolation of processes so if one process fails system can maintain intact.    When you have a lot of threads, creating a process might ease system load There are other ways synchronize as well, check out goroutines orhigher orders of synchronization in appendix. External ResourcesGuiding questions for man pages  How is a recursive mutex different than a default mutex?   How is mutex trylock different than mutex lock?   Why would a mutex lock fail? What’s an example?   What happens if a thread tries destroy a locked mutex?   Can a thread copy underlying bytes of a mutex instead of using apointer?   What is lifecycle of asemaphore?                   Topics  Atomic operations   Critical Section   Producer Consumer Problem   Using Condition Variables   Using Counting Semaphore   Implementing a barrier   Implementing a ring buffer   Using pthread_mutex   Implementing producer consumer   Analyzing multi-threaded coded Questions  What is atomic operation?   Why will following not work in parallel code  this will?    What are some downsides atomic operations? What would faster:keeping a local variable or many atomic operations?   What is critical section?   Once you have identified a critical section, what is one way ofassuring that only one thread will in section at a time?   Identify critical section here    How tight can you make critical section?   What is a producer consumer problem? How might above aproducer consumer problem used in above section? How is aproducer consumer problem related a reader writer problem?   What is a condition variable? Why is there an advantage using oneover a while loop?   Why is this code dangerous?    What is a counting semaphore? Give me an analogy a cookiejar/pizza box/limited food item.    What is a thread barrier?   Use a counting semaphore implement a barrier.    Write up a Producer/Consumer queue, How about a producer consumerstack?   Give me an implementation of a reader-writer lock with conditionvariables, make a struct with whatever you need, it needs able support following functions  only specification is that in between reader_lock reader_unlock, no writers can write. In between writer locks,only one writer may writing at a time.    Write code implement a producer consumer using ONLY threecounting semaphores. Assume there can more than one threadcalling enqueue dequeue. Determine initial value of eachsemaphore.    Write code implement a producer consumer using conditionvariables a mutex. Assume there can more than one threadcalling enqueue dequeue.    Use CVs implement add(unsigned int) subtract(unsigned int)blocking functions that never allow global value greaterthan 100.    Use CVs implement a barrier for 15 threads.    What does following code do?    Is following code correct? If it isn’t, could you fix it?    Sketch how use a binary semaphore as a mutex. Remember inaddition mutual exclusion, a mutex can only ever unlocked by thread who called it.     How many of following statements are true?   There can multiple active readers   There can multiple active writers   When there is an active writer number of active readers must zero   If there is an active reader number of active writers must zero   A writer must wait until current active readers havefinished   Dekker, T. J. , Edsgar Dijkstra. 1965. “Over de Sequentialiteit vanProcesbeschrijvingen. ” *E. W. Dijkstra Archive: Over de Sequentialiteitvan Procesbeschrijvingen (EWD 35)*. University of Texas Austin. . Peterson, Gary L. 1981. “Myths About Mutual Exclusion Problem. ”*Inf. Process. Lett. * 12: 115–16. ","url":"/coursebook/Synchronization"},{"title":"Threads","content":"                     ThreadsIf you think your programs crashing before, wait until they crash tentimes as fast - **A thread is short for ‘thread-of-execution’. It represents sequenceof instructions that CPU has will execute. remember how return from function calls, store values of automaticvariables parameters a thread uses a stack. Almost weirdly, a threadis a process, meaning that creating a thread is similar fork,except there is no copying meaning no copy on write. What thisallows is for a process share same address space, variables,heap, file descriptors etc. actual system call create athread is similar fork. It’s clone. We won’t go into specifics, but you can read keeping in mind that it is outside direct scope of this course. LWPor Lightweight Processes or threads are preferred forking for a lotof scenarios because there is a lot less overhead creating them. But insome cases, notably python uses this, multiprocessing is way makeyour code faster. Processes vs threadsCreating separate processes is useful when:  When more security is desired. For example, Chrome browser usesdifferent processes for different tabs.    When running an existing complete program then a new process isrequired, for example starting ‘gcc‘.    When you are running into synchronization primitives eachprocess is operating on something in system.    When you have too many threads – kernel tries schedule all threads near each other which could cause more harm than good.    When you don’t want worry about race conditions   When amount of communication is minimal enough that simple IPCneeds used.  On other hand, creating threads is more useful when:  You want leverage power of a multi-core system do one task   When you can’t deal with overhead of processes   When you want communication between processes simplified   When you want threads part of same process Thread InternalsYour main function other functions has automatic variables. We willstore them in memory using a stack keep track of how large stackis by using a simple pointer (the “stack pointer”). If thread callsanother function, we move our stack pointer down, so that we have morespace for parameters automatic variables. Once it returns from afunction, we can move stack pointer back up its previous value. We keep a copy of old stack pointer value - on stack! This iswhy returning from a function is quick. It’s easy ‘free’ memoryused by automatic variables because program needs change stack pointer. In a multi-threaded program, there are multiple stacks but only oneaddress space. pthread library allocates some stack space uses clone function call start thread at that stack address. A program can have more than one thread running inside a process. programget first thread for free! It runs code you write inside‘main’. If a program need more threads, it can call pthread_create create a new thread using pthread library. You’ll need pass apointer a function so that thread knows where start.  threads all live inside same virtual memory because they arepart of same process. Thus they can all see heap, globalvariables, program code. Thus, a program can have two (or more) CPUs working on your program at same time inside same process. It’s up operatingsystem assign threads CPUs. If a program has more activethreads than CPUs, kernel will assign thread a CPU for ashort duration or until it runs out of things do then willautomatically switch CPU work on another thread. For example, oneCPU might processing game AI while another thread is computing graphics output. Simple Usage use pthreads, include pthread. h compile link with-pthread or -lpthread compiler option. This option tells compiler that your program requires threading support. create athread, use function pthread_create. This function takes fourarguments:  first is a pointer a variable that will hold id of newly created thread.    second is a pointer attributes that we can use tweak tune some of advanced features of pthreads.    third is a pointer a function that we want run   Fourth is a pointer that will given our function  argument void *(*start_routine) (void *) is difficult read! Itmeans a pointer that takes a void * pointer returns a void *pointer. It looks like a function declaration except that name of function is wrapped with (* . . . . )In above example, result will NULL because busyfunction returned NULL. We need pass address-of result becausepthread_join will writing into contents of our pointer. In man pages, it warns that programmers should use pthread_t as anopaque type not look at internals. We do ignore that often,though. Pthread FunctionsHere are some common pthread functions:  pthread_create creates a new thread. Every thread gets a newstack. If a program calls pthread_create twice, Your process willcontain three stacks - one for each thread. first thread iscreated when process start, other two after create. Actually, there can more stacks than this, but let’s keep itsimple. important idea is that each thread requires a stackbecause stack contains automatic variables old CPU PCregister, so that it can go back executing calling functionafter function is finished.    pthread_cancel stops a thread. Note thread may still continue. For example, it can terminated when thread makes an operatingsystem call (e. g. write). In practice, pthread_cancel is rarelyused because a thread won’t clean up open resources like files. Analternative implementation is use a boolean (int) variable whosevalue is used inform other threads that they should finish clean up.    pthread_exit(void *) stops calling thread meaning threadnever returns after calling pthread_exit. pthread library willautomatically finish process if no other threads are running. pthread_exit(. . . ) is equivalent returning from thread’sfunction; both finish thread also set return value (void*pointer) for thread. Calling pthread_exit in mainthread is a common way for simple programs ensure that allthreads finish. For example, in following program, myfuncthreads will probably not have time get started. On otherhand exit() exits entire process sets process’ exitvalue. This is equivalent return (); in main method. Allthreads inside process are stopped. Note pthread_exitversion creates thread zombies; however, this is not a long-runningprocess, so we don’t care.     pthread_join() waits for a thread finish records its returnvalue. Finished threads will continue consume resources. Eventually, if enough threads are created, pthread_create willfail. In practice, this is only an issue for long-running processesbut is not an issue for simple, short-lived processes as all threadresources are automatically freed when process exits. This isequivalent turning your children into zombies, so keep this inmind for long-running processes. In exit example, we could alsowait on all threads.   There are many ways exit threads. Here is a non-complete list:  Returning from thread function   Calling pthread_exit   Canceling thread with pthread_cancel   Terminating process through a signal.    calling exit() or abort()   Returning from main   Executing another program   Unplugging your computer   Some undefined behavior can terminate your threads, it is undefinedbehavior Race ConditionsRace conditions are whenever outcome of a program is determined byits sequence of events determined by processor. This means that execution of code is non-deterministic. Meaning that sameprogram can run multiple times depending on how kernel schedules threads could produce inaccurate results. following is canonical race condition. Breaking down assembly there are many different accesses of code. We will assume that data is stored in eax register. code increment is following with no optimization (assume int_ptrcontains eax). Consider this access pattern. This access pattern will cause variable data 4. problemis when instructions are executed in parallel. This access pattern will cause variable data 2. This isundefined behavior a race condition. What we want is one thread access part of code at a time. But when compiled with -O2, assembly output is a single instruction. Shouldn’t that fix it? It is a single assembly instruction so nointerleaving? It doesn’t fix problems that hardware itself mayexperience a race condition because we as programmers didn’t tell hardware check for it. easiest way is add lock prefix(Guide , 1120). But we don’t want coding in assembly! We need come up with asoftware solution this problem. A day at racesHere is another small race condition. following code is supposed start ten threads with integers 0 through 9 inclusive. However, whenrun prints out 1 7 8 8 8 8 8 8 8 10! Or seldom does it print out whatwe expect. Can you see why? above code suffers from a race condition - value of i ischanging. new threads start later in example output lastthread starts after loop has finished. overcome thisrace-condition, we will give each thread a pointer its own data area. For example, for each thread we may want store id, a startingvalue an output value. We will instead treat i as a pointer castit by value. Race conditions aren’t in our code. They can in provided code Somefunctions like asctime, getenv, strtok, strerror notthread-safe. Let’s look at a simple function that is also not‘thread-safe’. result buffer could stored in global memory. This is good in a single-threaded program. We wouldn’t want return apointer an invalid address on stack, but there’s only one resultbuffer in entire memory. If two threads were use it at sametime, one would corrupt other. There are ways around this like using synchronization locks, but firstlet’s do this by design. How would you fix function above? You canchange any of parameters any return types. Here is one validsolution. Instead of making function responsible for memory, we made caller responsible! A lot of programs, hopefully your programs,have minimal communication needed. Often a malloc call is less work thanlocking a mutex or sending a message another thread. Don’t Cross StreamsA program can fork inside a process with multiple threads! However, child process only has a single thread, which is a clone of threadthat called fork. We can see this as a simple example, where background threads never print out a second message in childprocess. In practice, creating threads before forking can lead unexpectederrors because (as demonstrated above) other threads are immediatelyterminated when forking. Another thread might have locked a mutex likeby calling malloc never unlock it again. Advanced users may findpthread_atfork useful however we suggest a program avoid creatingthreads before forking unless you fully understand limitations difficulties of this approach. Embarrassingly Parallel Problems study of parallel algorithms has exploded over past few years. An embarrassingly parallel problem is any problem that needs littleeffort turn parallel. A lot of them have some synchronizationconcepts with them but not always. You already know a parallelizablealgorithm, Merge Sort!With your new understanding of threads, all you need do is create athread for left half, one for right half. Given that yourCPU has multiple real cores, you will see a speedup following. time complexity analysis gets interesting here as well. parallelalgorithm runs in \\(O(\\log^3(n))\\) running time because we have analysis assumes that we have a lot of cores. In practice though, we typically do two changes. One, once arraygets small enough, we ditch Parallel Merge Sort algorithm doconventional sort that works fast on small arrays, usually cachecoherency rules at this level. other thing that we know is that CPUsdon’t have infinite cores. get around that, we typically keep aworker pool. You won’t see speedup right away because of things likecache coherency scheduling extra threads. Over bigger pieces ofcode, though, you will start see speedups. Another embarrassingly parallel problem is parallel map. Say we want apply a function an entire array, one element at a time. Since none of elements depend on any other element, how would you goabout parallelizing this? What do you think would best way split up work between threads. Check out thread scheduling in appendix for more ways schedule. Other ProblemsFrom  Serving static files on a web server multiple users at once.    Mandelbrot set, Perlin noise, similar images, where eachpoint is calculated independently.    Rendering of computer graphics. In computer animation, each framemay rendered independently (see parallel rendering).    Brute-force searches in cryptography.    Notable real-world examples include distributed. net proof-of-work systems used in cryptocurrency.    BLAST searches in bioinformatics for multiple queries (but not forindividual large queries)   Large scale facial recognition systems that compare thousands ofarbitrary acquired faces (e. g. , a security or surveillance video viaclosed-circuit television) with a similarly large number ofpreviously stored faces (e. g. , a rogues gallery or similar watchlist).    Computer simulations comparing many independent scenarios, such asclimate models.    Evolutionary computation meta-heuristics such as genetic algorithms.    Ensemble calculations of numerical weather prediction.    Event simulation reconstruction in particle physics.    marching squares algorithm   Sieving step of quadratic sieve number field sieve.    Tree growth step of random forest machine learning technique.    Discrete Fourier Transform where each harmonic is independentlycalculated.  Advanced: Lightweight Processes?In beginning of chapter, we mentioned that threads areprocesses. What do we mean by that? You can create a thread like aprocess. Take a look at example code below. It seems pretty simple right? Why not use this functionality? First,there is a decent bit of boilerplate code. In addition, pthreads arepart of POSIX standard have defined functionality. Pthreads leta program set various attributes – some that resemble option inclone – customize your thread. But as we mentioned earlier, with eachlater of abstraction for portability reasons we lose some functionality. clone can do some neat things like keeping different parts of your heap same while creating copies of other pages. A program has finercontrol of scheduling because it is a process with same mappings. At no time in this course should you using clone. But in future,know that it is a perfectly viable alternative fork. You have careful research edge cases. Further ReadingGuiding questions:  What is first argument pthread create?   What is start routing in pthread create? How about arg?   Why might pthread create fail?   What are a few things that threads share in a process? What are afew things that threads have different?   How can a thread uniquely identify itself?   What are some examples of non thread safe library functions? Whymight they not thread safe?   How can a program stop a thread?   How can a program get back a thread’s “returnvalue”?          Topics  pthread life-cycle   Each thread has a stack   Capturing return values from a thread   Using pthread_join   Using pthread_create   Using pthread_exit   Under what conditions will a process exit Questions  What happens when a pthread gets created?   Where is each thread’s stack?   How does a program get a return value given a pthread_t? What are ways a thread can set that return value? What happens if aprogram discards return value?   Why is pthread_join important (think stack space, registers,return values)?   What does pthread_exit do if it is not last thread? What otherfunctions are called when after calling pthread_exit?   Give me three conditions under which a multi-threaded process willexit. Are there any more?   What is an embarrassingly parallel problem? Guide, Part. 2011. “Intel 64 Ia-32 Architectures SoftwareDeveloper’s Manual. ” *Volume 3B: System Programming Guide, Part* 2. ","url":"/coursebook/Threads"},{"title":"Home","content":"Coursebook This coursebook is being built by students faculty from University of Illinois. It is based on a crowd-source authoring wikibook experiment by Lawrence Angrave from CS @ Illinois, but is now its own . tex based project. Its source code is located at which you can find a pdf version of book as well. This book is an introduction programming in C, system programming (processes, threads, synchronization, networking more!). We assume you’ve already had some programming experience, in an earlier computer science course. If you have any typos report or content request, feel free file an issue at link above. Happy Reading!1.  2.       3.             4.          5.          6.        7.             8.        9.         10.       11.           12.          13.        14.      15.           16.   17.                    18.                 ","url":"/coursebook/index"},{"title":"Networking","content":"bibliography: ‘networking/networking. bib’…NetworkingNetworking has become arguably most important use of computers in past 10-20 years. Most of us nowadays can’t stand a place withoutwifi or any connectivity, so it is crucial as programmers that you havean understanding of networking how program communicate acrossnetworks. Although it may sound complicated, POSIX has defined nicestandards that make connecting outside world easy. POSIX alsolets you peer underneath hood optimize all little parts ofeach connection write high performant OSI Model Open Source Interconnection 7 layer model (OSI Model) is a sequenceof segments that define standards for both infrastructure protocolsfor forms of radio communication, in our case internet. 7 layermodel is as follows  Layer 1: physical layer. These are actual waves that carry bauds across wire. As an aside, bits don’t cross wirebecause in most mediums you can alter two characterstics of a wave – amplitude frequency – get more bits per clock cycle.    Layer 2: link layer. This is how each of agents react certain events (error detection, noisy channels, etc). This is where live.    Layer 3: network layer. This is heart of internet. bottom two protocols deal with communication between two differentcomputers that are directly connected. This layer deals with routingpackets from one endpoint another.    Layer 4: transport layer. This layer specifies how slices ofdata are received. bottom three layers make no guarantee about order that packets are received what happens when a packetis dropped. Using different protocols, this layer can.    Layer 5: session layer. This layer makes sure that if aconnection in previous layers is dropped, a new connection in lower layers can established, it looks like a nothinghappened end user.    Layer 6: presentation layer. This layer deals with encryption,compression, data translation. For example, portability betweendifferent operating systems like translating newlines windows newlines.    Layer 7: application layer. application layer is where manydifferent protocols live. are both defined at this level. Thisis typically where we define protocols across internet. Asprogrammers, we only go lower when we think we can create algorithmsthat are more suited our needs than all of below.  Just clear this is not a networking class. We won’t go over mostof these layers in depth. We will focus on some aspects of layers 3, 4, 7 because they are essential know if you are going doingsomething with internet, which at some point in your career you willbe. As for another definition, a protocol is a set of specifications putforward by that govern how implementers of protocol have theirprogram or circuit behave under specific circumastnces. Layer 3: Internet Protocol following is 30 second introduction internet protocol (IP), primary way send datagrams of information from one machine another. “IP4”, or more precisely, is version 4 of Internet Protocolthat describes how send of information across a network from onemachine another. Roughly 95% of all packets on Internet today areIPv4 packets. A significant limitation of IPv4 is that source destination addresses are limited 32 bits. IPv4 was designed at atime when idea of 4 billion devices connected same networkwas unthinkable or at least not worth making packet size larger. arewritten typically in a sequence of four octets delimited by periods“255. 255. 255. 0” for example. Each IPv4 includes a very small header - typically 20 , that includes asource destination address. Conceptually source destinationaddresses can split into two: a network number upper bits lower bits represent a particular host number on that network. A newer packet protocol solves many of limitations of IPv4 likemaking routing tables simpler 128 bit addresses. However, less than5% of web traffic is IPv6 based. We write IPv6 addresses in a sequenceof eight, four hexadecimal delimiters like“1F45:0000:0000:0000:0000:0000:0000:0000”. Since that can get unruly, wecan omit zeros “1F45::”. A machine can have an IPv6 address anIPv4 address. There are special IP Addresses. One such in IPv4 is , IPv6 as or alsoknown as localhost. Packets sent 127. 0. 0. 1 will never leave machine; address is specified same machine. There are alot of others that are denoted by certain octets being zeros or 255, maximum value. You won’t need know all terminology, just keep inmind that actual number of IP addresses that a machine can haveglobally over internet is smaller than number of “raw”addresses. For purposes of class, you need know at this layerthat IP deals with routing, fragmenting, reassembling upper levelprotocols. A more in-depth aside follows. In-depth IPv4 Specification internet protocol deals with routing, fragmentation, reassemblyof fragments. Datagrams are formatted as such{width=”. 8\\textwidth”}  first octet is version number, either 4 or 6   next octet is how long header is. Although it may seem that header is constant size, you can include optional parameters augment path taken or other instructions   next two octets specify total length of datagram. Thismeans this is header, data, footer, padding. This isgiven in multiple of octets, meaning that a value of 20 means20 octets.    next two are Identification number. IP handles taking packetsthat are too big sent over phsyical wire chunks themup. As such, this number identifies what datagram this originallybelonged to.    next octet is various bit flags that can set.    next octet half is fragment number. If this packet wasfragmented, this is number this fragment represents   next octet is time live. So this is number of “hops”(travels over a wire) a packet is allowed go. This is set becausedifferent routing protocols could cuase packets go in circles, packets must dropped at some point.    next octet is protocol number. Although protocols betweendifferent layers of OCI model are supposed black boxes,this is included, so that hardware can peer into underlyingprotocol efficiently. Take for example IP over IP (yes you can dothat!). Your ISP wraps IPv4 packets sent from your computer ISP in another IP layer sends packet off delivered website. On reverse trip packet is “unwrapped” original IP datagram is sent your computer. This was done becausewe ran out of IP addresses, this adds additional overhead but itis a necessary fix. Other common protocols are TCP, UDP, etc.    next two octets is an internet checksum. This is a CRC that iscalculated make sure that a wide variety of bit errorsare detected.    Source address is what people generally refer as IP address. There is no verification of this, so one host can pretend anyIP address possible   Destination address is where you want packet sent to. Thisis crucial in routing process as you need that route.    After: Your data! All layer of higher order protocols are put inthere   Additional options: Hosts of additional options   Footer: A bit of padding make sure your data is a multiple of 8 Routing internet protocol routing is an amazing intersection of theory application. We can imagine entire internet as a set of graphs. Mostpeers are connected what we call “peering points” these are WIFIrouters ethernet ports that one finds in their house, work, orpublic. These peering points are then connected a wired network ofrouters, switches, servers that all route themselves. At a top levelthere are two types of routing  Internal Routing Protocols. Internal protocols is routing designedfor within an ISP’s network. These protocols are meant fast more trusting because all computers, switches, routers arepart of an ISP. communication between two routers.    External Routing Protocols. These typically happen ISP ISPprotocol. Certain routers are designated as border routers. Theserouters talk routers from ISPs have have different policies fromaccepting or receiving packets. If an evil ISP is trying dump allnetwork traffic onto your ISP, these routers would deal with that. These protocols also deal with gathering information about outside world each router. In most routing protocols using linkstate or OSPF, a router must necessarily calculate shortest path destination. This means it needs information about “foreign” routers which is disseminated according these protocols.  These two protocols have interplay with each other nicely in order make sure that packets are mostly delivered. In addition, ISPs need nice each other because theoretically an ISP can handle lower loadby forwarding all packets another ISP. If everyone does that then, nopackets get delivered at all which won’t make customers happy at all. Sothese two protocols need fair so end result worksIf you want read more about this, look at wikipedia page forrouting here . Fragmentation/ReassemblyLower layers like WiFi Ethernet have maximum transmission sizes. reason being is  One host shouldn’t crowd medium for too long   If an error occurs, we want some sort of “progress bar” on how far communication has gone instead of retransmitting stream   There are physical limitations as well, keeping a laser beam inoptics working continuously may cause bit errors.  As such if internet protocol receives a packet that is too big for maximum size, it must chunk it up. TCP calculates how many datagramsit needs construct a packet ensures that they are all transmitted reconstructed at end receiver. reason that we barely usethis feature is that if any fragment is lost, entire packet is lost. Meaning that, assuming probability of receiving a packet assumingeach fragment is lost with an independent percentage, probability ofsuccessfully sending a packet drops off exponentially as packet sizeincreases. As such, TCP slices its packets so that it fits inside on IP datagram. only time that this applies is when sending UDP packets that are toobig, but most people who are using UDP optimize set same packetsize as well. IP MulticastA little known feature is that using IP protocol one can send adatagram all devices connected a router in what is called amulticast. Multicasts can also configured with groups, so one canefficiently slice up all connected routers send a piece ofinformation all of them efficiently. access this in a higherprotocol, you need use UDP specify a few more options. Note thatthis will cause undo stress on network, so a series of multicastscould flood network fast. What’s deal with IPv6?One of big features of IPv6 is address space. world ran outof IP addresses a while ago has been using hacks get around that. With IPv6 there are enough internal external addresses, so thatunless we discover alien civilizations, we probably won’t run out. other benefit is that these addresses are leased not bought, meaningthat if something drastic happens in let’s say internet of things there needs a change in block addressing scheme, it can done. Another big feature is security through IPsec. IPv4 was designed withlittle no security in mind. As such, now there is a key exchangesimilar TLS in higher layers that allows you encryptcommunication. Another feature is simplified processing. In order make internetfast, IPv4 IPv6 headers alike are actually implemented in hardware. That means that all header options are processed in circuits as theycome in. problem is that as IPv4 spec grew include a copiousamount of headers, hardware had become more more advanced support those headers. IPv6 reorders headers so that packets can dropped routed with less hardware cycles. In case of internet, every cycle matters when trying route world’s traffic. What’s My Address? obtain a linked list of IP addresses of current machine use whichwill return a linked list of IPv4 IPv6 IP addresses among otherinterfaces as well. We can examine each entry use print host’s IP address. struct includes family but does not include sizeof struct. Therefore we need manually determine struct sized based on family. ``` {. c language=”C”} (family == AF_INET) ? sizeof(struct sockaddr_in) : sizeof(struct sockaddr_in6) get your IP Address from command line use (or Windows’s ) Howeverthis command generates a lot of output for each interface, so we canfilter output using grep actually grab IP Address of a remote website. function canconvert a human readable domain name (e. g. ) into an IPv4 IPv6address. In fact it will return a linked-list of addrinfo structs:``` {. c language=”C”}struct addrinfo { int ai_flags; int ai_family; int ai_socktype; int ai_protocol; socklen_t ai_addrlen; struct sockaddr *ai_addr; char *ai_canonname; struct addrinfo *ai_next;};If you are wondering how the computer maps addresses, we willtalk about that in Layer 7. Spoiler: It is a service calledLayer 4: TCP ClientMost services on Internet today use because it efficiently hides complexity of lower, packet-level nature of Internet. TCP orTransport Control Protocol is a connection-based protocol that is builton top of IPv4 IPv6 therefore can described as “TCP/IP” or“TCP over IP”. TCP creates a pipe between two machines abstractsaway low level packet-nature of Internet. Thus, under mostconditions, bytes sent over a TCP connection will not lost orcorrupted. TCP has a number of features that set it apart from other transportprotocol UDP.   With IP, you are only allowed send packets a machine. If youwant one machine handle multiple flows of data, you have do itmanually with IP. TCP abstracts that an gives programmer a setof virtual sockets. Clients specify socket that you want packet sent TCP protocol makes sure that applicationsthat are waiting for packets on that port receive that. A processcan listen for incoming packets on a particular port. However onlyprocesses with (root) access can listen on ports less than 1024. Anyprocess can listen on ports 1024 or higher. An often used port isport 80: Port 80 is used for unencrypted http requests or web pages. For example, if a web browser connects then it will connecting port 80.    Packets can get dropped due network errors or congestion. Assuch, they need retransmitted but at same time retransmission shouldn’t cause packets more packets dropped. This needs balance tradeoff between flooding network speed.    Out of order packets. Packets may get routed more favorably due various reasons in IP. If a later packet arrives before anotherpacket, protocol should detect reorder them.    Duplicate packets. Packets can arrive twice. Packets can arrivetwice. As such, a protocol need able differentiate betweentwo packets given a sequence number subject overflow.    Error correction. There is a TCP checksum that handles bit errors. This is rarely used though.    Flow Control. Flow control is performed on receiver side. Thismay done so that a slow receiver doesn’t get overwhelmed withpackets. Servers especially that may handle 10000 or 10 millionconcurrent connection may need tell receivers slow down, butnot disconnect due load. There are also other prorblem of makingsure local network is not overwhelmed   Congestion control. Congestion control is performed on senderside. Congestion control is avoid a sender from flooding network with too many packets. This is really important make surethat each TCP connection is treated fairly. Meaning that twoconnections leaving a computer google youtube receive same bandwidth ping as each other. One can easily define aprotocol that takes all bandwidth leaves other protocols in dust, but this tends malicious because more often than notlimiting a computer a single TCP connection will yield same result.    Connection oriented/lifecycle oriented. You can really imagine a TCPconnection as a series of bytes sent through a pipe. There is a“lifecycle” a TCP connection though. What this means is that aTCP connection has a series of states certain packets receivedcan or not received can move it another state. TCP handlessetting up connection through SYN SYN-ACK ACK. This means client will send a SYNchronization packet that tells TCP whatstarting sequence start on. Then receiver will send a SYN-ACKmessage acknowledging synchronization number. Then clientwill ACKnowledge that with one last packet. connection is nowopen for both reading writing on both ends TCP will send data receiver of data will acknowledge that it received apacket. Then every so often if a packet is not sent, TCP will tradezero length packets make sure connection is still alive. Atany point, client server can send a FIN packet meaning that server will not transmit. This packet can altered with bitsthat only close read or write end of a particular connection. When all ends are closed then connection is over.  There are a list of things that TCP doesn’t provide though  Security. This means that if you connect an IP address that saysthat it is a certain website, TCP does not verify that this websiteis in fact that IP address. You could sending packets amalicious computer.    Encryption. Anybody can listen in on plain TCP. packets intransport are in plain text meaning that important things like yourpasswords could easily skimmed by servers regularly are.    Session Reconnection. This is handled by a higher protocols, but ifa TCP connection dies then a whole new one hast created transmission has started over again.    Delimiting Requests. TCP is naturally connection oriented. Applications that are communicating over TCP need find a uniqueway of telling each other that this request or response is over. HTTP delimits header through two carriage returns useseither a length field or one keeps listening until connectioncloses Note on network ordersIntegers can represented in least significant byte first ormost-significant byte first. Either approach is reasonable as long as machine itself is internally consistent. For network communicationswe need standardize on agreed format. returns 16 bit unsigned integer ‘short’ value xyz in network byteorder. returns 32 bit unsigned integer ‘long’ value xyz in networkbyte order. These functions are read as ‘host network’; inverse functions (,) convert network ordered byte values host-ordered ordering. So, ishost-ordering little-endian or big-endian? answer is - it depends onyour machine! It depends on actual architecture of host running code. If architecture happens same as network orderingthen result of these functions is just argument. For x86machines, host network ordering is different. Unless agreed otherwise whenever you read or write low level Cnetwork structures (e. g.  port address information), remember use above functions ensure correct conversion to/from a machineformat. Otherwise displayed or specified value may incorrect. This doesn’t apply protocols that negotiate endiannessbefore-hand. If two computers are CPU bound by converting messagesbetween network orders – this happens with JSON parsing all time inhigh performance systems – it may worth it negotiate if they areon similar endians send in little endian order. TCP ClientThere are three basic system calls you need connect a remotemachine:  call if successful, creates a linked-list of structs sets given pointer point first one.  In addition, you can use hints struct only grab certainentries like certain IP protocols etc. addrinfo structure thatis passed into define kind of connection you’d like. Forexample, specify stream-based protocols over IPv6: ``` {. c language=”C”}struct addrinfo hints;memset(&amp;hints, 0, sizeof(hints)); hints. ai_family = AF_INET6; // Only want IPv6 (use AF_INET for IPv4)hints. ai_socktype = SOCK_STREAM; // Only want stream-based connection    socket call creates an outgoing socket returns a descriptorthat can used with . In this sense it is network analogof that opens a file stream - except that we haven’t connected socket anything yet! Socket creates a socket with domain  AF_INET for IPv4 or AF_INET6for IPv6, is whether use UDP or TCP or other socket type, is anoptional choice of protocol configuration (for our examples this wecan just leave this as 0 for default). This call creates a socketobject in kernel with which one can communicate with outsideworld/network. You can use result of fill in parameters,or provide them manually.  socket call returns an integer - a file descriptor - and, forTCP clients, you can use it like a regular file descriptor i. e.  youcan use receive or send packets.  TCP sockets are similar except that they allow full duplexcommunication i. e.  you can send receive data in bothdirections independently.    Finally connect call attempts connection remotemachine. We pass original socket descriptor also socketaddress information which is stored inside addrinfo structure. There are different kinds of socket address structures which canrequire more memory. So in addition passing pointer, sizeof structure is also passed. help identify errors mistakes it is good practice check return value of allnetworking calls, including {. c language=\"C\"}// Pull out socket address info from addrinfo struct:connect(sockfd, p-&gt;ai_addr, p-&gt;ai_addrlen)   (Optional) clean up code call on first level struct.  There is an old function is deprecated; it’s old way convert a hostname into an IP address. port address still needs manually setusing function. It’s much easier write code support IPv4 AND IPv6using newerThis is all that is needed create a simple TCP client - howevernetwork communications offers many different levels of abstraction several attributes options that can set at each level ofabstraction. For example we haven’t talked about which can manipulateoptions for socket. For more information see this. Sending some dataOnce we have a successful connection we can read or write like any oldfile descriptor. Keep in mind if you are connected a website, youwant conform HTTP protocol specification in order get anysort of meaningful results back. There are libraries do this, usuallyyou don’t connect at socket level because there are other librariesor packages around it. number of bytes read or written may smaller than expected. Thus it is important check return value ofread write. A simple HTTP client that sends a request compliantURL is below. ``` {. c language=”C”}#include #include #include #include #include &lt;sys/types. h&gt; #include &lt;sys/socket. h&gt; #include #include #include &lt;sys/types. h&gt;#include &lt;sys/stat. h&gt;#include #ifndef _GNU_SOURCE#define _GNU_SOURCE#endiftypedef struct _host_info { char *hostname; char *port; char *resource;} host_info;host_info *get_info(char *uri);void free_info(host_info *info);host_info *send_request(host_info *info);ssize_t min(ssize_t a, ssize_t b) { return a &lt; b ? a : b;}host_info *get_info(char *uri) {void free_info(host_info *info) { free(info-&gt;hostname); free(info-&gt;port); free(info-&gt;resource); free(info);}static void send_get_request(FILE sock_file, host_info *info) { char *buffer; asprintf(&amp;buffer,  “GET %s HTTP/1. 0\\r\\n” “Connection: close\\r\\n” “Accept: */\\r\\n\\r\\n”,  info-&gt;resource); int sock_fd = fileno(sock_file); write(sock_fd, buffer, strlen(buffer)); free(buffer);}static void connect_to_address(int sock_fd, host_info *info) { struct addrinfo current, *result; memset(&amp;current, 0, sizeof(struct addrinfo)); current. ai_family = AF_INET; current. ai_socktype = SOCK_STREAM; int s = getaddrinfo(info-&gt;hostname, info-&gt;port, &amp;current, &amp;result); if (s != 0) { fprintf(stderr, “getaddrinfo: %s\\n”, gai_strerror(s)); exit(1); } if(connect(sock_fd, result-&gt;ai_addr, result-&gt;ai_addrlen) == -1){ perror(“connection error”); exit(1); } freeaddrinfo(result);}host_info *send_request(host_info *info) { int sock_fd = socket(AF_INET, SOCK_STREAM, 0); if (sock_fd == -1) { perror(“socket”); exit(1); } int optval = 1; int retval = setsockopt(sock_fd, SOL_SOCKET, SO_REUSEADDR, &amp;optval, sizeof(optval)); if(retval == -1) { perror(“setsockopt”); exit(1); } connect_to_address(sock_fd, info);int main(int argc, char *argv[]) { if(argc != 2) { fprintf(stderr, “Usage: %s http://hostname[:port]/path\\n”, *argv); return 1;  } char *uri = argv[1]; host_info *info = get_info(uri); do { host_info *temp = send_request(info); free_info(info); info = NULL; if (temp) { info = temp; } } while(info); example above demonstrates a request server using HypertextTransfer Protocol. A web page (or other resources) are requested using following request:There are four parts method e. g.  GET,POST,…); resource (e. g. //index. html /image. png); proctocol “HTTP/1. 0” two new lines( r n r n) server’s first response line describes HTTP version used whether request is successful using a 3 digit response code:If client had requested a non existing file, e. g. Then firstline includes response code is well-known response code:Layer 4: TCP Server four system calls required create a TCP server are: , . Eachhas a specific purpose should called in roughly above order  create a endpoint for networking communication. A new socket byitself is not particularly useful. Though we’ve specified either apacket or stream-based connections, it is not bound a particularnetwork interface or port. Instead socket returns a networkdescriptor that can used with later calls bind, listen accept.  As one gotcha, these sockets must declared passive. Passiveserver sockets do not actively try connect another host;instead they wait for incoming connections. Additionally, serversockets are not closed when peer disconnects. Instead clientcommunicates with a separate active socket on server that isspecific that connection.  Since a TCP connection is defined by sender address portalong with a receiver address port, a particular server portthere can one passive server socket but multiple active sockets:one for each currently open connection. server’s operatingsystem maintains a lookup table that associates a unique tuple withactive sockets, so that incoming packets can correctly routed correct socket.    call associates an abstract socket with an actual networkinterface port. It is possible call bind on a TCP client. port information used by bind can set manually many olderIPv4-only C code examples do this, or created using By default a port is not immediately released when server socketis closed. Instead, port enters a “TIMED-WAIT” state. This canlead significant confusion during development because timeoutcan make valid networking code appear fail.  able immediately re-use a port, specify before binding port.  ``` {. c language=”C”} int optval = 1; setsockopt(sfd, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof(optval)); bind(…); ``` Here’s .    call specifies queue size for number of incoming,unhandled connections i. e.  that have not yet been assigned a networkdescriptor by Typical values for a high performance server are 128or more.    Once server socket has been initialized server calls waitfor new connections. Unlike , this call will block. i. e.  ifthere are no new connections, this call will block only returnwhen a new client connects. returned TCP socket is associatedwith a particular tuple will used for all future incoming outgoing TCP packets that match this tuple.  Note call returns a new file descriptor. This file descriptor isspecific a particular client. It is common programming mistake use original server socket descriptor for server I/O thenwonder why networking code has failed.  system call can optionally provide information about remoteclient, by passing in a sockaddr struct. Different protocols havedifferently variants of , which are different sizes. simplest struct use is which is sufficiently large represent all possible types of sockaddr. Notice that C does nothave any model of inheritance. Therefore we need explicitly castour struct ‘base type’ struct sockaddr.  ``` {. c language=”C”} struct sockaddr_storage clientaddr; socklen_t clientaddrsize = sizeof(clientaddr); int client_id = accept(passive_socket, (struct sockaddr *) &amp;clientaddr, &amp;clientaddrsize);    (optional but highly recommended)  Use call when you no longer need read any more data from socket, write more data, or have finished doing both. When youshutdown a socket for further writing (or reading) that informationis also sent other end of connection. For example if youshutdown socket for further writing at server end, then amoment later, a blocked call could return 0 indicate that no morebytes are expected.  Use when your process no longer needs socket file descriptor.  If you -ed after creating a socket file descriptor, all processesneed close socket before socket resources can re-used. If you shutdown a socket for further read then all process are affected because you’ve changed socket, not just file descriptor.  Well written code will a socket before calling it.  There are a few gotchas creating a server.   Using socket descriptor of passive server socket(described above)   Not specifying SOCK_STREAM requirement for getaddrinfo   Not being able re-use an existing port.    Not initializing unused struct entries   call will fail if port is currently in use. Ports are permachine – not per process or user. In other words, you cannot useport 1234 while another process is using that port. Worse, ports areby default ‘tied up’ after a process has finished.  Server code exampleA working simple server example is shown below. Note this example isincomplete - for example it does not close either socket descriptor, orfree up memory created by``` {. c language=”C”}#include #include #include #include &lt;sys/types. h&gt;#include &lt;sys/socket. h&gt;#include #include #include &lt;arpa/inet. h&gt;int main(int argc, char **argv){ int s; int sock_fd = socket(AF_INET, SOCK_STREAM, 0);Layer 4: UDPUDP is a connectionless protocol that is built on top of IPv4 IPv6. It’s very simple use: Decide destination address port send your data packet! However network makes no guarantee aboutwhether packets will arrive. Packets (aka Datagrams) may droppedif network is congested. Packets may duplicated or arrive out oforder. Between two distant data-centers it’s typical see 3% packet loss. Atypical use case for UDP is when receiving up date data is moreimportant than receiving all of data. For example, a game may sendcontinuous updates of player positions. A streaming video signal maysend picture updates using UDPUDP Attributes  Unreliable Datagram Protocol Packets sent through UDP are notguaranteed reach their destination. probability that packet gets delivered goes down over time.    Simple UDP protocol is supposed have much less fluff thanTCP. Meaning that for TCP there are a lot of configurable parameters a lot of edge cases in implementation. UDP is just fire forget.    Stateless/Transaction UDP protocol does not keep a “state” of connection. This makes protocol more simple let’s protocol represent simple transactions like requesting or responding queries. There is also less overhead sending a UDP messagebecause there is no three way handshake.    Manual Flow/Congestion Control You have manually manage flow congestion control which is a double edged sword. On one handyou have full control over everything, but on other hand TCP hasdecades of optimization, meaning your protocol for its use casesneeds more efficient that that more beneficial use it.    Multicast This is one thing that you can only do with UDP. Thismeans that you can send a message every peer connected aparticular router that is part of a particular group.  UDP ClientUDP Clients are pretty versatile below is a simple client that sends apacket a server specified through command line. Note that thisclient sends a packet doesn’t wait for acknowledgement. It fires forgets. example below also uses because some legacy functionalitystill works pretty well for setting up a client. ``` {. c language=”C”} struct sockaddr_in addr; memset(&amp;addr, 0, sizeof(addr)); addr. sin_family = AF_INET; addr. sin_port = htons((uint16_t)port); struct hostent *serv = gethostbyname(hostname); if (!serv) { perror(“gethostbyname”); exit(1); }UDP ServerThere are a variety of function calls available send UDP sockets. Wewill use newer getaddrinfo help set up a socket structure. Remember that UDP is a simple packet-based (‘data-gram’) protocol ;there is no connection set up between two hosts. First,initialize hints addrinfo struct request an IPv6, passivedatagram socket. ``` {. c language=”C”}memset(&amp;hints, 0, sizeof(hints));hints. ai_family = AF_INET6; // use AF_INET instead for IPv4hints. ai_socktype = SOCK_DGRAM;hints. ai_flags = AI_PASSIVE; port number is less than 1024, so program will need privileges. We could have also specified a service name instead of a numeric portvalue. So far calls have been similar a TCP server. For a stream-basedservice we would call accept. For our UDP-serve we can just startwaiting for arrival of a packet on socket-``` {. c language=”C”}struct sockaddr_storage addr;int addrlen = sizeof(addr);// ssize_t recvfrom(int socket, void* buffer, size_t buflen, int flags, struct sockaddr *addr, socklen_t * address_len);byte_count = recvfrom(sockfd, buf, sizeof(buf), 0, &amp;addr, &amp;addrlen);Layer 7: HTTPLayer 7 of OSI layer deals with application level interfaces. Meaning that you can ignore everything below this layer treat aninternet as a way of communicating with another computer than can secure session may reconnect. Common layer 7 protocols are following  HTTP(S) - Hyper Text Transfer Protocol. Sends arbitrary data executes remote actions on a web server.    FTP - File Transfer Protocol. Transfers a file from one computer another   TFTP - Trivial File Transfer Protocol. Same as above but using UDP.    DNS - Domain Name Service. Translates hostnames IP addresses   SMTP - Simple Mail Transfer Protocol. Allows one send plain textemails an email server   SSH - Secure SHell. Allows one computer connect anothercomputer execute commands remotely.    Bitcoin - Decentralized crypto currency   BitTorrent - Peer peer file sharing protocol   NTP - Network Time Protocol. This protocol helps keep yourcomputer’s clock synced with outside world How is a website converted into an IP address?A system called “DNS” (Domain Name Service) is used. If a machine doesnot hold answer locally then it sends a UDP packet a local DNSserver. This server in turn may query other upstream DNS servers. DNS by itself is fast but not secure. DNS requests are not encrypted susceptible ‘man-in-the-middle’ attacks. For example, a coffee shopinternet connection could easily subvert your DNS requests send backdifferent IP addresses for a particular domain. way this is usuallysubverted is that after IP address is obtained then a connection isusually made over HTTPS. HTTPS uses what is called TLS (formerlyknown as SSL) secure transmissions verify IP address is whothey say they are. Nonblocking IONormally, when you call , if data is not available yet it will waituntil data is ready before function returns. When you’re readingdata from a disk, that delay may not long, but when you’re readingfrom a slow network connection it may take a long time for that data arrive, if it ever arrives. POSIX lets you set a flag on a file descriptor such that any call onthat file descriptor will return immediately, whether it has finished ornot. With your file descriptor in this mode, your call will start read operation, while it’s working you can do other useful work. This is called “nonblocking” mode, since call doesn’t block.  set a file descriptor nonblocking:``` {. c language=”C”}// fd is my file descriptorint flags = fcntl(fd, F_GETFL, 0);fcntl(fd, F_SETFL, flags | O_NONBLOCK);When a file is in nonblocking mode you call , it will returnimmediately with whatever bytes are available. Say 100 bytes havearrived from server at other end of your socket you call . Read will return immediately with a value of 100, meaning it read 100 of 150 bytes you asked for. Say you tried read remaining datawith a call , but last 50 bytes still hadn’t arrived yet. wouldreturn -1 set global error variable errno either EAGAINor EWOULDBLOCK. That’s system’s way of telling you data isn’tready yet. also works in nonblocking mode. Say you want send 40,000 bytes aremote server using a socket. system can only send so many bytes ata time. Common systems can send about 23,000 bytes at a time. Innonblocking mode, would return number of bytes it was able sendimmediately, or about 23,000. If you called right away again, it wouldreturn -1 set errno EAGAIN or EWOULDBLOCK. That’s system’sway of telling you it’s still busy sending last chunk of data, isn’t ready send more yet. How do I check when I/O has finished?There are a few ways. Let’s see how do it using select epoll. ``` {. c language=”C”}int select(int nfds,  fd_set *readfds,  fd_set *writefds, fd_set *exceptfds,  struct timeval *timeout);epollepoll is not part of POSIX, but it is supported by Linux. It is a moreefficient way wait for many file descriptors. It will tell youexactly which descriptors are ready. It even gives you a way store asmall amount of data with each descriptor, like an array index or apointer, making it easier access your data associated with thatdescriptor.  use epoll, first you must create a special file descriptor with. You won’tread or write this file descriptor; you’ll just pass it otherepoll_xxx functions call close() on it at end. ``` {. c language=”C”} epfd = epoll_create(1); wait for some of file descriptors become ready, use. epoll_eventstruct that it fills out will contain data you provided inevent. data when you added this file descriptor. This makes it easy foryou look up your own data associated with this file descriptor. ``` {. c language=”C”}int num_ready = epoll_wait(epfd, &amp;event, 1, timeout_milliseconds);if (num_ready &gt; 0) { MyData mypointer = (MyData) event. data. ptr; printf(“ready write on %d\\n”, mypointer-&gt;fd);} unsubscribe one file descriptor from epoll while leaving othersactive, use with option. ``` {. c language=”C”}epoll_ctl(epfd, EPOLL_CTL_DEL, mypointer-&gt;fd, NULL);In addition nonblocking , any calls on a nonblocking socketwill also nonblocking. wait for connection complete, use orepoll wait for socket writable. There are definitelyreasons use epoll over select but due to interface, there arefundamental problems with doing so. Remote Procedure CallsRemote Procedure Call. RPC is idea that we can execute a procedure(function) on a different machine. In practice procedure may executeon same machine, however it may in a different context - forexample under a different user with different permissions differentlifecycle. What is Privilege Separation? remote code will execute under a different user with differentprivileges from caller. In practice remote call may execute withmore or fewer privileges than caller. This in principle can used improve security of a system (by ensuring components operate withleast privilege). Unfortunately, security concerns need carefullyassessed ensure that RPC mechanisms cannot subverted performunwanted actions. For example, an RPC implementation may implicitlytrust any connected client perform any action, rather than a subsetof actions on a subset of data. What is stub code? What is marshalling? stub code is necessary code hide complexity of performinga remote procedure call. One of roles of stub code is marshall necessary data into a format that can sent as a bytestream a remote server. ``` {. c language=”C”}// On outside ‘getHiscore’ looks like a normal function call// On inside stub code performs all of work send receive data from remote machine. int getHighScore(char* game) { // Marshall request into a sequence of bytes: char* buffer; asprintf(&amp;buffer,”getHiscore(%s)!”, name);// Send down wire (we do not send zero byte; ‘!’ signifies end of message) write(fd, buffer, strlen(buffer) );// Wait for server send a response ssize_t bytesread = read(fd, buffer, sizeof(buffer));// Example: unmarshal bytes received back from text into an int buffer[bytesread] = 0; // Turn result into a C stringint score= atoi(buffer); free(buffer); return score;}Google Protocol Buffers is an open-source efficient binary protocol thatplaces a strong emphasis on high throughput with low CPU overhead minimal memory copying. Implementations exist for multiple languagesincluding Go, Python, C++ C. This means client server stub codein multiple languages can generated from . proto specificationfile marshall data from a binary stream. reduces versioning problem by ignoring unknown fields that arepresent in a message. See introduction Protocol Buffers for moreinformation. Topics  IPv4 vs IPv6   TCP vs UDP   Packet Loss/Connection Based   Get address info   DNS   TCP client calls   TCP server calls   shutdown   recvfrom   epoll vs select   RPC Questions  What is IPv4? IPv6? What are differences between them?   What is TCP? UDP? Give me advantages disadvantages of both ofthem. When would I use one not other?   Which protocol is connection less which one is connection based?   What is DNS? What is route that DNS takes?   What does socket do?   What are calls set up a TCP client?   What are calls set up a TCP server?   What is difference between a socket shutdown closing?   When can you use ? How about ?   What are some advantages over ? How about over ?   What is a remote procedure call? When should I use it?   What is marshalling/unmarshalling? Why is HTTP not an RPC? ","url":"/coursebook/networking"},{"title":"Development Guide","content":"Development in CS 341In this course, we use Virtual Machines (VMs) for all our development. We will not support development in any other environment (e. g. EWS). We would like stress that no matter what method you use develop code for CS 341, test all your final code on your VM. autograding environment is similar your VM. Thus even though your code “works” on your machine, it may not work on VMs thus for autograder. Connecting your VMFor all registered students in course, you will receive a VM in CS Department’s VM Farm provisioned by EngrIT. When your VM is provisioned you should receive an email about your VM. If you registered late, please email CS 341 Admin (you can find email on our ). Approximately 12-24 hours aftering registering for course your VM host name should also on this - so that’s another way lookup your VM name. (VPN needed). Once you have received your VM, you can connect your VM via SSH. If you are not on campus network you will need install use campus VPN.  VM number will included in email you received. If you use VS Code, please follow . Otherwise: On Linux / Mac, you can do something like   On Windows, you can use an SSH client like . Note that if you are not connected on-campus internet, you will need use a Virtual Private Network (VPN) connect your VM. Instructions on downloading using UIUC VPN can found . An alternative using UIUC VPN is SSH twice. You can first SSH into your EWS account then into your personal VM. Just remember that this causes potentially double network lag. If you are using VS Code SSH client, setup your . ssh config like this:If you want further information on what this is actually doing, you can read on proxying. Additionally, make sure your VM is on running, which can done . Use this lookup your VM name if needed. Note: Both of above links also require campus wifi or a VPNCreating your course repositoryYou will get starter code for all labs MPs through Git Github, submit your solutions graded in same way. Click on follow instructions create your own CS 341 repository. This process will also add you illinois-cs-coursework organization thus give you permission our release repository. Configuring GitOnce you are in your VM, you’ll need set up some global defaults. name email you input here will used mark your commits. Make sure replace FIRST_NAME LAST_NAME NETID@example. com with your information. For example:Cloning your course repositoryCheckout your repository as follows:Unfortunately, cloning a repository is not so easy. If you follow git’s prompt submit your username password, you will likely see an error message like following. If so, continue instructions in . Authenticating with GitHubThere are three ways that we recommend for authenticating with GitHubOption 1: Using GH Auth tool (Recommended)gh is Github’s official command line interface. Almost anything you can do through Github website, you can do through gh, this includes authenticating your Git: Run sudo apt update &amp;&amp; sudo apt install gh on your VM install gh.  Run gh auth login, choose Github. com for account type, HTTPS for protocol, Y for authenticating Git, then follow its instruction complete authentication. You can learn more about what gh can do . Option 2: Using a Personal Access TokenYou can think of a personal access token as a password with limited privileges an expiration date. create a token, go , click Generate new token (classic). We recommend only giving your new token repo scope, as that is all you need push pull from your repos. Once token is generated (be sure save it somewhere), you must further authorize token with your NetID access your CS 341 repos with it. See GitHub’s docs . Finally, you can run git clone again use your newly generated token in place of your password. If you’re using VSCode, you may need log out of Github in VSCode (Using Accounts button at bottom left) log in again. Option 3: Using  Create an SSH key on your VM. Currently, we recommend EdDSA key algorithm. You can create an EdDSA key with command ssh-keygen -t ed25519 -a 100. This command generates a private public key in directory ~/. ssh, where ~ denotes your home directory. It will prompt you enter a name for file storing your private key, will generate a . pub file for your public key. It’s not necessary enter a password for key.  Copy public key your clipboard. This is usually stored at a path like ~/. ssh/*. pub, where ~ denotes your home directory. You can print out public key terminal with cat command.  Log into your GitHub account, navigate Settings-&gt;SSH Keys, follow prompts add a new SSH key by pasting in public key on your clipboard. Please keep in mind that if you use this method, you will need use SSH protocol URLs (e. g. git@github. com:&lt;repo&gt;) when you pull from / push Github, not HTTPS protocol URLs (e. g. https://github. com/&lt;repo&gt;). Fetching from _releaseChange your directory into your repo folder:You’ve probably noticed repository is empty! In order access assignments, complete following steps. This adds _release repository as an extra remote, this step must completed every time you want initialize your repository on a new machine. Whenever you start an assignment, you will need run git pull release main retrieve starter code for assignment. Install compiler CS341 toolsYour VM should already provisioned with required tools. This section is for reference in case you need reinstall specific tools, e. g. in case where your VM must resetHere is script used provision VMs this semester:Installing Other StuffThis is your VM! You can sudo install whatever you want on it (given that it is school appropriate compliant with )You can install vim or emacs. If you’ve ever wanted become terminal-savvy, this is definitely course do it! If you don’t feel like learning a new language want stick GUIs, you can also ssh into your machine work on your code through VSCode, which is covered in greater detail in . If anything is unclear, either post on course forums or ask your TAs/CAs/fellow students! careful about messing up your VM. If your VM ever gets into an unusable state, please make a private post in course forums with your VM number, we will try resolve it. You may find ssh-copy-id useful (A web search using Google/Duck Duck Go is useful). You can also configure MS Code other GUI editors work remotely. However some people still use ‘out of box’ terminal-based editors like vi/vim that you can find (or install) on even smallest of Linux distributions, work even on low-bandwidth connections. Have fun! In worst case we can reset your VM back its initial state. Can’t login or turn on your VM?If you can’t connect -  Check helpful instructions at    Not on campus network? You will need use University VPN,    Check status of your VM on start/restart it if necessary. VMs are shutdown daily at 5am, or perhaps you created a fork-bomb while working on Shell MP.    Check slow loading class forum Still have VM issues?If you are sure that you follow setup guidance correctly you are on either Campus VPN or IllinoisNet WiFi but you still have VM issues (e. g. cannot access vc. cs. illinois. edu, cannot ssh into VM), then fastest resolution will come from directly contacting EngrIT with your issue using their . In form, under “Which lab(s) or remote resource(s) is your request about?”, you can type “CS VM Farm”. You can contact IT by directly emailing . This a bit faster than known ‘standard’ emails, , because these last two need an extra manual step get your request right support people. Include as many details as possible (Course number, your VM hostname, time of error, type of error, description of what you’ve tried. Provisioning a local VM using Vagrant (optional)If you are taking course remotely have a slow internet connection when using Campus VPN, you can set up a VM locally (on your own computer) using Vagrant. has instructions on how do that. Note: Your EngrIT-provisioned VM is still authoritative place for final testing. Your local Vagrant VM is just a way help remote students with development. ","url":"/tutorials/development"},{"title":"Vagrant Setup Guide","content":"Setup InstructionsWe are provision VMs. Vagrant allows us provide a consistent VM environment, similar your EngrIT-provisioned VM environment in which assignments will graded. Here are steps provision a VM on your own laptop using Vagrant:  You will first need install Vagrant. You can do this by following instructions at .    Next, you will need download VirtualBox. You can do this by going then downloading correct version for your operating system.    Next, you will need download a Vagrantfile. Vagrantfile sets enviornment for your VM, so please do not modify it. libraries configured are exact same versions as ones that will used when grading. We have 2 different versions depending on number of cores your computer has. If your computer has 2 cores, download . If your computer has 4 or more cores, download .    Next, make a directory called cs341-vm. Move downloaded file from step (3) into this folder, rename downloaded file Vagrantfile.  Now, everything needed for your VM should installed. Here are some commands that you will need use connect your personal VM. All these commands should run in cs341-vm directory (i. e. directory that contains Vagrantfile).  vagrant up - This command turns on configures VM according Vagrantfile.  vagrant halt - This command shuts down VM.  vagrant ssh - You can use this command SSH into VM. Make sure that VM is already running before trying SSH into VM.   After ssh’ing in, use gh auth login login Github configure git (if asked configure git protocol as well, answer Y).   Here’s complete list of commands: . If you want use a VScode SSH plugin edit files on Vagrant VM, you can configure plugin connect localhost port 2222 with user name “student” (e. g. ssh student@localhost -p 2222). No password is needed if you use correct ssh config files. ","url":"/tutorials/development_vagrant"},{"title":"Emacs Tutorial","content":"IntroductionThis course provides a great opportunity learn how program straight out of terminal, using either vim or emacs. Since I am an emacs user have already come across students in lab asking questions on how use customize it, I am creating this basics guide. For vim help, I’m afraid you’ll have look elsewhere, as I only know how quit out of vim without saving. Emacs CommandsHere are some of most commonly used default emacs key bindings. For a full list, look or :(As an example, C-x C-s means hold Ctrl press x, then hold Ctrl press s. Also, Meta key, denoted as M, is usually either left-Alt or Esc by default. On a Mac it is most likely going Esc. )Use arrow keys move around fileA note about “kill-buffer” when cutting/copying/pasting (and actually, when undoing too):In order copy/cut a region of text, move your cursor start of region set mark (C-@), then move cursor end of region use cut or copy (C-w or M-w), then move cursor location you would like paste to, then press (C-y). (Deleting a whole line with C-k also can used cut a line then paste it, undoing interacts with same kill-buffer. )Your ~/. emacs FileMost customization for emacs will done in your ~/. emacs file, which may exist when you first use emacs, but may also not, which is fine. All of commands I will describe below can added in any order in file. Although if a customization requires multiple lines, order of those lines may matter. I have not tested this theory, but I also believe if you make multiple conflicting changes, last change is one which will take effect. When editing this file, I actually tend use emacs, so I would type commandinto my terminal. Custom HotkeysOne of most useful customizations, I find, is creating your own hotkeys make your most-often used commands more intuitive. Do remember not override coding commands such as C-c, which you’ll need when actually coding. Other ones not overwrite include C-d C-z, which you may use later.  command add a new hotkey looks like this:When I write a hotkey, I always leave myself a comment, using ;; denote a comment, in order remember what hotkey does if it is not obvious. I also use this divide sections in my . emacs file as well.  two hotkeys I have set up on my personal machine now are these:In order find more actions you can do besides goto-line, which jumps a line number which you enter, or undo-only, which is, predictably, undo command for emacs, I recommend Google. Language-Specific CustomizationsThis next section describes a few commands I have found useful, each only take effect for certain languages. First, relevant this class, addresses block comments. This is a style choice I adapted due coding standards of my workplace last summer, but I have kept it since. command below ensures that each time I begin a new line of a block comment in C language, new line begins with a “* “. In other words, this:becomes this: code make this change is as follows:Another C customization I use is this:Which replaces a tab with four spaces, as comment suggests. You could also change this two spaces or any other number you prefer, just make sure your code is still readable. Similarly, because I also code in Python on a regular basis, I do same thing for Python with following lines as well:Also thinking ahead CS421, if you take it in OCaml, it’s worth noting that you can adapt emacs color your code correctly for filetypes it doesn’t normally know how handle, if someone has created setup do so, or you could do this yourself. This typically requires downloading a file, so keep in mind this filepath won’t likely same if you use it, but this is my command for that process:More General PreferencesHere are a few more miscellaneous customizations I use, with comments explain their usage:Mouse ModeOne popular mode which I choose not use, but I have already been asked about, is enabling mouse mode in emacs, essentially making it much more similar a text editor. This means you can use your mouse select where insert new characters, mark a region, use scroll wheel. (Note: Since I don’t use this mode, I found these commands on StackOverflow. )More HelpFor more information various manuals on use of emacs, look at . ","url":"/tutorials/emacs"},{"title":"Finding Filesystems Tools and Tips","content":"Provided below are some tools that can come in handy when writing debugging Finding Filesystems MP. You won’t need understand these complete MP, but they can streamline your workflow. catcat is generally used view contents of a file e. g. cat ‘filename’. As you might’ve seen in lecture, cat can also used create files from commandline, with ctrl+D (EOF) sent end. cat can also used write (&gt;) which can overwrite, append (») files. below example produces a file named other_file. txt that contains two copies of contents of file. txt. cpcp copies a file from a source destination creates a copy at a target destination.  above command creates a copy of file file. txt, called corrupted_file. txt, in current directory. You can also use cp with directories. For example, copy contents of one directory a target directory. cmpcmp compares two different files byte-by-byte outputs difference. Say for example that we modified following file at words “teetering”, “facing”, “reeling”. Running cmp on these two files would inform us of first conflict relative first file, which we can see in detail with -b. However, there are multiple conflicts in this case, see them all, we use -l flag for verbosity. It may help limit range by over which we compare via -n ‘LIMIT’, specify a better starting point by skipping over a number of bytes via -i ‘SKIP’. diffdiff operates similar cmp in that it compares differences in files, but has addition of informing which lines have modified in which way make files identical (a problem of edit distance). hexdumphexdump dumps content of a file in hexadecimal (or a base of your choosing).  leftmost column of numbers index output in hex, while values themselves are on right. This can useful, especially when debugging large files where indirect block behavior needs observed. For example, if you copy a file out fs see that is corrupted via cmp, you can use –skip ‘offset’ flag ignore first ‘offset’ bytes of input advance you where difference occurs. –length ‘length’ flag may also useful for limiting surpressing output beyond ‘length’ bytes. ","url":"/tutorials/filesystems_tools"},{"title":"SSHFS Workflow Tutorial","content":"SSHFS?SSHFS is a tool that allows you mount any directory from a remote machine on your local machine, consequently use your favorite text editor/IDE/code editing environment still able compile run your code on remote machine. Using SSHFS means that you don’t have include a git commit -A -m \"asdf\" git pull origin master in between every small change, ad your machine can cache files so you don’t have deal with network lag. Essentially, SSHFS will allow you directly edit any files that exist on a remote machine. InstallationYou need install SSHFS on your own machine (Windows, Linux, or MacOS). Ubuntu/DebianYou can easily install SSHFS using apt-get as follows:MacOSOn MacOS, you can install SSHFS via FUSE SSHFS from . You will want download both packages. Alternativey, if you have installed, you can also install it using these two commands:WindowsFor Windows, you can either install it in Ubuntu subsystem using apt-get, or download win-sshfs package. Using SSHFSIf you are trying mount your CS341 virtual machine, you do need on campus network or VPN able connect. These instructions apply Linux MacOS. Windows will later. Mounting Remote FilesystemYou’ll want make a directory mount remote file system on. Basically, sshfs will make it a “portal” from your machine remote machine. directory you make will used in next step. Then, you can use sshfs mount file system locally. You can also specify what entry point is on remote machine, rather than just starting at root of drive (/), you can have it start in your home folder (~) or any folder, really. replace with entry point you would like, or leave it empty mount root of drive. Mount point? mount point is directory that sshfs will give you access to. You can use whole machine as that directory, or just your CS241 directory that contains all of your code. After running this command, you will asked for your password, then filesystem will mounted locally. You can test this by doing ls ~/remote see contents of remote filesystem. Now, you can open any file that exists on remote machine with any program you have installed on your own machine (Atom/Sublime Text/etc). Enjoy!Unmounting FilesystemOnce you’re done, you can unmount it with(Note: depending on where you made mount point, you may not need sudo unmount remote filesystem. )WARNING: When you unmount, your changes will no longer saved, so make sure you have closed any remote files before unmounting remote machine. In fact, if you have a file open in Sublime Text, then unmount, open file will become red, because Sublime will notice that it no longer has access that file. You also do need unmount before logging out or shutting down your machine, or potentially disconnecting from Internet. WindowsOn Windows, after sucessful installation of win-sshfs, you can open it configure remote filesystem. You will need on campus network or VPN for this work as well. You’ll want add a new remote, you can name it whatever you would like. Then, you enter IP of remote (for VM’s, it is sp25-cs241-???. cs. illinois. edu). Then, enter your NETID password in their respective boxes, fill out mount point you would like. You can specify / mount at root of drive, you can specify any other directory you would like. Select drive letter, click mount finish process of mounting remote filesystem.  unmount, you can right-click drive letter you chose earlier in My Computer click eject. Other Useful LinksI recommend that you set up SSH keys so that you don’t have type in your password everytime you want mount remote filesystem or simply ssh into remote machine. Read more . DigitalOcean also has a lot more community tutorials that cover a wide range of useful topics when using Linux-based machines. ","url":"/tutorials/sshfs"},{"title":"VS Code Tutorial","content":"IntroductionMost of you have noticed that you must develop in your VMs for CS 341. This requires editing writing code within VM, which is usually done via vim text editor. Vim is a great tool, we highly encourage you at least pick up basics of vim so that you can comfortable using it throughout your careers as software engineers. Some good resources are , , and, for those who just want a basic cheat sheet, . All that said, we understand that it can frustrating use vim when you are working with large files projects, many of you would feel more comfortable using your traditional text editor of choice. We’ll provide a series of steps here that will help you set up a development environment that lets you edit your code locally in VS Code (you can modify this process use Atom or Sublime) run code in VM.  clear, you will not running your code locally. You will editing running your code on your VM through ssh (e. g. make, make test, running binaries, etc). However, you will able do all of that in VS code, which is synced VM through ssh. Steps  Set up a VPN if you aren’t on IllinoisNet. This is essential if you want develop outside of IllinoisNet’s network. Instructions for setting up a VPN are .   Open up a terminal or an ssh client (Putty, example) ssh into your VM using command:  Ensure that this successfully logs you into your VM, navigate an assignment directory. If this doesn’t log in correctly, following steps will not work. If you are unable ssh into your VM, make a post on EdStem. You may also need contact EngrIT.    Download install VS code from .   Install Remote SSH Extention from Microsoft: Click open remote window button at bottom left of editor:  Click “Connect Host… Remote-SSH”, then “+ Add New SSH Host”   Enter SSH Command shown above, then pick a configuration file save it to.    You can then click open remote button again, connect remote ssh host, pick VM you just added. It will prompt you for a platform (use linux) your netID password.    Now you have remote access your VM! integrated terminal file editor will run make changes on VM itself, not on your local machine. You can VM (if you have not done so already), open folder in editor (this may require you enter your password again). Happy Programming! ","url":"/tutorials/vscode"},{"title":"Networking","content":"Networking OverviewTCP vs UDPWe focus on TCP in this class. TCP HandshakesTCP Packet LayoutNetworking FunctionsSocketsocket creates an endpoint for communication returns a file descriptor that refers that endpoint. Bindbind associates an abstract network socket created with socket an actual networking interface/address. Listenlisten marks a socket as “passive”, or ready accept incoming connections. Acceptaccept accepts an incoming connection on a socket that has been listening. Connectconnect is used connect a socket a given address (which might have a socket listening for connections). Error checkingMake sure check errors for every call, networking can fail at any point! All networking functions specify in their manpages what types of errors you might have deal with. A few gotchasByte Ordering Convert your data to/from “network byte order” architecture-agnostic.  See man 3 htonl for more info. Socket Options Use setsockopt set SO_REUSEADDR on your socket.  Otherwise system won’t immediately reallow you use a socket after it’s been closed. Signal Handler Safety Most server applications are interupted through a signal.  Don’t do cleanup in signal handler! Not every function is signal handler safe.  Do this instead:  Fun Facts: Latency","url":"/slides/charming_chatroom"},{"title":"Synchronization","content":"Implementing a Sema-MoreThis is idea of a mutex: keep other person out while you do your thing. This is a semaphore:Just kidding, this is a real semaphore:Semamore OutlineStruct When max_value is reached  All threads trying post should blocked Where/how do you notify these blocked threads when a thread decreases semamore’s value below max_value?   When 0 is reached  All threads trying wait should blocked Where/how do you notify these blocked threads when a thread increases semamore’s value above 0?  Remember not burn CPUSpurious Wakeups?What is wrong with code above?(hint: what if we get woken up while condition is still true?)Not-So-Broken BarriersWhat does a barrier look like? Glad you asked. More information is in coursebook. Thread-Safe QueuesRemember CS 124/225! Appending head of a linked list, other edge cases, etc…Reminders Use a while loop check condition when using cond_wait.  A thread might awoken even condition for waking up is not reached.  Google spurious wakeups: https://goo. gl/TEJVOl Write a correctly working queue first before making it thread-safe PTHREAD_MUTEX_INITIALIZER initializes a mutex with default properties pthread_mutex_init(&amp;mtex, &amp;attr) allows specialized attributes Think of all critical/edge cases test your queue/semamore Consider one thread that starts working really late Semamore is not a real term!Questions?Credit Where Credit is DueCredit https://habrahabr. ru/post/277669/ for most of these animations!","url":"/slides/critical_concurrency"},{"title":"Deadlock Demolition","content":"DeadlockWhat is deadlock?From wikipedia: In an operating system, a deadlock occurs when a process or thread enters a waiting state because a requested system resource is held by another waiting process, which in turn is waiting for another resource held by another waiting process. Coffman ConditionsConditions on system its resources that are necessary sufficient for deadlock possibly occur. So violating any condition = preventing deadlock! Mutual Exclusion: No two processes can own a resource at same time.  Circular Wait: There is a ‘cyclic dependency’ in processes owning waiting for resources.  Hold Wait: Once a process owns a resource, it retains that ownership, even while waiting for another.  Lack of Preemption: Processes cannot forced give up owned resources. Dining philosophersA good example of deadlock is dining philosophers problem. In this problem, there are n philosophers trying have dinner with n chopsticks. Each requires two chopsticks eat. How can we allocate chopsticks such that every philosopher gets eat?Who’s a good dining philosopher?Solutions dining philsophers problemArbitratorHave one authority (e. g. a mutex). Have each philosopher grab that authority only when they have authority can they pick up their forks eat. They eat, put arbitrator forks down move on next philosopher (can random or sequential). Tradeoffs Very slow Only one thread running at a time Python’s global interpreter lock is implemented this wayLeave table (Stallings)Consider case of dining philosophers with n-chopsticks n-philosophers. Reduce number of philosophers currently allowed at table n-1 using a semaphore. Have them eat. Cycle out philosophers. Tradeoffs Very heavy on context switches for a process Needs way of “pausing” a philosopher (SIGSTOP for linux kernel) Need a “fair” cycling algorithmPartial Ordering (Dijkstra)Order chopsticks 1. . n. For each philosopher have them pick up lower number chopstick. Then, only if they can pick up lower chopstick, pick up higher chopstick. Why does this work?Tradeoffs Needs able order resources Doesn’t livelock but often leads one thread working at a time for large applications (databases) But good for dining philosophers!BONUS: Clean/Dirty (Chandy/Misra)(Beyond 341 scope) If you want a reeallly fast solution, given many philosophers numbered 1. . n. Relax problem assumptions– let philosophers talk each other only ask for chopsticks. Chopsticks can dirty or clean. Initially all start as dirty. For each pair of philosophers, assign chopstick between them philosopher with lower id. When one wants eat, they ask their neighbor for a chopstick. If neighbor’s chopstick is clean (they haven’t eaten yet), they keep chopstick. Otherwise, they clean relinquish it. Tradeoffs Ensures priority is given philosopher that has least recently eaten (starvation prevention).  Requires philosopher communication, so is not an exact instance of Dining Philosophers.  Requires careful resource ordering avoid an initial deadlock. A good overview of solutionsResource allocation graphWe can model resource allocation by having resources processes represented as vertices use edges show ownership of a resource. A cycle in resource allocation graph implies that we can have deadlock (assuming other Coffman Conditions hold). Example RAGRelation Dining Philosophers Dining Philosophers provide a more general view of preventing deadlock, RAG analysis can applied some of our previous solutions. Replace ‘philosopher’ with ‘process’ consider how our solutions stop a cycle.  Arbitrator: central authority is now only dependency (forms a ‘star’ graph).  Stallings: Remove a ‘process’, creating a path instead of a cycle.  Ordering Solutions: Ensure that at least one ‘process’ always can get all resources through ordering (creates a sink node). Questions?","url":"/slides/deadlock_demolition"},{"title":"Deepfried_DD","content":"The Real dd A highly configurable command-line utility used convert copy files Performs block level I/O, as opposed filesystem-level I/O for increased performanceWhat is a Block? A sequence of bytes with a predefined size Hard drives / SSDs typically have a sector (block) size of 4 kB This means read/write operations disk can only address 4 kB portions at a time.  If you write a 64 kB file disk, it will broken down into 16 writes of 4 kB eachReal dd UsageSome notable parameters: if=FILE: read from FILE instead of stdin of=FILE: write FILE instead of stdout bs=BYTES: bs is block size; read write up BYTES bytes at a time (default: 512); count=N: copy only N input blocks seek=N: skip N obs-sized blocks at start of output skip=N: skip N ibs-sized blocks at start of inputApplications of dd Data transfer, in-place modification of files Wiping disks for security (e. g. prior recycling hardware)  Contents of a file are not necessarily overwritten on regular deletion   Generating files with random data (will useful for testing in upcoming Networking MP) “Flashing” / installing custom ROMs (enhanced versions of vanilla OS) on Android devicesAdvanced Applications Kernel profiling (measure speed of dd if=/dev/zero of=/dev/null) Obtaining a finite data subsection of an infinite data stream Implementing conversion/analysis tools (e. g. hexdump)Warningsdd misuse can cause interesting errors: bs count definition errors can lead infinite size files  This can break password login on your machine!   of definition errors can overwrite endpoints:  Worst case: it can corrupt your hard disk/SSD  So define each parameter carefully, especially if running as root!Our Implementation of ddYou will use: File-level I/O (fread, fwrite, etc. ) copy data Interrupts (signal on SIGUSR1) get status reportsOur dd’s parameters -i &lt;file&gt;: input file (defaults stdin) -o &lt;file&gt;: output file (defaults stdout) -b &lt;size&gt;: block size, number of bytes copied at a time (defaults 512) -c &lt;count&gt;: total number of blocks copied (defaults entire file) -p &lt;count&gt;: number of blocks skip at start of input file (defaults 0) -k &lt;count&gt;: number of blocks skip at start of output file (defaults 0)Argument Parsing: getopt() getopt parses function arguments passed through command line.  Specify handle all special case function parameters. getopt(argc, argv, \"i:o:b:c:p:k:\")Example Usage. /dd -i input_file -o output_file -b 256 -c 1 Defines block size 256 bytes Copies 1 block from offset 0 of input_file offset 0 of output_fileQuestions?","url":"/slides/deepfried_dd"},{"title":"File Systems","content":"What do filesystems look like? inodes, they store metadata about node data blocks/nodes, they store actual data double indirect blocks (data)What our file system looks likeTraditional NTFS file systemsTypical file systems nowadaysInodeIndirect BlocksRead docs!There are a few intricacies with dealing with inodes. ","url":"/slides/finding_filesystems"},{"title":"Virtual Memory","content":"What’s in a memory address?Suppose I have an integer p allocated on stack, value of &amp;p is 0xAB0 (= 2736). What does this mean?In very old computers, this would imply that p is stored starting at 2736th byte in physical memory of computer. However, with modern computers, this is no longer true. Modern operating systems computers rely on virtual memory better abstract idea of computer memory. Consider a very simple virtual memory setup. kernel maintains a lookup table - every memory address given a process can looked up in this table see where it really lies in RAM. So kernel could do lookup(0xAB0) know where actually find some data being requested by a program. Let’s suppose system was 32 bits, so there are a total of 2^32 possible memory addresses (1 address = 1 byte). I can fit each address in a 4 byte (32 bit) integer - but my total storage required maintain a lookup table would 4 bytes x 2^32 addresses = 16 GB. This is a lot of memory!In order get around this issue, we can address memory as “pages”. A very common page size is 4 kilobytes. Now, I can maintain a lookup table that only refers segments of 4 KB in RAM, instead of individual bytes. On a 32 bit system, there would only 2^20 4 KB pages, so I can easily store a lookup table on system. But now how do I actually access specific bytes? answer is split up memory addresses we give user into two segments. On a 32 bit system, we can use first 20 bits of address tell us which page byte we’re looking for is in. So we can do a lookup in page table find out where in physical RAM that page is actually stored. Then, bottom 12 bits can used tell us exact offset into that region of RAM get byte we want.  lookup process then looks something like this:Virtual Memory VisualizationHow many pages are there in a 32bit machine (assume frame size of 4KB)?Answer: 2^32 address / 2^12 = 2^20 pages. Remember that 2^10 is 1024, so 2^20 is a bit more than one million. For a 64 bit machine, 2^64 / 2^12 = 2^52, which is roughly 10^15 pages. On a 32 bit machine with 2KB pages 4 Byte entries, how big would a single layered page table have to address all of physical memory? There are 2^32 addresses, each page is 2^11 bytes large. So there are a total of 2^21 pages. page directory needs hold a 4 byte entry corresponding each page, so total memory uses is 4 bytes * 2^21 = 8 MB. Multi-Level Page TableIn 64-bit systems, there are 10^15 4KB pages. We cannot afford use a single massive page directory, so we layer page tables. Page faults segmentation faults A segfault occurs when a memory access is invalid. Your program cannot recover from a segfault.  A page fault occurs when a page is not found in physical RAM.  Swap: When physical memory gets full, kernel sends some pages disk. What is an MMU? memory management unit in modern computing is a physical component inside a computer that is responsible for handling virtual memory requests from CPU. In this lab, you will implementing portions of an MMU in C. What is a TLB? Translation Look-aside Buffer is a “cache” for MMU.  most recently used addresses will stored.  For frequently accessed addresses, TLB can tell MMU directly where go (no translation necessary).  careful about bitshifting!Some parts of this lab require bit shifting when translating virtual memory addresses. Watch out for distinction between signed unsigned shifts!","url":"/slides/ideal_indirection"},{"title":"Welcome to CS 341","content":"What’s Lab Gonna Like?Rules Labs will begin with slides followed by a worksheet/Kahoot-style quiz.  You should work on your lab assignment for rest of class time. Lab Attendance Ten minute rule: if you aren’t here in first ten minutes of class, you don’t get credit.  Your total attendance grade will credited towards final exam, up 3%.  Near end of every lab, we will ask you swipe out. You may only leave early if you show us that you have finished lab.  Email GA (cs341admin@cs. illinois. edu) if you need an exemption for lab attendance. Different Lab Sections Due seating limitations, you are required go lab section you signed up for.  Labs will in-person.  If you need miss a lab, you may able switch labs make up attendance.   You must email TA in charge of your assigned lab TA for lab which you are going.    There will no attendance taken for week 1. UtilitiesVirtual MachinesWhat are they? A computer running on top of another computer via an emulation system.  Ex) running a Linux virtual machine on top of a Windows OS using a software like Virtualbox, which creates a virtualized version of Linux “inside” of Windows OS.  In this class, you will assigned a Linux (Ubuntu) virtual machine that has all prerequisite software for compiling running assignments. where xxx is VM number assigned you. VM UseWe will only help you with your assignments on your VM. We will not debug code running elsewhere. NoteYou are going need on campus network able access your VM. If you want make it work at home, make sure log in campus VPN first before ssh’ing. See for details. Late AddsIf enrolled in class recently, you should getting an email soon about accessing your VM. Everyone else should already have received an email with their VM’s details. What is ssh?SSH is short for secure shell (secure sh). SSH is a network protocol that leverages public key cryptography in order connect another computer. You may have used SSH in other classes connect EWS. What is sudo?All of you have probably heard of sudo before - it is short for super-user do, lets you execute any command as root. You have that ability on your VM. careful: there is no way faster crash your VM that throwing sudo around. VMs can only rebooted or re-imaged by staff. What is git?git is a version control system. That means it keeps track of changes in code, allows you group changes into a commit, provides tools manipulate commits. GDBA lot of you are afraid – don’t be!What is GDB? GDB is a program that allows you see “inside” a program as it executes.  From , GDB helps you catch bugs by enabled you to:  Start your program, specifying anything that might affect its behavior.  Make your program stop on specified conditions.  Examine what has happened, when your program has stopped.  Change things within in your program  GDB Commands layout src gives you a text-based GUI break &lt;file:line|function&gt; [if condition]: You can make powerful breakpoints by giving a line, but only under certain circumstances.  watch (type *)0xADDRESS: Watches an address for a read or write tells you when it has changed – useful for locating bugs.  backtrace, bt see what functions you are in up, down goes up down a stack frameNavigation print prints a variable (aliased p). You can use p/x print in hex.  next executes line goes next line, runs functions without stopping.  finish finishes function breaks.  step executes line goes next line. If there is a function, gdb steps into function.  continue resumes execution of your program. ","url":"/slides/lockpicking_lab"},{"title":"Review","content":"CHow are C strings represented in memory?What is wrong with malloc(strlen(s)) when copying strings?\"hello\" = [h][e][l][l][o][\\0]A C string is just an array of characters with a null terminator (\\0) at end. strlen(\"hello\") == 5strlen() does not count null terminator. If used with malloc, there won’t enough memory allocated for null terminator!Virtual MemoryExplain how a virtual address is converted into a physical address using a multi-level page table. You may use a concrete example e. g. a 64bit machine with 4KB pages. How long is offset? How many addresses do you need? One per Byte in pagePage size: 4 KB = 2^12 B How many bits do you need define 2^12 addresses?log2⁡ (2^12⁡) = 12 bits You take rest of bits split it up evenly among level of page tables. |-VPN1-|-VPN2-|-VPN3-|-Offset-| level_1 = page_table_base_register[VPN1] level_2 = level_1[VPN2] level_3 = level_2[VPN3] physical_address = level_3 + OffsetWhat is a page fault? When is it an error? When is it not an error?Page fault – program attempts access virtual memory that is not mapped up-to-date physical memory. There are three types Major - page is on disk needs loaded into memory (disk I/O) Minor – No mapping for page, but valid address (no disk I/O) Invalid - Memory being accessed is not part of virtual address space. There cannot a page corresponding it. When it’s an Error - Invalid (The operating system usually segfaults)When it’s not an Error - Major or MinorWhat is Spatial Temporal Locality? Swapping? Swap file? Demand Paging?Spatial Locality - Objects in adjacent memory addresses get used (think arrays). That is why a page table is a certain size. Temporal Locality - Objects used more recently get used. TLB takes advantage of thatSwapping - Taking a page in memory writing disk. Swap File - specific file on disk that pages get written to. Another solution is a swap space partition. Demand Paging - Only allocate pages as process requests themProcesses ThreadsExplain operating system actions required perform a process context switch. Step 1: Save state in process control block(pcb)This includes: Program Counter Registers Priority Stack Pointer / Address Space Open FilesStep 2: Flush Translation Lookaside Buffer (TLB)BUT with ASID or PCID (intel) may not necessary Used identify which process an entry is from Address space identifiers (ASID) assigned dynamically Interactive processes don’t get ASIDs ASID’s are short, too short identify all processes Stored in a data structure optimized for cache usageStep 3: Choose next process (scheduler’s job)Step 4: Load process state from control blockStep 5: Pop program counter, resume taskExplain actions required perform a thread context switch (to a thread in same process)Same as above EXCEPT Only need save Thread Control Block (TCB) instead of PCB(i. e. not whole address space, just stack) Don’t need flush TLB Different Scheduler:  kernel threads: OS handles it (so just like process scheduling) user-level threads: CPU handles it (so a library handles it)  SchedulingWhich scheduling algorithm results smallest average wait time?Round Robin (IF new processes sent back of queue) wait time ≤ (x number of processes on queue)Why not any other scheduler?FCFS: wait time ≤ sum of runtime of all processes on queueSJF/PSJF: wait time ≤ ∞ if shorter jobs keep arrivingPriority: waittime ≤ ∞ if higher priority jobs keep arrivingWhat scheduling algorithm has longest average response time?Priority process can always pushed lower on queue by higher priority processes priority doesn’t correspond runtimeWhy not any other scheduler?FCFS: response ≤ runtime of processes ahead of it on queueSJF/PSJF: ∞, but at least all jobs ahead of a process on queue have shorter runtimes. Priority doesn’t guarantee this. RR: response ≤ time quantum x number of processes ahead on queue. Synchronization DeadlockDefine circular wait, mutual exclusion, hold wait, no-preemption. How are these related deadlock?Coffman ConditionsCircular wait: There exists a cycle in Resource Allocation graph P1 is waiting for resources from P2 P2 is waiting for resources from P3 ect… PN is waiting for resources from P1Coffman Conditions Cont. Mutual Exclusion: no two processes can hold same resource at same timeHold Wait: Once a resource is obtained, process holds it until finishedNo pre-emption: Nothing can make a process give up a resourceWhat is difference between Deadlock Prevention, Deadlock Detection Deadlock Avoidance?Deadlock Prevention: Eliminate a Coffman conditions. Deadlocks become impossible. Deadlock Avoidance: Avoid by allocating resources in a safe manner. OS implements concurrency control. Deadlock Detection: When deadlock occurs, OS can detect resolve it. (i. e. use a Resource Allocation Graph detect deadlocks. kill processes or preempt resources resolve)IPC signalsGive an example of kernel generated signal. List 2 calls that can a process can use generate a SIGUSR1. Kernel generated signals: SIGSEGV SIGILL SIGXCPUTry running kill -l see all signalsraise(int signal) signals yourselfkill(pid_t pid, int signal) signal other processesWhat signals can caught ignored? What signals cannot caught?You can catch anything except SIGKILL SIGSTOPSee man page for signal(2) on how set signal disposition. NetworkingDescribe services provided by TCP but not UDP. What applications use TCP? What applications use UDP? TCP performs flow control, UDP does not TCP guarantees delivery, UDP is “best effort” TCP has a notion of a connection, UDP is connectionless TCP has 3-way (SYN - SYN/ACK - ACK) handshakeTCP is used for web browsing, email, file transfers, etc. UDP is used when data becomes stale quickly (e. g. audio/video streaming DNS). FilesBriefly explain permission bits (including sticky setuid bits) for files directories. drwxrwxr-x  d or - : directory or file   rwx : What owner of file is allowed do (read, write, execute)   rwx: What users in owner’s group are allowed do (read, write, execute)   r-x: What everyone else is allowed od (read execute, but not write) File SystemWhat information is stored in an inode? What file system information is not? uid: user ID of inode owner.  gid: ID of inode group (does not have include owner).  mode: a bitmask. Bottom 9 bits are read-write-execute for owner-group-others. Bits 11-10 are type of file.  nlink: hard link count. number of directories that file is linked from (directories can’t hard linked).  atim: access time. Time of last access or last time a file was read(2).  mtim: last modification time. Last time file was changed with write(2).  ctim: last change time. Last time file’s metadata was changed.  size: size of file in bytes direct: an array. direct[i] is ith data block’s offset (data_block_number) from data_root.  indirect: offset number (data_block_number) of a data block, which contains NUM_INDIRECT_BLOCKS number of data_block_number’s. ","url":"/slides/lovable_linux"},{"title":"Memory Mapped IO","content":"Learning Objectives Review of C file interface Introduction mmapC File Manipulation A higher level, more portable interface for interacting with file operations than syscalls.  Some familiar functions: fopen fwriteFseek Ftell Lets us move around position of a FILE* New position specified via an offset a whence origin Syscall analog for working with file descriptors: lseekFseek JuggleMMAPWhat is it? Syscall- can define a new memory mapping.  This can apply files or devices, letting us emulate writing through standard memory writes.  Files are loaded lazily into memory page by page writes can reflected underlying file depending on mapping’s settings.  On kernel end, only a memory mapping is created.  kernel/CPU is free do whatever under hood as long as when a process asks for a memory address a page is available. How do we implement this? Page faults!Remember this?Now, pages can tied file pages, instead of pages backed by physical RAM. MMAP for IPCLazy MMAP Laziness in this context means entire files may not mmapped.  Parts of files are assigned memory pages as they are needed.  When mmap is called, it’s possible that none of file is loaded into memory yet. MMAP Usagemmap is complicated! Here is signature:void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);Basic mapping parameters: addr: Page aligned address start mapping at or NULL let mmap choose length: Byte length of mappingCommon access settings: prot: Memory protection (r/w/x/none) flags: Update visibility other processes (ex. MAP_SHARED / MAP_PRIVATE) or define a non-file mapping (MAP_ANONYMOUS)File mapping options: fd: File descriptor used in a file mapping offset: Page-aligined offset in a file begin a mapping atSee man page for more!Mad Mad Access Patterns A file search problem: given a query a formatted file, implement a search either find value or report that no such value exists.  file size can exceed memory.  You will solve this problem twice:  Once with C file interface (lookup1. c) Once with mmap (lookup2. c)  BackgroundEfficient File Navigation If we want quickly navigate a file’s data, we can encode its contents using a data structure, in our case a tree.  We translate tree a flat array/file by providing a serialization scheme or an encoding. Here’s a serialization using an inorder traversal:Another example with a level-ordered traversal:Our TreesWe will use file offsets: root will always at offset 4 in a correct file.  Each node will hold file offsets of their children.  Offset 0 is analogous a NULL ptr. Tree Node StructureHow does word[0] work?Recall malloc!Implementation Notes Use strcmp on word field of each node traverse tree.  You will have handle certain errors, each with their own specific exit codes – check docs. Testing create_data for making your own BTRE files lookup1-reference / lookup2-reference for comparison","url":"/slides/mad_mad_access_pattern"},{"title":"MapReduce","content":"Inter Process Communication goal of IPC is communicate between different processes. Common ways do IPC include: Pipes Sockets Shared MemoryPipes Takes in a stream of bytes from an input file descriptor Spits out data through an output file descriptorPipes in shellPipes in code pipe() takes a single argument - an array of size 2.  It sets pipefd[0] reading end fd.  It sets pipefd[1] writing end fd. Pipe capacityHow much data can a pipe hold?Pipes' capacity depends on system configuration, but usually it ranges from 4 KiB 128 KiB. Check /proc/sys/fs/pipe-max-size!Reading from a pipe Returns 0 if all writing ends are closed.  Blocks if pipe is empty active writing ends exist.  Unblocks when data is written so pipe becomes nonempty. Writing a pipe Generates a SIGPIPE if all reading ends are closed.  Blocks if pipe is full active reading ends exist.  Unblocks when data is read so pipe becomes nonfull. Note: SIGPIPE kills your program by default. Catch or ignore it see write() returning -1 setting errno EPIPE. pipe() vs pipe2()pipe2() has an additional argument (flags). O_CLOEXEC closes both pipe fds on a successful exec. MapreduceWhat is MapReduce? A programming model: Map, then Reduce Originally developed at Google process large datasets with distributed systems Map: transform raw data into processed data Reduce: aggregate processed data into statistics 341 MapReduce is vastly oversimplifiedMapReduce ExampleParallelism Mapping is parallelizable: mapper function is independent per input element Assign different chunks across mappers Reducing is parallelizable: reducer function is associative - reduce(A[1. . . n]) = reduce(reduce(A[1. . . n/2]) + reduce(A[n/2. . . n])) Run multiple reducers together, then reduce output from reducersLab AssignmentImplement MapReduce orchestrator: Split up inputs Send them off mappers Agglomerate mapped outputs into a final result via a reducerNo need implement mappers or reducers yourself, a splitter tool is already provided. Implementation. /mapreduce &lt;input_file&gt; &lt;output_file&gt; &lt;mapper_executable&gt; &lt;reducer_executable&gt; &lt;mapper_count&gt;.  Split input file into &lt;mapper_count&gt; chunks using given splitter tool.  Start a mapper process for each chunk, pipe output of each mapper process into input of singular reducer process.  Pipe output of reducer process output file. ","url":"/slides/mapreduce"},{"title":"Memory","content":"Why am I doing this lab? Learn how make a basic memory checker Learn memory layout how malloc/free works How does free know how many bytes it has free?How does malloc() manage allocated memory? As you’ll encounter in this lab, one way of keeping track of memory is via metadata tags accomplish this, we allocate more memory than user requests We’ll use pointer arithmetic make sure that we return right pointer userWhat’s in #tags?Information about current block of memory: Pointer next link, if using a linked list Size of block Whatever else you want… Big PictureHints meta_data * head : head for linked-list total_memory_requested: keep track of bytes used total_memory_freed: keep track of bytes freed Think about how create a linked-list insert/remove Insert has constant time, but free doesn’t Have catch bad calls free increment invalid_addressesHey! Shouldn’t we not able do arithmetic with void pointers? Technically yeah, but gcc clang treats it as a char* In short, don’t do it because standard doesn’t guarantee itSplitting coalescing Reduce memory wastage! How can we use tags split a block? How can we use tags merge adjacent blocks?Understanding how do this will useful when you implement malloc!Questions?","url":"/slides/mini_memcheck"},{"title":"Memory","content":"Lab Time!Using pointersWhere can a pointer point to?HeapStackGlobalText…Anywhere!What is a function pointer?A pointer that stores address of a function’s codeWith this, we can pass a function as an argumentThis allows us reuse codeE. g. , sorting an array of arbitrary objects could use a function pointer as comparison functionPointer ArithmeticPart 1You will debugging several functions that all use pointers incorrectlyPart 2-We’ve given you a set of functions as toolsYour job is use these tools in right order print “Illinois”Hints about MPWhat is this NULL-terminated array?Maybe, we don’t want pass around size of array everywhereWe know that NULL is not a valid string (but this doesn’t work for every type)Useful Functions strdup: return a string copy strcpy,strncpy: copy a string another string toupper, tolower: uppercases/lowercases an input character  ispunct,isspace,isalpha: decide whether a character is punctuation/alphabetical/whitespace  Not so useful: strtokDebuggingValgrindValgrind is a framework for building program analysis tools. most popular Valgrind tool is memcheck, which detects memory leaks. You will use Valgrind very often in CS 341, autograder will run Valgrind against your code check for memory leaks. UsageGiven a program myprog arg1 arg2:valgrind --leak-check=yes myprog arg1 arg2Leak Types Memory block: A block of allocated, not-freed memory Definitely lost: A memory block wasn’t freed, no pointers point it.  Still reachable: A memory block wasn’t freed, but there are pointers it still left.  Indirectly lost: A memory block wasn’t freed that contained pointers other memory blocks.  Possibly lost: A memory block wasn’t freed, pointer it still exists but was moved (e. g. array)Questions?","url":"/slides/perilous_pointers"},{"title":"Remote Procedure Calls","content":"Remote Procedure CallsRemote procedure calls are a way execute a procedure (ex. function) that exists in a different context. POST /say HTTP/1. 1HOST: api. example. comContent-Type: application/json{\"name\": \"Racey McRacerson\"}/* Signature */function sayHello(name) { // . . . }/* Usage */sayHello(\"Racey McRacerson\"); |POST /say HTTP/1. 1HOST: api. example. comContent-Type: application/json{\"name\": \"Racey McRacerson\"}/* Signature */function clientContact(name) {// . . . }/* Usage */if(request == “/ping}clientContact(request. data);DNS ResolutionUDP Code","url":"/slides/resplendent_rpcs"},{"title":"Savvy Scheduler","content":"Scheduling Must efficiently select which process must run For sake of simplicity: Only considering single process/single thread single core systemsi. e. one thing running at a timeKey Terms - timestamps Arrival Time Start Time End TimeKey Terms - durations Response time = start time - arrival time Turnaround time = end time - arrival time Wait time = turnaround time - run timeMeasures of efficiency  Lowest average turnaround time   Lowest wait time   Latency Process State R - Running or Runnable S - Interruptible Sleeping (waiting on an event) D - Uninterruptable Sleep (IO typically, still on CPU) T - Stopped Z - Zombie process (terminated, but not reaped)Ready QueueA queue of runnable processes, not waiting for resources, ready executedWhy might a process (or thread) placed on ready queue?A process is placed on ready queue when it is able use a CPU. Some examples include: A process was blocked waiting a from storage or socket complete data is now available.  A new process has been created is ready start. Other situations A process thread was blocked on a synchronization primitive (condition variable, semaphore, mutex lock) but is now able continue.  A process is blocked waiting for a system call complete but a signal has been delivered signal handler needs run. Common Scheduling Algorithms Shortest Job First Priority queue First Come First Served Round Robin  Quantum = 500ms (for example)  Which schedulers suffer from starvation? Example: Shortest Job First with continuous stream of short processesConvoy EffectConvoy of processes following a CPU-intensive process, with potentially smaller resource requirements. Affects IO-intensive operations. FCFS suffers from this. What is pre-emption?When a more preferable (multiple criteria) process is ready, CPU can suspend current process (think SIGSTOP), can switch in new process. Later, process that was pre-empted can scheduled (SIGCONT)Without pre-emption processes will run until they are unable utilize CPU any further!Questions","url":"/slides/savvy_scheduler"},{"title":"Threads, Concurrency, and Synchronization","content":"Teaching ThreadsLearning Objectives Using pthreads speed up code Common patterns in multithreaded programsSo what is reduce?What does it look like in code?ExamplePthreads? What are thooooose?Pthreads are short for POSIX-threads. They are a standardized way of doing multithreading on POSIX-compliant systems. A thread is short for thread of execution, meaning that thread executes instructions independently of other threads. Signature thread somwhere write id of thread attr options that you set during pthread, for most part you don’t need worry about it start_routine where start your pthread arg arguments give each pthreadJoin Me! thread value of thread *not a pointer it retval where should I put resulting valueJust like waitpid, you want join all your terminated threads. Calling pthread_join on a thread makes your program wait for that thread finish before continuing. There is no analog of waitpid(-1, …) (which waits for any child process terminate) because if you need that ‘you probably need rethink your application design. ’ - man page. Killing threadsYou can guess what happens in pthread_kill. All parallel codeSome advanced stuffEach thread gets its own registers, stack pointer, stack. However, all threads within a program share heap, static, code (text) regions of memory. Parallel reduce: putting it all togetherWe want you split up work done by reduce into multiple threads, in order parallelize it. Dividing up work should look something like followingWait a minute, don’t we need mutexes stuff?You have been going through mutexes other synchronization primitives in lecture, but most efficient data structure uses no synchronization. This means that so long as no other thread touches exact samepiece of memory that another thread is touching – there is no race condition. We are then using threads their full potential of parallelism. Questions?","url":"/slides/teaching_threads"},{"title":"Processes","content":"Processes!  A process is an instance of a computer program that may running.    At start of each program, a program gets one process, but each program can make more processes.    Powerful, but isolated! Can only communicate with each other by explicit means.  Contents of a Process Memory Space Stack: Where declared variables live, grows down, readable &amp; writeable (rw) Heap: Where malloc’d memory lives, grows up, rw Data segment: globals, static vars, some parts rw, some parts read-only Text segment: program instructions, only executable (x) part of a programAddress Space of a ProcessForkingfork clones current process create a new process, called a child process. it copies state of existing process with a few minor differencesWhat is Copied Over? address space parent’s open file descriptors parent’s open directory streams parent’s pid (see getppid()) Environment variables Signal Handlers Synchronization PrimitivesWhat is NOT Copied over? process id (every child has their own) pending signals threads termination signal (SIGCHLD)Forkbomboccurs when there is an attempt create an infinite number of processes. This will often bring a system a near-standstillYou do NOT want do this (or else your VM will difficult recover)Process FlowchartUtilities UnleashedWhat are you going learn? What fork-exec-wait pattern is.  Why we use it.  String Manipulation. All Fork-Exec-Wait Codecreates a child processOn success, PID of child process is returned in parent, 0 is returned in child. On failure, -1 isreturned in parent, no child process is createdwait for state changes in a child of calling processA state change is considered be: child terminated child stopped by signal child resumed by signalwait allows system release resources associated with childotherwise terminated child remains in a “zombie” state Familyreplaces current process image with a new process image There are three modifiers/mnemonic  Either past a list or argv (null terminated array) of arguments Search for executable either in current directory or in path Use parent’s environment variables or use an environment setting  time . /time &lt;command&gt; &lt;args&gt; . . .  Try measuring time of running sleep 2 Should use fork-exec scheme.  Should take care of programs do not terminate successfully.  Command line arguments are not limited one.  Use format. h functions print out time/etc. time WorkflowHelper Functions struct timespec  time_t tv_sec; long tv_nsec; tv_sec = 10, tv_nsec = 992300000 -&gt; 10. 9923 sec   int clock_gettime(clockid_t, timespec *);  clockid_t: should use CLOCK_MONOTONIC in this lab   return 0 when success, -1 otherwiseenv . /env [key=val1] [key2=val1] . . . -- cmd [args] . .  . /env TZ=EST5EDT -- date - execute date under enviornment TZ=EST5EDT . /env TEMP=EST5EDT TZ=%TEMP -- date - why is this same as above?env WorkflowHelper Functions int setenv(const char* name, const char* value,  int overwrite) char *getenv(const char *name) Write a function that can find all %notation in a string Extend that function replace variables with environment variables Use getenv get environment variables familiar with: return array of strings, clear an array of strings-&gt; camelCasers","url":"/slides/utilities_unleashed"}]